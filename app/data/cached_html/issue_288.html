<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>OpenAI Does Deep Research, Google Goes to War, Alibaba Answers DeepSeek, Web Agents Do Tree Search  </title><meta name="description" content="The Batch AI News and Insights: At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance said, “I’m not here..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-288/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="OpenAI Does Deep Research, Google Goes to War, Alibaba Answers DeepSeek, Web Agents Do Tree Search  " data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch AI News and Insights: At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance said, “I’m not here..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="OpenAI Does Deep Research, Google Goes to War, Alibaba Answers DeepSeek, Web Agents Do Tree Search  " data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-288/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2025-02-12T11:46:34.000-08:00"/><meta property="article:modified_time" content="2025-02-13T13:40:46.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="Feb 12, 2025"/><meta property="article:tag" content="issue-288"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="OpenAI Does Deep Research, Google Goes to War, Alibaba Answers DeepSeek, Web Agents Do Tree Search  " data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch AI News and Insights: At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance said, “I’m not here..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-288/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1-.jpg"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1-.jpg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="676"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2025-02-12T11:46:34.000-08:00","dateModified":"2025-02-13T13:40:46.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"OpenAI Does Deep Research, Google Goes to War, Alibaba Answers DeepSeek, Web Agents Do Tree Search  ","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1-.jpg","width":1200,"height":676},"publisher":{"@type":"Organization","name":"OpenAI Does Deep Research, Google Goes to War, Alibaba Answers DeepSeek, Web Agents Do Tree Search  ","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch AI News and Insights: At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance said, “I’m not here..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-288/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 288</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Feb 12, 2025</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">13<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/feb-12-2025/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Feb 12, 2025</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">13<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-288/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-288/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-288/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc">
<!--kg-card-begin: html-->
<div id="elevenlabs-audionative-widget" data-height="90" data-width="100%" data-frameborder="no" data-scrolling="no" data-publicuserid="e20b5cfed36900db239c005920538f20ce435963e95a0a4106d34bdd6bf0e46d" data-playerurl="https://elevenlabs.io/player/index.html" >Loading the <a href="https://elevenlabs.io/text-to-speech?ref=dl-staging-website.ghost.io" target="_blank" rel="noopener">Elevenlabs Text to Speech</a> AudioNative Player...</div><script src="https://elevenlabs.io/player/audioNativeHelper.js" type="text/javascript"></script>
<!--kg-card-end: html-->
<p>Dear friends,</p><p>At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance&nbsp;<a href="https://x.com/gregory_c_allen/status/1889300802956591187?s=61&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_MW3ZsUxv6LnR3aWKk39uK3CDNTbIgQI7K_wwBMtikGPI3agA7fgg5SSi5o1C5_C50Axhy" rel="noopener">said</a>, “I’m not here to talk about AI safety. ... I’m here to talk about AI opportunity.” I’m thrilled to see the U.S. government focus on opportunities in AI. Further, while it is important to use AI responsibly and try to stamp out harmful applications, I feel “AI safety” is not the right terminology for addressing this important problem. Language shapes thought, so using the right words is important. I’d rather talk about “responsible AI” than “AI safety.” Let me explain.</p><p>First, there are clearly harmful applications of AI, such as non-consensual deepfake porn (which creates sexually explicit images of real people without their consent), the use of AI in misinformation, potentially unsafe medical diagnoses, addictive applications, and so on. We definitely want to stamp these out! There are many ways to apply AI in harmful or irresponsible ways, and we should discourage and prevent such uses.</p><p>However, the concept of “AI safety” tries to make AI — as a technology — safe, rather than making safe applications of it. Consider the similar, obviously flawed notion of “laptop safety.” There are great ways to use a laptop and many irresponsible ways, but I don’t consider laptops to be intrinsically either safe or unsafe. It is the application, or usage, that determines if a laptop is safe. Similarly, AI, a general-purpose technology with numerous applications, is neither safe nor unsafe. How someone chooses to use it determines whether it is harmful or beneficial.</p><p>Now, safety isn’t always a function only of how something is used. An unsafe airplane is one that, even in the hands of an attentive and skilled pilot, has a large chance of mishap. So we definitely should strive to build safe airplanes (and make sure they are operated responsibly)! The risk factors are associated with the construction of the aircraft rather than merely its application. Similarly, we want safe automobiles, blenders, dialysis machines, food, buildings, power plants, and much more.</p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1--1.jpg" class="kg-image" alt="“Responsible AI” written on a wall, with “Safety” crossed out in blue paint." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1--1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1--1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1--1.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><p>“AI safety” presupposes that AI, the underlying technology, can be unsafe. I find it more useful to think about how applications of AI can be unsafe.</p><p>Further, the term “responsible AI” emphasizes that it is our responsibility to avoid building applications that are unsafe or harmful and to discourage people from using even beneficial products in harmful ways.</p><p>If we shift the terminology for AI risks from “AI safety” to “responsible AI,” we can have more thoughtful conversations about what to do and what not to do.</p><p>I believe the 2023 Bletchley AI Safety Summit slowed down European AI development — without making anyone safer — by wasting time considering science-fiction AI fears rather than focusing on opportunities. Last month, at Davos, business and policy leaders also had strong concerns about whether Europe can dig itself out of the current regulatory morass and focus on building with AI. I am hopeful that the Paris meeting, unlike the one at Bletchley, will result in acceleration rather than deceleration.</p><p>In a world where AI is becoming pervasive, if we can shift the conversation away from “AI safety” toward responsible [use of] AI, we will speed up AI’s benefits and do a better job of addressing actual problems. That will actually make people safer.</p><p>Keep building!</p><p>Andrew&nbsp;</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/attention-in-transformers-concepts-and-code-in-pytorch?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2025/02/The-Batch-ads-and-exclusive-banners--11-.png" class="kg-image" alt="Promo banner for &quot;Attention in Transformers: Concepts and Code in PyTorch&quot;" loading="lazy" width="1680" height="945" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2025/02/The-Batch-ads-and-exclusive-banners--11-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/02/The-Batch-ads-and-exclusive-banners--11-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2025/02/The-Batch-ads-and-exclusive-banners--11-.png 1600w, https://dl-staging-website.ghost.io/content/images/2025/02/The-Batch-ads-and-exclusive-banners--11-.png 1680w" sizes="(min-width: 720px) 720px"></a></figure><p>Understand and implement the attention mechanism, a key element in transformer-based LLMs, using PyTorch. In this course, StatQuest’s Josh Starmer explains the core ideas behind attention mechanisms, the algorithm itself, and a step-by-step breakdown of how to implement them in PyTorch.&nbsp;<a href="https://www.deeplearning.ai/short-courses/attention-in-transformers-concepts-and-code-in-pytorch?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll now</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2025/02/DEEPRESEARCH_600px_opt.gif" class="kg-image" alt="ChatGPT interface drafting a research report on retail trends, including AI, e-commerce, and inflation." loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2025/02/DEEPRESEARCH_600px_opt.gif 600w"></figure><h1 id="agents-go-deep">Agents Go Deep</h1><p>OpenAI introduced a state-of-the-art agent that produces research reports by scouring the web and reasoning over what it finds.</p><p><strong>What’s new:</strong>&nbsp;OpenAI’s&nbsp;<a href="https://openai.com/index/introducing-deep-research/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">deep research</a>&nbsp;responds to users’ requests by generating a detailed report based on hundreds of online sources. The system generates text output, with images and other media expected soon. Currently the agent is available only to subscribers to ChatGPT Pro, but the company plans to roll it out to users of ChatGPT Plus, Team, and Enterprise.</p><p><strong>How it works:</strong>&nbsp;Deep research is an agent that uses OpenAI’s o3 model, which is not yet publicly available. The model was trained via reinforcement learning to use a browser and Python tools, similar to the way o1 learned to reason from reinforcement learning. OpenAI has not yet released detailed information about how it built the system.</p><ul><li>The system responds best to detailed prompts that specify the desired output (such as the desired information, comparisons, and format), the team said in its&nbsp;<a href="https://www.youtube.com/watch?v=YkCDVn3_wiw&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">announcement video</a>&nbsp;(which features Mark Chen, Josh Tobin, Neel Ajjarapu, and Isa Fulford, co-instructor of our short courses “<a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">ChatGPT Prompt Engineering for Developers</a>” and “<a href="https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">Building Systems with the ChatGPT API</a>”).</li><li>Before answering, Deep research asks clarifying questions about the task.</li><li>In the process of answering, the system presents a sidebar that summarizes the model’s chain of thought, terms it searched, websites it visited, and so on.</li><li>The system can take as long as 30 minutes to provide output.</li></ul><p><strong>Result</strong>: On a&nbsp;<a href="https://lastexam.ai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">benchmark</a>&nbsp;of 3,000 multiple-choice and short-answer questions that cover subjects from ecology to rocket science, OpenAI deep research achieved 26.6 percent accuracy. In comparison, DeepSeek-R1 (without web browsing or other tool use) achieved 9.4 percent accuracy and o1 (also without tool use) achieved 9.1 percent accuracy. On&nbsp;<a href="https://openreview.net/forum?id=fibxvahvs3&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">GAIA</a>, questions that are designed to be difficult for large language models without access to additional tools, OpenAI deep research achieved 67.36 percent accuracy, exceeding the&nbsp;<a href="https://h2o.ai/platform/enterprise-h2ogpte/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48#AgenticAI" rel="noopener">previous state of the art</a>&nbsp;of 63.64 percent accuracy.</p><p><strong>Behind the news:</strong>&nbsp;OpenAI’s deep research follows a similar offering of the same name by Google in December. A number of open source teams have built research agents that work in similar ways. Notable releases include a&nbsp;<a href="https://huggingface.co/blog/open-deep-research?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">Hugging Face</a>&nbsp;project that attempted to replicate OpenAI’s work (not including training) in 24 hours (which achieved 55.15 percent accuracy on GAIA) and&nbsp;<a href="https://gptr.dev/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">gpt-researcher</a>, which implemented agentic web search in 2023, long before Google and OpenAI launched their agentic research systems.</p><p><strong>Why it matters:</strong>&nbsp;Reasoning models like o1 or o3 made a splash not just because they delivered superior results but also because of the impressive reasoning steps the model took to produce the results. Combining that ability with web search and tool use enables large language models to formulate better answers to difficult questions, including those whose answers aren’t in the training data or whose answers change over time.</p><p><strong>We’re thinking:</strong>&nbsp;Taking as much as 30 minutes of processing to render a response, OpenAI’s deep research clearly illustrates why we need&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-we-need-more-compute-for-inference/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">more compute for inference</a>.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2025/02/GOOGLEWEAPONS4c.jpg" class="kg-image" alt="Illustration of the Google logo near a futuristic facility with fighter jets flying overhead." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2025/02/GOOGLEWEAPONS4c.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/02/GOOGLEWEAPONS4c.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2025/02/GOOGLEWEAPONS4c.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="google-joins-ai-peers-in-military-work">Google Joins AI Peers In Military Work</h1><p>Google revised its AI principles, reversing previous commitments to avoid work on weapons, surveillance, and other military applications beyond non-lethal uses like communications, logistics, and medicine.</p><p><strong>What’s new:</strong>&nbsp;Along with releasing its latest&nbsp;<a href="https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">Responsible AI Progress Report</a>&nbsp;and an updated AI&nbsp;<a href="https://deepmind.google/discover/blog/updating-the-frontier-safety-framework?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">safety framework</a>, Google removed key restrictions from its&nbsp;<a href="https://blog.google/technology/ai/responsible-ai-2024-report-ongoing-work/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">AI principles</a>. The new version omits a section in the previous document titled “Applications we will not pursue.” The deleted text&nbsp;<a href="https://web.archive.org/web/20250113105955/https://ai.google/responsibility/principles/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">pledged</a>&nbsp;to avoid “technologies that cause or are likely to cause overall harm” and, where the technology risks doing harm, to “proceed only where we believe that the benefits substantially outweigh the risks” with “appropriate safety constraints.”</p><p><strong>How it works:</strong>&nbsp;Google’s AI principles no longer prohibit specific applications but promote developing the technology to improve scientific inquiry, national security, and the economy.</p><ul><li>The revised principles state that AI development should be led by democracies. The company argues that such leadership is needed given growing global competition in AI from countries that are not widely considered liberal democracies.</li><li>The new principles stress “responsible development and deployment” to manage AI’s complexities and risks. They state that AI must be developed with safeguards at every stage, from design and testing to deployment and iteration, and those safeguards must adapt as technology and applications evolve.</li><li>The revised principles also emphasize collaborative progress, stating that Google aims to learn from others and build AI that’s broadly useful across industries and society.</li><li>Google emphasizes the need for “bold innovation,” stating that AI should be developed to assist, empower, and inspire people; drive economic progress; enable scientific breakthroughs; and help address global challenges. Examples include&nbsp;<a href="https://www.deeplearning.ai/the-batch/deepminds-alphafold-3-enhances-3d-biomolecular-modeling/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">AlphaFold 3</a>, which figures out how biological molecules interact, a key factor in designing chemical processes that affect them.</li><li>The revised principles are buttressed by the 2025 Responsible AI Progress Report. This document&nbsp;<a href="https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">outlines</a>&nbsp;the company’s efforts to evaluate risks through measures that align with the NIST AI Risk Management Framework including&nbsp;<a href="https://www.deeplearning.ai/the-batch/a-hacker-competition-to-break-guardrails-around-language-models/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">red teaming</a>, automated assessments, and input from independent experts.</li></ul><p><strong>Behind the news:&nbsp;</strong>Google’s new stance reverses a commitment it made in 2018 after employees&nbsp;<a href="https://www.nytimes.com/2018/04/04/technology/google-letter-ceo-pentagon-project.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">protested</a>&nbsp;its involvement in&nbsp;<a href="https://www.deeplearning.ai/the-batch/maven-a-system-that-analyzes-satellite-data-to-identify-targets-in-real-world-conflicts/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">Project Maven</a>, a Pentagon AI program for drone surveillance, from which Google ultimately withdrew. At the time, Google pledged not to develop AI applications for weapons or surveillance, which set it apart from Amazon and Microsoft. Since then, the company has expanded its work in defense,&nbsp;<a href="https://www.washingtonpost.com/technology/2025/01/21/google-ai-israel-war-hamas-attack-gaza/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">building on</a>&nbsp;a $1.3 billion contract with Israel. In 2024,&nbsp;<a href="https://www.washingtonpost.com/technology/2024/11/08/anthropic-meta-pentagon-military-openai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">Anthropic, Meta</a>, and&nbsp;<a href="https://www.wired.com/story/openai-anduril-defense/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">OpenAI</a>&nbsp;removed their restrictions on military and defense applications, and Anthropic and OpenAI&nbsp;<a href="https://www.washingtonpost.com/technology/2025/02/04/google-ai-policies-weapons-harm/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">strengthened</a>&nbsp;their ties with defense contractors such as Anduril and Palantir.</p><p><strong>Why it matters:</strong>&nbsp;Google’s shift in policy comes as AI is playing an increasing role in conflicts in Israel,&nbsp;<a href="https://www.deeplearning.ai/the-batch/does-ai-have-a-role-in-warfare/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">Ukraine</a>, and elsewhere, and while global geopolitical tensions are on the rise. While Google’s previous position kept it out of military AI development, defense contractors like Anduril, Northrop Grumman, and Palantir — not to mention AI-giant peers — stepped in. The new principles recognize the need for democratic countries to take the lead in developing technology and standards for its use as well as the massive business opportunity in military AI as governments worldwide seek new defense capabilities. Still, no widely accepted&nbsp;<a href="https://www.deeplearning.ai/the-batch/global-coalition-endorses-blueprint-for-ais-military-use/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48" rel="noopener">global framework</a>&nbsp;governs uses of AI in combat.</p><p><strong>We’re thinking:</strong>&nbsp;Knowing how and when to employ AI in warfare is one of the most difficult ethical questions of our time. Democratic nations have a right to defend themselves, and those of us who live in democracies have a responsibility to support fellow citizens who would put themselves in harm’s way to protect us. AI is transforming military strategy, and refusing to engage with it doesn’t make the risks go away.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2025/02/unnamed--47-.gif" class="kg-image" alt="AI model leaderboard comparing performance across tasks like math, vision, and document analysis." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2025/02/unnamed--47-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/02/unnamed--47-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2025/02/unnamed--47-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="alibaba%E2%80%99s-answer-to-deepseek">Alibaba’s Answer to DeepSeek</h1><p>While Hangzhou’s DeepSeek flexed its muscles, Chinese tech giant Alibaba vied for the spotlight with new open vision-language models.</p><p><strong>What’s new:</strong>&nbsp;Alibaba announced&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3lKN82ZQz0ZgdKpW8D3vqj1KdvzcW4gb52r78KX8BW51V9Ww6Y71m_VPLM_c7n1VFRW3P7zfJ6h7FqXMgWrp9bpt-GW6xhH5Z4dWBrGW2MKkjw8jqtyPVTkWw_1VdSDPW8Zw-9l5p3NmcW8k_hLy3y_qbNW72z7XH5dBVk0Vmxg4G8n-d80W61yrvJ5GpDNQW8DVNVg71JtbsW8MBkt32v28WWVmZ_Tv7jlzg-VnsLnv5rxSBMW5dWJ_54tqwSWW5h2YCs800ZMcW1638BQ7jm8YJW8sYbch5wS3KDW8JcCt48ChdDCf3cpJC404?ref=dl-staging-website.ghost.io" rel="noopener">Qwen2.5-VL</a>, a family of vision-language models (images and text in, text out) in sizes of 3 billion, 7 billion, and 72 billion parameters. The weights for all three models are available for download on&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3TT3qgyTW8wLKSR6lZ3kVW7VpmT46TpbchVl8-nn1_SjztW5mt2WB1kTdB4W2m8xbH2qhMRmW8HZwrM1hQRX7W30yp_F6J5HqzW4yTsrb6hjQbXW1kyrY-8qpBSHW4x0Jkv6pr5jNW5vWT4S3tyDypW90Xmh68rBMD2W18cqZh2h2DvhW4lpfmP4wjTT9VNL1TQ4QSknXW16sRVx5hCQFyN9kf1LVb7mc6W7tylrY51vNKjW5Q0QPB35QG_MW4M0WXC4qtGbCW9m2rWt5Kc35lW9kxT081dB9QrW40Xqdd500YnFW5j9ZJ16l_wPlW4BnwQq4xPZBRW5q8YhW8V585nW7QYzqT53RW5-W3JyXqN1_Ys-RW2FwvGc3Nb1dDdg2W0W04?ref=dl-staging-website.ghost.io" rel="noopener">Hugging Face</a>, each under a different license:&nbsp;Qwen2.5-VL-3B is&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tz3qgyTW7Y8-PT6lZ3m4N4B9J4Gq0WQzW1T3bqY5cZTxzW3Pz-Ls53V4HVW1HxqsR9l09xcW3swHjD5VB5bZW6ZtcZS25nG3kW65J_mt3Dx6RSW1D2BMK8YRL-dW2fytzv5lYy3vW37XXcp4zrYWjW71zTjV6Jb3lCW4DB8Zp1m6nFqW99kN0q91q20FW1rWFlV94DYWgW2rPhkK6-MPtWN66g4lfCldqlW8TzzN37Y8KYxN2V94WJPgmy0W1PNkXn1SpGdfN34dh55tB0K7V8Gsfx7qB8dpW1R86bj650-4sW5nH__754MWNvW1VSyqJ9gHKJlW5yTdQc6XgXYfVF1grr3TKSYwf6d_x5b04?ref=dl-staging-website.ghost.io" rel="noopener">free for non-commercial uses</a>, Qwen2.5-VL-7B is&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3V83qgyTW95jsWP6lZ3lkW4Zrs46216J4vW6s0Cf15pZ1rBN79PtWsCB5gxN73MRZSbClnLW6fW98F7QWHT8W8mWbfJ3T_Wk6W3DRW2r7FKFTgN63W2NkyV_SjN3tNCkZqNMCkW3YGWfn14mGCmW9g9fsj92P4WPW2tVk4w7fRLXCW2VGXR57jXyD8W2nRcNJ8zfTnLW462R245PdM5GW6zzHTv757vFPW552JvD4jxCk-W6FYgg44J2xl0W5bThdT63yqkqVDkw_5841PMzVyQp3f3DxDH_W1VVVLv8SBmdxW59kXzl7PFC8BW3VL3mT51LwW8VVzYJg5MssTrW5g40GW7hB5_3W3B9j9J4yvRsWW98Bv0D21xWWgW3wNQhL8sQVS2W3BDB8x1GjBBff7hvgMs04?ref=dl-staging-website.ghost.io" rel="noopener">free for commercial and noncommercial uses</a>&nbsp;under the Apache 2.0 license, and Qwen2.5-VL-72B is&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tz3qgyTW7Y8-PT6lZ3lQW7VP3VM2h_qVCW5XLQyq31vM0ZW32bCQJ6yZmyDW94CZjT7kLtGTW8DkK693HXRKhW5T35Rs5555rtMMhHtH13-42W2CW0Cq555QSHW8nFSw67FzzmyW31_dLX3gZ5CZW8BBrL3641QxcW5TzDVt8nwmljW1nvsQ5339gd8V-vpj86cBv6lW8-Vgbb3DsD-fW93Kr0z6KG_FrW3Lz5qq80TsSHVGjV501pWTZTW8DqMzQ7SH1SJW8hcNY48RthvrW70KFvs1tJZ-dW8znMw82mrDwKW2H-c7Y4r67RvF89McCsq3t0W4zyN9y3yhmt5W33mQ-w1Fsr9Sf7fllNY04?ref=dl-staging-website.ghost.io" rel="noopener">free to developers that have less than 100 million monthly active users</a>.&nbsp;You can try them out for free for a limited time in&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tz3qgyTW7Y8-PT6lZ3nGW5GGkcb6FGgSqW6MK_D_3DnXLBW5thRTd7RT-LLW8Y9m_m992pcBW7DVsnv1rXRLMW2jYpsb7rpXz1W4CJ_502zGPv8W1Z2cmb8HDcDLW3KXQ_081TsNzV3vpTr6D_n8vN7dCRZ0tWjpDW66QxSb2ht7YFW7THWw155vH5yW3Q1ZvR3kQt1KW1NbC_98CyFDHW3ysRJm1684q8W24VqMt6vmfWfW6S-bHX2BFHgpW3Wwv4_33rjwGW4JTZJC6rNybfW2pW9wm7JBzzwW5lPkmV35wFqWW3g4WQy76GSDGW1Q0Xnl2ggBMhV_zyk315vnN1W6jdRGq7rYPl0f94pNLP04?ref=dl-staging-website.ghost.io" rel="noopener">Alibaba Model Studio</a>, and Qwen2.5-VL-72B is available via the model selector in&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3mMW3Gxzd35qq0_rW3CGLyH9c2KCQW1ThFJP514ZwxW3kn8WD1NKHzlW7bZxQj5MW4rpW84cLLX16m-ZBW4nrs7L2b_WMYW76dW1g8JrC4sW5SnbCk32qn5SVfsRSb4pq73dW8lFG0y6hPXF-W2fQ3fN524PHWW2s0Xq63QTV88W6JwD_q5RmvvkW6PNf3r7Y77_hN3hz4ShnCF1xW7jCY6T5j3sGwW1fmTXc8Q_zCgW8Vvj3776SlBfVnCfVk3Jz0wtW1cM9Q53nrkKzVFNT2f6dRJqFf99vGVb04?ref=dl-staging-website.ghost.io" rel="noopener">Qwen Chat</a>.</p><p><strong>How it works:</strong>&nbsp;Qwen2.5-VL models accept up to 129,024 tokens of input according to the&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3V83qgyTW95jsWP6lZ3mrV4SK_237_8rHN91kQ3XsRQHrW1rQ3fK4vV3Z8N6t6x3wMRfJzW2qt5K54G7K9fW3jq3Tz6FdB0GW7NW81M37bWG5W8lMNVJ7Ll6cNW8Xyqwp3gz_7_W9g20sD8hq5c-W181D3W72Vv7RVxB_Dw45NCj0W9d75gH5dyfLPW990w452HWbNfW8_cmv51w3n_FW2d-cRw3MLMzDW1M_v6d6gHjwTW8xQBm94p_-fYW72GbPv26QSpyW5N8GXt8ylHMDVgjjSl2DmZMnN7GcjvJdfqX_N5x-4F3rwBY5W8ZSnl93TGqPsW4ZW7x75QVJmQW57FPJ37Hw1nzN59-J03K1qnNW5kncV27MWMQ3W2J2QQL6h64GRV-BSLb2t3LhCf5JC4QT04?ref=dl-staging-website.ghost.io" rel="noopener">developer reference</a>&nbsp;(other sources provide conflicting numbers) and generate up to 8,192 tokens of output. Alibaba has not released details about how it trained them.</p><ul><li>Qwen2.5-VL comprises a vision encoder and large language model. It can parse videos, images, text, and is capable of computer use (desktop and mobile).</li><li>The vision encoder accepts images of different sizes and represents them with different numbers of tokens depending on the size. For instance, one image might be 8 tokens and another 1125 tokens. This enabled the model to learn about the scale of images and to estimate the coordinates of objects in an image without rescaling.</li><li>To reduce computation incurred by the vision encoder, the team replaced attention (which considers the entire input context) with windowed attention (which limits the input context to a window around a given token) and used full attention only in four layers. The resulting efficiency improves training and inference speeds.</li></ul><p><strong>Results</strong>: Alibaba reports Qwen2.5-VL-72B’s performance on measures that span image and text problems, parsing documents, understanding videos, and interacting with computer programs. Across 21 benchmarks, it beat Microsoft Gemini 2.0 Flash, OpenAI GPT-4o, Anthropic Claude 3.5 Sonnet, and open competitors on 13 of them (where comparisons are&nbsp; relevant and available).</p><ul><li>For example, on answering math questions about images in&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3mDN621lXZTSKj1VtpVpG7jRkMNW4XF6Tx3DjWbjW4G7Fbp1NlzFsTHJ8R3qxjW8W8wZh1q6mNXpdW6WJDlS1__PW1W9jnxHS5Njw-4W79JDj84Gy-F7W3r8DDt7Lgdz7W8qPxCL1lgbYQVGqn8W2lzQn-W70ZSmd9hCk-LW3kb07R1nhDVBN6dKKfl1S6MzW2Bp_Ks68nMkzW62_XkK7Jzd2vVzXwDS8Cw07MW2mZCLC7p-SQZW1KvQHl8Rr3y0V5vsCh434Y9CVQP12N8Fh9r-f7tp_0H04?ref=dl-staging-website.ghost.io" rel="noopener">MathVista</a>, Qwen2.5-VL-72B achieved 74.8 percent, while the closest competing model (Gemini 2.0 Flash) achieved 73.1 percent.</li><li>In&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3lPW6VV7Ty6k5KVYVgBNwj97BncMW4Z69Gn7C7KjCN8Y5DjV4jkR0W7wstfZ8k7f8BW4W0HkS4R9GcLW5-pvmR2wRPy9VMQs5k2C3NgkW8bnzC16tFZLFW5yLsw28wRH50W8YWygL7TlMwYW84_xfJ8s4hBBW7pbqY52f05Q3N1v55-NjrL-SV_FTPZ1m7FDsW1dkkcg77QsdPN7vxrjQ5WvyVW8Cf31t7czfbRW7PtpGx5Y4l6YW1nnz3-5btlMWW6mHkPh14VRS_W30G7DS2vQhN9W2tgsGR7TdWQSW3zjby36bD86zf8fQbL604?ref=dl-staging-website.ghost.io" rel="noopener">Video-MME</a>, which evaluates a model’s ability to answer questions about videos, Qwen 2.5 VL achieved 73.3 percent. GPT-4o achieved 71.9 percent and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3nSW6wQnH45_Y08JW5XWGZx8jg8gdV6QS5217WmgRW7G3Scs4tPtxSW71hvJX7_vhvXW1jmfdT5J5-5DW3y7qfm1SP7GgN5jwvg2MxM0lW9ls7Ll5JyZvbW5tyMX26XjnWgW95tFz38HpH79W81f7m52NGVDBVv29KL2bH6XpW3Klkys452n3KW190qL-2pDl5yW1c6QmC9cKF3wW3g4V4p1fKgg5W94RD2X5plzZ_W82c-Lf6qNKNCW4Zv1XJ6r71yJW3Hq_rP5NbwC9W5h9Clv7k8L0Mf4kVknR04?ref=dl-staging-website.ghost.io" rel="noopener">InternVL2.5</a>, the next-best open competitor, achieved 72.1 percent.</li><li>Used in an agentic workflow, Qwen2.5-VL-72B outperformed Claude 3.5 Sonnet when controlling Android devices and navigating desktop user interfaces. However, it finished second to other open vision-language models in several tests.</li></ul><p><strong>More models:</strong>&nbsp;Alibaba also introduced competition for DeepSeek and a family of small models.</p><ul><li><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3m2W8HwsBK3MPwH6W4ckYcJ2yMrf_W8WhMjK6QLQkCW3_t1X45wCLKWN3zhmNZLThqHW5wvn328RzxDrW2H8HTM1MpcmQW7cdpQj3t393RW2WSxJp7c5gdNVkLcYb3wPhLsW7nrj9h4s25DxW4Rs7GH18n0lJW3dh-6R8DsVb5W5f6SK17lTDhmW8XsdLr5NjdBVW21L8Sj67d36HW6GyJzr1wbWSFW8rVwPg2xD7LhW1MdCPp1W5y2QW8Z40yg36bCsFW1hcwND54ys6_W3p2Ktp51hFjtW6v8T0Z1DrcFcN69TtmnknHDccjg4W04?ref=dl-staging-website.ghost.io" rel="noopener">Qwen2.5-Max</a>&nbsp;is a mixture-of-experts model that outperforms GPT-4o and DeepSeek-V3 on graduate-level science questions in&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3nwW35xPn86q9Xy8VK3tgZ6kgZ0bW4qVX-H2hhjPdW8JY91s2G_vLnW74-3Ry1_P36GW1K6Xb-8fznq2W8h3dPK7LRgPvW4-q-r871wYc3W9jCDDh5ZrSqfN4MW5jb-H-PrW5-Q8v37MRz36W1Vw2-q1xzKmZW1NRczT1rV2pGW7TjWzz7LWl-yW50dpJ033KMq-W7RrK_z8y0r9qN3k3bJ6x16GlVsnDY04B9srqW3rvQzV8NMdwrV-m9g22MXDt1W1Cyjpw7ntbjRW9dMQQ98t8zmbf1JqWMj04?ref=dl-staging-website.ghost.io" rel="noopener">GPQA-Diamond</a>&nbsp;and regularly updated benchmarks like&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3mDW8Lj_0-4-vW8sVkLzvM6BLzbXW27VSv78bFpdxW9kQGpy2YMFYTW9gmt_242mk_PW3x3V045hWxs1W28pf-56sRRNvVMCwdV28ckWnW920-w71MWXZcW2tvDJS56Cxk5W1nPRqp9j3M64W4SvZhs98yQn-W1wCM-c4H-QCdW1XwwzJ1Y0Z37W1ZxDr726m6W1W60JS8210zdQ7W9kF_z05DZ2X-W6DTLRq7j0kjwW7w46pB8Rp7S2W3TP59b2Jnc4PW2lvZ1d3pg_HKW1MNfSP6frD1DW7zxX-94D5NNQW8WFQWT8Qz6LYf8z__p604?ref=dl-staging-website.ghost.io" rel="noopener">Arena-Hard</a>,&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tz3qgyTW7Y8-PT6lZ3mJW4kRtpR1K16y6W5TCNVv547MQtW4zCX_L2gCD0DW7gkj3449HnD8W1tSXKH9bM-PzW7K7zF75tP1Y_W46DC003gPpT4W2Y74nK86NMJVW1gQf9X4gBCMZW55LXRR4fsh_nW4LtWjG6C04scV6VJT49jK0R7W80D_pF4rmLzSV-MXDm6XJp-1W47_sB29lH5hYW84Sw8H5R-Fr9W1kqW-L8zlGVHN8G13N4C1bMLW8W70V28WZkGWVHwL9L6kpYh5W22-3Kv1DfFDpW6QGnWH6ZFYK2W7VtKB45V9D89W70KyBx7k9fJtN244dgzmhb0qW36_71F8DC2K7f2XRg2R04?ref=dl-staging-website.ghost.io" rel="noopener">LiveBench</a>, and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3mjN4HxGBJRfLsJW6GHsTT83h1HfVvNkGt1W6nN1W3WzhQ21PGGsCW8-sHKw3kBg45W6lk1vP4rmvq8W6xhyQ-4kv7hwW74t4Xn8DBTFYVD32C21wh-NfW1BGL882drhKXW7S7Vk71zwVcjW8wF-467WwprxW5rz6Bx45vdCxW3R2_q16DM7jDVpGhd62n3FgmN3RhpW6Gbmj2W3GjBLb3GkvFsW18-FbB1rtBC2W55f-v71WwS_XW89gsYw3gH18-W284nps5N0l2qVFXC6Y4NM9dPf8wcrWR04?ref=dl-staging-website.ghost.io" rel="noopener">LiveCodeBench</a>. However, Qwen2.5-Max performed worse than o1 and DeepSeek-R1.</li><li><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3nqW83ZTHJ5tr4KxVPtMnK6Y4sy_W6TXMCn6ly60mN3VxrHSqKnBDVhznZ81Gxwl0W3ndP5p1Wg0D9W8YTDlS2lbw9wW1w4Ck46H7l_RW2FZCRZ1w2H2-N2GJpLD9D_Z5W86NbQB1tkvwmW6TcK8M8B0NzfW8hMbVz911LnCVF4Hfn324yV_W7fDMpB9fLpw7W90KgWM5957DqN4JMmch-3PnNN5ZKpMgVzgDDW3Nmmvk51Dl2VW332_Nm3B3FvkW2mzH8t2vpnZ0W7JzDmg7TSwF5Vl7q5_6yrWXnW5skNXy39z4Xjf7L601P04?ref=dl-staging-website.ghost.io" rel="noopener">Qwen2.5-1M</a>&nbsp;is a family of smaller language models (7 billion and 14 billion parameters) that accept up to 1 million tokens of input context.</li></ul><p><strong>Why it matters:</strong>&nbsp;Vision-language models are getting more powerful and versatile. Not long ago, it was an impressive feat simply to answer questions about a chart or diagram that mixed graphics with text. Now such models are paired with an agent to control computers and smartphones. Broadly speaking, the Qwen2.5-VL models outperform open and closed competitors and they’re open to varying degrees (though the data is not available), giving developers a range of highly capable choices.</p><p><strong>We</strong>’<strong>re thinking:</strong>&nbsp;We’re happy Alibaba released a vision-language model that is broadly permissive with respect to commercial use (although we’d prefer that all sizes were available under a standard open weights license). We hope to see technical reports that illuminate Alibaba’s training and fine-tuning recipes.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2025/02/unnamed--48-.gif" class="kg-image" alt="Diagram showing GPT-4o with and without search, highlighting task execution success and failure." loading="lazy" width="600" height="336" srcset="https://dl-staging-website.ghost.io/content/images/2025/02/unnamed--48-.gif 600w"></figure><h1 id="tree-search-for-web-agents">Tree Search for Web Agents</h1><p>Browsing the web to achieve a specific goal can be challenging for agents based on large language models and even for vision-language models that can process onscreen images of a browser. While some approaches address this difficulty in training the underlying model, the agent architecture can also make a difference.</p><p><strong>What’s new:</strong>&nbsp;Jing Yu Koh and colleagues at Carnegie Mellon University introduced&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3mGW33sV0K63TX_fW6qLlxx7YxG9GW2FB1bn5jDw4VW5Zntz52wD0_vW5ryxtN1-bDCHW3tdRFV4hh-5pW2JYklx2bCzyJVX-0JL1SK_jVW69ZyD56btDJNW6JG0lc1rWX30N2ncM2CN84C4W6jCTnC88-dhTW30LWj61pQ1ZsW71tJSy6wk-D-W9ffWpz60h4vvW8DDFKy2mkm-6W3HRsSD3dVXv7W6CrCXZ14bkgkW6D0nvF3q7FLsW2GhvKb6zdWk4W4knytQ3pNHWTW7KD0fl3LZCh3f5CRhb804?ref=dl-staging-website.ghost.io" rel="noopener">tree search for language model agents</a>, a method that allows agents to treat web interactions like tree searches. In this way, agents can explore possible chains of actions and avoid repeating mistakes.</p><p><strong>Key insight:</strong>&nbsp;Some web tasks, for instance finding a price of a particular item, require a chain of intermediate actions: navigating to the right page, scrolling to find the item, matching an image of the item to the image on the page, and so on. If an agent clicks the wrong link during this process, it might lose its way. The ability to evaluate possible actions and remember previous states of web pages can help an agent correct its mistakes and choose a chain of actions that achieves its goal.</p><p><strong>How it works:</strong>&nbsp;An agent based on GPT-4o attempted 200&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3SH3qgyTW69sMD-6lZ3mKW6RwhVb4vBRtSN8_2ZnjR6TmdW8qz456383tZ5V_RMkT5LPlY0W4JBgyz2HRjtbW7Pt5wG4MP4K5W1lrtC72FdT3ZW10FNBD14F6yjW6YRPry6PMW8LW7Gdm5v6d1NYlW1CHDvn1VrBMzW1psr2D4qCMMQW2tRBxS1Dsr99W920d1N40246wW2Xcjz95d2_pcW4VZSK14MRGK-N8DYPJVJqgkbW9hX2P36Gc1ZbW2mBV3f4qlw7sW33w3hs1mQcB6f2w-Ms004?ref=dl-staging-website.ghost.io" rel="noopener">tasks</a>&nbsp;using website mockups that mimicked an online retail store, Reddit-like forum, and directory of classified ads. The tasks included ordering an item to be delivered to a given address, finding specific images on the forum, and posting an ad. The authors annotated each web page using the method called&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3pmW2LQZyx1jDWLDW4GFzcw1FknClW1WK5YQ5sWPvSW1kbcT94rW0pCW5kL9sG16JHkvW8R-2w32btRF-N1MpZLFnpGYTW3W5xY95V7jH1W3ZSxC58hZJlYW5X2mPR2QrLlpW4qSlMM2smDK2W3GqzKh55pLPdW7Xrpp68rVFHqW5PHJZD2cB7l2N3QV0db7Bv_tW6VhGbD5N5Qp1W7WW4X74mzZ3KW6JLpC82_sLgrW3-lJ9z4GyyzcW2qt_Lm32-ql8W6qrY0d4nNtqcW6s70G68_nxHLf1Lf4nW04?ref=dl-staging-website.ghost.io" rel="noopener">Set of Mark</a>, which identifies every visual element capable of interaction with a bounding box and a numerical ID.</p><ul><li>The agent started with a web page and an instruction such as, “Tell me the number of reviews our store received that mention the term ‘not useful.’” It passed an image of the page to the LLM, which predicted five actions that could make progress toward completing the task such as scrolling up or down, hovering over an element, clicking, typing in a text field, or opening a new URL.</li><li>The agent executed the five actions. After each one, the LLM assessed the current state of the page using the previous states as context. The assessment assigned a value between 0 and 1 (meaning the task was complete). The agent kept a list of page states and their values.</li><li>The agent selected the web page state with the highest value after executing the five actions, and repeated the process, making a new set of five predictions based on the highest-value state.</li><li>This process is a search: The agent executed a chain of actions until the value of the new states dropped below the values of other states. If all new states had lower values, the agent backtracked to a previous state with a higher value and asked the LLM for five more actions. The search stopped when the agent had completed the task or explored 20 possible states.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared two agents, one that followed their search method and another that started at the same page and received the same instruction but took one action per state and never backtracked. The agents attempted 100 shopping tasks, 50 forum tasks, and 50 classified-ads tasks. The one equipped to search successfully completed 26.4 percent of the tasks, while the other agent completed 18.9 percent of the tasks.</p><p><strong>Why it matters:</strong>&nbsp;Search joins reflection, planning, tool use, and multi-agent collaboration as an emerging&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3TT3qgyTW8wLKSR6lZ3kxW7HPjWp1GZtG-W7tkb6K2wJWQ0N6WplKJ2nxZQW8mYTB43Z_4ZRW544L4h3z0Hl9W248hWN8vgtPtW48JV4D7JLN1RW2xDybW1x8swPW8xbfF17pZtDYW7bVmpP82CgLqW2QfV992WlCBhV54ddR5gx1zpW1kKrCg4lR3d6W61wNhM922dl0W42RlkZ3HNgQtN1X4485BrV67W26PMqz5qZr6bVB6nCx46NwcDW3v0NZs59wj73W7WMnkl5-Q1K-VwvDyL7MYXZtW7mqrKY8lvyppN4F4h5-bnRHDW7Hw46-61w9RwW1TrgP36RfmSJW28yddh1d6SFFW6SG9GT8mFgXPW6dHL1t31xKXLf1yl9H404?ref=dl-staging-website.ghost.io" rel="noopener">agentic design pattern</a>. Following many branching paths of actions enables an agent to determine the most effective set of actions to accomplish a task.</p><p><strong>We’re thinking:</strong>&nbsp;Agentic design patterns are progressing quickly! In combination with&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3V83qgyTW95jsWP6lZ3m4W1Kzxn_7ylBZDN4FBTglQ4NRbW6kYCY223MC-gW3g4Gp1861zgjVf41-h7y59qZW7TRF8d3K67GLW3mKSdz6bhvFDW8TZ3Cd9kGXHLW4n4NfN7dqxvkW3WwW443GFN-sVtvTtl4f2mbCW9ltVXf7VNgWhW3c4sz84cVhM3W1JB7257TS-Y9W3SYHBJ3bnB1jN7QqWchcSqRQW2KqtFD6ZrWZ7N4gqHJ0kkzWbW15KhRK6VC63NW3cm6RM4tNvGcW11CKrC26sD3QW7TQqmj1JZ2JmVfSjDV883kTDW1WZP6_4NsD_GW1LyQlM7n8m21W90XV2S2Ljn16W2jcrm91JZVYfW8kjq5T5y065KN7Hm8Flgh_c3W8mKTlS1FBYgTf4STLgW04?ref=dl-staging-website.ghost.io" rel="noopener">computer use</a>, this sort of search method may enable agents to execute a wide variety of desktop tasks.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/"><div class="absolute inset-0" data-gtm-event-title="ChatGPT Prompt Engineering for Developers"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-288/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-288/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-288/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm17" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-288","id":"67acf685de17ec0001710eb7","uuid":"8c9ba756-d566-440b-b44c-50ce9a262883","title":"OpenAI Does Deep Research, Google Goes to War, Alibaba Answers DeepSeek, Web Agents Do Tree Search","html":"\n\u003c!--kg-card-begin: html--\u003e\n\u003cdiv id=\"elevenlabs-audionative-widget\" data-height=\"90\" data-width=\"100%\" data-frameborder=\"no\" data-scrolling=\"no\" data-publicuserid=\"e20b5cfed36900db239c005920538f20ce435963e95a0a4106d34bdd6bf0e46d\" data-playerurl=\"https://elevenlabs.io/player/index.html\" \u003eLoading the \u003ca href=\"https://elevenlabs.io/text-to-speech?ref=dl-staging-website.ghost.io\" target=\"_blank\" rel=\"noopener\"\u003eElevenlabs Text to Speech\u003c/a\u003e AudioNative Player...\u003c/div\u003e\u003cscript src=\"https://elevenlabs.io/player/audioNativeHelper.js\" type=\"text/javascript\"\u003e\u003c/script\u003e\n\u003c!--kg-card-end: html--\u003e\n\u003cp\u003eDear friends,\u003c/p\u003e\u003cp\u003eAt the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance\u0026nbsp;\u003ca href=\"https://x.com/gregory_c_allen/status/1889300802956591187?s=61\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_MW3ZsUxv6LnR3aWKk39uK3CDNTbIgQI7K_wwBMtikGPI3agA7fgg5SSi5o1C5_C50Axhy\" rel=\"noopener\"\u003esaid\u003c/a\u003e, “I’m not here to talk about AI safety. ... I’m here to talk about AI opportunity.” I’m thrilled to see the U.S. government focus on opportunities in AI. Further, while it is important to use AI responsibly and try to stamp out harmful applications, I feel “AI safety” is not the right terminology for addressing this important problem. Language shapes thought, so using the right words is important. I’d rather talk about “responsible AI” than “AI safety.” Let me explain.\u003c/p\u003e\u003cp\u003eFirst, there are clearly harmful applications of AI, such as non-consensual deepfake porn (which creates sexually explicit images of real people without their consent), the use of AI in misinformation, potentially unsafe medical diagnoses, addictive applications, and so on. We definitely want to stamp these out! There are many ways to apply AI in harmful or irresponsible ways, and we should discourage and prevent such uses.\u003c/p\u003e\u003cp\u003eHowever, the concept of “AI safety” tries to make AI — as a technology — safe, rather than making safe applications of it. Consider the similar, obviously flawed notion of “laptop safety.” There are great ways to use a laptop and many irresponsible ways, but I don’t consider laptops to be intrinsically either safe or unsafe. It is the application, or usage, that determines if a laptop is safe. Similarly, AI, a general-purpose technology with numerous applications, is neither safe nor unsafe. How someone chooses to use it determines whether it is harmful or beneficial.\u003c/p\u003e\u003cp\u003eNow, safety isn’t always a function only of how something is used. An unsafe airplane is one that, even in the hands of an attentive and skilled pilot, has a large chance of mishap. So we definitely should strive to build safe airplanes (and make sure they are operated responsibly)! The risk factors are associated with the construction of the aircraft rather than merely its application. Similarly, we want safe automobiles, blenders, dialysis machines, food, buildings, power plants, and much more.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1--1.jpg\" class=\"kg-image\" alt=\"“Responsible AI” written on a wall, with “Safety” crossed out in blue paint.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1--1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1--1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1--1.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e“AI safety” presupposes that AI, the underlying technology, can be unsafe. I find it more useful to think about how applications of AI can be unsafe.\u003c/p\u003e\u003cp\u003eFurther, the term “responsible AI” emphasizes that it is our responsibility to avoid building applications that are unsafe or harmful and to discourage people from using even beneficial products in harmful ways.\u003c/p\u003e\u003cp\u003eIf we shift the terminology for AI risks from “AI safety” to “responsible AI,” we can have more thoughtful conversations about what to do and what not to do.\u003c/p\u003e\u003cp\u003eI believe the 2023 Bletchley AI Safety Summit slowed down European AI development — without making anyone safer — by wasting time considering science-fiction AI fears rather than focusing on opportunities. Last month, at Davos, business and policy leaders also had strong concerns about whether Europe can dig itself out of the current regulatory morass and focus on building with AI. I am hopeful that the Paris meeting, unlike the one at Bletchley, will result in acceleration rather than deceleration.\u003c/p\u003e\u003cp\u003eIn a world where AI is becoming pervasive, if we can shift the conversation away from “AI safety” toward responsible [use of] AI, we will speed up AI’s benefits and do a better job of addressing actual problems. That will actually make people safer.\u003c/p\u003e\u003cp\u003eKeep building!\u003c/p\u003e\u003cp\u003eAndrew\u0026nbsp;\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/attention-in-transformers-concepts-and-code-in-pytorch?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2025/02/The-Batch-ads-and-exclusive-banners--11-.png\" class=\"kg-image\" alt=\"Promo banner for \u0026quot;Attention in Transformers: Concepts and Code in PyTorch\u0026quot;\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/02/The-Batch-ads-and-exclusive-banners--11-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/02/The-Batch-ads-and-exclusive-banners--11-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2025/02/The-Batch-ads-and-exclusive-banners--11-.png 1600w, https://dl-staging-website.ghost.io/content/images/2025/02/The-Batch-ads-and-exclusive-banners--11-.png 1680w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eUnderstand and implement the attention mechanism, a key element in transformer-based LLMs, using PyTorch. In this course, StatQuest’s Josh Starmer explains the core ideas behind attention mechanisms, the algorithm itself, and a step-by-step breakdown of how to implement them in PyTorch.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/attention-in-transformers-concepts-and-code-in-pytorch?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eEnroll now\u003c/a\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2025/02/DEEPRESEARCH_600px_opt.gif\" class=\"kg-image\" alt=\"ChatGPT interface drafting a research report on retail trends, including AI, e-commerce, and inflation.\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2025/02/DEEPRESEARCH_600px_opt.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"agents-go-deep\"\u003eAgents Go Deep\u003c/h1\u003e\u003cp\u003eOpenAI introduced a state-of-the-art agent that produces research reports by scouring the web and reasoning over what it finds.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;OpenAI’s\u0026nbsp;\u003ca href=\"https://openai.com/index/introducing-deep-research/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003edeep research\u003c/a\u003e\u0026nbsp;responds to users’ requests by generating a detailed report based on hundreds of online sources. The system generates text output, with images and other media expected soon. Currently the agent is available only to subscribers to ChatGPT Pro, but the company plans to roll it out to users of ChatGPT Plus, Team, and Enterprise.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Deep research is an agent that uses OpenAI’s o3 model, which is not yet publicly available. The model was trained via reinforcement learning to use a browser and Python tools, similar to the way o1 learned to reason from reinforcement learning. OpenAI has not yet released detailed information about how it built the system.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe system responds best to detailed prompts that specify the desired output (such as the desired information, comparisons, and format), the team said in its\u0026nbsp;\u003ca href=\"https://www.youtube.com/watch?v=YkCDVn3_wiw\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eannouncement video\u003c/a\u003e\u0026nbsp;(which features Mark Chen, Josh Tobin, Neel Ajjarapu, and Isa Fulford, co-instructor of our short courses “\u003ca href=\"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eChatGPT Prompt Engineering for Developers\u003c/a\u003e” and “\u003ca href=\"https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eBuilding Systems with the ChatGPT API\u003c/a\u003e”).\u003c/li\u003e\u003cli\u003eBefore answering, Deep research asks clarifying questions about the task.\u003c/li\u003e\u003cli\u003eIn the process of answering, the system presents a sidebar that summarizes the model’s chain of thought, terms it searched, websites it visited, and so on.\u003c/li\u003e\u003cli\u003eThe system can take as long as 30 minutes to provide output.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResult\u003c/strong\u003e: On a\u0026nbsp;\u003ca href=\"https://lastexam.ai/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003ebenchmark\u003c/a\u003e\u0026nbsp;of 3,000 multiple-choice and short-answer questions that cover subjects from ecology to rocket science, OpenAI deep research achieved 26.6 percent accuracy. In comparison, DeepSeek-R1 (without web browsing or other tool use) achieved 9.4 percent accuracy and o1 (also without tool use) achieved 9.1 percent accuracy. On\u0026nbsp;\u003ca href=\"https://openreview.net/forum?id=fibxvahvs3\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eGAIA\u003c/a\u003e, questions that are designed to be difficult for large language models without access to additional tools, OpenAI deep research achieved 67.36 percent accuracy, exceeding the\u0026nbsp;\u003ca href=\"https://h2o.ai/platform/enterprise-h2ogpte/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48#AgenticAI\" rel=\"noopener\"\u003eprevious state of the art\u003c/a\u003e\u0026nbsp;of 63.64 percent accuracy.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;OpenAI’s deep research follows a similar offering of the same name by Google in December. A number of open source teams have built research agents that work in similar ways. Notable releases include a\u0026nbsp;\u003ca href=\"https://huggingface.co/blog/open-deep-research?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eHugging Face\u003c/a\u003e\u0026nbsp;project that attempted to replicate OpenAI’s work (not including training) in 24 hours (which achieved 55.15 percent accuracy on GAIA) and\u0026nbsp;\u003ca href=\"https://gptr.dev/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003egpt-researcher\u003c/a\u003e, which implemented agentic web search in 2023, long before Google and OpenAI launched their agentic research systems.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Reasoning models like o1 or o3 made a splash not just because they delivered superior results but also because of the impressive reasoning steps the model took to produce the results. Combining that ability with web search and tool use enables large language models to formulate better answers to difficult questions, including those whose answers aren’t in the training data or whose answers change over time.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Taking as much as 30 minutes of processing to render a response, OpenAI’s deep research clearly illustrates why we need\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/why-we-need-more-compute-for-inference/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003emore compute for inference\u003c/a\u003e.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2025/02/GOOGLEWEAPONS4c.jpg\" class=\"kg-image\" alt=\"Illustration of the Google logo near a futuristic facility with fighter jets flying overhead.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/02/GOOGLEWEAPONS4c.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/02/GOOGLEWEAPONS4c.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2025/02/GOOGLEWEAPONS4c.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"google-joins-ai-peers-in-military-work\"\u003eGoogle Joins AI Peers In Military Work\u003c/h1\u003e\u003cp\u003eGoogle revised its AI principles, reversing previous commitments to avoid work on weapons, surveillance, and other military applications beyond non-lethal uses like communications, logistics, and medicine.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Along with releasing its latest\u0026nbsp;\u003ca href=\"https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eResponsible AI Progress Report\u003c/a\u003e\u0026nbsp;and an updated AI\u0026nbsp;\u003ca href=\"https://deepmind.google/discover/blog/updating-the-frontier-safety-framework?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003esafety framework\u003c/a\u003e, Google removed key restrictions from its\u0026nbsp;\u003ca href=\"https://blog.google/technology/ai/responsible-ai-2024-report-ongoing-work/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eAI principles\u003c/a\u003e. The new version omits a section in the previous document titled “Applications we will not pursue.” The deleted text\u0026nbsp;\u003ca href=\"https://web.archive.org/web/20250113105955/https://ai.google/responsibility/principles/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003epledged\u003c/a\u003e\u0026nbsp;to avoid “technologies that cause or are likely to cause overall harm” and, where the technology risks doing harm, to “proceed only where we believe that the benefits substantially outweigh the risks” with “appropriate safety constraints.”\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Google’s AI principles no longer prohibit specific applications but promote developing the technology to improve scientific inquiry, national security, and the economy.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe revised principles state that AI development should be led by democracies. The company argues that such leadership is needed given growing global competition in AI from countries that are not widely considered liberal democracies.\u003c/li\u003e\u003cli\u003eThe new principles stress “responsible development and deployment” to manage AI’s complexities and risks. They state that AI must be developed with safeguards at every stage, from design and testing to deployment and iteration, and those safeguards must adapt as technology and applications evolve.\u003c/li\u003e\u003cli\u003eThe revised principles also emphasize collaborative progress, stating that Google aims to learn from others and build AI that’s broadly useful across industries and society.\u003c/li\u003e\u003cli\u003eGoogle emphasizes the need for “bold innovation,” stating that AI should be developed to assist, empower, and inspire people; drive economic progress; enable scientific breakthroughs; and help address global challenges. Examples include\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/deepminds-alphafold-3-enhances-3d-biomolecular-modeling/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eAlphaFold 3\u003c/a\u003e, which figures out how biological molecules interact, a key factor in designing chemical processes that affect them.\u003c/li\u003e\u003cli\u003eThe revised principles are buttressed by the 2025 Responsible AI Progress Report. This document\u0026nbsp;\u003ca href=\"https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eoutlines\u003c/a\u003e\u0026nbsp;the company’s efforts to evaluate risks through measures that align with the NIST AI Risk Management Framework including\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/a-hacker-competition-to-break-guardrails-around-language-models/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003ered teaming\u003c/a\u003e, automated assessments, and input from independent experts.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u0026nbsp;\u003c/strong\u003eGoogle’s new stance reverses a commitment it made in 2018 after employees\u0026nbsp;\u003ca href=\"https://www.nytimes.com/2018/04/04/technology/google-letter-ceo-pentagon-project.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eprotested\u003c/a\u003e\u0026nbsp;its involvement in\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/maven-a-system-that-analyzes-satellite-data-to-identify-targets-in-real-world-conflicts/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eProject Maven\u003c/a\u003e, a Pentagon AI program for drone surveillance, from which Google ultimately withdrew. At the time, Google pledged not to develop AI applications for weapons or surveillance, which set it apart from Amazon and Microsoft. Since then, the company has expanded its work in defense,\u0026nbsp;\u003ca href=\"https://www.washingtonpost.com/technology/2025/01/21/google-ai-israel-war-hamas-attack-gaza/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003ebuilding on\u003c/a\u003e\u0026nbsp;a $1.3 billion contract with Israel. In 2024,\u0026nbsp;\u003ca href=\"https://www.washingtonpost.com/technology/2024/11/08/anthropic-meta-pentagon-military-openai/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eAnthropic, Meta\u003c/a\u003e, and\u0026nbsp;\u003ca href=\"https://www.wired.com/story/openai-anduril-defense/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eOpenAI\u003c/a\u003e\u0026nbsp;removed their restrictions on military and defense applications, and Anthropic and OpenAI\u0026nbsp;\u003ca href=\"https://www.washingtonpost.com/technology/2025/02/04/google-ai-policies-weapons-harm/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003estrengthened\u003c/a\u003e\u0026nbsp;their ties with defense contractors such as Anduril and Palantir.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Google’s shift in policy comes as AI is playing an increasing role in conflicts in Israel,\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/does-ai-have-a-role-in-warfare/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eUkraine\u003c/a\u003e, and elsewhere, and while global geopolitical tensions are on the rise. While Google’s previous position kept it out of military AI development, defense contractors like Anduril, Northrop Grumman, and Palantir — not to mention AI-giant peers — stepped in. The new principles recognize the need for democratic countries to take the lead in developing technology and standards for its use as well as the massive business opportunity in military AI as governments worldwide seek new defense capabilities. Still, no widely accepted\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/global-coalition-endorses-blueprint-for-ais-military-use/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_mUbOQRVJ8cbLJtwxJu6RgzxZvQDI2NqoQ64aXFbRwE9EaVNCPgzesbR9esovkPT2A2t48\" rel=\"noopener\"\u003eglobal framework\u003c/a\u003e\u0026nbsp;governs uses of AI in combat.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Knowing how and when to employ AI in warfare is one of the most difficult ethical questions of our time. Democratic nations have a right to defend themselves, and those of us who live in democracies have a responsibility to support fellow citizens who would put themselves in harm’s way to protect us. AI is transforming military strategy, and refusing to engage with it doesn’t make the risks go away.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2025/02/unnamed--47-.gif\" class=\"kg-image\" alt=\"AI model leaderboard comparing performance across tasks like math, vision, and document analysis.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2025/02/unnamed--47-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2025/02/unnamed--47-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2025/02/unnamed--47-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"alibaba%E2%80%99s-answer-to-deepseek\"\u003eAlibaba’s Answer to DeepSeek\u003c/h1\u003e\u003cp\u003eWhile Hangzhou’s DeepSeek flexed its muscles, Chinese tech giant Alibaba vied for the spotlight with new open vision-language models.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Alibaba announced\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3lKN82ZQz0ZgdKpW8D3vqj1KdvzcW4gb52r78KX8BW51V9Ww6Y71m_VPLM_c7n1VFRW3P7zfJ6h7FqXMgWrp9bpt-GW6xhH5Z4dWBrGW2MKkjw8jqtyPVTkWw_1VdSDPW8Zw-9l5p3NmcW8k_hLy3y_qbNW72z7XH5dBVk0Vmxg4G8n-d80W61yrvJ5GpDNQW8DVNVg71JtbsW8MBkt32v28WWVmZ_Tv7jlzg-VnsLnv5rxSBMW5dWJ_54tqwSWW5h2YCs800ZMcW1638BQ7jm8YJW8sYbch5wS3KDW8JcCt48ChdDCf3cpJC404?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eQwen2.5-VL\u003c/a\u003e, a family of vision-language models (images and text in, text out) in sizes of 3 billion, 7 billion, and 72 billion parameters. The weights for all three models are available for download on\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3TT3qgyTW8wLKSR6lZ3kVW7VpmT46TpbchVl8-nn1_SjztW5mt2WB1kTdB4W2m8xbH2qhMRmW8HZwrM1hQRX7W30yp_F6J5HqzW4yTsrb6hjQbXW1kyrY-8qpBSHW4x0Jkv6pr5jNW5vWT4S3tyDypW90Xmh68rBMD2W18cqZh2h2DvhW4lpfmP4wjTT9VNL1TQ4QSknXW16sRVx5hCQFyN9kf1LVb7mc6W7tylrY51vNKjW5Q0QPB35QG_MW4M0WXC4qtGbCW9m2rWt5Kc35lW9kxT081dB9QrW40Xqdd500YnFW5j9ZJ16l_wPlW4BnwQq4xPZBRW5q8YhW8V585nW7QYzqT53RW5-W3JyXqN1_Ys-RW2FwvGc3Nb1dDdg2W0W04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eHugging Face\u003c/a\u003e, each under a different license:\u0026nbsp;Qwen2.5-VL-3B is\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tz3qgyTW7Y8-PT6lZ3m4N4B9J4Gq0WQzW1T3bqY5cZTxzW3Pz-Ls53V4HVW1HxqsR9l09xcW3swHjD5VB5bZW6ZtcZS25nG3kW65J_mt3Dx6RSW1D2BMK8YRL-dW2fytzv5lYy3vW37XXcp4zrYWjW71zTjV6Jb3lCW4DB8Zp1m6nFqW99kN0q91q20FW1rWFlV94DYWgW2rPhkK6-MPtWN66g4lfCldqlW8TzzN37Y8KYxN2V94WJPgmy0W1PNkXn1SpGdfN34dh55tB0K7V8Gsfx7qB8dpW1R86bj650-4sW5nH__754MWNvW1VSyqJ9gHKJlW5yTdQc6XgXYfVF1grr3TKSYwf6d_x5b04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003efree for non-commercial uses\u003c/a\u003e, Qwen2.5-VL-7B is\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3V83qgyTW95jsWP6lZ3lkW4Zrs46216J4vW6s0Cf15pZ1rBN79PtWsCB5gxN73MRZSbClnLW6fW98F7QWHT8W8mWbfJ3T_Wk6W3DRW2r7FKFTgN63W2NkyV_SjN3tNCkZqNMCkW3YGWfn14mGCmW9g9fsj92P4WPW2tVk4w7fRLXCW2VGXR57jXyD8W2nRcNJ8zfTnLW462R245PdM5GW6zzHTv757vFPW552JvD4jxCk-W6FYgg44J2xl0W5bThdT63yqkqVDkw_5841PMzVyQp3f3DxDH_W1VVVLv8SBmdxW59kXzl7PFC8BW3VL3mT51LwW8VVzYJg5MssTrW5g40GW7hB5_3W3B9j9J4yvRsWW98Bv0D21xWWgW3wNQhL8sQVS2W3BDB8x1GjBBff7hvgMs04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003efree for commercial and noncommercial uses\u003c/a\u003e\u0026nbsp;under the Apache 2.0 license, and Qwen2.5-VL-72B is\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tz3qgyTW7Y8-PT6lZ3lQW7VP3VM2h_qVCW5XLQyq31vM0ZW32bCQJ6yZmyDW94CZjT7kLtGTW8DkK693HXRKhW5T35Rs5555rtMMhHtH13-42W2CW0Cq555QSHW8nFSw67FzzmyW31_dLX3gZ5CZW8BBrL3641QxcW5TzDVt8nwmljW1nvsQ5339gd8V-vpj86cBv6lW8-Vgbb3DsD-fW93Kr0z6KG_FrW3Lz5qq80TsSHVGjV501pWTZTW8DqMzQ7SH1SJW8hcNY48RthvrW70KFvs1tJZ-dW8znMw82mrDwKW2H-c7Y4r67RvF89McCsq3t0W4zyN9y3yhmt5W33mQ-w1Fsr9Sf7fllNY04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003efree to developers that have less than 100 million monthly active users\u003c/a\u003e.\u0026nbsp;You can try them out for free for a limited time in\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tz3qgyTW7Y8-PT6lZ3nGW5GGkcb6FGgSqW6MK_D_3DnXLBW5thRTd7RT-LLW8Y9m_m992pcBW7DVsnv1rXRLMW2jYpsb7rpXz1W4CJ_502zGPv8W1Z2cmb8HDcDLW3KXQ_081TsNzV3vpTr6D_n8vN7dCRZ0tWjpDW66QxSb2ht7YFW7THWw155vH5yW3Q1ZvR3kQt1KW1NbC_98CyFDHW3ysRJm1684q8W24VqMt6vmfWfW6S-bHX2BFHgpW3Wwv4_33rjwGW4JTZJC6rNybfW2pW9wm7JBzzwW5lPkmV35wFqWW3g4WQy76GSDGW1Q0Xnl2ggBMhV_zyk315vnN1W6jdRGq7rYPl0f94pNLP04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eAlibaba Model Studio\u003c/a\u003e, and Qwen2.5-VL-72B is available via the model selector in\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3mMW3Gxzd35qq0_rW3CGLyH9c2KCQW1ThFJP514ZwxW3kn8WD1NKHzlW7bZxQj5MW4rpW84cLLX16m-ZBW4nrs7L2b_WMYW76dW1g8JrC4sW5SnbCk32qn5SVfsRSb4pq73dW8lFG0y6hPXF-W2fQ3fN524PHWW2s0Xq63QTV88W6JwD_q5RmvvkW6PNf3r7Y77_hN3hz4ShnCF1xW7jCY6T5j3sGwW1fmTXc8Q_zCgW8Vvj3776SlBfVnCfVk3Jz0wtW1cM9Q53nrkKzVFNT2f6dRJqFf99vGVb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eQwen Chat\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Qwen2.5-VL models accept up to 129,024 tokens of input according to the\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3V83qgyTW95jsWP6lZ3mrV4SK_237_8rHN91kQ3XsRQHrW1rQ3fK4vV3Z8N6t6x3wMRfJzW2qt5K54G7K9fW3jq3Tz6FdB0GW7NW81M37bWG5W8lMNVJ7Ll6cNW8Xyqwp3gz_7_W9g20sD8hq5c-W181D3W72Vv7RVxB_Dw45NCj0W9d75gH5dyfLPW990w452HWbNfW8_cmv51w3n_FW2d-cRw3MLMzDW1M_v6d6gHjwTW8xQBm94p_-fYW72GbPv26QSpyW5N8GXt8ylHMDVgjjSl2DmZMnN7GcjvJdfqX_N5x-4F3rwBY5W8ZSnl93TGqPsW4ZW7x75QVJmQW57FPJ37Hw1nzN59-J03K1qnNW5kncV27MWMQ3W2J2QQL6h64GRV-BSLb2t3LhCf5JC4QT04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003edeveloper reference\u003c/a\u003e\u0026nbsp;(other sources provide conflicting numbers) and generate up to 8,192 tokens of output. Alibaba has not released details about how it trained them.\u003c/p\u003e\u003cul\u003e\u003cli\u003eQwen2.5-VL comprises a vision encoder and large language model. It can parse videos, images, text, and is capable of computer use (desktop and mobile).\u003c/li\u003e\u003cli\u003eThe vision encoder accepts images of different sizes and represents them with different numbers of tokens depending on the size. For instance, one image might be 8 tokens and another 1125 tokens. This enabled the model to learn about the scale of images and to estimate the coordinates of objects in an image without rescaling.\u003c/li\u003e\u003cli\u003eTo reduce computation incurred by the vision encoder, the team replaced attention (which considers the entire input context) with windowed attention (which limits the input context to a window around a given token) and used full attention only in four layers. The resulting efficiency improves training and inference speeds.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults\u003c/strong\u003e: Alibaba reports Qwen2.5-VL-72B’s performance on measures that span image and text problems, parsing documents, understanding videos, and interacting with computer programs. Across 21 benchmarks, it beat Microsoft Gemini 2.0 Flash, OpenAI GPT-4o, Anthropic Claude 3.5 Sonnet, and open competitors on 13 of them (where comparisons are\u0026nbsp; relevant and available).\u003c/p\u003e\u003cul\u003e\u003cli\u003eFor example, on answering math questions about images in\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3mDN621lXZTSKj1VtpVpG7jRkMNW4XF6Tx3DjWbjW4G7Fbp1NlzFsTHJ8R3qxjW8W8wZh1q6mNXpdW6WJDlS1__PW1W9jnxHS5Njw-4W79JDj84Gy-F7W3r8DDt7Lgdz7W8qPxCL1lgbYQVGqn8W2lzQn-W70ZSmd9hCk-LW3kb07R1nhDVBN6dKKfl1S6MzW2Bp_Ks68nMkzW62_XkK7Jzd2vVzXwDS8Cw07MW2mZCLC7p-SQZW1KvQHl8Rr3y0V5vsCh434Y9CVQP12N8Fh9r-f7tp_0H04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMathVista\u003c/a\u003e, Qwen2.5-VL-72B achieved 74.8 percent, while the closest competing model (Gemini 2.0 Flash) achieved 73.1 percent.\u003c/li\u003e\u003cli\u003eIn\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3lPW6VV7Ty6k5KVYVgBNwj97BncMW4Z69Gn7C7KjCN8Y5DjV4jkR0W7wstfZ8k7f8BW4W0HkS4R9GcLW5-pvmR2wRPy9VMQs5k2C3NgkW8bnzC16tFZLFW5yLsw28wRH50W8YWygL7TlMwYW84_xfJ8s4hBBW7pbqY52f05Q3N1v55-NjrL-SV_FTPZ1m7FDsW1dkkcg77QsdPN7vxrjQ5WvyVW8Cf31t7czfbRW7PtpGx5Y4l6YW1nnz3-5btlMWW6mHkPh14VRS_W30G7DS2vQhN9W2tgsGR7TdWQSW3zjby36bD86zf8fQbL604?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eVideo-MME\u003c/a\u003e, which evaluates a model’s ability to answer questions about videos, Qwen 2.5 VL achieved 73.3 percent. GPT-4o achieved 71.9 percent and\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3nSW6wQnH45_Y08JW5XWGZx8jg8gdV6QS5217WmgRW7G3Scs4tPtxSW71hvJX7_vhvXW1jmfdT5J5-5DW3y7qfm1SP7GgN5jwvg2MxM0lW9ls7Ll5JyZvbW5tyMX26XjnWgW95tFz38HpH79W81f7m52NGVDBVv29KL2bH6XpW3Klkys452n3KW190qL-2pDl5yW1c6QmC9cKF3wW3g4V4p1fKgg5W94RD2X5plzZ_W82c-Lf6qNKNCW4Zv1XJ6r71yJW3Hq_rP5NbwC9W5h9Clv7k8L0Mf4kVknR04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eInternVL2.5\u003c/a\u003e, the next-best open competitor, achieved 72.1 percent.\u003c/li\u003e\u003cli\u003eUsed in an agentic workflow, Qwen2.5-VL-72B outperformed Claude 3.5 Sonnet when controlling Android devices and navigating desktop user interfaces. However, it finished second to other open vision-language models in several tests.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eMore models:\u003c/strong\u003e\u0026nbsp;Alibaba also introduced competition for DeepSeek and a family of small models.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3m2W8HwsBK3MPwH6W4ckYcJ2yMrf_W8WhMjK6QLQkCW3_t1X45wCLKWN3zhmNZLThqHW5wvn328RzxDrW2H8HTM1MpcmQW7cdpQj3t393RW2WSxJp7c5gdNVkLcYb3wPhLsW7nrj9h4s25DxW4Rs7GH18n0lJW3dh-6R8DsVb5W5f6SK17lTDhmW8XsdLr5NjdBVW21L8Sj67d36HW6GyJzr1wbWSFW8rVwPg2xD7LhW1MdCPp1W5y2QW8Z40yg36bCsFW1hcwND54ys6_W3p2Ktp51hFjtW6v8T0Z1DrcFcN69TtmnknHDccjg4W04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eQwen2.5-Max\u003c/a\u003e\u0026nbsp;is a mixture-of-experts model that outperforms GPT-4o and DeepSeek-V3 on graduate-level science questions in\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3nwW35xPn86q9Xy8VK3tgZ6kgZ0bW4qVX-H2hhjPdW8JY91s2G_vLnW74-3Ry1_P36GW1K6Xb-8fznq2W8h3dPK7LRgPvW4-q-r871wYc3W9jCDDh5ZrSqfN4MW5jb-H-PrW5-Q8v37MRz36W1Vw2-q1xzKmZW1NRczT1rV2pGW7TjWzz7LWl-yW50dpJ033KMq-W7RrK_z8y0r9qN3k3bJ6x16GlVsnDY04B9srqW3rvQzV8NMdwrV-m9g22MXDt1W1Cyjpw7ntbjRW9dMQQ98t8zmbf1JqWMj04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eGPQA-Diamond\u003c/a\u003e\u0026nbsp;and regularly updated benchmarks like\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3mDW8Lj_0-4-vW8sVkLzvM6BLzbXW27VSv78bFpdxW9kQGpy2YMFYTW9gmt_242mk_PW3x3V045hWxs1W28pf-56sRRNvVMCwdV28ckWnW920-w71MWXZcW2tvDJS56Cxk5W1nPRqp9j3M64W4SvZhs98yQn-W1wCM-c4H-QCdW1XwwzJ1Y0Z37W1ZxDr726m6W1W60JS8210zdQ7W9kF_z05DZ2X-W6DTLRq7j0kjwW7w46pB8Rp7S2W3TP59b2Jnc4PW2lvZ1d3pg_HKW1MNfSP6frD1DW7zxX-94D5NNQW8WFQWT8Qz6LYf8z__p604?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eArena-Hard\u003c/a\u003e,\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tz3qgyTW7Y8-PT6lZ3mJW4kRtpR1K16y6W5TCNVv547MQtW4zCX_L2gCD0DW7gkj3449HnD8W1tSXKH9bM-PzW7K7zF75tP1Y_W46DC003gPpT4W2Y74nK86NMJVW1gQf9X4gBCMZW55LXRR4fsh_nW4LtWjG6C04scV6VJT49jK0R7W80D_pF4rmLzSV-MXDm6XJp-1W47_sB29lH5hYW84Sw8H5R-Fr9W1kqW-L8zlGVHN8G13N4C1bMLW8W70V28WZkGWVHwL9L6kpYh5W22-3Kv1DfFDpW6QGnWH6ZFYK2W7VtKB45V9D89W70KyBx7k9fJtN244dgzmhb0qW36_71F8DC2K7f2XRg2R04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eLiveBench\u003c/a\u003e, and\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3mjN4HxGBJRfLsJW6GHsTT83h1HfVvNkGt1W6nN1W3WzhQ21PGGsCW8-sHKw3kBg45W6lk1vP4rmvq8W6xhyQ-4kv7hwW74t4Xn8DBTFYVD32C21wh-NfW1BGL882drhKXW7S7Vk71zwVcjW8wF-467WwprxW5rz6Bx45vdCxW3R2_q16DM7jDVpGhd62n3FgmN3RhpW6Gbmj2W3GjBLb3GkvFsW18-FbB1rtBC2W55f-v71WwS_XW89gsYw3gH18-W284nps5N0l2qVFXC6Y4NM9dPf8wcrWR04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eLiveCodeBench\u003c/a\u003e. However, Qwen2.5-Max performed worse than o1 and DeepSeek-R1.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3Tg3qgyTW7lCdLW6lZ3nqW83ZTHJ5tr4KxVPtMnK6Y4sy_W6TXMCn6ly60mN3VxrHSqKnBDVhznZ81Gxwl0W3ndP5p1Wg0D9W8YTDlS2lbw9wW1w4Ck46H7l_RW2FZCRZ1w2H2-N2GJpLD9D_Z5W86NbQB1tkvwmW6TcK8M8B0NzfW8hMbVz911LnCVF4Hfn324yV_W7fDMpB9fLpw7W90KgWM5957DqN4JMmch-3PnNN5ZKpMgVzgDDW3Nmmvk51Dl2VW332_Nm3B3FvkW2mzH8t2vpnZ0W7JzDmg7TSwF5Vl7q5_6yrWXnW5skNXy39z4Xjf7L601P04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eQwen2.5-1M\u003c/a\u003e\u0026nbsp;is a family of smaller language models (7 billion and 14 billion parameters) that accept up to 1 million tokens of input context.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Vision-language models are getting more powerful and versatile. Not long ago, it was an impressive feat simply to answer questions about a chart or diagram that mixed graphics with text. Now such models are paired with an agent to control computers and smartphones. Broadly speaking, the Qwen2.5-VL models outperform open and closed competitors and they’re open to varying degrees (though the data is not available), giving developers a range of highly capable choices.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe\u003c/strong\u003e’\u003cstrong\u003ere thinking:\u003c/strong\u003e\u0026nbsp;We’re happy Alibaba released a vision-language model that is broadly permissive with respect to commercial use (although we’d prefer that all sizes were available under a standard open weights license). We hope to see technical reports that illuminate Alibaba’s training and fine-tuning recipes.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2025/02/unnamed--48-.gif\" class=\"kg-image\" alt=\"Diagram showing GPT-4o with and without search, highlighting task execution success and failure.\" loading=\"lazy\" width=\"600\" height=\"336\" srcset=\"https://dl-staging-website.ghost.io/content/images/2025/02/unnamed--48-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"tree-search-for-web-agents\"\u003eTree Search for Web Agents\u003c/h1\u003e\u003cp\u003eBrowsing the web to achieve a specific goal can be challenging for agents based on large language models and even for vision-language models that can process onscreen images of a browser. While some approaches address this difficulty in training the underlying model, the agent architecture can also make a difference.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Jing Yu Koh and colleagues at Carnegie Mellon University introduced\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3mGW33sV0K63TX_fW6qLlxx7YxG9GW2FB1bn5jDw4VW5Zntz52wD0_vW5ryxtN1-bDCHW3tdRFV4hh-5pW2JYklx2bCzyJVX-0JL1SK_jVW69ZyD56btDJNW6JG0lc1rWX30N2ncM2CN84C4W6jCTnC88-dhTW30LWj61pQ1ZsW71tJSy6wk-D-W9ffWpz60h4vvW8DDFKy2mkm-6W3HRsSD3dVXv7W6CrCXZ14bkgkW6D0nvF3q7FLsW2GhvKb6zdWk4W4knytQ3pNHWTW7KD0fl3LZCh3f5CRhb804?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003etree search for language model agents\u003c/a\u003e, a method that allows agents to treat web interactions like tree searches. In this way, agents can explore possible chains of actions and avoid repeating mistakes.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;Some web tasks, for instance finding a price of a particular item, require a chain of intermediate actions: navigating to the right page, scrolling to find the item, matching an image of the item to the image on the page, and so on. If an agent clicks the wrong link during this process, it might lose its way. The ability to evaluate possible actions and remember previous states of web pages can help an agent correct its mistakes and choose a chain of actions that achieves its goal.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;An agent based on GPT-4o attempted 200\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3SH3qgyTW69sMD-6lZ3mKW6RwhVb4vBRtSN8_2ZnjR6TmdW8qz456383tZ5V_RMkT5LPlY0W4JBgyz2HRjtbW7Pt5wG4MP4K5W1lrtC72FdT3ZW10FNBD14F6yjW6YRPry6PMW8LW7Gdm5v6d1NYlW1CHDvn1VrBMzW1psr2D4qCMMQW2tRBxS1Dsr99W920d1N40246wW2Xcjz95d2_pcW4VZSK14MRGK-N8DYPJVJqgkbW9hX2P36Gc1ZbW2mBV3f4qlw7sW33w3hs1mQcB6f2w-Ms004?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003etasks\u003c/a\u003e\u0026nbsp;using website mockups that mimicked an online retail store, Reddit-like forum, and directory of classified ads. The tasks included ordering an item to be delivered to a given address, finding specific images on the forum, and posting an ad. The authors annotated each web page using the method called\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3S-3qgyTW6N1vHY6lZ3pmW2LQZyx1jDWLDW4GFzcw1FknClW1WK5YQ5sWPvSW1kbcT94rW0pCW5kL9sG16JHkvW8R-2w32btRF-N1MpZLFnpGYTW3W5xY95V7jH1W3ZSxC58hZJlYW5X2mPR2QrLlpW4qSlMM2smDK2W3GqzKh55pLPdW7Xrpp68rVFHqW5PHJZD2cB7l2N3QV0db7Bv_tW6VhGbD5N5Qp1W7WW4X74mzZ3KW6JLpC82_sLgrW3-lJ9z4GyyzcW2qt_Lm32-ql8W6qrY0d4nNtqcW6s70G68_nxHLf1Lf4nW04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eSet of Mark\u003c/a\u003e, which identifies every visual element capable of interaction with a bounding box and a numerical ID.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe agent started with a web page and an instruction such as, “Tell me the number of reviews our store received that mention the term ‘not useful.’” It passed an image of the page to the LLM, which predicted five actions that could make progress toward completing the task such as scrolling up or down, hovering over an element, clicking, typing in a text field, or opening a new URL.\u003c/li\u003e\u003cli\u003eThe agent executed the five actions. After each one, the LLM assessed the current state of the page using the previous states as context. The assessment assigned a value between 0 and 1 (meaning the task was complete). The agent kept a list of page states and their values.\u003c/li\u003e\u003cli\u003eThe agent selected the web page state with the highest value after executing the five actions, and repeated the process, making a new set of five predictions based on the highest-value state.\u003c/li\u003e\u003cli\u003eThis process is a search: The agent executed a chain of actions until the value of the new states dropped below the values of other states. If all new states had lower values, the agent backtracked to a previous state with a higher value and asked the LLM for five more actions. The search stopped when the agent had completed the task or explored 20 possible states.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The authors compared two agents, one that followed their search method and another that started at the same page and received the same instruction but took one action per state and never backtracked. The agents attempted 100 shopping tasks, 50 forum tasks, and 50 classified-ads tasks. The one equipped to search successfully completed 26.4 percent of the tasks, while the other agent completed 18.9 percent of the tasks.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Search joins reflection, planning, tool use, and multi-agent collaboration as an emerging\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3TT3qgyTW8wLKSR6lZ3kxW7HPjWp1GZtG-W7tkb6K2wJWQ0N6WplKJ2nxZQW8mYTB43Z_4ZRW544L4h3z0Hl9W248hWN8vgtPtW48JV4D7JLN1RW2xDybW1x8swPW8xbfF17pZtDYW7bVmpP82CgLqW2QfV992WlCBhV54ddR5gx1zpW1kKrCg4lR3d6W61wNhM922dl0W42RlkZ3HNgQtN1X4485BrV67W26PMqz5qZr6bVB6nCx46NwcDW3v0NZs59wj73W7WMnkl5-Q1K-VwvDyL7MYXZtW7mqrKY8lvyppN4F4h5-bnRHDW7Hw46-61w9RwW1TrgP36RfmSJW28yddh1d6SFFW6SG9GT8mFgXPW6dHL1t31xKXLf1yl9H404?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eagentic design pattern\u003c/a\u003e. Following many branching paths of actions enables an agent to determine the most effective set of actions to accomplish a task.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Agentic design patterns are progressing quickly! In combination with\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWFtn98tnvNfVxHryv6WJrNBVmLt1V5rZxh_MwF3V83qgyTW95jsWP6lZ3m4W1Kzxn_7ylBZDN4FBTglQ4NRbW6kYCY223MC-gW3g4Gp1861zgjVf41-h7y59qZW7TRF8d3K67GLW3mKSdz6bhvFDW8TZ3Cd9kGXHLW4n4NfN7dqxvkW3WwW443GFN-sVtvTtl4f2mbCW9ltVXf7VNgWhW3c4sz84cVhM3W1JB7257TS-Y9W3SYHBJ3bnB1jN7QqWchcSqRQW2KqtFD6ZrWZ7N4gqHJ0kkzWbW15KhRK6VC63NW3cm6RM4tNvGcW11CKrC26sD3QW7TQqmj1JZ2JmVfSjDV883kTDW1WZP6_4NsD_GW1LyQlM7n8m21W90XV2S2Ljn16W2jcrm91JZVYfW8kjq5T5y065KN7Hm8Flgh_c3W8mKTlS1FBYgTf4STLgW04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ecomputer use\u003c/a\u003e, this sort of search method may enable agents to execute a wide variety of desktop tasks.\u003c/p\u003e","comment_id":"67acf685de17ec0001710eb7","feature_image":"https://dl-staging-website.ghost.io/content/images/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1-.jpg","featured":false,"visibility":"public","created_at":"2025-02-12T11:29:09.000-08:00","updated_at":"2025-02-13T13:40:46.000-08:00","published_at":"2025-02-12T11:46:34.000-08:00","custom_excerpt":"The Batch AI News and Insights: At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance said, “I’m not here to talk about AI safety.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"67acf9dede17ec0001710ef1","name":"Feb 12, 2025","slug":"feb-12-2025","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/feb-12-2025/"},{"id":"67d1f29c9397160001d3f230","name":"issue-288","slug":"issue-288","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-288/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-288/","excerpt":"The Batch AI News and Insights: At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance said, “I’m not here to talk about AI safety.","reading_time":13,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"OpenAI Does Deep Research, Google Goes to War, Alibaba Answers DeepSeek, Web Agents Do Tree Search  ","meta_description":"The Batch AI News and Insights: At the Artificial Intelligence Action Summit in Paris this week, U.S. Vice President J.D. Vance said, “I’m not here...","email_subject":null,"frontmatter":null,"feature_image_alt":"“Responsible AI” written on a wall, with “Safety” crossed out in blue paint.","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2025/02/RESPONSIBLE-AI_Blue-Or4_1200px--1-.jpg","dimensions":{"width":1200,"height":676}},"banner":{"title":"ChatGPT Prompt Engineering for Developers","databaseId":29452,"id":"cG9zdDoyOTQ1Mg==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/05/cgpt-2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-288"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>