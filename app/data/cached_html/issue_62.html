<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>AI Researchers Under Fire, RL Agents in Danger, Bias in Synthetic</title><meta name="description" content="The Batch - AI News &amp; Insights: Controversy erupted over the need for transparency in research into AI for medicine | How does a convolutional neural network recognize a photo of a ski resort?" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-62/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="AI Researchers Under Fire, RL Agents in Danger, Bias in Synthetic" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: Controversy erupted over the need for transparency in research into AI for medicine | How does a convolutional neural network recognize a photo of a ski resort?" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="AI Researchers Under Fire, RL Agents in Danger, Bias in Synthetic" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-62/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2020-10-21T12:00:00.000-07:00"/><meta property="article:modified_time" content="2022-10-06T15:53:01.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-62"/><meta property="article:tag" content="Oct 21, 2020"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="AI Researchers Under Fire, RL Agents in Danger, Bias in Synthetic" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: Controversy erupted over the need for transparency in research into AI for medicine | How does a convolutional neural network recognize a photo of a ski resort?" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-62/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/ezgif.com-gif-maker2022.gif"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/ezgif.com-gif-maker2022.gif"/><meta property="og:image:width" content="576"/><meta property="og:image:height" content="324"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2020-10-21T12:00:00.000-07:00","dateModified":"2022-10-06T15:53:01.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"AI Researchers Under Fire, RL Agents in Danger, Bias in Synthetic","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/06/ezgif.com-gif-maker2022.gif","width":576,"height":324},"publisher":{"@type":"Organization","name":"AI Researchers Under Fire, RL Agents in Danger, Bias in Synthetic","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: Controversy erupted over the need for transparency in research into AI for medicine | How does a convolutional neural network recognize a photo of a ski resort?"}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-62/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 62</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Oct 21, 2020</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">11<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/oct-21-2020/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Oct 21, 2020</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">11<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-62/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-62/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-62/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,</em></p><p><em>Today Landing AI, where I am CEO, launched <a href="https://landing.ai/platform/?ref=dl-staging-website.ghost.io" rel="noopener">LandingLens</a>, an AI-powered platform that helps manufacturers develop computer vision solutions that can identify defective products. For AI to benefit a wide range of industries, we need platforms that enable experts in a variety of fields to build and deploy models. LandingLens is a step in this direction, and it’s available to manufacturers immediately.</em></p><p><em>A major challenge to taking advantage of AI throughout the economy is the sheer amount of customization needed. To use computer vision to inspect manufactured goods, we need to train a different model for each product we want to inspect: each smartphone model, each semiconductor chip, each home appliance, and so on. How can Landing AI build models for thousands of products without hiring thousands of machine learning engineers? It’s much better to empower the manufacturers to build and deploy these models themselves.</em></p><p><em>LandingLens enables experts in manufacturing — rather than experts in machine learning — to collect data, train models, deploy them, and carry out continuous learning. It helps them make sure their models work and scale up deployments. If the test data distribution drifts and the algorithm’s performance suddenly degrades, they’re empowered to collect new data and retrain the model without being beholden to an outside team.</em></p><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-gif-maker2022.gif" class="kg-image" alt="LandingLens platform" loading="lazy"></figure><p><em>Here are a few unique features of LandingLens:</em></p><ul><li><em><em>Rather than holding the training set fixed and trying to improve the model, we hold the model fixed and help manufacturers improve the training set. We’ve found that this approach leads to faster progress in production settings.</em></em></li><li><em><em>Rather than focusing on building models that recognize defects better than humans can, our tools aim to improve human-level performance. The better humans can recognize defects, the more consistently they’ll label those defects in training data, and the better the trained models will be. This is a very different philosophy from usual in AI research, where the goal often is to beat human-level performance.</em></em></li></ul><p><em>Having led AI teams at large consumer internet companies, I believe it’s time to take AI beyond the technology industry, to all industries. We’ve been building this platform for over a year, and I’m excited to be able to talk about it publicly. I hope that LandingLens — and other verticalized AI development platforms to come — will lower the bar for industrial deep learning and spread the benefits of AI throughout the economy.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h2 id="news"><strong>News</strong></h2><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-gif-maker2023.gif" class="kg-image" alt="Data related to a system that purportedly identified breast cancer" loading="lazy"></figure><h3 id="pushing-for-reproducible-research">Pushing for Reproducible Research</h3><p>Controversy erupted over the need for transparency in research into AI for medicine.<br><br><strong>What’s new:</strong> Google Health introduced a <a href="https://www.nature.com/articles/s41586-019-1799-6?ref=dl-staging-website.ghost.io" rel="noopener">system</a> that purportedly identified breast cancer more accurately than human radiologists. But the search giant’s healthcare division failed to disclose details that would have enabled others to reproduce its results, dozens of critics wrote in a letter to <em><a href="https://www.nature.com/articles/s41586-020-2766-y?ref=dl-staging-website.ghost.io" rel="noopener">Nature</a></em> (also published on <em><a href="https://arxiv.org/ftp/arxiv/papers/2003/2003.00898.pdf?ref=dl-staging-website.ghost.io" rel="noopener">Arxiv</a></em>).<br><br><strong>The critique:</strong> Researchers at Harvard, University of Toronto, Vector Institute, and elsewhere argue that AI systems used to diagnose life-threatening conditions should meet high standards of transparency. The Google research fell short on several counts:</p><ul><li>The authors didn’t release the trained model for others to verify their results.</li><li>Although they mentioned the framework and libraries used, they omitted training details such as learning rate, type of optimizer, number of training epochs, and data augmentation techniques. That’s like listing the ingredients in a cake recipe without disclosing the amounts, Benjamin Haibe-Kains of the University of Toronto, who co-authored the critique, told <em>The Batch</em>.</li><li>One dataset used in the study, <a href="https://arxiv.org/abs/2004.04742?ref=dl-staging-website.ghost.io" rel="noopener">Optimam</a>, is readily available. However, the authors also used patient data that remains private. In lieu of that dataset, the critics argue, the authors should have disclosed labels and model predictions that would allow for  independent statistical analysis.</li><li>Other details were also missing, leading to questions such as whether the model trained on a given patient’s data multiple times in a single training epoch.</li></ul><p><strong>The response:</strong> In a rebuttal published in <a href="https://www.nature.com/articles/s41586-020-2767-x?ref=dl-staging-website.ghost.io" rel="noopener"><em>Nature</em></a>, the Google researchers <a href="https://pbs.twimg.com/media/EkTQgmZWsAk3JK8?format=png&name=large&ref=dl-staging-website.ghost.io" rel="noopener">said</a> that keeping the model under wraps was part of “a sustainable venture to promote a vibrant ecosystem that supports future innovation.” The training details omitted are “of scant scientific value and limited utility to researchers outside our organization,” they added. They held back the proprietary dataset to protect patient privacy.<br><br><strong>Behind the news:</strong> AI researchers are struggling to balance trade secrets, open science, and privacy. The U.S. <a href="https://www.fda.gov/medical-devices/workshops-conferences-medical-devices/public-workshop-evolving-role-artificial-intelligence-radiological-imaging-02252020-02262020?ref=dl-staging-website.ghost.io" rel="noopener">Food and Drug Administration</a> hosted a workshop earlier this year aimed at developing best practices for validating AI systems that interpret medical images.<br><br><strong>Why it matters:</strong> Transparency makes it possible for scientists to verify and build on their colleagues’ findings, find flaws they may have missed, and ultimately build trust in the systems they deploy. Without sufficient information, the community can’t make rapid, reliable progress.<br><br><strong>We’re thinking:</strong> There are valid reasons to withhold some details. For instance, some datasets come with limitations on distribution to protect privacy. However, outside of circumstances like that, our view is that researchers owe it to each other to make research findings as reproducible as possible.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-gif-maker2016UNITS.gif" class="kg-image" alt="Graphs and examples of Network dissection technique" loading="lazy"></figure><h3 id="what-one-neuron-knows">What One Neuron Knows</h3><p>How does a convolutional neural network recognize a photo of a ski resort? New research shows that it bases its classification on specific neurons that recognize snow, mountains, trees, and houses. Zero those units, and the model will become blind to such high-altitude playgrounds. Shift their values strategically, and it will think it’s looking at a bedroom.<br><br><strong>What’s new:</strong> <a href="https://arxiv.org/abs/2009.05041?ref=dl-staging-website.ghost.io" rel="noopener">Network dissection</a> is a technique that reveals units in convolutional neural networks (CNNs) and generative adversarial networks (GANs) that encode not only features of objects, but the objects themselves. David Bau led researchers at Massachusetts Institute of Technology, Universitat Oberta de Catalunya, Chinese University of Hong Kong, and Adobe Research.<br><br><strong>Key insight:</strong> Previous <a href="https://arxiv.org/abs/1412.0035?ref=dl-staging-website.ghost.io" rel="noopener">work</a> discovered individual units that activated in the presence of specific objects and other image attributes, as well as image <a href="https://journals.plos.org/plosone/article/file?id=10.1371%2Fjournal.pone.0130140&type=printable&ref=dl-staging-website.ghost.io" rel="noopener">regions</a> on which individual units focused. But these efforts didn’t determine whether particular image attributes caused such activations or spuriously correlated with them. The authors explored that question by analyzing relationships between unit activations and network inputs and outputs.<br><br><strong>How it works:</strong> The authors mapped training images to activation values and then measured how those values affected CNN classifications or GAN images. This required calculations to represent every input-and-hidden-unit pair and every hidden-unit-and-output pair.</p><ul><li>The authors used an image segmentation network to label objects, materials, colors, and other attributes in training images. They chose datasets that show scenes containing various objects, which enabled them to investigate whether neurons trained to label a tableau encoded the objects within it.</li><li>Studying CNNs, the authors identified images that drove a given unit to its highest 1 percent of activation values, and then related those activations to specific attributes identified by the segmentation network.</li><li>To investigate GANs, they segmented images generated by the network and used the same technique to find relationships between activations and objects in those images.</li></ul><p><strong>Results:</strong> The authors trained a <a href="https://arxiv.org/abs/1409.1556?ref=dl-staging-website.ghost.io" rel="noopener">VGG-16</a> CNN on the <a href="https://github.com/CSAILVision/places365?ref=dl-staging-website.ghost.io" rel="noopener">places365</a> dataset of photos that depict a variety of scenes. When they removed the units most strongly associated with input classes and segmentation labels — sometimes one unit, sometimes several — the network’s classification accuracy fell an average of 53 percent. They trained a <a href="https://arxiv.org/abs/1710.10196?ref=dl-staging-website.ghost.io" rel="noopener">Progressive-GAN</a> on the <a href="https://www.yf.io/p/lsun?ref=dl-staging-website.ghost.io" rel="noopener">LSUN</a> dataset’s subset of kitchen images. Removing units strongly associated with particular segmentation labels decreased their prevalence in the generated output. For example, removing a single unit associated with trees decreased the number of trees in generated images by 53.3 percent. They also came up with a practical, if nefarious, application: By processing an image imperceptibly, they were able to alter the responses of a few key neurons in the CNN, causing it to misclassify images in predictable ways.<br><br><strong>Why it matters:</strong> We often think of neural networks as learning <a href="https://web.stanford.edu/~jlmcc/papers/PDP/Chapter3.pdf?ref=dl-staging-website.ghost.io" rel="noopener">distributed representations</a> in which the totality of many neurons’ activations represent the presence or absence of an object. This work suggests that this isn’t always the case. It also shows that neural networks can learn to encode human-understandable concepts in a single neuron, and they can do it without supervision.<br><br><strong>Yes, but:</strong> These findings suggest that neural networks are more interpretable than we realized — but only up to a point. Not every unit analyzed by the authors encoded a familiar concept. If we can’t understand a unit that’s important to a particular output, we’ll need to find another way to understand that output.<br><br><strong>We’re thinking:</strong> In 2005, neuroscientists at CalTech and UCLA <a href="https://www.scientificamerican.com/article/one-face-one-neuron/?ref=dl-staging-website.ghost.io" rel="noopener">discovered</a> a single neuron in a patient’s brain that appeared to respond only to the actress Halle Berry: photos, caricatures, even the spelling of her name. (In fact, this finding was an inspiration for Andrew’s <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/unsupervised_icml2012.pdf?ref=dl-staging-website.ghost.io" rel="noopener">early</a> <a href="http://www.robotics.stanford.edu/~ang/papers/icml09-ConvolutionalDeepBeliefNetworks.pdf?ref=dl-staging-website.ghost.io" rel="noopener">work</a> in unsupervised learning, which found a neuron that encoded cats.) Now we’re dying to know: Do today’s gargantuan models, trained on a worldwide web’s worth of text, also have a Halle Berry neuron?</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-gif-maker2019.gif" class="kg-image" alt="Takes from Agence, an interactive VR project" loading="lazy"></figure><h3 id="rl-agents-sos">RL Agents: SOS!</h3><p>A new multimedia experience lets audience members help artificially intelligent creatures work together to survive.<br><br>What’s new: <a href="https://www.agence.ai/?ref=dl-staging-website.ghost.io" rel="noopener">Agence</a>, an interactive virtual reality (VR) project from Toronto-based Transitional Forms and the National Film Board of Canada, blends audience participation with reinforcement learning to create an experience that’s half film, half video game. The production, which runs on VR, mobile, and desktop platforms, debuted at the <a href="https://www.labiennale.org/en/cinema/2020/venice-vr-expanded/agence?ref=dl-staging-website.ghost.io" rel="noopener">2020 Venice Biennale</a> exhibition of contemporary art. It’s available for download from <a href="https://store.steampowered.com/app/1308040/Agence/?ref=dl-staging-website.ghost.io" rel="noopener">Steam</a>.<br><br>How it works: Five cute, three-legged creatures live atop a tiny, spherical world. They must learn to work together to grow giant flowers for food without throwing the planet off-balance. Players can simply watch them work or play an active role in the story by planting flowers or moving agents around.</p><ul><li>Players can let the agents interact under control of a rules-based algorithm or turn on a reinforcement learning (RL) model that drives them to seek rewards, such as bites of fruit, and avoid repeating mistakes, such as falling off the edge of the world.</li><li>The agents were pre-trained in a stripped-down version of the game world using a method called <a href="https://openai.com/blog/openai-baselines-ppo/?ref=dl-staging-website.ghost.io" rel="noopener">proximal policy optimization</a>, which makes RL less sensitive to step size without the tradeoffs incurred by other approaches. The game’s creators settled on PPO because it was quickest at training the agents to solve the game’s physical challenges, such as learning to balance their weight to keep the world from spinning, technical director Dante Camarena told <em>The Batch</em>.</li><li>The developers are collecting data on how users interact with the agents. They’ll use the information to update the training simulation monthly.</li></ul><p><strong>Behind the news:</strong> Agence director Pietro Gagliano <a href="https://www.theverge.com/2015/9/15/9328673/virtual-reality-wins-first-emmy-sleepy-hollow?ref=dl-staging-website.ghost.io" rel="noopener">received</a> an Emmy in 2015 for a VR experience in which viewers encountered the Headless Horseman from the <em><a href="https://en.wikipedia.org/wiki/Sleepy_Hollow_(TV_series)?ref=dl-staging-website.ghost.io" rel="noopener">Sleepy Hollow</a></em> TV series.<br><br><strong>Why it matters:</strong> Agence represents a new type of medium in which the audience members collaborate with AI to create unique, immersive experiences. It offers new possibilities for user input and interactive storytelling that — whether or not Agence itself catches on — seem destined to transform electronic entertainment.<br><br><strong>We’re thinking:</strong> Video game opponents driven by rules can be challenging, but imagine trying to outsmart the cops in <em>Grand Theft Auto</em> if they could learn from your past heists.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM <a href="https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io" rel="noopener">DEEPLEARNING.AI</a></h2><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/1-3.gif" class="kg-image" alt="1-3" loading="lazy"></figure><p>Have you completed courses 1 and 2 of the <em>Generative Adversarial Networks Specialization</em>? Course 3 will be available on Coursera next week! Pre-enroll <a href="https://www.coursera.org/learn/apply-generative-adversarial-networks-gans?ref=dl-staging-website.ghost.io">here</a></p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-resize2020.gif" class="kg-image" alt="Contrast between real and real and synthetic datasets" loading="lazy"></figure><h3 id="battling-bias-in-synthetic-data">Battling Bias in Synthetic Data</h3><p>Synthetic datasets can inherit flaws in the real-world data they’re based on. Startups are working on solutions.</p><p><strong>What’s new:</strong> Generating synthetic datasets for training machine learning systems is a <a href="https://www.startus-insights.com/innovators-guide/5-top-emerging-synthetic-data-startups?ref=dl-staging-website.ghost.io" rel="noopener">booming business</a>. Companies that provide such datasets are exploring ways to avoid perpetuating biases in the source data.</p><p><strong>How it works:</strong> The cost of producing a high-quality training dataset is beyond the reach of some companies, and in situations where sufficient real-world data isn’t available, <a href="https://arxiv.org/abs/1909.11512?ref=dl-staging-website.ghost.io" rel="noopener">synthetic data</a> may be the only option. But such datasets can echo and even amplify biases including potentially harmful <a href="https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/?ref=dl-staging-website.ghost.io" rel="noopener">social biases</a>. Vendors like <a href="https://aireverie.com/?ref=dl-staging-website.ghost.io" rel="noopener">AI.Reverie</a>, <a href="https://www.genrocket.com/?ref=dl-staging-website.ghost.io" rel="noopener">GenRocket</a>, <a href="https://hazy.com/?ref=dl-staging-website.ghost.io" rel="noopener">Hazy</a>, and <a href="https://mostly.ai/?ref=dl-staging-website.ghost.io" rel="noopener">Mostly AI</a> are looking for ways to adjust their synthetic output — “<a href="https://slate.com/technology/2020/09/synthetic-data-artificial-intelligence-bias.html?ref=dl-staging-website.ghost.io" rel="noopener">distorting reality</a>,” as Hazy’s chief executive put it — to minimize the risk that models trained on their wares will result in unfair outcomes.</p><ul><li>In a recent <a href="https://mostly.ai/2020/05/08/diving-deep-into-fair-synthetic-data-generation-fairness-series-part-5/?ref=dl-staging-website.ghost.io" rel="noopener">experiment</a>, Mostly AI generated a dataset based on income data from the <a href="https://archive.ics.uci.edu/ml/datasets/Adult?ref=dl-staging-website.ghost.io" rel="noopener">1994 U.S. census</a>, in which men who earned more than $50,000 outnumbered women who earned that amount by 20 percent. To generate a more even distribution of earning power, the company built a generator that applied a penalty when the ratio of synthetic high-earners who were male versus female became lopsided. That approach narrowed the gap to 2 percent.</li><li>The company also generated a dataset based on the infamous Compas recidivism dataset, which has been <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing?ref=dl-staging-website.ghost.io" rel="noopener">shown</a> to lead models to overestimate the likelihood that a Black person would commit a crime and underestimate that likelihood for a White person. The initial synthetic dataset skewed toward Black recidivism by 24 percent. The company adjusted the generator using the same parity correction technique and reduced the difference to 1 percent.</li></ul><p><strong>Why it matters:</strong> Social biases in training datasets often reflect reality. It’s true that altering synthetic datasets to change the balance of, say, men and women who earn high incomes is trading one type of bias for another, rather than eliminating it altogether. The aim here is not necessarily to generate accurate data but to produce fair outcomes.</p><p><strong>We’re thinking:</strong> We need data, but more than that, we need to build models that result in fair outcomes.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/Batteries1.png" class="kg-image" alt="Information and components of a battery" loading="lazy"></figure><h3 id="getting-a-charge-from-ai">Getting a Charge From AI</h3><p>Machine learning is helping to design energy cells that charge faster and last longer.<br><br><strong>What’s new:</strong> Battery developers are using ML algorithms to devise new chemicals, components, and charging techniques faster than traditional techniques allow, according to <em><a href="https://www.wired.com/story/ai-is-throwing-battery-development-into-overdrive/?ref=dl-staging-website.ghost.io" rel="noopener">Wired</a></em>.<br><br><strong>How it works</strong>: Designing better batteries involves tweaking variables such as electrode architecture, chemical composition, and patterns of current and voltage during charging. Typically, researchers change one at a time and can’t analyze the results until a battery dies. AI lets them test many at once and get results while the battery still has juice.</p><ul><li>Researchers from MIT, Stanford, and the Toyota Research Institute test the longevity of prospective designs in machines that discharge and recharge them repeatedly. They trained a <a href="https://www.nature.com/articles/s41586-020-1994-5?ref=dl-staging-website.ghost.io" rel="noopener">model</a> on data from these rigs to find better ways to recharge lithium-ion batteries without degrading their working lifetime. The model enabled them to complete in 16 days experiments that ordinarily would have required 500.</li><li>A model at Argonne National Laboratory is <a href="https://pubs.rsc.org/en/content/articlelanding/2019/SC/C9SC02834J?ref=dl-staging-website.ghost.io#!divAbstract" rel="noopener">sifting</a> through a massive molecular database to find energy-storing chemicals. The model’s creators are also developing a platform that would let researchers and companies train their models using other people’s data without compromising anyone’s intellectual property.</li><li>A machine learning platform developed by California-based Wildcat Technologies helped InoBat, a Slovakian startup, develop a lithium-ion battery that purportedly <a href="https://inobatauto.eu/docs/World-first%20intelligent%20battery%20launch.pdf?ref=dl-staging-website.ghost.io" rel="noopener">increases the range of electric vehicles</a> by almost 20 percent. InoBat plans to begin producing the batteries by the end of 2021.</li></ul><p><strong>Behind the news:</strong> In recent years, machine learning has also helped researchers discover new molecules that <a href="https://pubs.rsc.org/en/content/articlelanding/2019/TA/C9TA06748E?ref=dl-staging-website.ghost.io#!divAbstract" rel="noopener">improve energy density</a>, <a href="https://www.sciencedirect.com/science/article/pii/S1876610218313419?ref=dl-staging-website.ghost.io" rel="noopener">predict how batteries will perform</a> in different electric vehicles, <a href="https://www.frontiersin.org/articles/10.3389/fenrg.2020.00116/full?ref=dl-staging-website.ghost.io#B69" rel="noopener">test</a> how well capacitor designs store energy, and advanced battery research in <a href="https://www.frontiersin.org/articles/10.3389/fenrg.2020.00116/full?ref=dl-staging-website.ghost.io" rel="noopener">many other ways</a>.<br><br><strong>Why it matters:</strong> Batteries that last long, charge fast, and cost little are a key enabler for devices from self-driving cars to brain implants.<br><br><strong>We’re thinking:</strong> In our recent <em>Heroes of NLP</em> interview, Chris Manning joked that “electricity is the new AI.” Maybe he was right! You can watch the whole thing <a href="https://www.youtube.com/watch?v=H343JRrncfc&list=PLkDaE6sCZn6Hmo-Hbqp00dRCrDcOV5AYr&index=1&ab_channel=Deeplearning.ai&ref=dl-staging-website.ghost.io" rel="noopener">here</a>.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://bit.ly/3YTVMir"><div class="absolute inset-0" data-gtm-event-title="Generative AI for Software Development"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-62/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-62/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-62/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm27" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-62","id":"60c02fd7274d5b003b1064f8","uuid":"d59428c2-0c63-4d30-b39d-2538674731d8","title":"The Batch: AI Researchers Under Fire, RL Agents in Danger, Bias in Synthetic Data, One Neuron to Rule Them All","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eToday Landing AI, where I am CEO, launched \u003ca href=\"https://landing.ai/platform/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eLandingLens\u003c/a\u003e, an AI-powered platform that helps manufacturers develop computer vision solutions that can identify defective products. For AI to benefit a wide range of industries, we need platforms that enable experts in a variety of fields to build and deploy models. LandingLens is a step in this direction, and it’s available to manufacturers immediately.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eA major challenge to taking advantage of AI throughout the economy is the sheer amount of customization needed. To use computer vision to inspect manufactured goods, we need to train a different model for each product we want to inspect: each smartphone model, each semiconductor chip, each home appliance, and so on. How can Landing AI build models for thousands of products without hiring thousands of machine learning engineers? It’s much better to empower the manufacturers to build and deploy these models themselves.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eLandingLens enables experts in manufacturing — rather than experts in machine learning — to collect data, train models, deploy them, and carry out continuous learning. It helps them make sure their models work and scale up deployments. If the test data distribution drifts and the algorithm’s performance suddenly degrades, they’re empowered to collect new data and retrain the model without being beholden to an outside team.\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-gif-maker2022.gif\" class=\"kg-image\" alt=\"LandingLens platform\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eHere are a few unique features of LandingLens:\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003e\u003cem\u003eRather than holding the training set fixed and trying to improve the model, we hold the model fixed and help manufacturers improve the training set. We’ve found that this approach leads to faster progress in production settings.\u003c/em\u003e\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003e\u003cem\u003eRather than focusing on building models that recognize defects better than humans can, our tools aim to improve human-level performance. The better humans can recognize defects, the more consistently they’ll label those defects in training data, and the better the trained models will be. This is a very different philosophy from usual in AI research, where the goal often is to beat human-level performance.\u003c/em\u003e\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cem\u003eHaving led AI teams at large consumer internet companies, I believe it’s time to take AI beyond the technology industry, to all industries. We’ve been building this platform for over a year, and I’m excited to be able to talk about it publicly. I hope that LandingLens — and other verticalized AI development platforms to come — will lower the bar for industrial deep learning and spread the benefits of AI throughout the economy.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"news\"\u003e\u003cstrong\u003eNews\u003c/strong\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-gif-maker2023.gif\" class=\"kg-image\" alt=\"Data related to a system that purportedly identified breast cancer\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"pushing-for-reproducible-research\"\u003ePushing for Reproducible Research\u003c/h3\u003e\u003cp\u003eControversy erupted over the need for transparency in research into AI for medicine.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Google Health introduced a \u003ca href=\"https://www.nature.com/articles/s41586-019-1799-6?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003esystem\u003c/a\u003e that purportedly identified breast cancer more accurately than human radiologists. But the search giant’s healthcare division failed to disclose details that would have enabled others to reproduce its results, dozens of critics wrote in a letter to \u003cem\u003e\u003ca href=\"https://www.nature.com/articles/s41586-020-2766-y?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eNature\u003c/a\u003e\u003c/em\u003e (also published on \u003cem\u003e\u003ca href=\"https://arxiv.org/ftp/arxiv/papers/2003/2003.00898.pdf?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eArxiv\u003c/a\u003e\u003c/em\u003e).\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eThe critique:\u003c/strong\u003e Researchers at Harvard, University of Toronto, Vector Institute, and elsewhere argue that AI systems used to diagnose life-threatening conditions should meet high standards of transparency. The Google research fell short on several counts:\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe authors didn’t release the trained model for others to verify their results.\u003c/li\u003e\u003cli\u003eAlthough they mentioned the framework and libraries used, they omitted training details such as learning rate, type of optimizer, number of training epochs, and data augmentation techniques. That’s like listing the ingredients in a cake recipe without disclosing the amounts, Benjamin Haibe-Kains of the University of Toronto, who co-authored the critique, told \u003cem\u003eThe Batch\u003c/em\u003e.\u003c/li\u003e\u003cli\u003eOne dataset used in the study, \u003ca href=\"https://arxiv.org/abs/2004.04742?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eOptimam\u003c/a\u003e, is readily available. However, the authors also used patient data that remains private. In lieu of that dataset, the critics argue, the authors should have disclosed labels and model predictions that would allow for  independent statistical analysis.\u003c/li\u003e\u003cli\u003eOther details were also missing, leading to questions such as whether the model trained on a given patient’s data multiple times in a single training epoch.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eThe response:\u003c/strong\u003e In a rebuttal published in \u003ca href=\"https://www.nature.com/articles/s41586-020-2767-x?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003e\u003cem\u003eNature\u003c/em\u003e\u003c/a\u003e, the Google researchers \u003ca href=\"https://pbs.twimg.com/media/EkTQgmZWsAk3JK8?format=png\u0026name=large\u0026ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003esaid\u003c/a\u003e that keeping the model under wraps was part of “a sustainable venture to promote a vibrant ecosystem that supports future innovation.” The training details omitted are “of scant scientific value and limited utility to researchers outside our organization,” they added. They held back the proprietary dataset to protect patient privacy.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e AI researchers are struggling to balance trade secrets, open science, and privacy. The U.S. \u003ca href=\"https://www.fda.gov/medical-devices/workshops-conferences-medical-devices/public-workshop-evolving-role-artificial-intelligence-radiological-imaging-02252020-02262020?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eFood and Drug Administration\u003c/a\u003e hosted a workshop earlier this year aimed at developing best practices for validating AI systems that interpret medical images.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Transparency makes it possible for scientists to verify and build on their colleagues’ findings, find flaws they may have missed, and ultimately build trust in the systems they deploy. Without sufficient information, the community can’t make rapid, reliable progress.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e There are valid reasons to withhold some details. For instance, some datasets come with limitations on distribution to protect privacy. However, outside of circumstances like that, our view is that researchers owe it to each other to make research findings as reproducible as possible.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-gif-maker2016UNITS.gif\" class=\"kg-image\" alt=\"Graphs and examples of Network dissection technique\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"what-one-neuron-knows\"\u003eWhat One Neuron Knows\u003c/h3\u003e\u003cp\u003eHow does a convolutional neural network recognize a photo of a ski resort? New research shows that it bases its classification on specific neurons that recognize snow, mountains, trees, and houses. Zero those units, and the model will become blind to such high-altitude playgrounds. Shift their values strategically, and it will think it’s looking at a bedroom.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2009.05041?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eNetwork dissection\u003c/a\u003e is a technique that reveals units in convolutional neural networks (CNNs) and generative adversarial networks (GANs) that encode not only features of objects, but the objects themselves. David Bau led researchers at Massachusetts Institute of Technology, Universitat Oberta de Catalunya, Chinese University of Hong Kong, and Adobe Research.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e Previous \u003ca href=\"https://arxiv.org/abs/1412.0035?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ework\u003c/a\u003e discovered individual units that activated in the presence of specific objects and other image attributes, as well as image \u003ca href=\"https://journals.plos.org/plosone/article/file?id=10.1371%2Fjournal.pone.0130140\u0026type=printable\u0026ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eregions\u003c/a\u003e on which individual units focused. But these efforts didn’t determine whether particular image attributes caused such activations or spuriously correlated with them. The authors explored that question by analyzing relationships between unit activations and network inputs and outputs.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The authors mapped training images to activation values and then measured how those values affected CNN classifications or GAN images. This required calculations to represent every input-and-hidden-unit pair and every hidden-unit-and-output pair.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe authors used an image segmentation network to label objects, materials, colors, and other attributes in training images. They chose datasets that show scenes containing various objects, which enabled them to investigate whether neurons trained to label a tableau encoded the objects within it.\u003c/li\u003e\u003cli\u003eStudying CNNs, the authors identified images that drove a given unit to its highest 1 percent of activation values, and then related those activations to specific attributes identified by the segmentation network.\u003c/li\u003e\u003cli\u003eTo investigate GANs, they segmented images generated by the network and used the same technique to find relationships between activations and objects in those images.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The authors trained a \u003ca href=\"https://arxiv.org/abs/1409.1556?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eVGG-16\u003c/a\u003e CNN on the \u003ca href=\"https://github.com/CSAILVision/places365?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eplaces365\u003c/a\u003e dataset of photos that depict a variety of scenes. When they removed the units most strongly associated with input classes and segmentation labels — sometimes one unit, sometimes several — the network’s classification accuracy fell an average of 53 percent. They trained a \u003ca href=\"https://arxiv.org/abs/1710.10196?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eProgressive-GAN\u003c/a\u003e on the \u003ca href=\"https://www.yf.io/p/lsun?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eLSUN\u003c/a\u003e dataset’s subset of kitchen images. Removing units strongly associated with particular segmentation labels decreased their prevalence in the generated output. For example, removing a single unit associated with trees decreased the number of trees in generated images by 53.3 percent. They also came up with a practical, if nefarious, application: By processing an image imperceptibly, they were able to alter the responses of a few key neurons in the CNN, causing it to misclassify images in predictable ways.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e We often think of neural networks as learning \u003ca href=\"https://web.stanford.edu/~jlmcc/papers/PDP/Chapter3.pdf?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003edistributed representations\u003c/a\u003e in which the totality of many neurons’ activations represent the presence or absence of an object. This work suggests that this isn’t always the case. It also shows that neural networks can learn to encode human-understandable concepts in a single neuron, and they can do it without supervision.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eYes, but:\u003c/strong\u003e These findings suggest that neural networks are more interpretable than we realized — but only up to a point. Not every unit analyzed by the authors encoded a familiar concept. If we can’t understand a unit that’s important to a particular output, we’ll need to find another way to understand that output.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e In 2005, neuroscientists at CalTech and UCLA \u003ca href=\"https://www.scientificamerican.com/article/one-face-one-neuron/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ediscovered\u003c/a\u003e a single neuron in a patient’s brain that appeared to respond only to the actress Halle Berry: photos, caricatures, even the spelling of her name. (In fact, this finding was an inspiration for Andrew’s \u003ca href=\"https://static.googleusercontent.com/media/research.google.com/en//archive/unsupervised_icml2012.pdf?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eearly\u003c/a\u003e \u003ca href=\"http://www.robotics.stanford.edu/~ang/papers/icml09-ConvolutionalDeepBeliefNetworks.pdf?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ework\u003c/a\u003e in unsupervised learning, which found a neuron that encoded cats.) Now we’re dying to know: Do today’s gargantuan models, trained on a worldwide web’s worth of text, also have a Halle Berry neuron?\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-gif-maker2019.gif\" class=\"kg-image\" alt=\"Takes from Agence, an interactive VR project\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"rl-agents-sos\"\u003eRL Agents: SOS!\u003c/h3\u003e\u003cp\u003eA new multimedia experience lets audience members help artificially intelligent creatures work together to survive.\u003cbr\u003e\u003cbr\u003eWhat’s new: \u003ca href=\"https://www.agence.ai/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eAgence\u003c/a\u003e, an interactive virtual reality (VR) project from Toronto-based Transitional Forms and the National Film Board of Canada, blends audience participation with reinforcement learning to create an experience that’s half film, half video game. The production, which runs on VR, mobile, and desktop platforms, debuted at the \u003ca href=\"https://www.labiennale.org/en/cinema/2020/venice-vr-expanded/agence?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003e2020 Venice Biennale\u003c/a\u003e exhibition of contemporary art. It’s available for download from \u003ca href=\"https://store.steampowered.com/app/1308040/Agence/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eSteam\u003c/a\u003e.\u003cbr\u003e\u003cbr\u003eHow it works: Five cute, three-legged creatures live atop a tiny, spherical world. They must learn to work together to grow giant flowers for food without throwing the planet off-balance. Players can simply watch them work or play an active role in the story by planting flowers or moving agents around.\u003c/p\u003e\u003cul\u003e\u003cli\u003ePlayers can let the agents interact under control of a rules-based algorithm or turn on a reinforcement learning (RL) model that drives them to seek rewards, such as bites of fruit, and avoid repeating mistakes, such as falling off the edge of the world.\u003c/li\u003e\u003cli\u003eThe agents were pre-trained in a stripped-down version of the game world using a method called \u003ca href=\"https://openai.com/blog/openai-baselines-ppo/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eproximal policy optimization\u003c/a\u003e, which makes RL less sensitive to step size without the tradeoffs incurred by other approaches. The game’s creators settled on PPO because it was quickest at training the agents to solve the game’s physical challenges, such as learning to balance their weight to keep the world from spinning, technical director Dante Camarena told \u003cem\u003eThe Batch\u003c/em\u003e.\u003c/li\u003e\u003cli\u003eThe developers are collecting data on how users interact with the agents. They’ll use the information to update the training simulation monthly.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Agence director Pietro Gagliano \u003ca href=\"https://www.theverge.com/2015/9/15/9328673/virtual-reality-wins-first-emmy-sleepy-hollow?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ereceived\u003c/a\u003e an Emmy in 2015 for a VR experience in which viewers encountered the Headless Horseman from the \u003cem\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Sleepy_Hollow_(TV_series)?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eSleepy Hollow\u003c/a\u003e\u003c/em\u003e TV series.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Agence represents a new type of medium in which the audience members collaborate with AI to create unique, immersive experiences. It offers new possibilities for user input and interactive storytelling that — whether or not Agence itself catches on — seem destined to transform electronic entertainment.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Video game opponents driven by rules can be challenging, but imagine trying to outsmart the cops in \u003cem\u003eGrand Theft Auto\u003c/em\u003e if they could learn from your past heists.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM \u003ca href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eDEEPLEARNING.AI\u003c/a\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/1-3.gif\" class=\"kg-image\" alt=\"1-3\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003cp\u003eHave you completed courses 1 and 2 of the \u003cem\u003eGenerative Adversarial Networks Specialization\u003c/em\u003e? Course 3 will be available on Coursera next week! Pre-enroll \u003ca href=\"https://www.coursera.org/learn/apply-generative-adversarial-networks-gans?ref=dl-staging-website.ghost.io\"\u003ehere\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-resize2020.gif\" class=\"kg-image\" alt=\"Contrast between real and real and synthetic datasets\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"battling-bias-in-synthetic-data\"\u003eBattling Bias in Synthetic Data\u003c/h3\u003e\u003cp\u003eSynthetic datasets can inherit flaws in the real-world data they’re based on. Startups are working on solutions.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Generating synthetic datasets for training machine learning systems is a \u003ca href=\"https://www.startus-insights.com/innovators-guide/5-top-emerging-synthetic-data-startups?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ebooming business\u003c/a\u003e. Companies that provide such datasets are exploring ways to avoid perpetuating biases in the source data.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The cost of producing a high-quality training dataset is beyond the reach of some companies, and in situations where sufficient real-world data isn’t available, \u003ca href=\"https://arxiv.org/abs/1909.11512?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003esynthetic data\u003c/a\u003e may be the only option. But such datasets can echo and even amplify biases including potentially harmful \u003ca href=\"https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003esocial biases\u003c/a\u003e. Vendors like \u003ca href=\"https://aireverie.com/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eAI.Reverie\u003c/a\u003e, \u003ca href=\"https://www.genrocket.com/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eGenRocket\u003c/a\u003e, \u003ca href=\"https://hazy.com/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eHazy\u003c/a\u003e, and \u003ca href=\"https://mostly.ai/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMostly AI\u003c/a\u003e are looking for ways to adjust their synthetic output — “\u003ca href=\"https://slate.com/technology/2020/09/synthetic-data-artificial-intelligence-bias.html?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003edistorting reality\u003c/a\u003e,” as Hazy’s chief executive put it — to minimize the risk that models trained on their wares will result in unfair outcomes.\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn a recent \u003ca href=\"https://mostly.ai/2020/05/08/diving-deep-into-fair-synthetic-data-generation-fairness-series-part-5/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eexperiment\u003c/a\u003e, Mostly AI generated a dataset based on income data from the \u003ca href=\"https://archive.ics.uci.edu/ml/datasets/Adult?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003e1994 U.S. census\u003c/a\u003e, in which men who earned more than $50,000 outnumbered women who earned that amount by 20 percent. To generate a more even distribution of earning power, the company built a generator that applied a penalty when the ratio of synthetic high-earners who were male versus female became lopsided. That approach narrowed the gap to 2 percent.\u003c/li\u003e\u003cli\u003eThe company also generated a dataset based on the infamous Compas recidivism dataset, which has been \u003ca href=\"https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eshown\u003c/a\u003e to lead models to overestimate the likelihood that a Black person would commit a crime and underestimate that likelihood for a White person. The initial synthetic dataset skewed toward Black recidivism by 24 percent. The company adjusted the generator using the same parity correction technique and reduced the difference to 1 percent.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Social biases in training datasets often reflect reality. It’s true that altering synthetic datasets to change the balance of, say, men and women who earn high incomes is trading one type of bias for another, rather than eliminating it altogether. The aim here is not necessarily to generate accurate data but to produce fair outcomes.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e We need data, but more than that, we need to build models that result in fair outcomes.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/Batteries1.png\" class=\"kg-image\" alt=\"Information and components of a battery\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"getting-a-charge-from-ai\"\u003eGetting a Charge From AI\u003c/h3\u003e\u003cp\u003eMachine learning is helping to design energy cells that charge faster and last longer.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Battery developers are using ML algorithms to devise new chemicals, components, and charging techniques faster than traditional techniques allow, according to \u003cem\u003e\u003ca href=\"https://www.wired.com/story/ai-is-throwing-battery-development-into-overdrive/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eWired\u003c/a\u003e\u003c/em\u003e.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works\u003c/strong\u003e: Designing better batteries involves tweaking variables such as electrode architecture, chemical composition, and patterns of current and voltage during charging. Typically, researchers change one at a time and can’t analyze the results until a battery dies. AI lets them test many at once and get results while the battery still has juice.\u003c/p\u003e\u003cul\u003e\u003cli\u003eResearchers from MIT, Stanford, and the Toyota Research Institute test the longevity of prospective designs in machines that discharge and recharge them repeatedly. They trained a \u003ca href=\"https://www.nature.com/articles/s41586-020-1994-5?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003emodel\u003c/a\u003e on data from these rigs to find better ways to recharge lithium-ion batteries without degrading their working lifetime. The model enabled them to complete in 16 days experiments that ordinarily would have required 500.\u003c/li\u003e\u003cli\u003eA model at Argonne National Laboratory is \u003ca href=\"https://pubs.rsc.org/en/content/articlelanding/2019/SC/C9SC02834J?ref=dl-staging-website.ghost.io#!divAbstract\" rel=\"noopener\"\u003esifting\u003c/a\u003e through a massive molecular database to find energy-storing chemicals. The model’s creators are also developing a platform that would let researchers and companies train their models using other people’s data without compromising anyone’s intellectual property.\u003c/li\u003e\u003cli\u003eA machine learning platform developed by California-based Wildcat Technologies helped InoBat, a Slovakian startup, develop a lithium-ion battery that purportedly \u003ca href=\"https://inobatauto.eu/docs/World-first%20intelligent%20battery%20launch.pdf?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eincreases the range of electric vehicles\u003c/a\u003e by almost 20 percent. InoBat plans to begin producing the batteries by the end of 2021.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e In recent years, machine learning has also helped researchers discover new molecules that \u003ca href=\"https://pubs.rsc.org/en/content/articlelanding/2019/TA/C9TA06748E?ref=dl-staging-website.ghost.io#!divAbstract\" rel=\"noopener\"\u003eimprove energy density\u003c/a\u003e, \u003ca href=\"https://www.sciencedirect.com/science/article/pii/S1876610218313419?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003epredict how batteries will perform\u003c/a\u003e in different electric vehicles, \u003ca href=\"https://www.frontiersin.org/articles/10.3389/fenrg.2020.00116/full?ref=dl-staging-website.ghost.io#B69\" rel=\"noopener\"\u003etest\u003c/a\u003e how well capacitor designs store energy, and advanced battery research in \u003ca href=\"https://www.frontiersin.org/articles/10.3389/fenrg.2020.00116/full?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003emany other ways\u003c/a\u003e.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Batteries that last long, charge fast, and cost little are a key enabler for devices from self-driving cars to brain implants.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e In our recent \u003cem\u003eHeroes of NLP\u003c/em\u003e interview, Chris Manning joked that “electricity is the new AI.” Maybe he was right! You can watch the whole thing \u003ca href=\"https://www.youtube.com/watch?v=H343JRrncfc\u0026list=PLkDaE6sCZn6Hmo-Hbqp00dRCrDcOV5AYr\u0026index=1\u0026ab_channel=Deeplearning.ai\u0026ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ehere\u003c/a\u003e.\u003c/p\u003e","comment_id":"60c02fd7274d5b003b1064f8","feature_image":"https://dl-staging-website.ghost.io/content/images/2021/06/ezgif.com-gif-maker2022.gif","featured":false,"visibility":"public","created_at":"2021-06-08T20:04:55.000-07:00","updated_at":"2022-10-06T15:53:01.000-07:00","published_at":"2020-10-21T12:00:00.000-07:00","custom_excerpt":"Today Landing AI, where I am CEO, launched LandingLens, an AI-powered platform that helps manufacturers develop computer vision solutions that can identify defective products. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"60c03006274d5b003b1064ff","name":"issue-62","slug":"issue-62","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-62/"},{"id":"60cc31e670a082003e13dd60","name":"Oct 21, 2020","slug":"oct-21-2020","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/oct-21-2020/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-62/","excerpt":"Today Landing AI, where I am CEO, launched LandingLens, an AI-powered platform that helps manufacturers develop computer vision solutions that can identify defective products. ","reading_time":11,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"AI Researchers Under Fire, RL Agents in Danger, Bias in Synthetic","meta_description":"The Batch - AI News \u0026 Insights: Controversy erupted over the need for transparency in research into AI for medicine | How does a convolutional neural network recognize a photo of a ski resort?","email_subject":null,"frontmatter":null,"feature_image_alt":"LandingLens platform","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/06/ezgif.com-gif-maker2022.gif","dimensions":{"width":576,"height":324}},"banner":{"title":"Generative AI for Software Development","databaseId":35156,"id":"cG9zdDozNTE1Ng==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/08/Vertical-side-banner-ads-5.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3YTVMir","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-62"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>