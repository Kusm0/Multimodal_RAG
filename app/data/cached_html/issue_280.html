<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, and more...</title><meta name="description" content="The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-280/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-280/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2024-12-18T12:00:00.000-08:00"/><meta property="article:modified_time" content="2025-02-13T14:04:48.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="Dec 18, 2024"/><meta property="article:tag" content="issue-280"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-280/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32--1.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32--1.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="675"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2024-12-18T12:00:00.000-08:00","dateModified":"2025-02-13T14:04:48.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, and more...","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32--1.png","width":1200,"height":675},"publisher":{"@type":"Organization","name":"Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, and more...","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-280/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 280</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Dec 18, 2024</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">14<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/dec-18-2024/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Dec 18, 2024</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">14<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-280/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-280/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-280/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p>Dear friends,</p><p>I’m thrilled that former students and postdocs of mine&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3lJW3T2Kh61hRqtsW1JtsWY8TpQ8vW7mp25p45438WN258BYBFZphzW7C7jpx3BK7t0W5TwYfs3tmfqHW33_fqh3sYgVdW81WG_G6R59-GVZSCSs9fb3v-N23mdhkyzq30W1_kZZ668dR4xW4GptYX1qLzSWW5cr5Js5Xnz0LN36WG6mFw0Y1W3MzHzh7J46xqW6N-v_J7F2202W3G_5nx4xKBsfVN0hrc6HwlJTW1RYGfZ1MczqrW7dfnJ76Vf9gxV1JBFw5Nl4gpW5XwrY31mSs01W6JysM98CCRVkW7v-93Z3Dkj8PW24G0vv5412JBW3vHPjs2MV2bzN2P50ZPGvSzfW6fN2wC6xdJB4W4sxHty3Q2HTnV2Fb--93gfz2dgkR6n04?ref=dl-staging-website.ghost.io" rel="noopener">won</a>&nbsp;both of this year’s NeurIPS Test of Time Paper Awards. This award recognizes papers published 10 years ago that have significantly shaped the research field. The recipients included Ian Goodfellow (who, as an undergraduate, built my first GPU server for deep learning in his dorm room) and his collaborators for their work on generative adversarial networks, and my former postdoc Ilya Sutskever and PhD student Quoc Le (with Oriol Vinyals) for their work on sequence-to-sequence learning. Congratulations to all these winners!</p><p>By nature, I tend to focus on the future rather than the past. Steve Jobs famously&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3n4W3_-r-W84wnj8W7Qtsbm60wWsVW1LlX3K5sl5_7W2MgX8L9cxM2FVlHpnZ5BrG19W2-lcpj4qlm5hW85wVh88-PFgmW41N3BY2rPd1VW7CPp6G8VlRFCW2V2fyn3hPvt7W6zdt3r9kBwTNN8MqZkck76M4W8Xjq8l8n_tyYW7sF44W1WTkH1V2pyfG8t8bLFW7mdnGy3M7WGfW5zt2Gq621lVlW2Nds8n7kpH9pN3jC8ZbPRJPGW82V5Vv8CMwxNVF--ch6R9KwpW2Vc-SD5gdT5HW5NZFpX2s_fYzW6sjTL05cSS61W26gbYk8BnLbtW8_mgXS48hpf2W4N-Gfp7p8XfQW3_QJr045ygHSVG6sB-5gSFVMN3nWJc0j_jRcW1KpXwM1_4GC9W4cmvwJ2fkL1Xf3bw7-404?ref=dl-staging-website.ghost.io" rel="noopener">declined</a>&nbsp;to build a corporate museum, instead donating Apple's archives to Stanford University, because he wanted to keep the company forward-looking. Jeff Bezos encourages teams to approach every day as if it were “Day 1,” a mindset that emphasizes staying in the early, innovative stage of a company or industry. These philosophies resonate with me.</p><p>But taking a brief look at the past can help us reflect on lessons for the future. One takeaway from looking at what worked 10 to 15 years ago is that many of the teams I led bet heavily on scaling to drive AI progress — a bet that laid a foundation to build larger and larger AI systems. At the time, the idea of scaling up neural networks was controversial, and I was on the fringe. I recall distinctly that, around &nbsp;2008, Yoshua Bengio advised me not to bet on scaling and to focus on inventing algorithms instead!</p><p>A lesson I carry from that time is to not worry about what others think, but follow your convictions, especially if you have data to support your beliefs. Small-scale experiments performed by my Stanford group convinced me that scaling up neural networks would drive significant progress, and that’s why I was willing to ignore the skeptics. The diagram below, generated by Adam Coates and Honglak Lee, is the one that most firmed up my beliefs at that time. It shows that, for a range of models, the larger we scaled them, the better they perform. I remember presenting it at&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3nZN1clRG9-xcXmW6LM7sF41KGQRW9c_fmX6FsSZWW2FLBXT6HB405W7302sw1y43FFW6ty9qn4n8nvtW4jBPHY5p6dY4W69yf9N92vCvHN1TZ7sf6xD7HW1wMz5_7mkjvDV-N0s38Fk6pYW2hbMzH6VTFGtW6SdbCK4-VHlPW3h12Km8k_DgsW6gq2Cw72QkQyW2Z45KG4HGWgfW6Gn5nP8hhNKKW4kLy_X1j9xX0N3t_dF_35s6pVYpBdM5SLwyhW7RCKb48dz5fmMVfzFFLwLphW2dTm6f1H9KlqW74J6J91f1PnvW26_ywZ7Cv91xW6Dgzp-7TjbVNW2g9jKK6lggblV_sTMp3B-znmVlh0p02xPv2dW7LCCRH2w8pg0f20cy8-04?ref=dl-staging-website.ghost.io" rel="noopener">CIFAR 2010</a>, and if I had to pick a single reason why I pushed through to start Google Brain and set as the team’s #1 goal to scale up deep learning algorithms, it is this diagram!</p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32-.png" class="kg-image" alt="Graph showing cross-validation accuracy vs. number of features for raw and whitened inputs." loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--32-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--32-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32-.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>I also remember presenting at NeurIPS in 2008 our&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3mGN3yphdrjvHGZW6_n0-q2tvbDKW7W1W776bD3tRW7JLmy96j91X7W8Sn2y51tCBrTW2F5g2r1hxDpZVdTzGk989fY8W7KndVg8Bs4RpW1ltFr645-wPpW3v4g9v1y_CypW50n-Wb1_rQ6tW1jjpk54nmGQgW3d3J0j8DDMC1W182CQg4mx3C9W5DTnSn4DPHvJW1_Nrr91q2-6VW2xM_1S5147nvW8BBHXW3w9Sz1W14Tc-f2xXC4yW4drrhz6KvyWRW2BDXmp47hJ0PW6hzcJF50yvSTW7qMqCy6FXGWQW6nKKvQ5c7fnXW7HpXJ58yyY7zW1jgm0L1WF0mQf3y9nG604?ref=dl-staging-website.ghost.io" rel="noopener">work</a>&nbsp;on using GPUs to scale up training neural networks. (By the way, one measure of success in academia is when your work becomes sufficiently widely accepted that no one cites it anymore. I’m quite pleased the idea that GPUs should be used for AI — which was controversial back then — is now such a widely accepted “fact” that no one bothers to cite early papers that pushed for it.😃)</p><p>When I&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3pPW1cQ4pF5jhFNlW1RNksF84CPbHW1tlbMg1ykbh9W32wF5C3mKxWLW3s0_8q5qxXPyW1D5Lpf1QfDtpW2vCyKF6q97DpW5KkQqH8c6V1mW7LSLxz7qxhtTW81__rH4stTm-W9fxThQ655w1KW7bl8gj5-SW6RW2HLXPX8jyqw4W2F-0-92StYQtW821Pbb19r21sW4gp1y24K9J9NW1N6sHD9ltx96N7QjfP6GHM89N3KwFDLyLQHNW1VNHRz6KZ2SkW7qq6sc4h_yMkW1Wfrg47XJLV4W81YN-64zbMSKVyCN911N4x2cW7bdRG62rmSYVW1TDN6C1WBQt4f4lCv1204?ref=dl-staging-website.ghost.io" rel="noopener">started</a>&nbsp;Google Brain, the thesis was simple: I wanted to use the company’s &nbsp;huge computing capability to scale up deep learning. Shortly afterward, I&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3pbN95F1_c3czdnW2kXP-w4__TrrW34g89C3d0KWLW1ZfzCM2btrszW6LJYFy5lbrgyW3g6W665dG9XkN6f-1zM9TxzPW6zrvvs7r_HzjW3x7qy29gqDyhVCDRF630R0nSW7cy_mc8qzHYSW85sHdh6VYSs8W38wtQP843_W_W29yP_c8_3WqHN9fDy2S5xDmqW5W0gPy5jp2Q8W5N0DQz4HQdnbW7zJw-230fPqKW2r8MBZ11QPJYW1gbYlX48wsrbW5QCyh295tMyXW1cScLT1QVV1-W4v1QPg5WcM5rW7rp_nz6jJ3Ggf95d9Hn04?ref=dl-staging-website.ghost.io" rel="noopener">built</a>&nbsp;Stanford’s first supercomputer for deep learning using GPUs, since I could move faster at Stanford than within a large company. A few years later, my team at Baidu showed that as you scale up a model, its performance&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3m6W3N0HhV7nTx5KW4zLfsL3B6JH4W6T7DhT6nqGY5W7V6S6F1Mzg_DW3RmNM63GmGftVkkXvD8_NBm-W7FkMky80kXX2W3RHS0Y2gTy50W6Kc5h38_F_C7V8cGkB2hZhKXW59_8c67zh1lmW4WmGlv7ZF9gFW984cmr4gSx0NW7Tt3bG7vhFTHW79fDjS36K9mJN4Hst9M2_X0QW11R0ZF302-jTW5XlSTK7BlvPKW5fj5124lC5bbN47Mk6TStvLdW6c8Sq110fws1W8HMCVv6Lyqk7W81TBS98-NmNsW2c4-HX5sC32Sf6x4tTM04?ref=dl-staging-website.ghost.io" rel="noopener">improves</a>&nbsp;linearly on a log-log scale, which was a precursor to OpenAI’s scaling laws.</p><p>As I look to the future, I’m sure there are ideas that many people are skeptical about today, but will prove to be accurate. Scaling up AI models turned out to be useful for many teams, and it continues to be exciting, but now I’m even more excited by upcoming ideas that will prove to be even more valuable in the future.</p><p>This past year, I spent a lot of time encouraging teams to build applications with agentic AI and worked to share best practices. I have a few hypotheses for additional technologies that will be important next year. I plan to spend the winter holiday playing with a few of them, and I will have more to share next year. But if you have an idea that you have conviction on, so long as you can do so responsibly, I encourage you to pursue it!</p><p>Keep learning,</p><p>Andrew</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/reasoning-with-o1/?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png" class="kg-image" alt="Promo banner for &quot;Reasoning with o1&quot;" loading="lazy" width="1890" height="1063" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png 1890w" sizes="(min-width: 720px) 720px"></a></figure><p>In our latest short course, you’ll learn how to use OpenAI o1 for advanced reasoning in tasks like coding, planning, and image analysis. Explore tradeoffs between intelligence gains and cost as well as techniques, such as meta prompting, to optimize performance.&nbsp;<a href="https://www.deeplearning.ai/short-courses/reasoning-with-o1/?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll now!</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--33-.png" class="kg-image" alt="Benchmark results for Phi-4, GPT, LLaMA-3.3, and Qwen 2.5 models." loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--33-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--33-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--33-.png 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="phi-4-beats-models-five-times-its-size">Phi-4 Beats Models Five Times Its Size</h1><p>Microsoft updated its smallest&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3nWW24271h7nfgx1W1N1kQz8qyz3KW4SnV0H568b6bN1qf6MNhlJGsW7nYKsN2q24gDW3flkW89l3Y10W6RQnQy4zVXPyW7Fg5xc7PRrgrN7Bh1S95C8y6W6gxnZ28JvLwMW78jxWS5ydBBQW6cGK5_1fN9vLW2Ywpkk37dfNSW8gR0Gz63YSS8VW1ZX47bDZY5W8QdK874ZnpqDW64qsLN6k3ym4W9fDYLY3pX2p9W39q94R1LJd7dW3n-dDr3pJXCQW33NN494_Ck6sW8Rykxx6T1r4cW4CTLBV4DQNPdW7bMj8k50M2VVf8Q8WZg04?ref=dl-staging-website.ghost.io" rel="noopener">model family</a>&nbsp;with a single, surprisingly high-performance model.</p><p><strong>What’s new:</strong>&nbsp;Marah Abdin and a team at Microsoft released&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pwW6Sp4rK3GbwYZVK3_7c2kDnNpW6_6C3_4jkZXhW5JvBB26Xys6bW71vKbM5TWFF6W73XmJN14BNlmW1Ql8826DMVJhN59HSH9J6ZpmN1-NpvVQxDnNW8981GL6FY2tbW4w0fxL8Cq9DlVk3c5s4Kh-kzW7W5PsG7278cLW8j9ZSq2SBfHSW1kDm382t8GN5V_b9196T-QBSW7kmy742BnCx8W5h-t7H6btCsqW2lfrGt14zKZYN2G7nFYfmRxVM32rKk_7mN-VMrT3H3L49Pwd1WwwY04?ref=dl-staging-website.ghost.io" rel="noopener">Phi-4</a>, a large language model of 14 billion parameters that outperforms Llama 3.3 70B and Qwen 2.5 (72 billion parameters) on math and reasoning benchmarks. The model is available at&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3nMW8LKGpb6H6nKRW39HQ2d3NYBvTW8Pdrpj4h3Mp6W1PSx4g3wG7FDW53KR2y2cXT13W5xPCmj6rN_r_W6g0bHm6ls9WCW3Y225S8l-w9YVZ4cnS8vzSwsW7S5cWR2L5n-HW4f18296FJhWwMt-YkFFxWhrW73MK-02plSLlW2G6bnp67MdLxN65_FCrLPSnCW26119Q24VrftW21-jjv63rd5jW96s2kK19Ly-wN5Zcl-p5DHHqVJtbBk36_7NkW1QlXyb50HsQgW6wvZdG2m_hsbW7lc13X76wCbTVFcF8y195CdzVsPW-g7XqDDCVXNNQ2108y1CdwSLfz04?ref=dl-staging-website.ghost.io" rel="noopener">Azure AI Foundry</a>&nbsp;under a&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3nSVSz1Sk5T9sc3W8nTDSK5TR0bkW8kzpCq7PfHQ6N2cPk0PjW7LNW69GVdP51xfwNW6ks5xk4PRbF4W27_VD63dsXYCN1QZ53my1KfxN61KVZyFydQHW1p2Jql7j2xVqW1RwsH24C799PW22pymJ1bDCk5W3VM7Lf30yqDtW1VXd0M3xJBcQN9hJ01SsJc8SW2hRySr4-9Z_1W5MNsBl8-8sgRW91SH3b6gNfcDW7nKKXx5PBPV1W2nZ51V412TGjW3d5N_h8M0q0ZW5HLWZh4TjZpvVVHJgt6BTncXW6qwq2j1Qdd1cW8642N_7PDz9SW3PDW2b3J1LyNW8B7-Zt122LJvW30fpp84X_QJHW6X_tZB5yS-43W1mr8gq2ZN9gMW1WMvXN7Sjwx9W6qMX713C_pt_f3KYghT04?ref=dl-staging-website.ghost.io" rel="noopener">license</a>&nbsp;that permits non-commercial uses, and the weights will be released via&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7t43qgyTW8wLKSR6lZ3lyW4H3w-B1bfvk7VYMJC11mQXX-W8VLk1n8DVzSqW1F8NZZ1GYyhYW3Qv7Mv6lVHMqW246w0962z8b9W1ggrqD1zrh7LVm3hVT3syrNRW28N_8L6kN1-bW99FKlv3zk0qMW7D7pnb8rDCMjN2CQTRS_ShYbW6g3_mK8KnKpBW7jy1X028fRdSW3QwZj-4DjSr7W7HzPzB20hF4bW7cRCK17ShcV1W4V8TqQ2BqbhbW1ktmnq8Hzy3-W7vwtZL5wJY-FW7X9N0s7MmtQhMJ7gsQX99bVW3Tq2zm7PBK_SW3QLW8K72_RpKW3s2xHS3Mhh_HN88WDcc3gyVlW2VmFjh2SYbX9W1WQ3h48bdPW_f76YD2004?ref=dl-staging-website.ghost.io" rel="noopener">Hugging Face</a>&nbsp;next week.</p><p><strong>How it works:</strong>&nbsp;Phi-4 is a transformer that processes up to 16,000 tokens of input context. The ways the authors constructed the pretraining and fine-tuning datasets accounts for most of its performance advantage over other models.</p><ul><li>Much of the pretraining set was high-quality data from the web or existing datasets. The authors used known high-quality datasets and repositories of high-quality web data (like books and research papers). They also filtered websites using classifiers they trained to recognize high-quality text.</li><li>The rest of the pretraining data was generated or rewritten by GPT-4o. Given snippets of text from web pages, code, scientific papers, and books, GPT-4o rewrote them as exercises, discussions, question-and-answer pairs, and structured reasoning tasks. GPT-4o then followed a feedback loop to improve its accuracy by critiquing its own outputs and generating new ones.</li><li>The authors fine-tuned Phi-4 on existing and newly generated data they acquired in similar ways.</li><li>They further fine-tuned it on two rounds of generated data using&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7t43qgyTW8wLKSR6lZ3lmW4rmcNk6BTVd3W55vCTH5G1B--Vzvy8D7dzRZ2W12C9fb65-ZnZW5nNfzr1m4dxMW4QqmKV7JQnKcW3b-0713qbzwkW5F96Qn15p-W-W23z2LT5xrsryW8vsYD070nHRYW6ydWKc5BG9HZW2q0nG64Y05TSW60pQY_5v3F38W7H4ZTS4Y5tXdN7P5bwqDqBTYVyk--b5Kg1qTW6xlRhk3S33QNW95kv9h4H467fW4ncLmc2nJW38W4PB6sj5BWmT6Vgkbjp7yN5G9W57V90P7C6fHJW2Rsm9c4-q80gW447NJ71TZVwTW2YvMKW8wdTn-W4wcdlb6KZDvPW9gn5_z6YCW6-W4d8Gcf5nD7B7f3R5MxC04?ref=dl-staging-website.ghost.io" rel="noopener">Direct Preference Optimization (DPO)</a>, which trains models to be more likely to generate a preferred example and less likely to generate a not-preferred example. In the first round, the authors generated preferred/not-preferred pairs by identifying important tokens in generated responses: They considered a token to be important if, after the model generated it (as part of a partial response), the probability that it ultimately would produce a correct output significantly improved (or declined). They measured this probability by generating multiple completions of a given prompt and determining the percentage of times the model produced the correct answer after generating a given token. The preferred/not-preferred pairs (in which one element of the pair is composed of an input, token(s) to generate, and preferred or not-preferred label) took tokens generated prior to the important token as the input, the important token as the preferred token, and the important token that decreased the probability as the not-preferred token.</li><li>In the second round of generating preferred/not-preferred pairs and fine-tuning via DPO, the authors generated responses from GPT-4o, GPT-4 Turbo, and Phi-4, and then used GPT-4o to rate them. Highly rated responses were preferred, and lower-rated responses were not preferred.</li></ul><p><strong>Results:</strong>&nbsp;Of 13 benchmarks, Phi-4 outperforms Llama 3.3 70B (its most recent open weights competitor) on six and Qwen 2.5 on five.</p><ul><li>Phi-4 outperforms Llama 3.3 70B, Qwen 2.5, and GPT-4o on&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3lrW495vP740qPgTW25CR0Q3JfYPdW11r07l5qGV4NW8Jp_MW2bJ49FW1JWK7D5K_W68W4vXJKk68NyL6N8YX8qMC5s5xW2QTy4f8B5hf1W7Fj4nv2fzfcMW1QZ04b4LpJtXW8GTnPG6HW36rW1gdbxf406S3yW5XV0Rs5r9W_FW7794wJ6FGv7ZT-wLh89CbkqW6zBg075pmqsQVZ5WwJ7nk1_8W7k9j1m98R8X-W3MGjqy1PW3zWW691kWh49Wv8RW5xCDzm1rfyTCW9dv24-6W9ZtzdsF-rK04?ref=dl-staging-website.ghost.io" rel="noopener">GPQA</a>&nbsp;(graduate level questions and answers) and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3lsW263H4J4wx8lVW4hxXZ890XSBZW2clqYc6LG-djW6SW8293LTH8WW9fw4V87jZ7JQW7j5MdM2GhjDlW4tKpcT8d7rlMW6J_qyQ8pHRPfW48R-VZ1clQZPW75pJPc8dkgyNW9d7lK62nVvNCVBN_MX8lNknhW1XN3QP4hyYr-W610NMz6BsSnfW7nGYbj6FvfVWW5l7Jy47WJT7KW7jhGKw2vXmtkN7-vY_MvnJ14W3kZtgQ6j40-VVKh-z567kb3BW5pHY7885qfKdW7c-10S3NszvLf5nlZyK04?ref=dl-staging-website.ghost.io" rel="noopener">MATH</a>&nbsp;(competition-level math problems).</li><li>However, Llama 3.3 70B wins&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3nnN6_pZnJxHMl9W3250d66d8xWFW3gdjMm340bknW6g6R926bv-sfW6DZF284Ln91cW3sHGVM60qrYfW6JzMn_6yRRzBW9bmqJ-1B2sK8W3FSxQJ9jkNSYW2pnLZd2cCVPZW5mkZJ56TT23zW8TjsmB6LQy0FN4FhwNTJSfD0W8lvfqH6ywYhHW6XMXsj4Ck8CXN8sw2Jh7ChdgW1cGbrz3d168lW3fPw6J23dMypW3LfdPp5HcVFPW7nCvdD7506WNN7RbtWzQ90H8W1b5C1y7J22t3f4Yf2LK04?ref=dl-staging-website.ghost.io" rel="noopener">DROP</a>&nbsp;(reading comprehension) and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pTVBszKN1lCzTxW1Mg0q42PHbJdW3KF84q5Z1D2tVFMMjq47254_W4ngBgk8nRMPBW5ffzV85gyj6PW6cQGKk5m74cLW7BvnS76JtrMVW6WkBHg8BTspBW2zcwfx99v4cSW8Gvrc74RjDMWW2Cg4gn1M3bYrW352Hbm5y2G4NW73DCns3kT2TLW2LFKH77Mbs3cN6r6v4bxpnvsVJQlQ51n85GtW48bZl17qgrQJVVHFcP15xTGfN8B5qr9vlPd1W2sLNy_7QbLCtW4Km6Hr7fzgL5f249tXg04?ref=dl-staging-website.ghost.io" rel="noopener">SimpleQA</a>&nbsp;(answering questions about basic facts). Llama 3.3 70B also performs significantly better on IFEval (instruction-following).</li></ul><p><strong>Why it matters:</strong>&nbsp;Phi-4 shows that there’s still room to improve the performance of small models by curating training data, following the age-old adage that better data makes a better model.</p><p><strong>We’re thinking:</strong>&nbsp;Some researchers&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3n5W152-5K97C3_ZW3cGXDk60FY9vW5zm66k7_vb3VVKpnTD2RSfv5W3QGq6X8VcVgFW7yD3tx1R9BtjW7r10tp5b6JyqVRqQS5475Fp-W5xQJCT4VjfP9W8N0v7m2z9PL2W1pKJ_X6xxnPRW2MyT457Qq0XDVk6xh61mynfGW2pfJld2RHvbvW1FGD3Z1CRXZhW543g8D5CJK8rW6tvYT131xxxDW8-1FSl1-vJMcW1d_kk-9c2T9_W5s2t5m5ZQPByN63fvS0BsZhWN5DhzdXkLQ5mf32WLgj04?ref=dl-staging-website.ghost.io" rel="noopener">found</a>&nbsp;that earlier versions of Phi showed signs of overfitting to certain benchmarks. In their paper, the Microsoft team stressed that they had improved the data decontamination process for Phi-4 and added an appendix on their method. We trust that independent tests will show that Phi-4 is as impressive as its benchmark scores suggest.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--39-.gif" class="kg-image" alt="A GIF with scenes of a man at a café, a working robot, a ghost in a mirror, and a speeding truck." loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--39-.gif 600w"></figure><h1 id="open-video-gen-closes-the-gap">Open Video Gen Closes the Gap</h1><p>The gap is narrowing between closed and open models for video generation.</p><p><strong>What’s new:</strong>&nbsp;Tencent released&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3lpW7mzLrL1PMYDnT-14m7JMbH6VW3XS85btjmWW8zp7xz4Qg9vTW8cqK7V4pvzbgVYWLMb17HbPJW97z9Vs7VLTbtW89MkfQ72rVvxVhCDpJ6HFD6JW6L_y3T4Bf1tVW3BL3GW1G6x3TVShBcT7VP3xjW3BZt8h2hlyF9W354M5S31gTTvW463P8572_wFXW3RrsPY7GCgd4W5YX72q5BNT_DW3KPskg2bbbVpW1xPZ-36-rQ_fW4GVnYl1TpS4vW8nkzN68hMqtwW5dfTPH75kQPSf2y_SZF04?ref=dl-staging-website.ghost.io" rel="noopener">HunyuanVideo</a>, a video generator that delivers performance competitive with commercial models. The model is available as&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3nXW4pmLhw4PVBgFW7zHR2X6JKTBTW8Hr8g963qDfbN1vMcB5fQCQKVhhVqw7m0rTSW16D_MM22nH5GW4dGQMQ49gHd7VhPd_G1zCCHgW2_BcFV2X6fRNW8JnXZr23_t-7W3ldLw47fnTLMW6lrB003KlMvdW7lRw0h65zFj_W8ZC3s_7ZhX49W7KqzB22z7Ld4V_421g9hXHb_W8d6Djs7rCshRW33LzsS37xZVBW2v4_8Z3F640fN5NJnSw14J4KW1hZRyb22_McnN88DSnG1Zl6cW8k21Q53KzBn3W6HbqZb5t1mHvf74qpwP04?ref=dl-staging-website.ghost.io" rel="noopener">open code</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3nLW3vjgcN68ghTTW86xSNF19JzjpN72XxsYWYJW8W7c0_8p60Q11MW6L8QYB4ckvtxN1J-vpVBxqgqN88yvpGFRwBDW444Nj18Kx8hfW699Yss8grDvRVG9rSn3hghvtW2Z2c-46VHHkZW1CbL6P75qJBwW7mHk_g5Tq01vW5PSS378SSJXLW8Nt9wS6SzprMW2cnypx7ljrMZW28PScZ8MfVtHW1w1Fm96rDM3RW7lnZqf4LbNBPW25rGWs6z52c4W3T31wZ77t7gpVNWVXK5-txKzW2mM9CQ3gFtM4W7NLrrh5tD-dZf2dL41l04?ref=dl-staging-website.ghost.io" rel="noopener">open weights</a>&nbsp;for developers who have less than a 100 million monthly users and live outside the EU, UK, and South Korea.</p><p><strong>How it works:</strong>&nbsp;HunyuanVideo comprises a convolutional video encoder-decoder, two text encoders, a time-step encoder, and a transformer. The team trained the model in stages (first the encoder-decoder, then the system as a whole) using undisclosed datasets before fine-tuning the system.</p><ul><li>The team trained the encoder-decoder to reconstruct images and videos.</li><li>They trained the system to remove noise from noisy embeddings of videos. They started with low-resolution images; then higher-resolution images; then low-resolution, shorter videos; and&nbsp; progressively increased to higher-resolution, longer videos.</li><li>Given a video, the encoder embedded it. Given a text description of the video, a pretrained&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3pYW4JSD4k918pxYW1m3BKq2j1JL3W4rsZTk6MfJtNW7J065r2xxnW0W2XDyqZ6Mx3FkW3MbMxn5-fjj-V9KzBt4rM0k-VhqmVL1VzL-kW8ynXj52_sVvHW5Tpgmt8T9kFnW68gJ_4220j6GW2LHjWS4lGSs4W1mwXMn7tcTk1W7s137455TtqGW48rnwY2ptvqmW4t0jrL1ThxsyV6f8395Q00HKW4q3x7689lGRYW6Pt6fp79Q5cxVN9QSZ9ff3nsW5RHPkM6dkFYKVyqGmy8Y6ZGbW1_-wKl6ysrdnW5gXdZR3BQ-f9W3x1Jvp92D7NDW2B-ctm83ct80W8-xFRs14b9_2W4-JDz01MFf7yW7nD8nT2NMHV9W3jMs4H3W9Z7NN86NYnTQk1ZtW4RS6z32y8F2mf6jXqGT04?ref=dl-staging-website.ghost.io" rel="noopener">Hunyuan-Large</a>&nbsp;produced a detailed embedding of the text and a pretrained&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pWVc1CS55VC4X6W3mR0vY6tv3qSW490xrp1tpcq7W1GqZ9r313PM3W5VrVb73647dnW8vDRjn9l-s9PW1zqgMF2RSckBN78vWqYm_1jCW5vyK6s432my5W5RqD7f3dXKQWW80ZF-y6chM-5N6KTky_64lJcN61hbX_1q8cwW5Sbp4S4CPd1wN93lFxZRnYd9W4RwQ3Y18ZMjBV_z2wb4MK0DsW94j8PH4Wzy9bN59ftd1yVDpBVZfngT3fkkGjW3DnzzC7pQQ16W2sHp188tZHYCf40NrBF04?ref=dl-staging-website.ghost.io" rel="noopener">CLIP</a>&nbsp;produced a general embedding. A vanilla neural network embedded the current timestep. Given the video embedding with added noise, the two text embeddings, and the time-step embedding, the transformer learned to generate a noise-free embedding.</li><li>The team fine-tuned the system to remove noise from roughly 1 million video examples that had been curated and annotated by humans to select those with the most aesthetically pleasing and compelling motions.</li><li>At inference, given pure noise, a text description, and the current time step, the text encoders embed the text and the vanilla neural network embeds the time step. Given the noise, text embeddings, and the time-step embedding, the transformer generates a noise-free embedding, and the decoder turns it back into video.</li></ul><p><strong>Results:</strong>&nbsp;60 people judged responses to 1,533 text prompts by HunyuanVideo,&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3lPW1-r2Cj84X2yWW5JPnVm3lw_HNW4DNv5M3_wQ_-N7gQhlmRk-1xMGsbzNChJw9N4wh4Jy_M-tJW8nBTK15MXjjlW8CqBDY1hyr0HN799TwQdBChlW3N9Q1D8ksdjHW56jZZD1t7Pf_W23p02G7XDMN3N4DbLKJMJ_hLW87HsCc32pt90W1qTTQG3M8LnwW8w2ryd8pbHkRN6T1Y32zT-WWW4hyr1B2S-SnjN8FWVD5WThzBW16yK0v5Pc9ZGW3MmkXX6kLlXdW3hnqjW1ZkR3JW62sh0s15M92_W66Y3Yv5-6dNXf364px404?ref=dl-staging-website.ghost.io" rel="noopener">Gen-3</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3kPW5bnv4m3VBpPHW8ZW0-W7ld7PVW891gZv3--1Q-W8PsLXW5JJX6xW2g1xsH2KQx5xVHdFdG1ZSDD1W33KRLD4zQywgW8PtB928-P2nPW2SlQtt51r1KWW2vvb6s4TsT98W3lHzYs57TkypN90ft7MjkwWlW4dY5xQ3_GY-FMSPZHjDFgpHW5VKZ6l41SMJ9W1tDjfC4yV0LnW5g0-R97hsZg_W4X-Fx769z8hRW2Q54K_6rwBHLW6BwZ4Y7CfM63W2nG42j8ZDTwLW3k193K4N5tVwf8gLClR04?ref=dl-staging-website.ghost.io" rel="noopener">Luma 1.6</a>. The judges preferred HunyuanVideo’s output overall. Examining the systems’ output in more detail, they preferred HunyuanVideo’s quality of motion but Gen-3’s visual quality.</p><p><strong>Behind the news:</strong>&nbsp;In February, OpenAI’s announcement of&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3lYN3y_s5-pLnpqW3X7Gyp82p9kTW3CB80F4z1ZRsW7-x42N579jbNW27Y_Rv88CKKTW41qP8d8x_LbjW2vFLGL843qJDVjQHdF5SSDlJW4nYRGw55r05XW8vTdP_6X2R9bW5L4J92679MR5N6DXyTT7msHDVvCxYz2sqMWmW9f46-72-hvP3W4sFPfc5GKqFKW33T3c62kXNn-Vq_R8W73Ch93V_W-DY85S44SW33C4V61v7PdSN8LXjY3Nm_PsW6nq4vK55cy1GW1DB_G74RDhY-W17j9kl52NtNHW3zYPFb4VT4wKW7wjz4c7lXM6kW976K-G5jYBslW7Bkz124wx33tV5kKz126Q1jLW5jb7vf649j59W6rxpM_3V8Y91f3T8JNK04?ref=dl-staging-website.ghost.io" rel="noopener">Sora</a>&nbsp;(which was released as this article was in production) marked a new wave of video generators that quickly came to include Google&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3nqW21VKC55p4VgXW6bj4Pl4d8BMcV2yzty3jzlpRW6-LgNg8kn81BW2g1qWm1P53QxW5CXWlm74mwJZW1Z2wYY6fMQ46W3B_QRh6sb5HpW4QTd_M4yzc6DW7xTmfQ6HHPClW1pJNzC6R9-vnW7nBDJP6Zmll7W1lMm5V4vMfm0LhXm0tdC1WW8N7mY13Hc9VPW5P2s7K6ZMnMvW7PD0RW5Qjnm7W52s9QX2-Hp8BW3QQQrN836lZ5W2Q_Bfb2Hn9DgW8BL53327vnGRVwVPZq536W4VW2xL7Ml6bt-YzW5WDZgM12Lq51W6dkw5N53_1fnW2mYV7D2S7X0SW3cpnKD6lxvHpW3gD-Tn65wx6cW43yfDh3v-t4zW67Yz3128_D9RdNWM_F04?ref=dl-staging-website.ghost.io" rel="noopener">Veo</a>, Meta&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3lKW4Ch0QT2yGfqnN8yVbQ7_H62xW2FfmKT6T8DH6W6-6lVh1ZylDKW98JRbY5XK-C-W7Yfl2L1lfdxLN2clJrGWV4NhW3vYyP41_PRhsW5fhyps7gmPTRW4fhP8g8cMKh7W5hCmsH2FXcFHW8VwHm84LVfLYN6S_gRxFBKm-W4qnQ9G8d9jR1N7GPK-wPScd6W6GxV394Z47w0W3_8nC94-xphLW6rZhtX97zT1MW6mTqnv4DnFPHW5JW8jz3rJ9HGW9kN-SG6cZqkbN3FpDL74yx3tW3KHSfH6Vb61vW5vgJ9H4W-yj5W7t-Z-t7pLFZMW1W5TgX4l2JgmW8Rm6S67y1DbhW8KnHmm7pk0x9W750TY-4rnw5fW59nygT2_0V0dW6rXz_54Frz-mW6WfHGC5Qnl0sf76zywP04?ref=dl-staging-website.ghost.io" rel="noopener">Movie Gen</a>, Runway&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3nPW4GVgjw3WcC9lVLZbMq2-K_-LW8JK9M37fWbxnW50ySyT3Wn962W5KRvWK8Vxc0sW67NN_k501mWtN3-Cp7BlxLs-W2vBmf73lwpz5W8tvsrr7dzyQBW29stdY5f8T8_W5K75bG3mn4_QW3KP_V16Hs1xFW285Pq93RfLWnW8V5sZG1Hz5tjW7PHX0Y7LLL65W47BMnH3C-RFBW3bzTKb6qwPbKW4t_jRF4nXm5ZW11hJ_F22wBNYVm_K-j6XJ3XYN5V1p9RTGgTDW8KZzbg38y0YYW52qx1h2K_ZClW5q59Xm4t2qC5f7vfbH804?ref=dl-staging-website.ghost.io" rel="noopener">Gen-3 Alpha</a>, and Stability AI&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3m-W88d_qW1t3k7gW5vcWKH33mMHyW6dJD587SS5VrW2nXlQf97LSvzW1G6k9w39P1c5W10SwhY6ZZX_qW5Vrrvk7S25x9W3Pwby87S-k9sW229N8m5PGV9PW1qPc3V7yRBc3VDlBZJ8kXbXlW12Ld9K64rFvnVPnG8R2kfWV9W4NMcw628HGtzW20ldKv828lPyN6rGgG_hXGThW5XCPRN1kr7Z3W1H9c2x4GgbsDW5PC2xL7Gf5CsN8B3DSyvs2ZDN82hdg9chlP4VqT0f26BB5ZGf7k7zx804?ref=dl-staging-website.ghost.io" rel="noopener">Stable Video Diffusion</a>. Open source alternatives like&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3p5W76w-td6BLqCFW5Jp2dz3-5wTWW2K4gwl8y5Y8RVg0f8W6m8lBLW9cJb2j8TDR34W3fvRzf7WS6mxW48NcSZ6cd8z4W97mP2y2VC2S_W4tnXD89l4N4ZVpXzGM1RNlkCW6hHDHk6ZfBmCW8Gr85N66FKQRW9lfYtB81T3NcW36Qgr15Q8dG3M2x7lFQrSCtW2V_gbW44VjhdW5PjmjC6bVblnW7fBC2Z1vDmV5W7LCJRg7ll1njW33qWGp67LVKSW40wTx63JHhzVW169-V16qPV4xf8ssLDg04?ref=dl-staging-website.ghost.io" rel="noopener">Mochi</a>&nbsp;continue to fall short of publicly available commercial video generators.</p><p><strong>Why it matters:</strong>&nbsp;Research in image generation has advanced at a rapid pace, while progress in video generation has been slower. One reason may be the cost of processing, which is especially intensive when it comes to video. The growing availability of pretrained, open source video generators could accelerate the pace by relieving researchers of the need to pretrain models and enabling them to experiment with fine-tuning and other post-training for specific tasks and applications.</p><p><strong>We’re thinking:</strong>&nbsp;Tencent’s open source models are great contributions to research and development in video generation. It’s exciting to see labs in China contributing high-performance models to the open source community!</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--40-.gif" class="kg-image" alt="Performance comparison for Gemini models across benchmarks." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--40-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--40-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--40-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="multimodal-modeling-on-the-double">Multimodal Modeling on the Double</h1><p>Google’s Gemini 2.0 Flash, the first member of its updated Gemini family of large multimodal models, combines speed with performance that exceeds that of its earlier flagship model, Gemini 1.5 Pro, on several measures.</p><p><strong>What’s new:</strong>&nbsp;Gemini 2.0 Flash processes an immense 2 million tokens of input context including text, images, video, and speech, and generates text, images, and speech. Text input/output is available in English, Spanish, Japanese, Chinese, and Hindi, while speech input/output is available in English only for now. It can use tools, generate function calls, and respond to a real-time API — capabilities that underpin a set of pre-built agents that perform tasks like research and coding. Gemini 2.0 Flash is&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3lKW8c5hrT6Dt0JdW471Z0S4wh_QcW7wHHqV2dxkTkW2xql-Z81np14N3fWNfCB6JgvW85KhzW6tzpW5W4d5v9g6KwScmW5xvbn-8sQHhGW34j1nP2HKJ-3W6D-Gc61DwX3BN2tyNZtMJgWzW5rbxhk4J6j0jW4WtTpZ5LSK8PN2ZB1k3mn4PjW7tQk4x6vTG94W1nmxfG97LhTmN2QfN5xjqdhCW4whbcS1fdWn_W2bpVPn2gxTjTW26H_X587y9G1W5k_ktp9bS1JKW1cC69s5Mlp3BW2J9Lyw5rx6yTN24VsmFxDbM2W411Yf12ZjhMBVz6Rvm87VrrCf3_RV5604?ref=dl-staging-website.ghost.io" rel="noopener">available</a>&nbsp;for free in an experimental preview version via Google AI Studio, Google Developer API, and Gemini Chat.</p><p><strong>How it works:</strong>&nbsp;Gemini 2.0 Flash (parameter count undisclosed) matches or outperforms several competing models on key benchmarks, according to Google’s report.</p><ul><li>Gemini 2.0 Flash is faster than Gemini 1.5 Flash. It offers relatively low average latency (0.53 seconds to receive the first token, just ahead of Mistral Large 2 and GPT-4o mini) and relatively high output speed (169.5 tokens per second, just ahead of AWS Nova Lite and OpenAI o1 Preview but behind Llama),&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3p8W12s7mv8htlBHVJgLmB9ccYCSW7f2kd33pSF0xMG0jYy6cMJRW30P7KW6Q6gCBW6PH0Rj33g9s1W3MlfMB4hFlyxW1nZJz91D53YDW4Ml_y94zPrZxW3rvB47114mVZW1CD12V58LbVGW4fqR9M5kHyl5W11v1Jl8jqkkMW3QJ5dB8jr3lzW4h7mwP5ZrCp0W13vpZ48ZvYd9W40TkQw2G_S0lW5_x6cW40_ZyHN7l32Pq5WKzbW467k416wwCGKW7NrPBj6KTffZW8nR7lC22bbQsW8Kqwcw2w_klmW4q4Vp_84JV8CW1MJldw9k297RW7Fp7gv8xg1-Vf3gqFq404?ref=dl-staging-website.ghost.io" rel="noopener">according to</a>&nbsp;Artificial Analysis.</li><li>It beats Gemini 1.5 Pro on multiple key benchmarks, including measures of language understanding (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pHN73WlcFzm_68W5TbmFn8bBy49W3Dgr8F1Sy71hW1cc9xy5J4BkhW3K_TWc4NwN4DW72td0x8CLnjKW72S1LX8F-KN7W2kZ7Mn2DgnWNW1DZPtw53GR89VlftcP87fyR1W72-gjY6tClGdW15wFdz1kzt6YW2q8bdq4rWcmWW8Kq1rq5wgGH7W74swpZ7r6DCwW47pSy18-JDnpW3L88Xv1ZPzSJMzsdyRlkY6WW8TCZgH7cK9dfW89zMFF4TXqY_MtsXPc1dplZW3XsPgY5P7b1ydH1gyl04?ref=dl-staging-website.ghost.io" rel="noopener">MMLU-Pro</a>) and visual and multimedia understanding (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pRW7sxmVz69yY3BW98kc773Z5LCzW8qTjDR1mBwZbW3QnmdQ1PtN2-W4ZTMTy8zfvC5W4GCZh27DSFtnW3XkkPL5cWqQ1TKtPZ2QFkGyN1KsSPkHc6G_VHFL60275mHBW8rxZyY3G6SNNW5px0JS1CrB7lV913QZ8bkGs0W1tqHCt36brxlN1MrK91h7LMwW3Q4S393bQ32jW3Tsz8P1rFd_sW8VgbNy3L_4d6W4ZcygQ1zsnjHW4ng0n32NYQmHW6rbPsw7F2sQQW4tsGc41JHpjMdPW4WW04?ref=dl-staging-website.ghost.io" rel="noopener">MMMU</a>). It also excels at competition-level math problems, achieving&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3m3N7q-PNPM3KGCW8rr-fv8b745PW46BGjX5gJjjQW16z40h872TcqVb7h2-60FqWwW6B-80J73DMMxW6M00pg2FnMwfW69cQHv8n2hSZW11YGB-5KyL-nN4N9L-HQ282tN3S439177rvpW6xCQMj3Bch8mW25b6r78W0z5yW2yVZcR2gN28bW3lxmGR320NwRW6FRg0h5SLyPhW77pNXL3lG5zGN4CXj4WtxpjFW4HyxGh1NWQ7cW2v3PZD628SNQW5H8Qz114CF40W4YKPGR49Zl1zVrVtMY6TMgCRW7NlNtK8xtq9QVnjh0W5MFnmVVp2c-y1XPS2Df62FGC404?ref=dl-staging-website.ghost.io" rel="noopener">state-of-the-art</a>&nbsp;results on&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3kJW8zGTlX3HNzWQW1hF05_3nvdN6N4MRG1NJ2SzrW9gqDGZ6XPlLSVL5sBH6PjfYSW3ppsGz1S-qy8W1TH4262jgz0RW7Nyxyd7-SmSgN5Q41mC4Y9z4W875-xl1ljfY3W8FGZPf2l_0M7W5fz7Cb1VtMxnW93WpNY8vf_KnW8K1Wbn5LvmLVTQySS67q0BdN2zzLkTDVXz7VsX17_5H01gcW4hz7c11JBglqW1CHP8J4r55ygW2kZwtw8rDssFN2gzWzGmJ6NTW7chnzJ8fDBqpf4st5kz04?ref=dl-staging-website.ghost.io" rel="noopener">MATH</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3n2W7SYjM_6k8p4yW8NnsBF84wZHGW2h6wV17CMZ-bW350qRT92W5t_W6vZF3W5CJc88W4ZNR-_8LhqShW3DQxhY782QDpW6gQKJC7YH8JYW16K7Pk5vKMgRW18bP2X7SdYCDW2wpgH-7-d_lzW747xPk4m8QWmW9c67n249x5tSW4KMjxy1Bgk3yN4Vr17wgcpTFW1MZwJ58TsbYvW5QkgZS47XymPW5bRtLf1yt056VQFv3k3213_sW28NRZ45RzbtmW41C8B016SkHFMDqHBPVG_34W7kgVmp3BssdnVY6rhZ3GDC8rW2dSMl111tMx2W3mqq238NkPLrW5bQ_l91LXqC4W95-Xp131ngZDW4HPnQ88Xb9zFW6qq-V78JQNjgW4T-M905QVVVZN5-rWxxdVGPgdpvL0404?ref=dl-staging-website.ghost.io" rel="noopener">HiddenMath</a>. It outperforms Gemini 1.5 Pro when generating Python, Java, and SQL code (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3krN9lDJSjhp47MW92fPZy6qHVH_W73SQ-P4JGT2yW84Yw7L4vQ5fCVNXL047m82pLW2gCxzg1F8-3zN5tD-Ypc7bzpW8lV2qx8dt8TKW1cWJgD6wksSFW8F5kh_2lRQwRW4-HX9N433R5BW1KwLt57CTwh3W6kq6J84kVsg9N5lJ5WL64xpJW5Z4Ntz2m-zrLW75dY6b6s781KW6qqplW8qHBdrW3fsNCt8Y_wChW6cfFRT5G81V2W8gd6mD1RNzqqW5fPZz65-jd9NW37G9Sd9kGpN-f1t5SrP04?ref=dl-staging-website.ghost.io" rel="noopener">Natural2Code</a>) and (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3nzW2WcCZ04WvXrkW41th8T7qLTpJW8lVYB15L4VWcW4dts4w6c1-phW3bdFjk4h24KpW1tBCvl63Cv4VW4lSWtC1tSfD_W3xY9wq7YFHJJW1n5b8m7cxB-_W7nffsP7Tk46RW8zCJDz7m1R_vW8-DVdd3g6y4hN3jF01rNPdYYW40D5r51QKCQkW77XYtK58jg0rW7JK0GG22-yqVV6h2wc8k2nSDW7WmQyc3Y3sC9VC0mQd7HVKQ4VFVcZ_2d4T9vVyX9Lx20F6PPW6crpYn4jjf1Qf16GLkK04?ref=dl-staging-website.ghost.io" rel="noopener">LiveCodeBench</a>).</li><li>Compared to competing models, Gemini 2.0 Flash does well on language and multimedia understanding. On MMLU-Pro, Gemini 2.0 Flash outperforms GPT-4o and is just behind Claude 3.5 Sonnet,&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3mdW6D6Cf_8gNqglVFb4vg7Vt4qvW7pypMY5wTnTCW2nWq449b6cnyW3pGcGD6M7pB-W5Lk9sX7Sg-rLVH8pSZ4-PssWW3BQXLT4sn4lfW58yhsb3449DPW2sWbCs241B6NW56YyxF2_RG-VVNq4mQ125KtVVdrZ9N8Nb14SW7qts7y1cv2y9W4JDJRq69wRfhN524t8fHdqXkW7xcrcl8MCY3MW47rF6T6jXC05W1fvynV2mMJjfW3YBgWr8bDYgbW6kVMCL6PJBYDW2ytCDf6MSYWFVSgLJJ5l-Q1NW2Fx_HK7f4-PKf3y9z2n04?ref=dl-staging-website.ghost.io" rel="noopener">according to TIGER-Lab</a>. Google reports a score of 70.7 percent on MMMU, which would put it ahead of GPT-4o and Claude 3.5 Sonnet, but behind o1’s, on the&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3njN3fcGNsW44cnW6cLrDh6r10MHW3xtJ3z1PsmCbW1gppj11Yc46JN68_dZwRtT0mW6mpcbk8GSg2fW43L-651Jr2nYW3YJr-X7jpCGzW7L7BH15vB00sW5WztyV2QY2RxW7Mzdjx3-sHJ2Mvm15xmFhL8N3dF20wZDfTrF5Fc7kWXVsrW2gMSkk5cvksQW9c9lvY2hzMSDW86Yck77Gk-V-W6zPrht3Ndk3PW6VLd751y1jlmW6kxCl82MfybDW5r1cf32kcWCgW5g8Z0t3JqFzPf134cZ204?ref=dl-staging-website.ghost.io" rel="noopener">MMMU leaderboard</a>&nbsp;as of this publication date. It does less well on tests of coding ability, in which it underperforms Claude 3.5 Sonnet, GPT-4o, o1-preview, and o1-mini.</li><li>The&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3p1W4zRQ-F1cw_T3W43SkR-2cHh1TN83N8-YX3qwgVrqLL17KjkTdW4ghMvJ6y_Wh7W36TYbf7FdZ30W8s4vqj6dHf_yW823pdV1BRn9qV4y8cX8dCXbBVG6wVS7CwjSWW8Hdh4W7_Zq4NW26YzZn1hz76TW2tCpYK7L60hqW7H97R_1L_z15W5ncFlp581nwbVYLCL_7kwFPnN67BDFwgHJFHW3pJMZV31DX5CW8kS9fG56mGt7W94F97R72dcklW72zlk_2XbnvGN3dfZcjnzbWBW7CLvbd5S242MW7ZN6VR4VjFqsW62pKK44Y7GBcW3bwBsH7bj_BZW8KfN_Z362WR2W72C3cC3dbxGdW8dtHvP6mCHD_VHV-rC2hBzKXf2B-4wT04?ref=dl-staging-website.ghost.io" rel="noopener">Multimodal Live API</a>&nbsp;feeds live-streamed inputs from cameras or screens to Gemini 2.0 Flash, enabling real-time applications like live translation and video recognition.</li><li>The model’s multimodal input/output capabilities enable it to identify and locate objects in images and reason about them. For instance, it can locate a spilled drink and suggest ways to clean it up. It can alter images according to natural-language commands, such as turning a picture of a car into a convertible, and explain the changes step by step.</li></ul><p><strong>Agents at your service:</strong>&nbsp;Google also introduced four agents that take advantage of Gemini 2.0 Flash’s ability to use tools, call functions, and respond to the API in real time. Most are available via a waitlist.</p><ul><li><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3p-W8Kbcmy3V3-kXW2N0yng81d7m1W5QwTf55DTxPyW8MHPMq5vd-x3W2fxFbB3LDTMCW1-x0823HK6sYVw8FZ86l4ng2W3D5xv65MZRq6W8M3hFY2lhSw8W80Fm8C73JCVHW509Psl9l45zqW3RpV507vbkpCW93tNGS1nZQ-dW8fJmDW4RwVHpW6sWDXQ8R4x5wW5mM-LD76ByQsW51Jdt93BgDp8W2grbT-36wRSpW8x1-Yd5P-QKcW6yXNfn34LNv4F1QJ5JSpLm-W7szdQx6gTrNLW6m9PXl2YHL4WW3KQ4c37ddp01f8nT8FH04?ref=dl-staging-website.ghost.io" rel="noopener">Astra</a>, which was previewed in May, is an AI assistant for smartphones (and for prototype&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7t43qgyTW8wLKSR6lZ3lvW1pHLKr6xfVFDN3B0Zn0dQJSFW7hxRmR78XLBwW4NJPyx1Bm4k5W8ZKm7G6BD_BSW95br4M199v8MVwwn0h2v7Fv0W8t1vTK1-McvXN3n8406JLR7HW7fzGVC1CZJvhN6QQND0F9G4lW2RSSYl3tBPG4W67zBg78BHxxbW6pTZBl7HRRQVW3VP5rX8sHns7W6XTnxx3Jj-fLW77b-kp8lwdMVW2jQyDP4hCT_qW60JFnN4wqxJTW8wyHRt4yLy-1W8cr4m_7SyHgfW8DKkS0700xd_W8lqX-Z1NqGstW3nYDhP2CFqW8N5LhzJgRYMgVVXNC7Z4v8_GsF2qffF5nRwhW6p6qJD5qtcLMf43_nz-04?ref=dl-staging-website.ghost.io" rel="noopener">alternative-reality glasses</a>&nbsp;that are in beta test with US and UK users). Astra recognizes video, text, images, and audio in real time and integrates with Google services to help manage calendars, send emails, and answer search queries.</li><li><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3kNN5MHqlc9vHq5Ml60R4mKhy5W7tqm2W2gyjc5VjSrvb1dVRp9N64h_jcvFxYpW94_7Yh2XyjZRW4wym256Cykw1W530Nwh7cmPkrW3tCQTG3dQzhDW3SDTLW26Dh-FW7jc5xG8R0P_LW5Vnjpj4_V67mVddxWJ21CjtLW8vPYlH7_rV3rN4kDGsZSwY0rW8r3h0_2ySJNqW999S6k7R5ckgVr0QKC8WNvSxN6vbzFGdxWDZVG5qYh8mDJr-W919f8P87Z9HsW32qWPk9gZ_fNW87wJF17thtfRN3jFPkDVfCJWf7XTtQP04?ref=dl-staging-website.ghost.io" rel="noopener">Mariner</a>&nbsp;automatically compares product prices, buys tickets, and organizes schedules on a user’s behalf using a Chrome browser extension.</li><li><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3p_W7fPjqf172_58W1YsfTw8pXhrSW3lNBG986bn_LW44wbpn3Zln92VB78P22lrqKKW5XrxMr4tbWxWW1cHqcw5vQMPWW1qKNWv7x67p9W67GqYp84q07MW4mmBv26QTXNhW6Nx7xp14XY_jW85lhqj7MZpk7W2Tp82Q16S1psW77Mz6B6xGvNMW79zL3Q8dMYcdW4-jPhp7CSvj8W4Bqxs_3GlNhsW8lVlHh3JfGVPW5lH5pB1NPhpQW68pQ9c98Lnh7W9d9dgV3cflSMW6Z89rT3d6F4RW1TQf0f5PJG0DW4hwFVh1pbC3MW1MHFhp32NGz_W7KqWWp1Bh_Tkf3NvxfY04?ref=dl-staging-website.ghost.io" rel="noopener">Deep Research</a>&nbsp;is a multimodal research assistant that analyzes datasets, summarized text, and compiles reports. It’s designed for academic and professional research and is available to&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3m3VmzFjR3GKjlTN6knXmZ4SP3NW11Pfmw903lbBW4B6Cm695l_q6W54BVzy3ChsqXW268pQ263gmHWW7TBvcZ4ywPzwW66jGY71XbwJQW8lg19048K4Z-Mk0TZVhW4RTW2LXlP7424xDgW5bJFGS862PtfW3LH3yN7TnSyqW1TnrwL7kgf5-V49b072LNCgWW88q_-G4BX8zkW8JC-TS6p145cW88445F2Dq5gPW3Cr-Bc8Yv4NRW2qrnTF2Q7hX9W62WcCD2HHQ5qN6tH34RHCKjHf57rdwK04?ref=dl-staging-website.ghost.io" rel="noopener">Gemini Advanced</a>&nbsp;subscribers.</li><li><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3kWW4PJ0Wg6tDnJRV4JWbb7YnFC1N42J9351JJv3W605Ccb4Rgnp1W82LlTc5ZBL5HW3w0stk2lYVdrW70K5yr6hD6HTW1DWpph6JyVT8W8QrV9N75CznlW7m8vvV8lL_wdW7xYrcL5d5klZW3q-vjv495GBBW5G3vnw7zN_N1W59Sw3D4TBv5KW8wTb_y1NrxDcW1bs1pK3rY55RW30mnlW7HN-8fW9bYdZs8D7B87W2-zzvp7MxVWkW576R0t97kcrcW34wGzv3XhjhkN76kGWJfqY2VW93J2gx4Yk_39W1R2c715vFx2wW53rZbQ8LHMS9W1BMbl97lbPq8W84JjkN8zXzrZW7MfN-_3m_2jrW5C1g3l2xZMhlVGBsym6R7p_jf6K8n3T04?ref=dl-staging-website.ghost.io" rel="noopener">Jules</a>&nbsp;is a coding agent for Python and JavaScript. Given text instructions, Jules creates plans, identifies bugs, writes and completes code, issues GitHub pull requests, and otherwise streamlines development. Jules is slated for general availability in early 2025.</li></ul><p><strong>Behind the news:</strong>&nbsp;OpenAI showed off GPT-4o’s capability for real-time video understanding in May, but Gemini 2.0 Flash beat it to the punch: Google launched the new model and its multimodal API one day ahead of ChatGPT’s Advanced Voice with Vision.</p><p><strong>Why it matters:</strong>&nbsp;Speed and multimodal input/output are valuable characteristics for any AI model, and they’re especially useful in agentic applications. Google CEO Sundar Pichai said he wants Gemini to be a “universal assistant.” The new Gemini-based applications for coding, research, and video analysis are steps in that direction.</p><p><strong>We’re thinking:</strong>&nbsp;While other large language models can take advantage of search, Gemini 2.0 Flash generates calls to Google Search and uses that capability in agentic tools — a demonstration of how Google’s dominance in search strengthens its efforts in AI.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--41-.gif" class="kg-image" alt="Animation showcasing 7 key NLP topics visually expanding on the screen." loading="lazy" width="600" height="336" srcset="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--41-.gif 600w"></figure><h1 id="when-llms-propose-research-ideas">When LLMs Propose Research Ideas</h1><p>How do agents based on large language models compare to human experts when it comes to proposing machine learning research? Pretty well, according to one study.</p><p><strong>What’s new:</strong>&nbsp;Chenglei Si, Diyi Yang, and Tatsunori Hashimoto at Stanford produced ideas for research in machine learning using Anthropic’s Claude 3.5 Sonnet and human researchers, and also&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3l2W5yW_P75MtsD_N8pQ7dx5GCRxVgsLjP6jKTqCW44xvwW5hBXMHW9hNsVJ53_LRhW1-7LlW5p7DnLW68tCdZ4Pnsv8W27fJQ48mRX9bW6qR7sz56p9QGW7xH4HY793yL_W3-6rRv8lDdRpW1pXW8m1lcWR9W7S4SZV27TqTTW57XdP21zNC0xW4fHLZV2x5nQpW6TFyHf4wJ4svW7R8l3n5NgTKRVjDBT9320My4W56Z5Y01k6qT5W8gn3P64Ct4_gW3JC1t_5w_znfW7NSZ8J64gdlrf2rDjpb04?ref=dl-staging-website.ghost.io" rel="noopener">evaluated</a>&nbsp;them using both manual and automated methods. Claude 3.5 Sonnet generated competitive proposals, but its evaluations of proposals were less compelling.</p><p><strong>How it works:</strong>&nbsp;Each proposal included a problem statement, motivation, step-by-step plan, backup plan, and examples of baseline outcomes versus expected experimental outcomes.</p><ul><li><strong>Automated proposal generation:</strong>&nbsp;Given one of seven topics (bias, coding, safety, multilinguality, factuality, math, or uncertainty) and 10 related papers found by the Semantic Scholar search engine, Claude 3.5 Sonnet generated 4,000 research ideas. The authors embedded the ideas using&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3mLW43832822vYxLW82YDyp6h3xRqW5h_D0c1jR75GV4W3P28kzW6mW7qQh1s36JMw7W4fVnn-8tr9k0W48d9XN7W2cbcW1_lLPH7HdFdvW3nXNDJ7D7ZnfW8HK5Bt64hyBZW7d1PWt5QL-TqW3H4r0b3wX6DSW2_1Tps69j1j4W3XD6FH5k7RlSVCS0wf6p4Pl3W5yrBvJ8HzhsvW8TzHcf5y11T7W77CslQ32HP11VnXfhk2b4YWYN7TYhFDMY2dxW5VfbVY8Xgr9CN3tCVBZmgPV_W7xvpnw28t5c8W1R6rqJ3l-6SCVShWrN1pXHB8W1xn-NN1nJ8P1f4SLl4M04?ref=dl-staging-website.ghost.io" rel="noopener">all-MiniLM-L6-v2</a>&nbsp;and removed duplicate ideas based on the cosine similarity of their embeddings. This left roughly 200 AI-generated ideas for each topic. For each remaining idea, the model generated a proposal.</li><li><strong>Automated ranking:</strong>&nbsp;Claude Sonnet 3.5 ranked the proposals in a five-round tournament that awarded points for superior quality and pitted highest-scoring proposals against one another. In addition, one of the authors manually ranked the generated proposals.</li><li><strong>Human proposal generation:</strong>&nbsp;The authors paid 49 machine learning engineers to propose their own ideas. They obscured authorship by prompting an unidentified large language model to edit them according to a style guide. Then they manually checked the rewritten proposals to ensure that the model’s editing didn’t change their content significantly.</li><li><strong>Human ranking:</strong>&nbsp;A group of 79 machine learning engineers reviewed the 49 human-written proposals, the top 49 AI-generated proposals ranked by humans, and the top 49 AI-generated proposals ranked by AI (resulting in two to four reviews per proposal). They scored the proposals between 1 and 10 on five factors: novelty, feasibility, expected effectiveness, how exciting they were, and overall quality.</li></ul><p><strong>Results:</strong>&nbsp;Human judges deemed proposals generated by Claude 3.5 Sonnet as good as or better than those produced by humans. However, large language models proved less effective at judging the proposals’ quality.</p><ul><li>On average, humans scored the AI-generated and human-written proposals roughly equally in feasibility, expected effectiveness, how exciting they were, and overall quality. They deemed the AI-generated proposals significantly more novel. The top AI-generated proposals as ranked by humans achieved an average 5.78 novelty. The top AI-generated proposal as ranked by AI achieved an average 5.62 novelty. Human-written proposals achieved an average 4.86 novelty.</li><li>The authors found that LLMs don’t yet match human performance when it comes to judging scientific papers. They compared the rates of agreement among five LLMs that evaluated proposals in their experiment, human judgements of the proposals, and human reviews of papers submitted to the NeurIPS and&nbsp; ICLR conferences. The most consistent LLM, Claude 3.5 Sonnet, was 53.3 percent consistent with average human judgment. The human judges were 56.1 percent consistent. Reviewers for NeurIPS and ICLR were 66 and 71.9 percent consistent respectively. Random chance was 50 percent.</li></ul><p><strong>Why it matters:</strong>&nbsp;AI models play a growing&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3nTN8Hf0M07TqKmW98hRWz75mJDlV8wWKQ5QzFb4W3W8dp06cHM4QW1PWy_-8gsqypW3vFPwg2lpv0mW21C-W34BNxCwW8Cp05X8mPMbkW3RK1hD2TZ458W3zxW3w1RLzpHW5nZgBY60f-rnW4k7fnV1B3jZsVpPQ814LjXl3W5kb99K1D3wfTW7csbHb6Nb9SFVX55VN5f6ZqSW5PSRwl2XRrWzN1mjWP7MW6LtN8pYQlGFV1XHW3871kJ4sBSP1W99Fh1S76QpdQW6L2Q4r2G3QWZN2hz2mZGS4-VW8kBHV_2NVC01W4Hp-gD3GLcnSN307RbG1_l5gf5mT7ls04?ref=dl-staging-website.ghost.io" rel="noopener">role</a>&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3pFN8b2ZTwT6S_3W2wz8Ls2SnndDW6xcFfJ1hGksRW5rV9Pd4thpTrW37w9jP1LG2TwW96PCNd82Sj5CW4RF6km2nqYD1W5sr2Ct8LtPDdN7cCcjQPXYNBVNcQ1Q4D3csSW7FNttZ6jCC5JN98RtnDb5Y35W7C30W35L4nh4N5LWnzcQKFQQW6K6YP181tlD3W3_M4VD3NPsx5W7TQ2_Q3s9HRrW64fz_94kNLX0W7VMs2p1bC5jxVYTJD17xjPWcW14cftx33p11pW2P4D2M6MjssDW66vHpY5RtjnWW3TS53-4WCTfHF89-cpm7RDWW1GJgj96dlRK4f1_V8Tn04?ref=dl-staging-website.ghost.io" rel="noopener">in</a>&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rC5nR32W5BWr2F6lZ3mDW870w3q3-HYStW119w_85MVr67W977sW56jqj__W7tHnZ97DmDn_W1kwt0d8mH36xVXCKmg39MQGZW8mkKDP4GWW2zW2GjFSs2vYHsQN8YDK8WLJyRPW8YGN9D3mfSZQW11sPCD9k4QcXW1BQZYZ4b3KYvN6Mn-914-9tfW8y4gmC59qRJVW72flG61fxt-LW4RR49Z7mWj2QW8MGNHt92W0LXW98NkQn7xfgm5W1tnyrD5wMttyW7gKyWd9h8LLdW8ff-Kq87rF3KW5zwyw82VbM8lW736p807LYCLgW8XF0qR4tyF89W45Xyrv5jnqWGVgRnnD8wlXvDW4FmjMl5-tKKXVp0mGJ2pr7CkW7zVSXz7KJQV0N8PJdtBX6RgwW3scRvy91scXVW7T3M_87XVSsSW7jbv2y7pl8NMW4fHmWv4JL3X9f54h31q04?ref=dl-staging-website.ghost.io" rel="noopener">scientific</a>&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3lsW8nw3p44BCGTdN1dp9d5xSXMVW2VC5bY3F81_zVS4LvQ11r5GWW4wXc_15J1yM6Vjzf7c3VkjDKW77K5vK2mVLYtW1sqXJ286HcTmN17QJLvyKSqTN4bCVbshRct7W8kfqXz914XnRW5bt0G95KKlp6W23DJM31NnCsRW7JyRVW6XGw5ZW5-TQSl6LZVkQW5C8mVr2v0WHhW4LxfWR8FQZR8W7pFQXZ1-zccSW76DKJK7Cl_7PW18BdyS6hcP6RW1n8_Ft7H8KTKVt8NLv15tTrmW8ZthBW1ZsTcpW6hgZWf5TB6CMW66YDPw6kDHzHW27Npp15FwGb_f4zPYmK04?ref=dl-staging-website.ghost.io" rel="noopener">discovery</a>. This work shows they can set directions for research — in machine learning, at least —&nbsp; that rival those set by humans. However, human evaluation remains the gold standard for comparing performance on complex problems like generating text.</p><p><strong>We’re thinking:</strong>&nbsp;Coming up with good research ideas is hard! That a large language model can do it with some competency has exciting implications for the future of both AI and science.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="Mathematics for Machine learning and data science specialization. Enroll now to the course" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="Mathematics for Machine learning and data science specialization. Enroll now to the course" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/"><div class="absolute inset-0" data-gtm-event-title="Mathematics for Machine learning and data science specialization"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-280/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-280/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-280/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm88" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-280","id":"676325a54b838200017dcc41","uuid":"95b67b7d-2c9b-4eac-9423-e2f84007c631","title":"Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, Gemini 2.0 Flash Accelerates Multimodal Modeling, LLMs Propose Research Ideas","html":"\u003cp\u003eDear friends,\u003c/p\u003e\u003cp\u003eI’m thrilled that former students and postdocs of mine\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3lJW3T2Kh61hRqtsW1JtsWY8TpQ8vW7mp25p45438WN258BYBFZphzW7C7jpx3BK7t0W5TwYfs3tmfqHW33_fqh3sYgVdW81WG_G6R59-GVZSCSs9fb3v-N23mdhkyzq30W1_kZZ668dR4xW4GptYX1qLzSWW5cr5Js5Xnz0LN36WG6mFw0Y1W3MzHzh7J46xqW6N-v_J7F2202W3G_5nx4xKBsfVN0hrc6HwlJTW1RYGfZ1MczqrW7dfnJ76Vf9gxV1JBFw5Nl4gpW5XwrY31mSs01W6JysM98CCRVkW7v-93Z3Dkj8PW24G0vv5412JBW3vHPjs2MV2bzN2P50ZPGvSzfW6fN2wC6xdJB4W4sxHty3Q2HTnV2Fb--93gfz2dgkR6n04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ewon\u003c/a\u003e\u0026nbsp;both of this year’s NeurIPS Test of Time Paper Awards. This award recognizes papers published 10 years ago that have significantly shaped the research field. The recipients included Ian Goodfellow (who, as an undergraduate, built my first GPU server for deep learning in his dorm room) and his collaborators for their work on generative adversarial networks, and my former postdoc Ilya Sutskever and PhD student Quoc Le (with Oriol Vinyals) for their work on sequence-to-sequence learning. Congratulations to all these winners!\u003c/p\u003e\u003cp\u003eBy nature, I tend to focus on the future rather than the past. Steve Jobs famously\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3n4W3_-r-W84wnj8W7Qtsbm60wWsVW1LlX3K5sl5_7W2MgX8L9cxM2FVlHpnZ5BrG19W2-lcpj4qlm5hW85wVh88-PFgmW41N3BY2rPd1VW7CPp6G8VlRFCW2V2fyn3hPvt7W6zdt3r9kBwTNN8MqZkck76M4W8Xjq8l8n_tyYW7sF44W1WTkH1V2pyfG8t8bLFW7mdnGy3M7WGfW5zt2Gq621lVlW2Nds8n7kpH9pN3jC8ZbPRJPGW82V5Vv8CMwxNVF--ch6R9KwpW2Vc-SD5gdT5HW5NZFpX2s_fYzW6sjTL05cSS61W26gbYk8BnLbtW8_mgXS48hpf2W4N-Gfp7p8XfQW3_QJr045ygHSVG6sB-5gSFVMN3nWJc0j_jRcW1KpXwM1_4GC9W4cmvwJ2fkL1Xf3bw7-404?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003edeclined\u003c/a\u003e\u0026nbsp;to build a corporate museum, instead donating Apple's archives to Stanford University, because he wanted to keep the company forward-looking. Jeff Bezos encourages teams to approach every day as if it were “Day 1,” a mindset that emphasizes staying in the early, innovative stage of a company or industry. These philosophies resonate with me.\u003c/p\u003e\u003cp\u003eBut taking a brief look at the past can help us reflect on lessons for the future. One takeaway from looking at what worked 10 to 15 years ago is that many of the teams I led bet heavily on scaling to drive AI progress — a bet that laid a foundation to build larger and larger AI systems. At the time, the idea of scaling up neural networks was controversial, and I was on the fringe. I recall distinctly that, around \u0026nbsp;2008, Yoshua Bengio advised me not to bet on scaling and to focus on inventing algorithms instead!\u003c/p\u003e\u003cp\u003eA lesson I carry from that time is to not worry about what others think, but follow your convictions, especially if you have data to support your beliefs. Small-scale experiments performed by my Stanford group convinced me that scaling up neural networks would drive significant progress, and that’s why I was willing to ignore the skeptics. The diagram below, generated by Adam Coates and Honglak Lee, is the one that most firmed up my beliefs at that time. It shows that, for a range of models, the larger we scaled them, the better they perform. I remember presenting it at\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3nZN1clRG9-xcXmW6LM7sF41KGQRW9c_fmX6FsSZWW2FLBXT6HB405W7302sw1y43FFW6ty9qn4n8nvtW4jBPHY5p6dY4W69yf9N92vCvHN1TZ7sf6xD7HW1wMz5_7mkjvDV-N0s38Fk6pYW2hbMzH6VTFGtW6SdbCK4-VHlPW3h12Km8k_DgsW6gq2Cw72QkQyW2Z45KG4HGWgfW6Gn5nP8hhNKKW4kLy_X1j9xX0N3t_dF_35s6pVYpBdM5SLwyhW7RCKb48dz5fmMVfzFFLwLphW2dTm6f1H9KlqW74J6J91f1PnvW26_ywZ7Cv91xW6Dgzp-7TjbVNW2g9jKK6lggblV_sTMp3B-znmVlh0p02xPv2dW7LCCRH2w8pg0f20cy8-04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eCIFAR 2010\u003c/a\u003e, and if I had to pick a single reason why I pushed through to start Google Brain and set as the team’s #1 goal to scale up deep learning algorithms, it is this diagram!\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32-.png\" class=\"kg-image\" alt=\"Graph showing cross-validation accuracy vs. number of features for raw and whitened inputs.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--32-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--32-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eI also remember presenting at NeurIPS in 2008 our\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3mGN3yphdrjvHGZW6_n0-q2tvbDKW7W1W776bD3tRW7JLmy96j91X7W8Sn2y51tCBrTW2F5g2r1hxDpZVdTzGk989fY8W7KndVg8Bs4RpW1ltFr645-wPpW3v4g9v1y_CypW50n-Wb1_rQ6tW1jjpk54nmGQgW3d3J0j8DDMC1W182CQg4mx3C9W5DTnSn4DPHvJW1_Nrr91q2-6VW2xM_1S5147nvW8BBHXW3w9Sz1W14Tc-f2xXC4yW4drrhz6KvyWRW2BDXmp47hJ0PW6hzcJF50yvSTW7qMqCy6FXGWQW6nKKvQ5c7fnXW7HpXJ58yyY7zW1jgm0L1WF0mQf3y9nG604?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ework\u003c/a\u003e\u0026nbsp;on using GPUs to scale up training neural networks. (By the way, one measure of success in academia is when your work becomes sufficiently widely accepted that no one cites it anymore. I’m quite pleased the idea that GPUs should be used for AI — which was controversial back then — is now such a widely accepted “fact” that no one bothers to cite early papers that pushed for it.😃)\u003c/p\u003e\u003cp\u003eWhen I\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3pPW1cQ4pF5jhFNlW1RNksF84CPbHW1tlbMg1ykbh9W32wF5C3mKxWLW3s0_8q5qxXPyW1D5Lpf1QfDtpW2vCyKF6q97DpW5KkQqH8c6V1mW7LSLxz7qxhtTW81__rH4stTm-W9fxThQ655w1KW7bl8gj5-SW6RW2HLXPX8jyqw4W2F-0-92StYQtW821Pbb19r21sW4gp1y24K9J9NW1N6sHD9ltx96N7QjfP6GHM89N3KwFDLyLQHNW1VNHRz6KZ2SkW7qq6sc4h_yMkW1Wfrg47XJLV4W81YN-64zbMSKVyCN911N4x2cW7bdRG62rmSYVW1TDN6C1WBQt4f4lCv1204?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003estarted\u003c/a\u003e\u0026nbsp;Google Brain, the thesis was simple: I wanted to use the company’s \u0026nbsp;huge computing capability to scale up deep learning. Shortly afterward, I\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3pbN95F1_c3czdnW2kXP-w4__TrrW34g89C3d0KWLW1ZfzCM2btrszW6LJYFy5lbrgyW3g6W665dG9XkN6f-1zM9TxzPW6zrvvs7r_HzjW3x7qy29gqDyhVCDRF630R0nSW7cy_mc8qzHYSW85sHdh6VYSs8W38wtQP843_W_W29yP_c8_3WqHN9fDy2S5xDmqW5W0gPy5jp2Q8W5N0DQz4HQdnbW7zJw-230fPqKW2r8MBZ11QPJYW1gbYlX48wsrbW5QCyh295tMyXW1cScLT1QVV1-W4v1QPg5WcM5rW7rp_nz6jJ3Ggf95d9Hn04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ebuilt\u003c/a\u003e\u0026nbsp;Stanford’s first supercomputer for deep learning using GPUs, since I could move faster at Stanford than within a large company. A few years later, my team at Baidu showed that as you scale up a model, its performance\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3m6W3N0HhV7nTx5KW4zLfsL3B6JH4W6T7DhT6nqGY5W7V6S6F1Mzg_DW3RmNM63GmGftVkkXvD8_NBm-W7FkMky80kXX2W3RHS0Y2gTy50W6Kc5h38_F_C7V8cGkB2hZhKXW59_8c67zh1lmW4WmGlv7ZF9gFW984cmr4gSx0NW7Tt3bG7vhFTHW79fDjS36K9mJN4Hst9M2_X0QW11R0ZF302-jTW5XlSTK7BlvPKW5fj5124lC5bbN47Mk6TStvLdW6c8Sq110fws1W8HMCVv6Lyqk7W81TBS98-NmNsW2c4-HX5sC32Sf6x4tTM04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eimproves\u003c/a\u003e\u0026nbsp;linearly on a log-log scale, which was a precursor to OpenAI’s scaling laws.\u003c/p\u003e\u003cp\u003eAs I look to the future, I’m sure there are ideas that many people are skeptical about today, but will prove to be accurate. Scaling up AI models turned out to be useful for many teams, and it continues to be exciting, but now I’m even more excited by upcoming ideas that will prove to be even more valuable in the future.\u003c/p\u003e\u003cp\u003eThis past year, I spent a lot of time encouraging teams to build applications with agentic AI and worked to share best practices. I have a few hypotheses for additional technologies that will be important next year. I plan to spend the winter holiday playing with a few of them, and I will have more to share next year. But if you have an idea that you have conviction on, so long as you can do so responsibly, I encourage you to pursue it!\u003c/p\u003e\u003cp\u003eKeep learning,\u003c/p\u003e\u003cp\u003eAndrew\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/reasoning-with-o1/?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png\" class=\"kg-image\" alt=\"Promo banner for \u0026quot;Reasoning with o1\u0026quot;\" loading=\"lazy\" width=\"1890\" height=\"1063\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-12-16T174314.640.png 1890w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eIn our latest short course, you’ll learn how to use OpenAI o1 for advanced reasoning in tasks like coding, planning, and image analysis. Explore tradeoffs between intelligence gains and cost as well as techniques, such as meta prompting, to optimize performance.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/reasoning-with-o1/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eEnroll now!\u003c/a\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--33-.png\" class=\"kg-image\" alt=\"Benchmark results for Phi-4, GPT, LLaMA-3.3, and Qwen 2.5 models.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--33-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--33-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--33-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"phi-4-beats-models-five-times-its-size\"\u003ePhi-4 Beats Models Five Times Its Size\u003c/h1\u003e\u003cp\u003eMicrosoft updated its smallest\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3nWW24271h7nfgx1W1N1kQz8qyz3KW4SnV0H568b6bN1qf6MNhlJGsW7nYKsN2q24gDW3flkW89l3Y10W6RQnQy4zVXPyW7Fg5xc7PRrgrN7Bh1S95C8y6W6gxnZ28JvLwMW78jxWS5ydBBQW6cGK5_1fN9vLW2Ywpkk37dfNSW8gR0Gz63YSS8VW1ZX47bDZY5W8QdK874ZnpqDW64qsLN6k3ym4W9fDYLY3pX2p9W39q94R1LJd7dW3n-dDr3pJXCQW33NN494_Ck6sW8Rykxx6T1r4cW4CTLBV4DQNPdW7bMj8k50M2VVf8Q8WZg04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003emodel family\u003c/a\u003e\u0026nbsp;with a single, surprisingly high-performance model.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Marah Abdin and a team at Microsoft released\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pwW6Sp4rK3GbwYZVK3_7c2kDnNpW6_6C3_4jkZXhW5JvBB26Xys6bW71vKbM5TWFF6W73XmJN14BNlmW1Ql8826DMVJhN59HSH9J6ZpmN1-NpvVQxDnNW8981GL6FY2tbW4w0fxL8Cq9DlVk3c5s4Kh-kzW7W5PsG7278cLW8j9ZSq2SBfHSW1kDm382t8GN5V_b9196T-QBSW7kmy742BnCx8W5h-t7H6btCsqW2lfrGt14zKZYN2G7nFYfmRxVM32rKk_7mN-VMrT3H3L49Pwd1WwwY04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ePhi-4\u003c/a\u003e, a large language model of 14 billion parameters that outperforms Llama 3.3 70B and Qwen 2.5 (72 billion parameters) on math and reasoning benchmarks. The model is available at\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3nMW8LKGpb6H6nKRW39HQ2d3NYBvTW8Pdrpj4h3Mp6W1PSx4g3wG7FDW53KR2y2cXT13W5xPCmj6rN_r_W6g0bHm6ls9WCW3Y225S8l-w9YVZ4cnS8vzSwsW7S5cWR2L5n-HW4f18296FJhWwMt-YkFFxWhrW73MK-02plSLlW2G6bnp67MdLxN65_FCrLPSnCW26119Q24VrftW21-jjv63rd5jW96s2kK19Ly-wN5Zcl-p5DHHqVJtbBk36_7NkW1QlXyb50HsQgW6wvZdG2m_hsbW7lc13X76wCbTVFcF8y195CdzVsPW-g7XqDDCVXNNQ2108y1CdwSLfz04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eAzure AI Foundry\u003c/a\u003e\u0026nbsp;under a\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3nSVSz1Sk5T9sc3W8nTDSK5TR0bkW8kzpCq7PfHQ6N2cPk0PjW7LNW69GVdP51xfwNW6ks5xk4PRbF4W27_VD63dsXYCN1QZ53my1KfxN61KVZyFydQHW1p2Jql7j2xVqW1RwsH24C799PW22pymJ1bDCk5W3VM7Lf30yqDtW1VXd0M3xJBcQN9hJ01SsJc8SW2hRySr4-9Z_1W5MNsBl8-8sgRW91SH3b6gNfcDW7nKKXx5PBPV1W2nZ51V412TGjW3d5N_h8M0q0ZW5HLWZh4TjZpvVVHJgt6BTncXW6qwq2j1Qdd1cW8642N_7PDz9SW3PDW2b3J1LyNW8B7-Zt122LJvW30fpp84X_QJHW6X_tZB5yS-43W1mr8gq2ZN9gMW1WMvXN7Sjwx9W6qMX713C_pt_f3KYghT04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003elicense\u003c/a\u003e\u0026nbsp;that permits non-commercial uses, and the weights will be released via\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7t43qgyTW8wLKSR6lZ3lyW4H3w-B1bfvk7VYMJC11mQXX-W8VLk1n8DVzSqW1F8NZZ1GYyhYW3Qv7Mv6lVHMqW246w0962z8b9W1ggrqD1zrh7LVm3hVT3syrNRW28N_8L6kN1-bW99FKlv3zk0qMW7D7pnb8rDCMjN2CQTRS_ShYbW6g3_mK8KnKpBW7jy1X028fRdSW3QwZj-4DjSr7W7HzPzB20hF4bW7cRCK17ShcV1W4V8TqQ2BqbhbW1ktmnq8Hzy3-W7vwtZL5wJY-FW7X9N0s7MmtQhMJ7gsQX99bVW3Tq2zm7PBK_SW3QLW8K72_RpKW3s2xHS3Mhh_HN88WDcc3gyVlW2VmFjh2SYbX9W1WQ3h48bdPW_f76YD2004?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eHugging Face\u003c/a\u003e\u0026nbsp;next week.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Phi-4 is a transformer that processes up to 16,000 tokens of input context. The ways the authors constructed the pretraining and fine-tuning datasets accounts for most of its performance advantage over other models.\u003c/p\u003e\u003cul\u003e\u003cli\u003eMuch of the pretraining set was high-quality data from the web or existing datasets. The authors used known high-quality datasets and repositories of high-quality web data (like books and research papers). They also filtered websites using classifiers they trained to recognize high-quality text.\u003c/li\u003e\u003cli\u003eThe rest of the pretraining data was generated or rewritten by GPT-4o. Given snippets of text from web pages, code, scientific papers, and books, GPT-4o rewrote them as exercises, discussions, question-and-answer pairs, and structured reasoning tasks. GPT-4o then followed a feedback loop to improve its accuracy by critiquing its own outputs and generating new ones.\u003c/li\u003e\u003cli\u003eThe authors fine-tuned Phi-4 on existing and newly generated data they acquired in similar ways.\u003c/li\u003e\u003cli\u003eThey further fine-tuned it on two rounds of generated data using\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7t43qgyTW8wLKSR6lZ3lmW4rmcNk6BTVd3W55vCTH5G1B--Vzvy8D7dzRZ2W12C9fb65-ZnZW5nNfzr1m4dxMW4QqmKV7JQnKcW3b-0713qbzwkW5F96Qn15p-W-W23z2LT5xrsryW8vsYD070nHRYW6ydWKc5BG9HZW2q0nG64Y05TSW60pQY_5v3F38W7H4ZTS4Y5tXdN7P5bwqDqBTYVyk--b5Kg1qTW6xlRhk3S33QNW95kv9h4H467fW4ncLmc2nJW38W4PB6sj5BWmT6Vgkbjp7yN5G9W57V90P7C6fHJW2Rsm9c4-q80gW447NJ71TZVwTW2YvMKW8wdTn-W4wcdlb6KZDvPW9gn5_z6YCW6-W4d8Gcf5nD7B7f3R5MxC04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eDirect Preference Optimization (DPO)\u003c/a\u003e, which trains models to be more likely to generate a preferred example and less likely to generate a not-preferred example. In the first round, the authors generated preferred/not-preferred pairs by identifying important tokens in generated responses: They considered a token to be important if, after the model generated it (as part of a partial response), the probability that it ultimately would produce a correct output significantly improved (or declined). They measured this probability by generating multiple completions of a given prompt and determining the percentage of times the model produced the correct answer after generating a given token. The preferred/not-preferred pairs (in which one element of the pair is composed of an input, token(s) to generate, and preferred or not-preferred label) took tokens generated prior to the important token as the input, the important token as the preferred token, and the important token that decreased the probability as the not-preferred token.\u003c/li\u003e\u003cli\u003eIn the second round of generating preferred/not-preferred pairs and fine-tuning via DPO, the authors generated responses from GPT-4o, GPT-4 Turbo, and Phi-4, and then used GPT-4o to rate them. Highly rated responses were preferred, and lower-rated responses were not preferred.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;Of 13 benchmarks, Phi-4 outperforms Llama 3.3 70B (its most recent open weights competitor) on six and Qwen 2.5 on five.\u003c/p\u003e\u003cul\u003e\u003cli\u003ePhi-4 outperforms Llama 3.3 70B, Qwen 2.5, and GPT-4o on\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3lrW495vP740qPgTW25CR0Q3JfYPdW11r07l5qGV4NW8Jp_MW2bJ49FW1JWK7D5K_W68W4vXJKk68NyL6N8YX8qMC5s5xW2QTy4f8B5hf1W7Fj4nv2fzfcMW1QZ04b4LpJtXW8GTnPG6HW36rW1gdbxf406S3yW5XV0Rs5r9W_FW7794wJ6FGv7ZT-wLh89CbkqW6zBg075pmqsQVZ5WwJ7nk1_8W7k9j1m98R8X-W3MGjqy1PW3zWW691kWh49Wv8RW5xCDzm1rfyTCW9dv24-6W9ZtzdsF-rK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eGPQA\u003c/a\u003e\u0026nbsp;(graduate level questions and answers) and\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3lsW263H4J4wx8lVW4hxXZ890XSBZW2clqYc6LG-djW6SW8293LTH8WW9fw4V87jZ7JQW7j5MdM2GhjDlW4tKpcT8d7rlMW6J_qyQ8pHRPfW48R-VZ1clQZPW75pJPc8dkgyNW9d7lK62nVvNCVBN_MX8lNknhW1XN3QP4hyYr-W610NMz6BsSnfW7nGYbj6FvfVWW5l7Jy47WJT7KW7jhGKw2vXmtkN7-vY_MvnJ14W3kZtgQ6j40-VVKh-z567kb3BW5pHY7885qfKdW7c-10S3NszvLf5nlZyK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMATH\u003c/a\u003e\u0026nbsp;(competition-level math problems).\u003c/li\u003e\u003cli\u003eHowever, Llama 3.3 70B wins\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3nnN6_pZnJxHMl9W3250d66d8xWFW3gdjMm340bknW6g6R926bv-sfW6DZF284Ln91cW3sHGVM60qrYfW6JzMn_6yRRzBW9bmqJ-1B2sK8W3FSxQJ9jkNSYW2pnLZd2cCVPZW5mkZJ56TT23zW8TjsmB6LQy0FN4FhwNTJSfD0W8lvfqH6ywYhHW6XMXsj4Ck8CXN8sw2Jh7ChdgW1cGbrz3d168lW3fPw6J23dMypW3LfdPp5HcVFPW7nCvdD7506WNN7RbtWzQ90H8W1b5C1y7J22t3f4Yf2LK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eDROP\u003c/a\u003e\u0026nbsp;(reading comprehension) and\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pTVBszKN1lCzTxW1Mg0q42PHbJdW3KF84q5Z1D2tVFMMjq47254_W4ngBgk8nRMPBW5ffzV85gyj6PW6cQGKk5m74cLW7BvnS76JtrMVW6WkBHg8BTspBW2zcwfx99v4cSW8Gvrc74RjDMWW2Cg4gn1M3bYrW352Hbm5y2G4NW73DCns3kT2TLW2LFKH77Mbs3cN6r6v4bxpnvsVJQlQ51n85GtW48bZl17qgrQJVVHFcP15xTGfN8B5qr9vlPd1W2sLNy_7QbLCtW4Km6Hr7fzgL5f249tXg04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eSimpleQA\u003c/a\u003e\u0026nbsp;(answering questions about basic facts). Llama 3.3 70B also performs significantly better on IFEval (instruction-following).\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Phi-4 shows that there’s still room to improve the performance of small models by curating training data, following the age-old adage that better data makes a better model.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Some researchers\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3n5W152-5K97C3_ZW3cGXDk60FY9vW5zm66k7_vb3VVKpnTD2RSfv5W3QGq6X8VcVgFW7yD3tx1R9BtjW7r10tp5b6JyqVRqQS5475Fp-W5xQJCT4VjfP9W8N0v7m2z9PL2W1pKJ_X6xxnPRW2MyT457Qq0XDVk6xh61mynfGW2pfJld2RHvbvW1FGD3Z1CRXZhW543g8D5CJK8rW6tvYT131xxxDW8-1FSl1-vJMcW1d_kk-9c2T9_W5s2t5m5ZQPByN63fvS0BsZhWN5DhzdXkLQ5mf32WLgj04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003efound\u003c/a\u003e\u0026nbsp;that earlier versions of Phi showed signs of overfitting to certain benchmarks. In their paper, the Microsoft team stressed that they had improved the data decontamination process for Phi-4 and added an appendix on their method. We trust that independent tests will show that Phi-4 is as impressive as its benchmark scores suggest.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--39-.gif\" class=\"kg-image\" alt=\"A GIF with scenes of a man at a café, a working robot, a ghost in a mirror, and a speeding truck.\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--39-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"open-video-gen-closes-the-gap\"\u003eOpen Video Gen Closes the Gap\u003c/h1\u003e\u003cp\u003eThe gap is narrowing between closed and open models for video generation.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Tencent released\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3lpW7mzLrL1PMYDnT-14m7JMbH6VW3XS85btjmWW8zp7xz4Qg9vTW8cqK7V4pvzbgVYWLMb17HbPJW97z9Vs7VLTbtW89MkfQ72rVvxVhCDpJ6HFD6JW6L_y3T4Bf1tVW3BL3GW1G6x3TVShBcT7VP3xjW3BZt8h2hlyF9W354M5S31gTTvW463P8572_wFXW3RrsPY7GCgd4W5YX72q5BNT_DW3KPskg2bbbVpW1xPZ-36-rQ_fW4GVnYl1TpS4vW8nkzN68hMqtwW5dfTPH75kQPSf2y_SZF04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eHunyuanVideo\u003c/a\u003e, a video generator that delivers performance competitive with commercial models. The model is available as\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3nXW4pmLhw4PVBgFW7zHR2X6JKTBTW8Hr8g963qDfbN1vMcB5fQCQKVhhVqw7m0rTSW16D_MM22nH5GW4dGQMQ49gHd7VhPd_G1zCCHgW2_BcFV2X6fRNW8JnXZr23_t-7W3ldLw47fnTLMW6lrB003KlMvdW7lRw0h65zFj_W8ZC3s_7ZhX49W7KqzB22z7Ld4V_421g9hXHb_W8d6Djs7rCshRW33LzsS37xZVBW2v4_8Z3F640fN5NJnSw14J4KW1hZRyb22_McnN88DSnG1Zl6cW8k21Q53KzBn3W6HbqZb5t1mHvf74qpwP04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eopen code\u003c/a\u003e\u0026nbsp;and\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3nLW3vjgcN68ghTTW86xSNF19JzjpN72XxsYWYJW8W7c0_8p60Q11MW6L8QYB4ckvtxN1J-vpVBxqgqN88yvpGFRwBDW444Nj18Kx8hfW699Yss8grDvRVG9rSn3hghvtW2Z2c-46VHHkZW1CbL6P75qJBwW7mHk_g5Tq01vW5PSS378SSJXLW8Nt9wS6SzprMW2cnypx7ljrMZW28PScZ8MfVtHW1w1Fm96rDM3RW7lnZqf4LbNBPW25rGWs6z52c4W3T31wZ77t7gpVNWVXK5-txKzW2mM9CQ3gFtM4W7NLrrh5tD-dZf2dL41l04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eopen weights\u003c/a\u003e\u0026nbsp;for developers who have less than a 100 million monthly users and live outside the EU, UK, and South Korea.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;HunyuanVideo comprises a convolutional video encoder-decoder, two text encoders, a time-step encoder, and a transformer. The team trained the model in stages (first the encoder-decoder, then the system as a whole) using undisclosed datasets before fine-tuning the system.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe team trained the encoder-decoder to reconstruct images and videos.\u003c/li\u003e\u003cli\u003eThey trained the system to remove noise from noisy embeddings of videos. They started with low-resolution images; then higher-resolution images; then low-resolution, shorter videos; and\u0026nbsp; progressively increased to higher-resolution, longer videos.\u003c/li\u003e\u003cli\u003eGiven a video, the encoder embedded it. Given a text description of the video, a pretrained\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3pYW4JSD4k918pxYW1m3BKq2j1JL3W4rsZTk6MfJtNW7J065r2xxnW0W2XDyqZ6Mx3FkW3MbMxn5-fjj-V9KzBt4rM0k-VhqmVL1VzL-kW8ynXj52_sVvHW5Tpgmt8T9kFnW68gJ_4220j6GW2LHjWS4lGSs4W1mwXMn7tcTk1W7s137455TtqGW48rnwY2ptvqmW4t0jrL1ThxsyV6f8395Q00HKW4q3x7689lGRYW6Pt6fp79Q5cxVN9QSZ9ff3nsW5RHPkM6dkFYKVyqGmy8Y6ZGbW1_-wKl6ysrdnW5gXdZR3BQ-f9W3x1Jvp92D7NDW2B-ctm83ct80W8-xFRs14b9_2W4-JDz01MFf7yW7nD8nT2NMHV9W3jMs4H3W9Z7NN86NYnTQk1ZtW4RS6z32y8F2mf6jXqGT04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eHunyuan-Large\u003c/a\u003e\u0026nbsp;produced a detailed embedding of the text and a pretrained\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pWVc1CS55VC4X6W3mR0vY6tv3qSW490xrp1tpcq7W1GqZ9r313PM3W5VrVb73647dnW8vDRjn9l-s9PW1zqgMF2RSckBN78vWqYm_1jCW5vyK6s432my5W5RqD7f3dXKQWW80ZF-y6chM-5N6KTky_64lJcN61hbX_1q8cwW5Sbp4S4CPd1wN93lFxZRnYd9W4RwQ3Y18ZMjBV_z2wb4MK0DsW94j8PH4Wzy9bN59ftd1yVDpBVZfngT3fkkGjW3DnzzC7pQQ16W2sHp188tZHYCf40NrBF04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eCLIP\u003c/a\u003e\u0026nbsp;produced a general embedding. A vanilla neural network embedded the current timestep. Given the video embedding with added noise, the two text embeddings, and the time-step embedding, the transformer learned to generate a noise-free embedding.\u003c/li\u003e\u003cli\u003eThe team fine-tuned the system to remove noise from roughly 1 million video examples that had been curated and annotated by humans to select those with the most aesthetically pleasing and compelling motions.\u003c/li\u003e\u003cli\u003eAt inference, given pure noise, a text description, and the current time step, the text encoders embed the text and the vanilla neural network embeds the time step. Given the noise, text embeddings, and the time-step embedding, the transformer generates a noise-free embedding, and the decoder turns it back into video.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;60 people judged responses to 1,533 text prompts by HunyuanVideo,\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3lPW1-r2Cj84X2yWW5JPnVm3lw_HNW4DNv5M3_wQ_-N7gQhlmRk-1xMGsbzNChJw9N4wh4Jy_M-tJW8nBTK15MXjjlW8CqBDY1hyr0HN799TwQdBChlW3N9Q1D8ksdjHW56jZZD1t7Pf_W23p02G7XDMN3N4DbLKJMJ_hLW87HsCc32pt90W1qTTQG3M8LnwW8w2ryd8pbHkRN6T1Y32zT-WWW4hyr1B2S-SnjN8FWVD5WThzBW16yK0v5Pc9ZGW3MmkXX6kLlXdW3hnqjW1ZkR3JW62sh0s15M92_W66Y3Yv5-6dNXf364px404?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eGen-3\u003c/a\u003e\u0026nbsp;and\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3kPW5bnv4m3VBpPHW8ZW0-W7ld7PVW891gZv3--1Q-W8PsLXW5JJX6xW2g1xsH2KQx5xVHdFdG1ZSDD1W33KRLD4zQywgW8PtB928-P2nPW2SlQtt51r1KWW2vvb6s4TsT98W3lHzYs57TkypN90ft7MjkwWlW4dY5xQ3_GY-FMSPZHjDFgpHW5VKZ6l41SMJ9W1tDjfC4yV0LnW5g0-R97hsZg_W4X-Fx769z8hRW2Q54K_6rwBHLW6BwZ4Y7CfM63W2nG42j8ZDTwLW3k193K4N5tVwf8gLClR04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eLuma 1.6\u003c/a\u003e. The judges preferred HunyuanVideo’s output overall. Examining the systems’ output in more detail, they preferred HunyuanVideo’s quality of motion but Gen-3’s visual quality.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;In February, OpenAI’s announcement of\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3lYN3y_s5-pLnpqW3X7Gyp82p9kTW3CB80F4z1ZRsW7-x42N579jbNW27Y_Rv88CKKTW41qP8d8x_LbjW2vFLGL843qJDVjQHdF5SSDlJW4nYRGw55r05XW8vTdP_6X2R9bW5L4J92679MR5N6DXyTT7msHDVvCxYz2sqMWmW9f46-72-hvP3W4sFPfc5GKqFKW33T3c62kXNn-Vq_R8W73Ch93V_W-DY85S44SW33C4V61v7PdSN8LXjY3Nm_PsW6nq4vK55cy1GW1DB_G74RDhY-W17j9kl52NtNHW3zYPFb4VT4wKW7wjz4c7lXM6kW976K-G5jYBslW7Bkz124wx33tV5kKz126Q1jLW5jb7vf649j59W6rxpM_3V8Y91f3T8JNK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eSora\u003c/a\u003e\u0026nbsp;(which was released as this article was in production) marked a new wave of video generators that quickly came to include Google\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3nqW21VKC55p4VgXW6bj4Pl4d8BMcV2yzty3jzlpRW6-LgNg8kn81BW2g1qWm1P53QxW5CXWlm74mwJZW1Z2wYY6fMQ46W3B_QRh6sb5HpW4QTd_M4yzc6DW7xTmfQ6HHPClW1pJNzC6R9-vnW7nBDJP6Zmll7W1lMm5V4vMfm0LhXm0tdC1WW8N7mY13Hc9VPW5P2s7K6ZMnMvW7PD0RW5Qjnm7W52s9QX2-Hp8BW3QQQrN836lZ5W2Q_Bfb2Hn9DgW8BL53327vnGRVwVPZq536W4VW2xL7Ml6bt-YzW5WDZgM12Lq51W6dkw5N53_1fnW2mYV7D2S7X0SW3cpnKD6lxvHpW3gD-Tn65wx6cW43yfDh3v-t4zW67Yz3128_D9RdNWM_F04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eVeo\u003c/a\u003e, Meta\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3lKW4Ch0QT2yGfqnN8yVbQ7_H62xW2FfmKT6T8DH6W6-6lVh1ZylDKW98JRbY5XK-C-W7Yfl2L1lfdxLN2clJrGWV4NhW3vYyP41_PRhsW5fhyps7gmPTRW4fhP8g8cMKh7W5hCmsH2FXcFHW8VwHm84LVfLYN6S_gRxFBKm-W4qnQ9G8d9jR1N7GPK-wPScd6W6GxV394Z47w0W3_8nC94-xphLW6rZhtX97zT1MW6mTqnv4DnFPHW5JW8jz3rJ9HGW9kN-SG6cZqkbN3FpDL74yx3tW3KHSfH6Vb61vW5vgJ9H4W-yj5W7t-Z-t7pLFZMW1W5TgX4l2JgmW8Rm6S67y1DbhW8KnHmm7pk0x9W750TY-4rnw5fW59nygT2_0V0dW6rXz_54Frz-mW6WfHGC5Qnl0sf76zywP04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMovie Gen\u003c/a\u003e, Runway\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3nPW4GVgjw3WcC9lVLZbMq2-K_-LW8JK9M37fWbxnW50ySyT3Wn962W5KRvWK8Vxc0sW67NN_k501mWtN3-Cp7BlxLs-W2vBmf73lwpz5W8tvsrr7dzyQBW29stdY5f8T8_W5K75bG3mn4_QW3KP_V16Hs1xFW285Pq93RfLWnW8V5sZG1Hz5tjW7PHX0Y7LLL65W47BMnH3C-RFBW3bzTKb6qwPbKW4t_jRF4nXm5ZW11hJ_F22wBNYVm_K-j6XJ3XYN5V1p9RTGgTDW8KZzbg38y0YYW52qx1h2K_ZClW5q59Xm4t2qC5f7vfbH804?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eGen-3 Alpha\u003c/a\u003e, and Stability AI\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3m-W88d_qW1t3k7gW5vcWKH33mMHyW6dJD587SS5VrW2nXlQf97LSvzW1G6k9w39P1c5W10SwhY6ZZX_qW5Vrrvk7S25x9W3Pwby87S-k9sW229N8m5PGV9PW1qPc3V7yRBc3VDlBZJ8kXbXlW12Ld9K64rFvnVPnG8R2kfWV9W4NMcw628HGtzW20ldKv828lPyN6rGgG_hXGThW5XCPRN1kr7Z3W1H9c2x4GgbsDW5PC2xL7Gf5CsN8B3DSyvs2ZDN82hdg9chlP4VqT0f26BB5ZGf7k7zx804?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eStable Video Diffusion\u003c/a\u003e. Open source alternatives like\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3p5W76w-td6BLqCFW5Jp2dz3-5wTWW2K4gwl8y5Y8RVg0f8W6m8lBLW9cJb2j8TDR34W3fvRzf7WS6mxW48NcSZ6cd8z4W97mP2y2VC2S_W4tnXD89l4N4ZVpXzGM1RNlkCW6hHDHk6ZfBmCW8Gr85N66FKQRW9lfYtB81T3NcW36Qgr15Q8dG3M2x7lFQrSCtW2V_gbW44VjhdW5PjmjC6bVblnW7fBC2Z1vDmV5W7LCJRg7ll1njW33qWGp67LVKSW40wTx63JHhzVW169-V16qPV4xf8ssLDg04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMochi\u003c/a\u003e\u0026nbsp;continue to fall short of publicly available commercial video generators.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Research in image generation has advanced at a rapid pace, while progress in video generation has been slower. One reason may be the cost of processing, which is especially intensive when it comes to video. The growing availability of pretrained, open source video generators could accelerate the pace by relieving researchers of the need to pretrain models and enabling them to experiment with fine-tuning and other post-training for specific tasks and applications.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Tencent’s open source models are great contributions to research and development in video generation. It’s exciting to see labs in China contributing high-performance models to the open source community!\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--40-.gif\" class=\"kg-image\" alt=\"Performance comparison for Gemini models across benchmarks.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--40-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--40-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--40-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"multimodal-modeling-on-the-double\"\u003eMultimodal Modeling on the Double\u003c/h1\u003e\u003cp\u003eGoogle’s Gemini 2.0 Flash, the first member of its updated Gemini family of large multimodal models, combines speed with performance that exceeds that of its earlier flagship model, Gemini 1.5 Pro, on several measures.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Gemini 2.0 Flash processes an immense 2 million tokens of input context including text, images, video, and speech, and generates text, images, and speech. Text input/output is available in English, Spanish, Japanese, Chinese, and Hindi, while speech input/output is available in English only for now. It can use tools, generate function calls, and respond to a real-time API — capabilities that underpin a set of pre-built agents that perform tasks like research and coding. Gemini 2.0 Flash is\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3lKW8c5hrT6Dt0JdW471Z0S4wh_QcW7wHHqV2dxkTkW2xql-Z81np14N3fWNfCB6JgvW85KhzW6tzpW5W4d5v9g6KwScmW5xvbn-8sQHhGW34j1nP2HKJ-3W6D-Gc61DwX3BN2tyNZtMJgWzW5rbxhk4J6j0jW4WtTpZ5LSK8PN2ZB1k3mn4PjW7tQk4x6vTG94W1nmxfG97LhTmN2QfN5xjqdhCW4whbcS1fdWn_W2bpVPn2gxTjTW26H_X587y9G1W5k_ktp9bS1JKW1cC69s5Mlp3BW2J9Lyw5rx6yTN24VsmFxDbM2W411Yf12ZjhMBVz6Rvm87VrrCf3_RV5604?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eavailable\u003c/a\u003e\u0026nbsp;for free in an experimental preview version via Google AI Studio, Google Developer API, and Gemini Chat.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Gemini 2.0 Flash (parameter count undisclosed) matches or outperforms several competing models on key benchmarks, according to Google’s report.\u003c/p\u003e\u003cul\u003e\u003cli\u003eGemini 2.0 Flash is faster than Gemini 1.5 Flash. It offers relatively low average latency (0.53 seconds to receive the first token, just ahead of Mistral Large 2 and GPT-4o mini) and relatively high output speed (169.5 tokens per second, just ahead of AWS Nova Lite and OpenAI o1 Preview but behind Llama),\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3p8W12s7mv8htlBHVJgLmB9ccYCSW7f2kd33pSF0xMG0jYy6cMJRW30P7KW6Q6gCBW6PH0Rj33g9s1W3MlfMB4hFlyxW1nZJz91D53YDW4Ml_y94zPrZxW3rvB47114mVZW1CD12V58LbVGW4fqR9M5kHyl5W11v1Jl8jqkkMW3QJ5dB8jr3lzW4h7mwP5ZrCp0W13vpZ48ZvYd9W40TkQw2G_S0lW5_x6cW40_ZyHN7l32Pq5WKzbW467k416wwCGKW7NrPBj6KTffZW8nR7lC22bbQsW8Kqwcw2w_klmW4q4Vp_84JV8CW1MJldw9k297RW7Fp7gv8xg1-Vf3gqFq404?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eaccording to\u003c/a\u003e\u0026nbsp;Artificial Analysis.\u003c/li\u003e\u003cli\u003eIt beats Gemini 1.5 Pro on multiple key benchmarks, including measures of language understanding (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pHN73WlcFzm_68W5TbmFn8bBy49W3Dgr8F1Sy71hW1cc9xy5J4BkhW3K_TWc4NwN4DW72td0x8CLnjKW72S1LX8F-KN7W2kZ7Mn2DgnWNW1DZPtw53GR89VlftcP87fyR1W72-gjY6tClGdW15wFdz1kzt6YW2q8bdq4rWcmWW8Kq1rq5wgGH7W74swpZ7r6DCwW47pSy18-JDnpW3L88Xv1ZPzSJMzsdyRlkY6WW8TCZgH7cK9dfW89zMFF4TXqY_MtsXPc1dplZW3XsPgY5P7b1ydH1gyl04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMMLU-Pro\u003c/a\u003e) and visual and multimedia understanding (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3pRW7sxmVz69yY3BW98kc773Z5LCzW8qTjDR1mBwZbW3QnmdQ1PtN2-W4ZTMTy8zfvC5W4GCZh27DSFtnW3XkkPL5cWqQ1TKtPZ2QFkGyN1KsSPkHc6G_VHFL60275mHBW8rxZyY3G6SNNW5px0JS1CrB7lV913QZ8bkGs0W1tqHCt36brxlN1MrK91h7LMwW3Q4S393bQ32jW3Tsz8P1rFd_sW8VgbNy3L_4d6W4ZcygQ1zsnjHW4ng0n32NYQmHW6rbPsw7F2sQQW4tsGc41JHpjMdPW4WW04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMMMU\u003c/a\u003e). It also excels at competition-level math problems, achieving\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3m3N7q-PNPM3KGCW8rr-fv8b745PW46BGjX5gJjjQW16z40h872TcqVb7h2-60FqWwW6B-80J73DMMxW6M00pg2FnMwfW69cQHv8n2hSZW11YGB-5KyL-nN4N9L-HQ282tN3S439177rvpW6xCQMj3Bch8mW25b6r78W0z5yW2yVZcR2gN28bW3lxmGR320NwRW6FRg0h5SLyPhW77pNXL3lG5zGN4CXj4WtxpjFW4HyxGh1NWQ7cW2v3PZD628SNQW5H8Qz114CF40W4YKPGR49Zl1zVrVtMY6TMgCRW7NlNtK8xtq9QVnjh0W5MFnmVVp2c-y1XPS2Df62FGC404?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003estate-of-the-art\u003c/a\u003e\u0026nbsp;results on\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3kJW8zGTlX3HNzWQW1hF05_3nvdN6N4MRG1NJ2SzrW9gqDGZ6XPlLSVL5sBH6PjfYSW3ppsGz1S-qy8W1TH4262jgz0RW7Nyxyd7-SmSgN5Q41mC4Y9z4W875-xl1ljfY3W8FGZPf2l_0M7W5fz7Cb1VtMxnW93WpNY8vf_KnW8K1Wbn5LvmLVTQySS67q0BdN2zzLkTDVXz7VsX17_5H01gcW4hz7c11JBglqW1CHP8J4r55ygW2kZwtw8rDssFN2gzWzGmJ6NTW7chnzJ8fDBqpf4st5kz04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMATH\u003c/a\u003e\u0026nbsp;and\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rj5nR32W50kH_H6lZ3n2W7SYjM_6k8p4yW8NnsBF84wZHGW2h6wV17CMZ-bW350qRT92W5t_W6vZF3W5CJc88W4ZNR-_8LhqShW3DQxhY782QDpW6gQKJC7YH8JYW16K7Pk5vKMgRW18bP2X7SdYCDW2wpgH-7-d_lzW747xPk4m8QWmW9c67n249x5tSW4KMjxy1Bgk3yN4Vr17wgcpTFW1MZwJ58TsbYvW5QkgZS47XymPW5bRtLf1yt056VQFv3k3213_sW28NRZ45RzbtmW41C8B016SkHFMDqHBPVG_34W7kgVmp3BssdnVY6rhZ3GDC8rW2dSMl111tMx2W3mqq238NkPLrW5bQ_l91LXqC4W95-Xp131ngZDW4HPnQ88Xb9zFW6qq-V78JQNjgW4T-M905QVVVZN5-rWxxdVGPgdpvL0404?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eHiddenMath\u003c/a\u003e. It outperforms Gemini 1.5 Pro when generating Python, Java, and SQL code (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3krN9lDJSjhp47MW92fPZy6qHVH_W73SQ-P4JGT2yW84Yw7L4vQ5fCVNXL047m82pLW2gCxzg1F8-3zN5tD-Ypc7bzpW8lV2qx8dt8TKW1cWJgD6wksSFW8F5kh_2lRQwRW4-HX9N433R5BW1KwLt57CTwh3W6kq6J84kVsg9N5lJ5WL64xpJW5Z4Ntz2m-zrLW75dY6b6s781KW6qqplW8qHBdrW3fsNCt8Y_wChW6cfFRT5G81V2W8gd6mD1RNzqqW5fPZz65-jd9NW37G9Sd9kGpN-f1t5SrP04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eNatural2Code\u003c/a\u003e) and (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3nzW2WcCZ04WvXrkW41th8T7qLTpJW8lVYB15L4VWcW4dts4w6c1-phW3bdFjk4h24KpW1tBCvl63Cv4VW4lSWtC1tSfD_W3xY9wq7YFHJJW1n5b8m7cxB-_W7nffsP7Tk46RW8zCJDz7m1R_vW8-DVdd3g6y4hN3jF01rNPdYYW40D5r51QKCQkW77XYtK58jg0rW7JK0GG22-yqVV6h2wc8k2nSDW7WmQyc3Y3sC9VC0mQd7HVKQ4VFVcZ_2d4T9vVyX9Lx20F6PPW6crpYn4jjf1Qf16GLkK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eLiveCodeBench\u003c/a\u003e).\u003c/li\u003e\u003cli\u003eCompared to competing models, Gemini 2.0 Flash does well on language and multimedia understanding. On MMLU-Pro, Gemini 2.0 Flash outperforms GPT-4o and is just behind Claude 3.5 Sonnet,\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3mdW6D6Cf_8gNqglVFb4vg7Vt4qvW7pypMY5wTnTCW2nWq449b6cnyW3pGcGD6M7pB-W5Lk9sX7Sg-rLVH8pSZ4-PssWW3BQXLT4sn4lfW58yhsb3449DPW2sWbCs241B6NW56YyxF2_RG-VVNq4mQ125KtVVdrZ9N8Nb14SW7qts7y1cv2y9W4JDJRq69wRfhN524t8fHdqXkW7xcrcl8MCY3MW47rF6T6jXC05W1fvynV2mMJjfW3YBgWr8bDYgbW6kVMCL6PJBYDW2ytCDf6MSYWFVSgLJJ5l-Q1NW2Fx_HK7f4-PKf3y9z2n04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eaccording to TIGER-Lab\u003c/a\u003e. Google reports a score of 70.7 percent on MMMU, which would put it ahead of GPT-4o and Claude 3.5 Sonnet, but behind o1’s, on the\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3njN3fcGNsW44cnW6cLrDh6r10MHW3xtJ3z1PsmCbW1gppj11Yc46JN68_dZwRtT0mW6mpcbk8GSg2fW43L-651Jr2nYW3YJr-X7jpCGzW7L7BH15vB00sW5WztyV2QY2RxW7Mzdjx3-sHJ2Mvm15xmFhL8N3dF20wZDfTrF5Fc7kWXVsrW2gMSkk5cvksQW9c9lvY2hzMSDW86Yck77Gk-V-W6zPrht3Ndk3PW6VLd751y1jlmW6kxCl82MfybDW5r1cf32kcWCgW5g8Z0t3JqFzPf134cZ204?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMMMU leaderboard\u003c/a\u003e\u0026nbsp;as of this publication date. It does less well on tests of coding ability, in which it underperforms Claude 3.5 Sonnet, GPT-4o, o1-preview, and o1-mini.\u003c/li\u003e\u003cli\u003eThe\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3p1W4zRQ-F1cw_T3W43SkR-2cHh1TN83N8-YX3qwgVrqLL17KjkTdW4ghMvJ6y_Wh7W36TYbf7FdZ30W8s4vqj6dHf_yW823pdV1BRn9qV4y8cX8dCXbBVG6wVS7CwjSWW8Hdh4W7_Zq4NW26YzZn1hz76TW2tCpYK7L60hqW7H97R_1L_z15W5ncFlp581nwbVYLCL_7kwFPnN67BDFwgHJFHW3pJMZV31DX5CW8kS9fG56mGt7W94F97R72dcklW72zlk_2XbnvGN3dfZcjnzbWBW7CLvbd5S242MW7ZN6VR4VjFqsW62pKK44Y7GBcW3bwBsH7bj_BZW8KfN_Z362WR2W72C3cC3dbxGdW8dtHvP6mCHD_VHV-rC2hBzKXf2B-4wT04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMultimodal Live API\u003c/a\u003e\u0026nbsp;feeds live-streamed inputs from cameras or screens to Gemini 2.0 Flash, enabling real-time applications like live translation and video recognition.\u003c/li\u003e\u003cli\u003eThe model’s multimodal input/output capabilities enable it to identify and locate objects in images and reason about them. For instance, it can locate a spilled drink and suggest ways to clean it up. It can alter images according to natural-language commands, such as turning a picture of a car into a convertible, and explain the changes step by step.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eAgents at your service:\u003c/strong\u003e\u0026nbsp;Google also introduced four agents that take advantage of Gemini 2.0 Flash’s ability to use tools, call functions, and respond to the API in real time. Most are available via a waitlist.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3p-W8Kbcmy3V3-kXW2N0yng81d7m1W5QwTf55DTxPyW8MHPMq5vd-x3W2fxFbB3LDTMCW1-x0823HK6sYVw8FZ86l4ng2W3D5xv65MZRq6W8M3hFY2lhSw8W80Fm8C73JCVHW509Psl9l45zqW3RpV507vbkpCW93tNGS1nZQ-dW8fJmDW4RwVHpW6sWDXQ8R4x5wW5mM-LD76ByQsW51Jdt93BgDp8W2grbT-36wRSpW8x1-Yd5P-QKcW6yXNfn34LNv4F1QJ5JSpLm-W7szdQx6gTrNLW6m9PXl2YHL4WW3KQ4c37ddp01f8nT8FH04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eAstra\u003c/a\u003e, which was previewed in May, is an AI assistant for smartphones (and for prototype\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7t43qgyTW8wLKSR6lZ3lvW1pHLKr6xfVFDN3B0Zn0dQJSFW7hxRmR78XLBwW4NJPyx1Bm4k5W8ZKm7G6BD_BSW95br4M199v8MVwwn0h2v7Fv0W8t1vTK1-McvXN3n8406JLR7HW7fzGVC1CZJvhN6QQND0F9G4lW2RSSYl3tBPG4W67zBg78BHxxbW6pTZBl7HRRQVW3VP5rX8sHns7W6XTnxx3Jj-fLW77b-kp8lwdMVW2jQyDP4hCT_qW60JFnN4wqxJTW8wyHRt4yLy-1W8cr4m_7SyHgfW8DKkS0700xd_W8lqX-Z1NqGstW3nYDhP2CFqW8N5LhzJgRYMgVVXNC7Z4v8_GsF2qffF5nRwhW6p6qJD5qtcLMf43_nz-04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ealternative-reality glasses\u003c/a\u003e\u0026nbsp;that are in beta test with US and UK users). Astra recognizes video, text, images, and audio in real time and integrates with Google services to help manage calendars, send emails, and answer search queries.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sv3qgyTW7lCdLW6lZ3kNN5MHqlc9vHq5Ml60R4mKhy5W7tqm2W2gyjc5VjSrvb1dVRp9N64h_jcvFxYpW94_7Yh2XyjZRW4wym256Cykw1W530Nwh7cmPkrW3tCQTG3dQzhDW3SDTLW26Dh-FW7jc5xG8R0P_LW5Vnjpj4_V67mVddxWJ21CjtLW8vPYlH7_rV3rN4kDGsZSwY0rW8r3h0_2ySJNqW999S6k7R5ckgVr0QKC8WNvSxN6vbzFGdxWDZVG5qYh8mDJr-W919f8P87Z9HsW32qWPk9gZ_fNW87wJF17thtfRN3jFPkDVfCJWf7XTtQP04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMariner\u003c/a\u003e\u0026nbsp;automatically compares product prices, buys tickets, and organizes schedules on a user’s behalf using a Chrome browser extension.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3p_W7fPjqf172_58W1YsfTw8pXhrSW3lNBG986bn_LW44wbpn3Zln92VB78P22lrqKKW5XrxMr4tbWxWW1cHqcw5vQMPWW1qKNWv7x67p9W67GqYp84q07MW4mmBv26QTXNhW6Nx7xp14XY_jW85lhqj7MZpk7W2Tp82Q16S1psW77Mz6B6xGvNMW79zL3Q8dMYcdW4-jPhp7CSvj8W4Bqxs_3GlNhsW8lVlHh3JfGVPW5lH5pB1NPhpQW68pQ9c98Lnh7W9d9dgV3cflSMW6Z89rT3d6F4RW1TQf0f5PJG0DW4hwFVh1pbC3MW1MHFhp32NGz_W7KqWWp1Bh_Tkf3NvxfY04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eDeep Research\u003c/a\u003e\u0026nbsp;is a multimodal research assistant that analyzes datasets, summarized text, and compiles reports. It’s designed for academic and professional research and is available to\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3m3VmzFjR3GKjlTN6knXmZ4SP3NW11Pfmw903lbBW4B6Cm695l_q6W54BVzy3ChsqXW268pQ263gmHWW7TBvcZ4ywPzwW66jGY71XbwJQW8lg19048K4Z-Mk0TZVhW4RTW2LXlP7424xDgW5bJFGS862PtfW3LH3yN7TnSyqW1TnrwL7kgf5-V49b072LNCgWW88q_-G4BX8zkW8JC-TS6p145cW88445F2Dq5gPW3Cr-Bc8Yv4NRW2qrnTF2Q7hX9W62WcCD2HHQ5qN6tH34RHCKjHf57rdwK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eGemini Advanced\u003c/a\u003e\u0026nbsp;subscribers.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7tn3qgyTW95jsWP6lZ3kWW4PJ0Wg6tDnJRV4JWbb7YnFC1N42J9351JJv3W605Ccb4Rgnp1W82LlTc5ZBL5HW3w0stk2lYVdrW70K5yr6hD6HTW1DWpph6JyVT8W8QrV9N75CznlW7m8vvV8lL_wdW7xYrcL5d5klZW3q-vjv495GBBW5G3vnw7zN_N1W59Sw3D4TBv5KW8wTb_y1NrxDcW1bs1pK3rY55RW30mnlW7HN-8fW9bYdZs8D7B87W2-zzvp7MxVWkW576R0t97kcrcW34wGzv3XhjhkN76kGWJfqY2VW93J2gx4Yk_39W1R2c715vFx2wW53rZbQ8LHMS9W1BMbl97lbPq8W84JjkN8zXzrZW7MfN-_3m_2jrW5C1g3l2xZMhlVGBsym6R7p_jf6K8n3T04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eJules\u003c/a\u003e\u0026nbsp;is a coding agent for Python and JavaScript. Given text instructions, Jules creates plans, identifies bugs, writes and completes code, issues GitHub pull requests, and otherwise streamlines development. Jules is slated for general availability in early 2025.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;OpenAI showed off GPT-4o’s capability for real-time video understanding in May, but Gemini 2.0 Flash beat it to the punch: Google launched the new model and its multimodal API one day ahead of ChatGPT’s Advanced Voice with Vision.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Speed and multimodal input/output are valuable characteristics for any AI model, and they’re especially useful in agentic applications. Google CEO Sundar Pichai said he wants Gemini to be a “universal assistant.” The new Gemini-based applications for coding, research, and video analysis are steps in that direction.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;While other large language models can take advantage of search, Gemini 2.0 Flash generates calls to Google Search and uses that capability in agentic tools — a demonstration of how Google’s dominance in search strengthens its efforts in AI.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--41-.gif\" class=\"kg-image\" alt=\"Animation showcasing 7 key NLP topics visually expanding on the screen.\" loading=\"lazy\" width=\"600\" height=\"336\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--41-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"when-llms-propose-research-ideas\"\u003eWhen LLMs Propose Research Ideas\u003c/h1\u003e\u003cp\u003eHow do agents based on large language models compare to human experts when it comes to proposing machine learning research? Pretty well, according to one study.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Chenglei Si, Diyi Yang, and Tatsunori Hashimoto at Stanford produced ideas for research in machine learning using Anthropic’s Claude 3.5 Sonnet and human researchers, and also\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sb3qgyTW6N1vHY6lZ3l2W5yW_P75MtsD_N8pQ7dx5GCRxVgsLjP6jKTqCW44xvwW5hBXMHW9hNsVJ53_LRhW1-7LlW5p7DnLW68tCdZ4Pnsv8W27fJQ48mRX9bW6qR7sz56p9QGW7xH4HY793yL_W3-6rRv8lDdRpW1pXW8m1lcWR9W7S4SZV27TqTTW57XdP21zNC0xW4fHLZV2x5nQpW6TFyHf4wJ4svW7R8l3n5NgTKRVjDBT9320My4W56Z5Y01k6qT5W8gn3P64Ct4_gW3JC1t_5w_znfW7NSZ8J64gdlrf2rDjpb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eevaluated\u003c/a\u003e\u0026nbsp;them using both manual and automated methods. Claude 3.5 Sonnet generated competitive proposals, but its evaluations of proposals were less compelling.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Each proposal included a problem statement, motivation, step-by-step plan, backup plan, and examples of baseline outcomes versus expected experimental outcomes.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eAutomated proposal generation:\u003c/strong\u003e\u0026nbsp;Given one of seven topics (bias, coding, safety, multilinguality, factuality, math, or uncertainty) and 10 related papers found by the Semantic Scholar search engine, Claude 3.5 Sonnet generated 4,000 research ideas. The authors embedded the ideas using\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3mLW43832822vYxLW82YDyp6h3xRqW5h_D0c1jR75GV4W3P28kzW6mW7qQh1s36JMw7W4fVnn-8tr9k0W48d9XN7W2cbcW1_lLPH7HdFdvW3nXNDJ7D7ZnfW8HK5Bt64hyBZW7d1PWt5QL-TqW3H4r0b3wX6DSW2_1Tps69j1j4W3XD6FH5k7RlSVCS0wf6p4Pl3W5yrBvJ8HzhsvW8TzHcf5y11T7W77CslQ32HP11VnXfhk2b4YWYN7TYhFDMY2dxW5VfbVY8Xgr9CN3tCVBZmgPV_W7xvpnw28t5c8W1R6rqJ3l-6SCVShWrN1pXHB8W1xn-NN1nJ8P1f4SLl4M04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eall-MiniLM-L6-v2\u003c/a\u003e\u0026nbsp;and removed duplicate ideas based on the cosine similarity of their embeddings. This left roughly 200 AI-generated ideas for each topic. For each remaining idea, the model generated a proposal.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAutomated ranking:\u003c/strong\u003e\u0026nbsp;Claude Sonnet 3.5 ranked the proposals in a five-round tournament that awarded points for superior quality and pitted highest-scoring proposals against one another. In addition, one of the authors manually ranked the generated proposals.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHuman proposal generation:\u003c/strong\u003e\u0026nbsp;The authors paid 49 machine learning engineers to propose their own ideas. They obscured authorship by prompting an unidentified large language model to edit them according to a style guide. Then they manually checked the rewritten proposals to ensure that the model’s editing didn’t change their content significantly.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHuman ranking:\u003c/strong\u003e\u0026nbsp;A group of 79 machine learning engineers reviewed the 49 human-written proposals, the top 49 AI-generated proposals ranked by humans, and the top 49 AI-generated proposals ranked by AI (resulting in two to four reviews per proposal). They scored the proposals between 1 and 10 on five factors: novelty, feasibility, expected effectiveness, how exciting they were, and overall quality.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;Human judges deemed proposals generated by Claude 3.5 Sonnet as good as or better than those produced by humans. However, large language models proved less effective at judging the proposals’ quality.\u003c/p\u003e\u003cul\u003e\u003cli\u003eOn average, humans scored the AI-generated and human-written proposals roughly equally in feasibility, expected effectiveness, how exciting they were, and overall quality. They deemed the AI-generated proposals significantly more novel. The top AI-generated proposals as ranked by humans achieved an average 5.78 novelty. The top AI-generated proposal as ranked by AI achieved an average 5.62 novelty. Human-written proposals achieved an average 4.86 novelty.\u003c/li\u003e\u003cli\u003eThe authors found that LLMs don’t yet match human performance when it comes to judging scientific papers. They compared the rates of agreement among five LLMs that evaluated proposals in their experiment, human judgements of the proposals, and human reviews of papers submitted to the NeurIPS and\u0026nbsp; ICLR conferences. The most consistent LLM, Claude 3.5 Sonnet, was 53.3 percent consistent with average human judgment. The human judges were 56.1 percent consistent. Reviewers for NeurIPS and ICLR were 66 and 71.9 percent consistent respectively. Random chance was 50 percent.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;AI models play a growing\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3nTN8Hf0M07TqKmW98hRWz75mJDlV8wWKQ5QzFb4W3W8dp06cHM4QW1PWy_-8gsqypW3vFPwg2lpv0mW21C-W34BNxCwW8Cp05X8mPMbkW3RK1hD2TZ458W3zxW3w1RLzpHW5nZgBY60f-rnW4k7fnV1B3jZsVpPQ814LjXl3W5kb99K1D3wfTW7csbHb6Nb9SFVX55VN5f6ZqSW5PSRwl2XRrWzN1mjWP7MW6LtN8pYQlGFV1XHW3871kJ4sBSP1W99Fh1S76QpdQW6L2Q4r2G3QWZN2hz2mZGS4-VW8kBHV_2NVC01W4Hp-gD3GLcnSN307RbG1_l5gf5mT7ls04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003erole\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3pFN8b2ZTwT6S_3W2wz8Ls2SnndDW6xcFfJ1hGksRW5rV9Pd4thpTrW37w9jP1LG2TwW96PCNd82Sj5CW4RF6km2nqYD1W5sr2Ct8LtPDdN7cCcjQPXYNBVNcQ1Q4D3csSW7FNttZ6jCC5JN98RtnDb5Y35W7C30W35L4nh4N5LWnzcQKFQQW6K6YP181tlD3W3_M4VD3NPsx5W7TQ2_Q3s9HRrW64fz_94kNLX0W7VMs2p1bC5jxVYTJD17xjPWcW14cftx33p11pW2P4D2M6MjssDW66vHpY5RtjnWW3TS53-4WCTfHF89-cpm7RDWW1GJgj96dlRK4f1_V8Tn04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ein\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7rC5nR32W5BWr2F6lZ3mDW870w3q3-HYStW119w_85MVr67W977sW56jqj__W7tHnZ97DmDn_W1kwt0d8mH36xVXCKmg39MQGZW8mkKDP4GWW2zW2GjFSs2vYHsQN8YDK8WLJyRPW8YGN9D3mfSZQW11sPCD9k4QcXW1BQZYZ4b3KYvN6Mn-914-9tfW8y4gmC59qRJVW72flG61fxt-LW4RR49Z7mWj2QW8MGNHt92W0LXW98NkQn7xfgm5W1tnyrD5wMttyW7gKyWd9h8LLdW8ff-Kq87rF3KW5zwyw82VbM8lW736p807LYCLgW8XF0qR4tyF89W45Xyrv5jnqWGVgRnnD8wlXvDW4FmjMl5-tKKXVp0mGJ2pr7CkW7zVSXz7KJQV0N8PJdtBX6RgwW3scRvy91scXVW7T3M_87XVSsSW7jbv2y7pl8NMW4fHmWv4JL3X9f54h31q04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003escientific\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVFdmP2Fs0F0N3zPdYDSNGxHW5n2k0f5pLzl_N6TZ7sP3qgyTW7Y8-PT6lZ3lsW8nw3p44BCGTdN1dp9d5xSXMVW2VC5bY3F81_zVS4LvQ11r5GWW4wXc_15J1yM6Vjzf7c3VkjDKW77K5vK2mVLYtW1sqXJ286HcTmN17QJLvyKSqTN4bCVbshRct7W8kfqXz914XnRW5bt0G95KKlp6W23DJM31NnCsRW7JyRVW6XGw5ZW5-TQSl6LZVkQW5C8mVr2v0WHhW4LxfWR8FQZR8W7pFQXZ1-zccSW76DKJK7Cl_7PW18BdyS6hcP6RW1n8_Ft7H8KTKVt8NLv15tTrmW8ZthBW1ZsTcpW6hgZWf5TB6CMW66YDPw6kDHzHW27Npp15FwGb_f4zPYmK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ediscovery\u003c/a\u003e. This work shows they can set directions for research — in machine learning, at least —\u0026nbsp; that rival those set by humans. However, human evaluation remains the gold standard for comparing performance on complex problems like generating text.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Coming up with good research ideas is hard! That a large language model can do it with some competency has exciting implications for the future of both AI and science.\u003c/p\u003e","comment_id":"676325a54b838200017dcc41","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32--1.png","featured":false,"visibility":"public","created_at":"2024-12-18T11:42:29.000-08:00","updated_at":"2025-02-13T14:04:48.000-08:00","published_at":"2024-12-18T12:00:00.000-08:00","custom_excerpt":"The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"67632aa24b838200017dcc85","name":"Dec 18, 2024","slug":"dec-18-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/dec-18-2024/"},{"id":"67632aa24b838200017dcc86","name":"issue-280","slug":"issue-280","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-280/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-280/","excerpt":"The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards.","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Phi-4 Breaks Size Barrier, HunyuanVideo Narrows Open Source Gap, and more...","meta_description":"The Batch AI News and Insights: I’m thrilled that former students and postdocs of mine won both of this year’s NeurIPS Test of Time Paper Awards.","email_subject":null,"frontmatter":null,"feature_image_alt":"Graph showing cross-validation accuracy vs. number of features for raw and whitened inputs.","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--32--1.png","dimensions":{"width":1200,"height":675}},"banner":{"title":"Mathematics for Machine learning and data science specialization","databaseId":29052,"id":"cG9zdDoyOTA1Mg==","featuredImage":{"node":{"altText":"Mathematics for Machine learning and data science specialization. Enroll now to the course","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/3.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-280"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>