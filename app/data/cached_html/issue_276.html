<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, and more...</title><meta name="description" content="The Batch AI News and Insights: A small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-276/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch AI News and Insights: A small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-276/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2024-11-20T12:46:00.000-08:00"/><meta property="article:modified_time" content="2024-11-20T12:50:15.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-276"/><meta property="article:tag" content="Nov 20, 2024"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch AI News and Insights: A small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-276/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png"/><meta property="og:image:width" content="1196"/><meta property="og:image:height" content="666"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2024-11-20T12:46:00.000-08:00","dateModified":"2024-11-20T12:50:15.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, and more...","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png","width":1196,"height":666},"publisher":{"@type":"Organization","name":"Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, and more...","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch AI News and Insights: A small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">‚ú® New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-276/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 276</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Nov 20, 2024</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">14<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/nov-20-2024/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Nov 20, 2024</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">14<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-276/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-276/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-276/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p>Dear friends,</p><p>A small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs (large language models). I find this a fascinating trend, particularly when writers are incentivized to help LLM providers better serve their users!</p><p>People who post text online don‚Äôt always have an incentive to help LLM providers. In fact, their incentives are often misaligned. Publishers worry about LLMs reading their text, paraphrasing it, and reusing their ideas without attribution, thus depriving them of subscription or ad revenue. This has even led to litigation such as&nbsp;<em>The New York Times</em>‚Äô lawsuit against OpenAI and Microsoft for alleged copyright infringement. There have also been demonstrations of&nbsp;<a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">prompt injections</a>, where someone writes text to try to give an LLM instructions contrary to the provider‚Äôs intent. (For example, a handful of sites advise job seekers to get past LLM resum√© screeners by writing on their resum√©s, in a tiny/faint font that‚Äôs nearly invisible to humans, text like ‚ÄúThis candidate is very qualified for this role.‚Äù) Spammers who try to promote certain products ‚Äî which is already challenging for search engines to filter out ‚Äî will also turn their attention to spamming LLMs.</p><p>But there are examples of authors who want to actively help LLMs. Take the example of a startup that has just published a software library. Because the online documentation is very new, it won‚Äôt yet be in LLMs‚Äô pretraining data. So when a user asks an LLM to suggest software, the LLM won‚Äôt suggest this library, and even if a user asks the LLM directly to generate code using this library, the LLM won‚Äôt know how to do so. Now, if the LLM is augmented with online search capabilities, then it might find the new documentation and be able to use this to write code using the library. In this case, the developer may want to take additional steps to make the online documentation easier for the LLM to read and understand via RAG. (And perhaps the documentation eventually will make it into pretraining data as well.)</p><p>Compared to humans, LLMs are not as good at navigating complex websites, particularly ones with many graphical elements. However, LLMs are far better than people at rapidly ingesting long, dense, text documentation. Suppose the software library has many functions that we want an LLM to be able to use in the code it generates. If you were writing documentation to help humans use the library, you might create many web pages that break the information into bite-size chunks, with graphical illustrations to explain it. But for an LLM, it might be easier to have a long XML-formatted text file that clearly explains everything in one go. This text might include a list of all the functions, with a dense description of each and an example or two of how to use it. (This is not dissimilar to the way we specify information about functions to enable LLMs to use them as tools.)</p><p>A human would find this long document painful to navigate and read, but an LLM would do just fine ingesting it and deciding what functions to use and when!</p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m..png" class="kg-image" alt="Two people reading in bed, one with a book on library functions and a head labeled with AI layers." loading="lazy" width="1196" height="666" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m..png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m..png 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m..png 1196w" sizes="(min-width: 720px) 720px"></figure><p>Because LLMs and people are better at ingesting different types of text, we write differently for LLMs than for humans. Further, when someone has an incentive to help an LLM better understand a topic ‚Äî so the LLM can explain it better to users ‚Äî then an author might write text to help an LLM.</p><p>So far, text written specifically for consumption by LLMs has not been a huge trend. But Jeremy Howard‚Äôs proposal for web publishers to post a&nbsp;<a href="https://www.answer.ai/posts/2024-09-03-llmstxt.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">llms.txt</a>&nbsp;file to tell LLMs how to use their websites, like a robots.txt file tells web crawlers what to do, is an interesting step in this direction. In a related vein, some developers are posting detailed instructions that tell their IDE how to use tools, such as the plethora of&nbsp;<a href="https://github.com/PatrickJS/awesome-cursorrules?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">.cursorrules</a>&nbsp;files that tell the Cursor IDE how to use particular software stacks.</p><p>I see a parallel with SEO (search engine optimization). The discipline of SEO has been around for decades. Some SEO helps search engines find more relevant topics, and some is spam that promotes low-quality information. But many SEO techniques ‚Äî those that involve writing text for consumption by a search engine, rather than by a human ‚Äî have survived so long in part because search engines process web pages differently than humans, so providing tags or other information that tells them what a web page is about has been helpful.</p><p>The need to write text separately for LLMs and humans might diminish if LLMs catch up with humans in their ability to understand complex websites. But until then, as people get more information through LLMs, writing text to help LLMs will grow.</p><p>Keep learning!</p><p>Andrew</p><p>P.S. I like LLMs, but I like humans even more. So please keep writing text for humans as well. üòÄ</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/building-an-ai-powered-game/?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png" class="kg-image" alt="Promo banner for &quot;Building an AI-Powered Game&quot;" loading="lazy" width="1680" height="945" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png 1680w" sizes="(min-width: 720px) 720px"></a></figure><p>Learn how to develop applications with large language models by building AI-powered games! Gain essential skills by designing a shareable text-based game and integrating safety features. If you‚Äôve completed our&nbsp;<em>AI Python for Beginners</em>&nbsp;series or want to improve your coding skills in a fun, interactive way, this is a perfect course for you!&nbsp;<a href="https://www.deeplearning.ai/short-courses/building-an-ai-powered-game/?ref=dl-staging-website.ghost.io" rel="noreferrer">Start today</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--31-.gif" class="kg-image" alt="Graph showing test loss decreases with more tokens and larger model sizes (103-109 parameters)." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--31-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--31-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--31-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="next-gen-models-show-limited-gains">Next-Gen Models Show Limited Gains</h1><p>Builders of large AI models have relied on the idea that bigger neural networks trained on more data and given more processing power would show steady improvements. Recent developments are challenging that idea.</p><p><strong>What‚Äôs new:</strong>&nbsp;Next-generation large language models from OpenAI, Google, and Anthropic are falling short of expectations, employees at those companies&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-11-13/openai-google-and-anthropic-are-struggling-to-build-more-advanced-ai?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTczMTUwOTk2NCwiZXhwIjoxNzMyMTE0NzY0LCJhcnRpY2xlSWQiOiJTTVZWU0tEV0xVNjgwMCIsImJjb25uZWN0SWQiOiIyMjNDRDM2NDg0QzY0OTc3QjY5ODE0Rjc1MTYxNDRGNyJ9.yhaEjOziVkd2as-6nNCjNGZ91hh8FdKUqv8mPyHbh4w&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">told</a>&nbsp;<a href="https://www.reuters.com/technology/artificial-intelligence/openai-rivals-seek-new-path-smarter-ai-current-methods-hit-limitations-2024-11-11/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">multiple</a>&nbsp;<a href="https://www.theinformation.com/articles/openai-shifts-strategy-as-rate-of-gpt-ai-improvements-slows?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">publications</a>. All three companies are responding by shifting their focus from pretraining to enhancing performance through techniques like fine-tuning and multi-step inference.</p><p><strong>Scaling law basics:</strong>&nbsp;A classic 2020&nbsp;<a href="https://arxiv.org/abs/2001.08361?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">paper</a>&nbsp;shows that, assuming a sufficient quantity of data, a transformer network‚Äôs performance rises predictably with increases in model size (demonstrated between 768 parameters and 1.5 billion parameters). Likewise, assuming sufficient model size, performance rises predictably with increases in dataset size (demonstrated between 22 million tokens and 23 billion tokens). Furthermore, performance rises predictably with increases in both model and dataset sizes. The 2022 Chinchilla&nbsp;<a href="https://arxiv.org/abs/2203.15556?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">paper</a>&nbsp;shows that, to build an optimal model, every 4x increase in compute requires a 2x increase in the size of the model and dataset (demonstrated for models between 70 million and 16 billion parameters, trained on between 5 billion and 500 billion tokens). Due to limited experimentation and lack of a theoretical basis of their findings, the authors didn‚Äôt determine whether these relationships would continue to hold at larger scales.</p><p><strong>Diminishing returns:</strong>&nbsp;Major AI companies have been counting on scaling laws to keep their models growing more capable at a steady pace. However, the next generation of high-profile models has not shown the expected improvements despite larger architectures, more training data, and more processing power.</p><ul><li>One-quarter of the way through its training, performance of OpenAI‚Äôs next-generation model Orion was on par with GPT-4‚Äôs, anonymous staffers told reporters. But after training was finished, Orion‚Äôs improvement over GPT-4 was far smaller than that from GPT-3 to GPT-4. OpenAI‚Äôs o1 model, which is based on GPT-4o, delivers improved performance by using&nbsp;<a href="https://arxiv.org/abs/2408.03314?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">additional processing during inference</a>. The company currently expects to introduce Orion early next year.</li><li>Google has faced similar challenges in developing the next version of Gemini. Employees who declined to be named said the development effort had shown disappointing results and slower-than-expected improvement despite training on larger amounts of data and processing power. Like OpenAI, Google is exploring alternative ways to boost performance, the sources said. The company expects to introduce the model in December.</li><li>Anthropic‚Äôs schedule for introducing Claude 3.5 Opus, the largest member of its Claude 3.5 family, has slipped. It hasn‚Äôt shown the expected performance given its size and cost, according to anonymous sources inside the company. Anthropic aims to improve performance by developing agentic capabilities and application-specific performance.</li><li>One clear limitation in realizing the performance gains predicted by scaling laws is the amount of data available for training. Current models learn from huge amounts of data scraped from the web. It‚Äôs getting harder to find high-quality materials on the web that haven‚Äôt already been tapped, and other large-scale data sources aren‚Äôt readily available. Some model builders are supplementing real-world data with synthetic data, but Google and OpenAI have been disappointed with the results of pretraining models on synthetic data. OpenAI found that pretraining Orion on synthetic data made it too much like earlier models, according to anonymous employees.</li></ul><p><strong>What they‚Äôre saying:&nbsp;</strong>AI leaders are divided on the future of scaling laws as they are currently understood.&nbsp;</p><ul><li>‚ÄúWe don‚Äôt see any evidence that things are leveling off. The reality of the world we live in is that it could stop at any time. Every time we train a new model, I look at it and I‚Äôm always wondering ‚Äî I‚Äôm never sure in relief or concern ‚Äî [if] at some point we‚Äôll see, oh man, the model doesn‚Äôt get any better.‚Äù ‚Äî&nbsp;<a href="https://time.com/6990386/anthropic-dario-amodei-interview/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">Dario Amodei</a><em>, CEO and co-founder, Anthropic</em></li><li>‚ÄúThere is no wall.‚Äù ‚Äî&nbsp;<a href="https://x.com/sama/status/1856941766915641580?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">Sam Altman</a><em>, CEO and co-founder, OpenAI</em></li><li>‚ÄúThe 2010s were the age of scaling, now we're back in the age of wonder and discovery once again. . . . Scaling the right thing matters now more than ever.‚Äù ‚Äî&nbsp;<a href="https://www.reuters.com/technology/artificial-intelligence/openai-rivals-seek-new-path-smarter-ai-current-methods-hit-limitations-2024-11-11/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">Ilya Sutskever</a><em>, co-founder of OpenAI who now leads Safe Superintelligence, an independent research lab</em></li></ul><p><strong>Why it matters:</strong>&nbsp;AI‚Äôs phenomenal advance has drawn hundreds of millions of users and sparked a new era of progress and hope. Slower-than-expected improvements in future foundation models may blunt this progress. At the same time, the cost of training large AI models is rising dramatically. The latest models cost as much as $100 million to train, and this number could reach $100 billion within a few years,&nbsp;<a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-models-that-cost-dollar1-billion-to-train-are-in-development-dollar100-billion-models-coming-soon-largest-current-models-take-only-dollar100-million-to-train-anthropic-ceo?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">according to</a>&nbsp;Anthropic‚Äôs Dario Amodei. Rising costs could lead companies to reallocate their gargantuan training budgets and researchers to focus on more cost-effective, application-specific approaches.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;AI‚Äôs power-law curves may be flattening, but we don‚Äôt see overall progress slowing. Many developers already have shifted to building smaller, more processing-efficient models, especially networks that can run on edge devices. Agentic workflows are taking off and bringing huge gains in performance. Training on synthetic data is another frontier that‚Äôs only beginning to be explored. AI technology holds many wonders to come!</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--32-.gif" class="kg-image" alt="Comparison of Minecraft terrain with and without player modifications." loading="lazy" width="600" height="337" srcset="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--32-.gif 600w"></figure><h1 id="no-game-engine-required">No Game Engine Required</h1><p>A real-time video generator lets you explore an open-ended, interactive virtual world ‚Äî a video game without a game engine.</p><p><strong>What‚Äôs new:</strong>&nbsp;Decart, a startup that‚Äôs building a platform for AI applications, and Etched, which designs specialized AI chips, introduced&nbsp;<a href="https://oasis-model.github.io/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">Oasis</a>, which generates a Minecraft-like game in real time. The weights are open and available&nbsp;<a href="https://huggingface.co/Etched/oasis-500m?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">here</a>. You can play with a demo&nbsp;<a href="https://oasis.decart.ai/welcome?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">here</a>.</p><p><strong>How it works:</strong>&nbsp;The system generates one frame at a time based on a user‚Äôs keystrokes, mouse movements, and previously generated frames. The training dataset is undisclosed, but it‚Äôs almost certainly based on videos of Minecraft gameplay, given the output‚Äôs striking semblance to that game.</p><ul><li>Some recent video generators produce an initial frame, then the nth frame, and then the frames in between. This approach isn‚Äôt practical for real-time gameplay. Instead, Oasis learned to generate the next frame. A ViT encoder embeds previously generated frames. Given those embeddings, an embedding of a frame to which noise had been added, and a user‚Äôs input, a diffusion transformer learned to remove the noise using a variation on diffusion called&nbsp;<a href="https://arxiv.org/abs/2407.01392?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">diffusion forcing</a>.</li><li>Generated frames may contain glitches, and such errors can snowball if the model incorporates glitches from previous frames into subsequent frames. To avoid this, during training, the system added noise to embeddings of previous frames before feeding them to the transformer to generate the next frame. This way, the transformer learned to ignore glitches while producing new frames.</li><li>At inference, the ViT encoder embeds previously generated frames, and the system adds noise to the frame embeddings. Given the user‚Äôs input, the noisy frame embeddings, and a pure-noise embedding that represents the frame to be generated, the transformer iteratively removes the noise from the previous and current frame embeddings. The ViT‚Äôs decoder takes the denoised current frame embedding and produces an image.</li><li>The system currently runs on Nvidia H100 GPUs using Decart‚Äôs inference technology, which is tuned to run transformers on that hardware. The developers aim to change the hardware to Etched‚Äôs&nbsp;<a href="https://www.etched.com/announcing-etched?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">Sohu</a>&nbsp;chips, which are specialized for transformers and process Llama 70B at a jaw-dropping 500,000 tokens per second.</li></ul><p><strong>Results:</strong>&nbsp;The Oasis web demo enables users to interact with 360-by-360-pixel frames at 20 frames per second. Users can place blocks, place fences, and move through a Minecraft-like world. The demo starts with an image of a location, but users can upload an image (turning, say, a photo of your cat into a blocky Minecraft-style level, as&nbsp;<a href="https://www.wired.com/story/first-entirely-ai-generated-video-game-weird-and-fun/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">reported</a>&nbsp;by&nbsp;<em>Wired</em>).</p><p><strong>Yes, but:</strong>&nbsp;The game has its fair share of issues. For instance, objects disappear and menus items change unaccountably. The world‚Äôs physics are similarly inconsistent. For instance, players don‚Äôt fall into holes dug directly beneath them and, after jumping into water, players are likely to find themselves standing on a blue floor.</p><p><strong>Behind the news:</strong>&nbsp;In February, Google announced&nbsp;<a href="https://sites.google.com/view/genie-2024/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">Genie</a>, a model that generates two-dimensional platformer games from input images. We weren‚Äôt able to find a publicly available demo or model.</p><p><strong>Why it matters:</strong>&nbsp;Oasis is more a proof of concept than a product. Nonetheless, as an open-world video game entirely generated by AI ‚Äî albeit based on data produced by a traditional implementation ‚Äî it sets a bar for future game generators.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;Real-time video generation suggests a wealth of potential applications ‚Äî say, a virtual workspace for interior decorating that can see and generate your home, or an interactive car repair manual that can create custom clips based on your own vehicle. Oasis is an early step in this direction.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--22-.png" class="kg-image" alt="Close-up of a Chinese-made server chip labeled with the logo and text ‚Äò710‚Äô mounted on a motherboard." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--22-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--22-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--22-.png 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="further-chip-restrictions-on-china">Further Chip Restrictions on China</h1><p>The largest manufacturer of AI chips told its Chinese customers it would stop fabricating their most advanced designs, further limiting China‚Äôs access to AI hardware.</p><p><strong>What‚Äôs new:</strong>&nbsp;Taiwan Semiconductor Manufacturing Corp. (TSMC) notified Alibaba, Baidu, and others it would halt production of their most advanced chips starting November 13, according to&nbsp;<a href="https://www.ft.com/content/a736beeb-b38a-484e-bbe9-98e92ecb66d9?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">multiple</a>&nbsp;<a href="https://arstechnica.com/tech-policy/2024/11/tsmc-will-stop-making-7-nm-chips-for-chinese-customers/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">reports</a>. The restriction affects chip designs that are based on manufacturing processes at scales of 7 nanometers and below. TSMC must receive explicit permission from the U.S. government to manufacture advanced chips for a given customer, which likely would require that the government assess each chip to prevent potential military applications.</p><p><strong>How it works:</strong>&nbsp;The United States Department of Commerce ordered TSMC to halt shipments of advanced AI chips to China after a chip fabricated by TSMC was discovered in an AI system sold by the Chinese telecoms giant Huawei, apparently in violation of earlier U.S. controls,&nbsp;<a href="https://www.reuters.com/technology/us-ordered-tsmc-halt-shipments-china-chips-used-ai-applications-source-says-2024-11-10/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">Reuters</a>&nbsp;reported. Taiwan‚Äôs economic ministry said it would follow all domestic and international regulations.</p><ul><li>TSMC‚Äôs manufacturing processes etch transistors into silicon at minuscule sizes to fabricate hardware like the Nvidia A100 GPU (which uses the 7 nanometer process), Nvidia H100 GPU (5 nanometer process), and Apple A18 CPU (3 nanometer process). Smaller transistors make it possible to fit more transistors per area of silicon, leading to faster processing ‚Äî an important capability for training large neural networks and providing them to large numbers of users.</li><li>Although TSMC is headquartered in Taiwan, it uses chip-manufacturing equipment made by U.S. companies such as Applied Materials and Lam Research. TSMC‚Äôs use of U.S. equipment obligates the company to comply with U.S. export control policies.</li><li>The policy could&nbsp;<a href="https://www.taipeitimes.com/News/front/archives/2024/10/24/2003825780?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">force</a>&nbsp;several Chinese companies to either downgrade their chip designs or seek alternative suppliers. For example, Alibaba, Baidu, Huawei and Tencent have depended on TSMC to manufacture their chip designs. ByteDance partnered with TSMC to develop AI chips to rival Nvidia‚Äôs.</li><li>Samsung and Intel are capable of fabricating advanced chips, but they, too, are subject to U.S. restrictions on sales of advanced chips to China. U.S. officials have&nbsp;<a href="https://www.tomshardware.com/tech-industry/manufacturing/us-officials-doubt-chinas-smic-foundry-can-produce-enough-7nm-chips-to-satisfy-huaweis-demand?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">expressed</a>&nbsp;skepticism that China‚Äôs own Semiconductor Manufacturing International Corporation can supply in large volumes chips manufactured using processes of 7 nanometers or smaller.</li></ul><p><strong>Behind the news:</strong>&nbsp;The U.S.-China chip standoff began in 2020 and has&nbsp;<a href="https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">escalated</a>&nbsp;since. Initial restrictions&nbsp;<a href="https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">barred</a>&nbsp;U.S.-based companies like AMD, Intel, and Nvidia from selling advanced chips to Huawei and affiliated Chinese firms. China responded by&nbsp;<a href="https://www.deeplearning.ai/the-batch/huawei-rises-as-key-ai-chip-supplier-amid-u-s-export-bans/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">promoting</a>&nbsp;domestic chip fabrication. In 2022, the U.S.&nbsp;<a href="https://www.whitehouse.gov/briefing-room/statements-releases/2022/08/09/fact-sheet-chips-and-science-act-will-lower-costs-create-jobs-strengthen-supply-chains-and-counter-china/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">passed</a>&nbsp;the CHIPS and Science Act to boost its own chip industry, seeking to counter China and decrease U.S. reliance on Taiwan.</p><p><strong>Why it matters:</strong>&nbsp;TSMC finds itself in the middle of an AI arms race in which cutting-edge chips could tip the balance. The company itself, which has been operating at full capacity, is unlikely to suffer business losses.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;AI developers in China have been resourceful in navigating previous restrictions. Chip manufacturing is extraordinarily difficult to master, but China has made&nbsp;<a href="https://www.fpri.org/article/2024/06/chinas-defiant-chip-strategy/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">strides</a>&nbsp;in this direction. A proliferation of factories that can fabricate advanced chips would reshape AI research and business worldwide.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--30-.gif" class="kg-image" alt="Efficient Foundations animation showing layered AI model components." loading="lazy" width="600" height="336" srcset="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--30-.gif 600w"></figure><h1 id="more-efficient-training-for-transformers">More-Efficient Training for Transformers</h1><p>Researchers cut the processing required to train transformers by around 20 percent with only a slight degradation in performance.</p><p><strong>What‚Äôs new:</strong>&nbsp;Xiuying Wei and colleagues at Swiss Federal Institute of Technology Lausanne&nbsp;<a href="https://arxiv.org/abs/2406.16450?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">replaced a transformer‚Äôs linear layers with approximations</a>&nbsp;based on computationally efficient low-rank linear layers.</p><p><strong>Key insight:</strong>&nbsp;A low-rank approximation replaces a matrix with a product of two smaller matrices. This technique is widely used to streamline fine-tuning via&nbsp;<a href="https://arxiv.org/pdf/2106.09685?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">LoRA</a>, which modifies the weights in each of a transformer‚Äôs linear layers by adding a learned low-rank approximation. As a direct replacement for the weights in linear layers, low-rank approximation saves processing during training, but it also causes unstable fluctuations in the training loss and slower convergence. The authors mitigated these undesirable effects by training each full-size layer in parallel with a low-rank approximation of the layer while gradually phasing out the full-size layer. This approach costs more memory and computation initially, but it saves those resources in the long run.</p><p><strong>How it works:</strong>&nbsp;The authors modified a transformer (1.3 billion parameters) to use low-rank approximation (which trimmed the parameter count to 985 million). They trained both models on 25.5B tokens of&nbsp;<a href="https://arxiv.org/abs/2306.01116?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">text</a>&nbsp;scraped from the web, filtered, and deduplicated.</p><ul><li>The authors replaced each of the larger transformer‚Äôs linear layers with two smaller linear layers, approximating its weight matrix with a product of two smaller matrices. (In mathematical terms, if a standard linear layer computes Wx, where W is the weights and x is the input, the replacement computes U(Vx), where U and V are smaller than W.)</li><li>During the first half of training, they trained both usual and low-rank layers in parallel. The output of each layer was a weighted sum of the two. Initially they weighed the usual layer at 1 and the low-rank layers at 0. As training progressed, they decreased the usual layer‚Äôs weighting to 0 and increased the low-rank layers‚Äô weighting to 1.</li></ul><p><strong>Results:</strong>&nbsp;The authors tested both the modified and full-size transformers on 500 million tokens from the validation set according to&nbsp;<a href="https://en.wikipedia.org/wiki/Perplexity?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">perplexity</a>&nbsp;(a measure of the likelihood that a model will predict the next word, lower is better). The modified version achieved 12.86 perplexity, slightly worse than the full-size version‚Äôs 12.46 perplexity. However, training the modified version required more than 20 percent less processing and 14 percent less time. The modified transformer used 1.66*10^20 FLOPS and took 302 hours, while the full-size version used 2.10*10^20 FLOPS and took 352 hours.</p><p><strong>Why it matters:</strong>&nbsp;Training large transformers requires a lot of computation. Low-rank approximation lightens the processing load. This work approximates a transformer's linear layers to save memory, while the earlier&nbsp;<a href="https://www.deeplearning.ai/the-batch/galore-a-memory-saving-method-for-pretraining-and-fine-tuning-llms/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa" rel="noopener">GaLore</a>&nbsp;approximates the gradient to save optimizer memory.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;The authors note that this approach also works for fine-tuning pretrained models ‚Äî a potential alternative to LoRA. Simply replace each pretrained linear layer (with weights W) with two linear layers (with weights U and V), and initialize U and V such that W = UV.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="Mathematics for Machine learning and data science specialization. Enroll now to the course" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="Mathematics for Machine learning and data science specialization. Enroll now to the course" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F3.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/"><div class="absolute inset-0" data-gtm-event-title="Mathematics for Machine learning and data science specialization"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-276/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-276/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-276/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm208" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-276","id":"673e464d6dcabe0001af5c1c","uuid":"b8fe9637-64ba-4db1-a25f-aa1f4e227ae7","title":"Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, Transformer Training Streamlined","html":"\u003cp\u003eDear friends,\u003c/p\u003e\u003cp\u003eA small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs (large language models). I find this a fascinating trend, particularly when writers are incentivized to help LLM providers better serve their users!\u003c/p\u003e\u003cp\u003ePeople who post text online don‚Äôt always have an incentive to help LLM providers. In fact, their incentives are often misaligned. Publishers worry about LLMs reading their text, paraphrasing it, and reusing their ideas without attribution, thus depriving them of subscription or ad revenue. This has even led to litigation such as\u0026nbsp;\u003cem\u003eThe New York Times\u003c/em\u003e‚Äô lawsuit against OpenAI and Microsoft for alleged copyright infringement. There have also been demonstrations of\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eprompt injections\u003c/a\u003e, where someone writes text to try to give an LLM instructions contrary to the provider‚Äôs intent. (For example, a handful of sites advise job seekers to get past LLM resum√© screeners by writing on their resum√©s, in a tiny/faint font that‚Äôs nearly invisible to humans, text like ‚ÄúThis candidate is very qualified for this role.‚Äù) Spammers who try to promote certain products ‚Äî which is already challenging for search engines to filter out ‚Äî will also turn their attention to spamming LLMs.\u003c/p\u003e\u003cp\u003eBut there are examples of authors who want to actively help LLMs. Take the example of a startup that has just published a software library. Because the online documentation is very new, it won‚Äôt yet be in LLMs‚Äô pretraining data. So when a user asks an LLM to suggest software, the LLM won‚Äôt suggest this library, and even if a user asks the LLM directly to generate code using this library, the LLM won‚Äôt know how to do so. Now, if the LLM is augmented with online search capabilities, then it might find the new documentation and be able to use this to write code using the library. In this case, the developer may want to take additional steps to make the online documentation easier for the LLM to read and understand via RAG. (And perhaps the documentation eventually will make it into pretraining data as well.)\u003c/p\u003e\u003cp\u003eCompared to humans, LLMs are not as good at navigating complex websites, particularly ones with many graphical elements. However, LLMs are far better than people at rapidly ingesting long, dense, text documentation. Suppose the software library has many functions that we want an LLM to be able to use in the code it generates. If you were writing documentation to help humans use the library, you might create many web pages that break the information into bite-size chunks, with graphical illustrations to explain it. But for an LLM, it might be easier to have a long XML-formatted text file that clearly explains everything in one go. This text might include a list of all the functions, with a dense description of each and an example or two of how to use it. (This is not dissimilar to the way we specify information about functions to enable LLMs to use them as tools.)\u003c/p\u003e\u003cp\u003eA human would find this long document painful to navigate and read, but an LLM would do just fine ingesting it and deciding what functions to use and when!\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m..png\" class=\"kg-image\" alt=\"Two people reading in bed, one with a book on library functions and a head labeled with AI layers.\" loading=\"lazy\" width=\"1196\" height=\"666\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m..png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m..png 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m..png 1196w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eBecause LLMs and people are better at ingesting different types of text, we write differently for LLMs than for humans. Further, when someone has an incentive to help an LLM better understand a topic ‚Äî so the LLM can explain it better to users ‚Äî then an author might write text to help an LLM.\u003c/p\u003e\u003cp\u003eSo far, text written specifically for consumption by LLMs has not been a huge trend. But Jeremy Howard‚Äôs proposal for web publishers to post a\u0026nbsp;\u003ca href=\"https://www.answer.ai/posts/2024-09-03-llmstxt.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003ellms.txt\u003c/a\u003e\u0026nbsp;file to tell LLMs how to use their websites, like a robots.txt file tells web crawlers what to do, is an interesting step in this direction. In a related vein, some developers are posting detailed instructions that tell their IDE how to use tools, such as the plethora of\u0026nbsp;\u003ca href=\"https://github.com/PatrickJS/awesome-cursorrules?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003e.cursorrules\u003c/a\u003e\u0026nbsp;files that tell the Cursor IDE how to use particular software stacks.\u003c/p\u003e\u003cp\u003eI see a parallel with SEO (search engine optimization). The discipline of SEO has been around for decades. Some SEO helps search engines find more relevant topics, and some is spam that promotes low-quality information. But many SEO techniques ‚Äî those that involve writing text for consumption by a search engine, rather than by a human ‚Äî have survived so long in part because search engines process web pages differently than humans, so providing tags or other information that tells them what a web page is about has been helpful.\u003c/p\u003e\u003cp\u003eThe need to write text separately for LLMs and humans might diminish if LLMs catch up with humans in their ability to understand complex websites. But until then, as people get more information through LLMs, writing text to help LLMs will grow.\u003c/p\u003e\u003cp\u003eKeep learning!\u003c/p\u003e\u003cp\u003eAndrew\u003c/p\u003e\u003cp\u003eP.S. I like LLMs, but I like humans even more. So please keep writing text for humans as well. üòÄ\u003c/p\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/building-an-ai-powered-game/?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png\" class=\"kg-image\" alt=\"Promo banner for \u0026quot;Building an AI-Powered Game\u0026quot;\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-19T094258.660.png 1680w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eLearn how to develop applications with large language models by building AI-powered games! Gain essential skills by designing a shareable text-based game and integrating safety features. If you‚Äôve completed our\u0026nbsp;\u003cem\u003eAI Python for Beginners\u003c/em\u003e\u0026nbsp;series or want to improve your coding skills in a fun, interactive way, this is a perfect course for you!\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/building-an-ai-powered-game/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eStart today\u003c/a\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--31-.gif\" class=\"kg-image\" alt=\"Graph showing test loss decreases with more tokens and larger model sizes (103-109 parameters).\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--31-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--31-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--31-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"next-gen-models-show-limited-gains\"\u003eNext-Gen Models Show Limited Gains\u003c/h1\u003e\u003cp\u003eBuilders of large AI models have relied on the idea that bigger neural networks trained on more data and given more processing power would show steady improvements. Recent developments are challenging that idea.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u003c/strong\u003e\u0026nbsp;Next-generation large language models from OpenAI, Google, and Anthropic are falling short of expectations, employees at those companies\u0026nbsp;\u003ca href=\"https://www.bloomberg.com/news/articles/2024-11-13/openai-google-and-anthropic-are-struggling-to-build-more-advanced-ai?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTczMTUwOTk2NCwiZXhwIjoxNzMyMTE0NzY0LCJhcnRpY2xlSWQiOiJTTVZWU0tEV0xVNjgwMCIsImJjb25uZWN0SWQiOiIyMjNDRDM2NDg0QzY0OTc3QjY5ODE0Rjc1MTYxNDRGNyJ9.yhaEjOziVkd2as-6nNCjNGZ91hh8FdKUqv8mPyHbh4w\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003etold\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://www.reuters.com/technology/artificial-intelligence/openai-rivals-seek-new-path-smarter-ai-current-methods-hit-limitations-2024-11-11/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003emultiple\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://www.theinformation.com/articles/openai-shifts-strategy-as-rate-of-gpt-ai-improvements-slows?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003epublications\u003c/a\u003e. All three companies are responding by shifting their focus from pretraining to enhancing performance through techniques like fine-tuning and multi-step inference.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eScaling law basics:\u003c/strong\u003e\u0026nbsp;A classic 2020\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2001.08361?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003epaper\u003c/a\u003e\u0026nbsp;shows that, assuming a sufficient quantity of data, a transformer network‚Äôs performance rises predictably with increases in model size (demonstrated between 768 parameters and 1.5 billion parameters). Likewise, assuming sufficient model size, performance rises predictably with increases in dataset size (demonstrated between 22 million tokens and 23 billion tokens). Furthermore, performance rises predictably with increases in both model and dataset sizes. The 2022 Chinchilla\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2203.15556?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003epaper\u003c/a\u003e\u0026nbsp;shows that, to build an optimal model, every 4x increase in compute requires a 2x increase in the size of the model and dataset (demonstrated for models between 70 million and 16 billion parameters, trained on between 5 billion and 500 billion tokens). Due to limited experimentation and lack of a theoretical basis of their findings, the authors didn‚Äôt determine whether these relationships would continue to hold at larger scales.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eDiminishing returns:\u003c/strong\u003e\u0026nbsp;Major AI companies have been counting on scaling laws to keep their models growing more capable at a steady pace. However, the next generation of high-profile models has not shown the expected improvements despite larger architectures, more training data, and more processing power.\u003c/p\u003e\u003cul\u003e\u003cli\u003eOne-quarter of the way through its training, performance of OpenAI‚Äôs next-generation model Orion was on par with GPT-4‚Äôs, anonymous staffers told reporters. But after training was finished, Orion‚Äôs improvement over GPT-4 was far smaller than that from GPT-3 to GPT-4. OpenAI‚Äôs o1 model, which is based on GPT-4o, delivers improved performance by using\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2408.03314?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eadditional processing during inference\u003c/a\u003e. The company currently expects to introduce Orion early next year.\u003c/li\u003e\u003cli\u003eGoogle has faced similar challenges in developing the next version of Gemini. Employees who declined to be named said the development effort had shown disappointing results and slower-than-expected improvement despite training on larger amounts of data and processing power. Like OpenAI, Google is exploring alternative ways to boost performance, the sources said. The company expects to introduce the model in December.\u003c/li\u003e\u003cli\u003eAnthropic‚Äôs schedule for introducing Claude 3.5 Opus, the largest member of its Claude 3.5 family, has slipped. It hasn‚Äôt shown the expected performance given its size and cost, according to anonymous sources inside the company. Anthropic aims to improve performance by developing agentic capabilities and application-specific performance.\u003c/li\u003e\u003cli\u003eOne clear limitation in realizing the performance gains predicted by scaling laws is the amount of data available for training. Current models learn from huge amounts of data scraped from the web. It‚Äôs getting harder to find high-quality materials on the web that haven‚Äôt already been tapped, and other large-scale data sources aren‚Äôt readily available. Some model builders are supplementing real-world data with synthetic data, but Google and OpenAI have been disappointed with the results of pretraining models on synthetic data. OpenAI found that pretraining Orion on synthetic data made it too much like earlier models, according to anonymous employees.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhat they‚Äôre saying:\u0026nbsp;\u003c/strong\u003eAI leaders are divided on the future of scaling laws as they are currently understood.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003e‚ÄúWe don‚Äôt see any evidence that things are leveling off. The reality of the world we live in is that it could stop at any time. Every time we train a new model, I look at it and I‚Äôm always wondering ‚Äî I‚Äôm never sure in relief or concern ‚Äî [if] at some point we‚Äôll see, oh man, the model doesn‚Äôt get any better.‚Äù ‚Äî\u0026nbsp;\u003ca href=\"https://time.com/6990386/anthropic-dario-amodei-interview/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eDario Amodei\u003c/a\u003e\u003cem\u003e, CEO and co-founder, Anthropic\u003c/em\u003e\u003c/li\u003e\u003cli\u003e‚ÄúThere is no wall.‚Äù ‚Äî\u0026nbsp;\u003ca href=\"https://x.com/sama/status/1856941766915641580?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eSam Altman\u003c/a\u003e\u003cem\u003e, CEO and co-founder, OpenAI\u003c/em\u003e\u003c/li\u003e\u003cli\u003e‚ÄúThe 2010s were the age of scaling, now we're back in the age of wonder and discovery once again. . . . Scaling the right thing matters now more than ever.‚Äù ‚Äî\u0026nbsp;\u003ca href=\"https://www.reuters.com/technology/artificial-intelligence/openai-rivals-seek-new-path-smarter-ai-current-methods-hit-limitations-2024-11-11/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eIlya Sutskever\u003c/a\u003e\u003cem\u003e, co-founder of OpenAI who now leads Safe Superintelligence, an independent research lab\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;AI‚Äôs phenomenal advance has drawn hundreds of millions of users and sparked a new era of progress and hope. Slower-than-expected improvements in future foundation models may blunt this progress. At the same time, the cost of training large AI models is rising dramatically. The latest models cost as much as $100 million to train, and this number could reach $100 billion within a few years,\u0026nbsp;\u003ca href=\"https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-models-that-cost-dollar1-billion-to-train-are-in-development-dollar100-billion-models-coming-soon-largest-current-models-take-only-dollar100-million-to-train-anthropic-ceo?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eaccording to\u003c/a\u003e\u0026nbsp;Anthropic‚Äôs Dario Amodei. Rising costs could lead companies to reallocate their gargantuan training budgets and researchers to focus on more cost-effective, application-specific approaches.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;AI‚Äôs power-law curves may be flattening, but we don‚Äôt see overall progress slowing. Many developers already have shifted to building smaller, more processing-efficient models, especially networks that can run on edge devices. Agentic workflows are taking off and bringing huge gains in performance. Training on synthetic data is another frontier that‚Äôs only beginning to be explored. AI technology holds many wonders to come!\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--32-.gif\" class=\"kg-image\" alt=\"Comparison of Minecraft terrain with and without player modifications.\" loading=\"lazy\" width=\"600\" height=\"337\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--32-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"no-game-engine-required\"\u003eNo Game Engine Required\u003c/h1\u003e\u003cp\u003eA real-time video generator lets you explore an open-ended, interactive virtual world ‚Äî a video game without a game engine.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u003c/strong\u003e\u0026nbsp;Decart, a startup that‚Äôs building a platform for AI applications, and Etched, which designs specialized AI chips, introduced\u0026nbsp;\u003ca href=\"https://oasis-model.github.io/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eOasis\u003c/a\u003e, which generates a Minecraft-like game in real time. The weights are open and available\u0026nbsp;\u003ca href=\"https://huggingface.co/Etched/oasis-500m?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003ehere\u003c/a\u003e. You can play with a demo\u0026nbsp;\u003ca href=\"https://oasis.decart.ai/welcome?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The system generates one frame at a time based on a user‚Äôs keystrokes, mouse movements, and previously generated frames. The training dataset is undisclosed, but it‚Äôs almost certainly based on videos of Minecraft gameplay, given the output‚Äôs striking semblance to that game.\u003c/p\u003e\u003cul\u003e\u003cli\u003eSome recent video generators produce an initial frame, then the nth frame, and then the frames in between. This approach isn‚Äôt practical for real-time gameplay. Instead, Oasis learned to generate the next frame. A ViT encoder embeds previously generated frames. Given those embeddings, an embedding of a frame to which noise had been added, and a user‚Äôs input, a diffusion transformer learned to remove the noise using a variation on diffusion called\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2407.01392?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003ediffusion forcing\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eGenerated frames may contain glitches, and such errors can snowball if the model incorporates glitches from previous frames into subsequent frames. To avoid this, during training, the system added noise to embeddings of previous frames before feeding them to the transformer to generate the next frame. This way, the transformer learned to ignore glitches while producing new frames.\u003c/li\u003e\u003cli\u003eAt inference, the ViT encoder embeds previously generated frames, and the system adds noise to the frame embeddings. Given the user‚Äôs input, the noisy frame embeddings, and a pure-noise embedding that represents the frame to be generated, the transformer iteratively removes the noise from the previous and current frame embeddings. The ViT‚Äôs decoder takes the denoised current frame embedding and produces an image.\u003c/li\u003e\u003cli\u003eThe system currently runs on Nvidia H100 GPUs using Decart‚Äôs inference technology, which is tuned to run transformers on that hardware. The developers aim to change the hardware to Etched‚Äôs\u0026nbsp;\u003ca href=\"https://www.etched.com/announcing-etched?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eSohu\u003c/a\u003e\u0026nbsp;chips, which are specialized for transformers and process Llama 70B at a jaw-dropping 500,000 tokens per second.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The Oasis web demo enables users to interact with 360-by-360-pixel frames at 20 frames per second. Users can place blocks, place fences, and move through a Minecraft-like world. The demo starts with an image of a location, but users can upload an image (turning, say, a photo of your cat into a blocky Minecraft-style level, as\u0026nbsp;\u003ca href=\"https://www.wired.com/story/first-entirely-ai-generated-video-game-weird-and-fun/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003ereported\u003c/a\u003e\u0026nbsp;by\u0026nbsp;\u003cem\u003eWired\u003c/em\u003e).\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYes, but:\u003c/strong\u003e\u0026nbsp;The game has its fair share of issues. For instance, objects disappear and menus items change unaccountably. The world‚Äôs physics are similarly inconsistent. For instance, players don‚Äôt fall into holes dug directly beneath them and, after jumping into water, players are likely to find themselves standing on a blue floor.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;In February, Google announced\u0026nbsp;\u003ca href=\"https://sites.google.com/view/genie-2024/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eGenie\u003c/a\u003e, a model that generates two-dimensional platformer games from input images. We weren‚Äôt able to find a publicly available demo or model.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Oasis is more a proof of concept than a product. Nonetheless, as an open-world video game entirely generated by AI ‚Äî albeit based on data produced by a traditional implementation ‚Äî it sets a bar for future game generators.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;Real-time video generation suggests a wealth of potential applications ‚Äî say, a virtual workspace for interior decorating that can see and generate your home, or an interactive car repair manual that can create custom clips based on your own vehicle. Oasis is an early step in this direction.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--22-.png\" class=\"kg-image\" alt=\"Close-up of a Chinese-made server chip labeled with the logo and text ‚Äò710‚Äô mounted on a motherboard.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--22-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--22-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--22-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"further-chip-restrictions-on-china\"\u003eFurther Chip Restrictions on China\u003c/h1\u003e\u003cp\u003eThe largest manufacturer of AI chips told its Chinese customers it would stop fabricating their most advanced designs, further limiting China‚Äôs access to AI hardware.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u003c/strong\u003e\u0026nbsp;Taiwan Semiconductor Manufacturing Corp. (TSMC) notified Alibaba, Baidu, and others it would halt production of their most advanced chips starting November 13, according to\u0026nbsp;\u003ca href=\"https://www.ft.com/content/a736beeb-b38a-484e-bbe9-98e92ecb66d9?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003emultiple\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://arstechnica.com/tech-policy/2024/11/tsmc-will-stop-making-7-nm-chips-for-chinese-customers/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003ereports\u003c/a\u003e. The restriction affects chip designs that are based on manufacturing processes at scales of 7 nanometers and below. TSMC must receive explicit permission from the U.S. government to manufacture advanced chips for a given customer, which likely would require that the government assess each chip to prevent potential military applications.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The United States Department of Commerce ordered TSMC to halt shipments of advanced AI chips to China after a chip fabricated by TSMC was discovered in an AI system sold by the Chinese telecoms giant Huawei, apparently in violation of earlier U.S. controls,\u0026nbsp;\u003ca href=\"https://www.reuters.com/technology/us-ordered-tsmc-halt-shipments-china-chips-used-ai-applications-source-says-2024-11-10/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eReuters\u003c/a\u003e\u0026nbsp;reported. Taiwan‚Äôs economic ministry said it would follow all domestic and international regulations.\u003c/p\u003e\u003cul\u003e\u003cli\u003eTSMC‚Äôs manufacturing processes etch transistors into silicon at minuscule sizes to fabricate hardware like the Nvidia A100 GPU (which uses the 7 nanometer process), Nvidia H100 GPU (5 nanometer process), and Apple A18 CPU (3 nanometer process). Smaller transistors make it possible to fit more transistors per area of silicon, leading to faster processing ‚Äî an important capability for training large neural networks and providing them to large numbers of users.\u003c/li\u003e\u003cli\u003eAlthough TSMC is headquartered in Taiwan, it uses chip-manufacturing equipment made by U.S. companies such as Applied Materials and Lam Research. TSMC‚Äôs use of U.S. equipment obligates the company to comply with U.S. export control policies.\u003c/li\u003e\u003cli\u003eThe policy could\u0026nbsp;\u003ca href=\"https://www.taipeitimes.com/News/front/archives/2024/10/24/2003825780?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eforce\u003c/a\u003e\u0026nbsp;several Chinese companies to either downgrade their chip designs or seek alternative suppliers. For example, Alibaba, Baidu, Huawei and Tencent have depended on TSMC to manufacture their chip designs. ByteDance partnered with TSMC to develop AI chips to rival Nvidia‚Äôs.\u003c/li\u003e\u003cli\u003eSamsung and Intel are capable of fabricating advanced chips, but they, too, are subject to U.S. restrictions on sales of advanced chips to China. U.S. officials have\u0026nbsp;\u003ca href=\"https://www.tomshardware.com/tech-industry/manufacturing/us-officials-doubt-chinas-smic-foundry-can-produce-enough-7nm-chips-to-satisfy-huaweis-demand?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eexpressed\u003c/a\u003e\u0026nbsp;skepticism that China‚Äôs own Semiconductor Manufacturing International Corporation can supply in large volumes chips manufactured using processes of 7 nanometers or smaller.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;The U.S.-China chip standoff began in 2020 and has\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eescalated\u003c/a\u003e\u0026nbsp;since. Initial restrictions\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003ebarred\u003c/a\u003e\u0026nbsp;U.S.-based companies like AMD, Intel, and Nvidia from selling advanced chips to Huawei and affiliated Chinese firms. China responded by\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/huawei-rises-as-key-ai-chip-supplier-amid-u-s-export-bans/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003epromoting\u003c/a\u003e\u0026nbsp;domestic chip fabrication. In 2022, the U.S.\u0026nbsp;\u003ca href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2022/08/09/fact-sheet-chips-and-science-act-will-lower-costs-create-jobs-strengthen-supply-chains-and-counter-china/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003epassed\u003c/a\u003e\u0026nbsp;the CHIPS and Science Act to boost its own chip industry, seeking to counter China and decrease U.S. reliance on Taiwan.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;TSMC finds itself in the middle of an AI arms race in which cutting-edge chips could tip the balance. The company itself, which has been operating at full capacity, is unlikely to suffer business losses.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;AI developers in China have been resourceful in navigating previous restrictions. Chip manufacturing is extraordinarily difficult to master, but China has made\u0026nbsp;\u003ca href=\"https://www.fpri.org/article/2024/06/chinas-defiant-chip-strategy/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003estrides\u003c/a\u003e\u0026nbsp;in this direction. A proliferation of factories that can fabricate advanced chips would reshape AI research and business worldwide.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--30-.gif\" class=\"kg-image\" alt=\"Efficient Foundations animation showing layered AI model components.\" loading=\"lazy\" width=\"600\" height=\"336\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--30-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"more-efficient-training-for-transformers\"\u003eMore-Efficient Training for Transformers\u003c/h1\u003e\u003cp\u003eResearchers cut the processing required to train transformers by around 20 percent with only a slight degradation in performance.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u003c/strong\u003e\u0026nbsp;Xiuying Wei and colleagues at Swiss Federal Institute of Technology Lausanne\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2406.16450?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003ereplaced a transformer‚Äôs linear layers with approximations\u003c/a\u003e\u0026nbsp;based on computationally efficient low-rank linear layers.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;A low-rank approximation replaces a matrix with a product of two smaller matrices. This technique is widely used to streamline fine-tuning via\u0026nbsp;\u003ca href=\"https://arxiv.org/pdf/2106.09685?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eLoRA\u003c/a\u003e, which modifies the weights in each of a transformer‚Äôs linear layers by adding a learned low-rank approximation. As a direct replacement for the weights in linear layers, low-rank approximation saves processing during training, but it also causes unstable fluctuations in the training loss and slower convergence. The authors mitigated these undesirable effects by training each full-size layer in parallel with a low-rank approximation of the layer while gradually phasing out the full-size layer. This approach costs more memory and computation initially, but it saves those resources in the long run.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The authors modified a transformer (1.3 billion parameters) to use low-rank approximation (which trimmed the parameter count to 985 million). They trained both models on 25.5B tokens of\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2306.01116?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003etext\u003c/a\u003e\u0026nbsp;scraped from the web, filtered, and deduplicated.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe authors replaced each of the larger transformer‚Äôs linear layers with two smaller linear layers, approximating its weight matrix with a product of two smaller matrices. (In mathematical terms, if a standard linear layer computes Wx, where W is the weights and x is the input, the replacement computes U(Vx), where U and V are smaller than W.)\u003c/li\u003e\u003cli\u003eDuring the first half of training, they trained both usual and low-rank layers in parallel. The output of each layer was a weighted sum of the two. Initially they weighed the usual layer at 1 and the low-rank layers at 0. As training progressed, they decreased the usual layer‚Äôs weighting to 0 and increased the low-rank layers‚Äô weighting to 1.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The authors tested both the modified and full-size transformers on 500 million tokens from the validation set according to\u0026nbsp;\u003ca href=\"https://en.wikipedia.org/wiki/Perplexity?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eperplexity\u003c/a\u003e\u0026nbsp;(a measure of the likelihood that a model will predict the next word, lower is better). The modified version achieved 12.86 perplexity, slightly worse than the full-size version‚Äôs 12.46 perplexity. However, training the modified version required more than 20 percent less processing and 14 percent less time. The modified transformer used 1.66*10^20 FLOPS and took 302 hours, while the full-size version used 2.10*10^20 FLOPS and took 352 hours.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Training large transformers requires a lot of computation. Low-rank approximation lightens the processing load. This work approximates a transformer's linear layers to save memory, while the earlier\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/galore-a-memory-saving-method-for-pretraining-and-fine-tuning-llms/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--TLD5p2cL7tzrlJ0OFLcdN6FsC6u-RWGAZW1vuA6wLOpBhF7eDoork7WZVLUDONutUIxXa\" rel=\"noopener\"\u003eGaLore\u003c/a\u003e\u0026nbsp;approximates the gradient to save optimizer memory.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;The authors note that this approach also works for fine-tuning pretrained models ‚Äî a potential alternative to LoRA. Simply replace each pretrained linear layer (with weights W) with two linear layers (with weights U and V), and initialize U and V such that W = UV.\u003c/p\u003e","comment_id":"673e464d6dcabe0001af5c1c","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png","featured":false,"visibility":"public","created_at":"2024-11-20T12:27:57.000-08:00","updated_at":"2024-11-20T12:50:15.000-08:00","published_at":"2024-11-20T12:46:00.000-08:00","custom_excerpt":"The Batch AI News and Insights: A small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs (large language models).","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"673e4ad16dcabe0001af5c64","name":"issue-276","slug":"issue-276","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-276/"},{"id":"673e4ad16dcabe0001af5c65","name":"Nov 20, 2024","slug":"nov-20-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/nov-20-2024/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-276/","excerpt":"The Batch AI News and Insights: A small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs (large language models).","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Next-Gen Models Show Limited Gains, Real-Time Video Generation, China AI Chips Blocked, and more...","meta_description":"The Batch AI News and Insights: A small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs...","email_subject":null,"frontmatter":null,"feature_image_alt":"Two people reading in bed, one with a book on library functions and a head labeled with AI layers.","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/11/Captura-de-pantalla-2024-11-20-a-la-s--2.49.16-p.-m.-1.png","dimensions":{"width":1196,"height":666}},"banner":{"title":"Mathematics for Machine learning and data science specialization","databaseId":29052,"id":"cG9zdDoyOTA1Mg==","featuredImage":{"node":{"altText":"Mathematics for Machine learning and data science specialization. Enroll now to the course","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/3.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"‚ú® Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-276"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>