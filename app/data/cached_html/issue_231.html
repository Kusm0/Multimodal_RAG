<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, and more</title><meta name="description" content="The Batch AI News and Insights: It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-231/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch AI News and Insights: It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-231/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2024-01-10T12:15:13.000-08:00"/><meta property="article:modified_time" content="2024-03-11T08:47:49.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-231"/><meta property="article:tag" content="Jan 10, 2024"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch AI News and Insights: It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-231/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--100-.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--100-.png"/><meta property="og:image:width" content="1680"/><meta property="og:image:height" content="945"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2024-01-10T12:15:13.000-08:00","dateModified":"2024-03-11T08:47:49.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, and more","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--100-.png","width":1680,"height":945},"publisher":{"@type":"Organization","name":"AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, and more","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch AI News and Insights: It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">‚ú® New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-231/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 231</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Jan 10, 2024</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">15<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/jan-10-2024/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Jan 10, 2024</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">15<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-231/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-231/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-231/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,&nbsp;</em></p><p><em>It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt that way after finishing&nbsp;</em><a href="https://arxiv.org/abs/2305.18290?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>Direct Preference Optimization</em></a><em>&nbsp;(DPO) by Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Chris Manning, and Chelsea Finn. (I didn't actually stand up and clap, since I was in a crowded coffee shop when I read it and would have gotten weird looks!</em>&nbsp;üòÄ<em>)</em></p><p><em>This beautiful work proposes a much simpler alternative to RLHF (reinforcement learning from human feedback) for aligning language models to human preferences. Further, people often ask if universities ‚Äî which don't have the massive compute resources of big tech ‚Äî can still do cutting-edge research on large language models (LLMs). The answer, to me, is obviously yes! This article is a beautiful example of algorithmic and mathematical insight arrived at by an academic group thinking deeply.&nbsp;<br><br>RLHF became a key algorithm for LLM training thanks to the&nbsp;</em><a href="https://www.deeplearning.ai/the-batch/a-kinder-gentler-language-model/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>InstructGPT</em></a><em>&nbsp;paper, which adapted the technique to that purpose. A typical implementation of the algorithm works as follows:&nbsp;</em></p><ul><li><em>Get humans to compare pairs of LLM outputs, generated in response to the same prompt, to specify which one they prefer. For example, humans typically prefer the more helpful, less toxic output.</em></li><li><em>Use the human preferences to learn a reward function. The reward function, typically represented using a transformer network, is trained to give a higher reward (or score) to the outputs that the humans preferred.</em></li><li><em>Finally, using the learned reward, run a reinforcement learning algorithm to tune the LLM to (i) maximize the reward of the answers generated, while (ii) not letting the LLM change too much (as a form of regularization).</em></li></ul><p><em>This is a relatively complex algorithm. It needs to separately represent a reward function and an LLM. Also, the final, reinforcement learning step is well known to be finicky to the choice of hyperparameters.</em></p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--99-.png" class="kg-image" alt="" loading="lazy" width="2000" height="1125" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/The-Batch-ads-and-exclusive-banners--99-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/The-Batch-ads-and-exclusive-banners--99-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/01/The-Batch-ads-and-exclusive-banners--99-.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--99-.png 2000w" sizes="(min-width: 720px) 720px"></figure><p><em>DPO dramatically simplifies the whole thing. Rather than needing separate transformer networks to represent a reward function and an LLM, the authors show how, given an LLM, you can figure out the reward function (plus regularization term) that that LLM is best at maximizing. This collapses the two transformer networks into one. Thus, you now need to train only the LLM and no longer have to deal with a separately trained reward function. The DPO algorithm trains the LLM directly, so as to make the reward function (which is implicitly defined by the LLM) consistent with the human preferences. Further, the authors show that DPO is better at achieving RLHF's optimization objective (that is, (i) and (ii) above) than most implementations of RLHF itself.&nbsp;</em></p><p><em>RLHF is a key building block of the most advanced LLMs. It‚Äôs fantastic that these Stanford authors ‚Äî through clever thinking and mathematical insight ‚Äî seem to have replaced it with something simpler and more elegant. While it's easy to get excited about a piece of research before it has stood the test of time, I am cautiously optimistic that DPO will have a huge impact on LLMs and beyond in the next few years. Indeed, it is already making its way into some top-performing models, such as Mistral‚Äôs&nbsp;</em><a href="https://mistral.ai/news/mixtral-of-experts?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>Mixtral</em></a><em>.&nbsp;&nbsp;</em></p><p><em>That we can replace such fundamental building blocks of LLMs is a sign that the field is still new and much innovation lies ahead. Also, while it's always nice to have massive numbers of NVIDIA H100 or AMD MI300X GPUs, this work is another illustration ‚Äî out of many, I want to emphasize ‚Äî that deep thinking with only modest computational resources can carry you far.&nbsp;</em></p><p><em>A few weeks ago at NeurIPS (where DPO was published), I found it remarkable both (i) how much highly innovative research there is coming out of academic labs, independent labs, and companies small and large, and (ii) how much our media landscape skews attention toward work published by the big tech companies. I suspect that if DPO had been published by one of the big LLM companies, it would have made a huge PR splash and been announced as a massive breakthrough. Let us all, as builders of AI systems, make sure we recognize the breakthroughs wherever they occur.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. We just launched our first short course that uses JavaScript! In ‚Äã‚Äã‚ÄúBuild LLM Apps with LangChain.js,‚Äù taught by LangChain‚Äôs founding engineer Jacob Lee, you‚Äôll learn many steps that are common in AI development, including how to use (i) data loaders to pull data from common sources such as PDFs, websites, and databases; (ii) different models to write applications that are not vendor-specific; and (iii) parsers that extract and format the output for your downstream code to process. You‚Äôll also use the LangChain Expression Language (LCEL), which makes it easy to compose chains of modules to perform complex tasks. Putting it all together, you‚Äôll build a conversational question-answering LLM application capable of using external data as context. Please sign up&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>here</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--89-.png" class="kg-image" alt="" loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/unnamed--89-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/unnamed--89-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--89-.png 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="deep-learning-discovers-antibiotics">Deep Learning Discovers Antibiotics</h1><p>Biologists used neural networks to find a new class of antibiotics.</p><p><strong>What‚Äôs new:&nbsp;</strong>Researchers at MIT and Harvard&nbsp;<a href="https://www.nature.com/articles/s41586-023-06887-8?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">trained</a>&nbsp;models to screen chemical compounds for those that kill methicillin-resistant&nbsp;<em>Staphylococcus aureus</em>&nbsp;(MRSA), the deadliest among bacteria that have evolved to be invulnerable to common antibiotics, and aren‚Äôt toxic to humans.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors built a training set of 39,312 compounds including most known antibiotics and a diverse selection of other molecules. In a lab, they tested each compound for its ability to inhibit growth of MRSA and its toxicity to human liver, skeletal muscle, and lung cells. Using the resulting data, they trained four ensembles of 20 graph neural networks each to classify compounds for (i) antibiotic properties, (ii) toxicity to the liver, (iii) toxicity to skeletal muscles, and (iv) toxicity to the lungs.&nbsp;</p><ul><li>They ran their four ensembles on 12 million compounds from the&nbsp;<a href="https://mcule.com/database/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Mcule</a>&nbsp;database and a Broad Institute&nbsp;<a href="https://github.com/felixjwong/antibioticsai?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">database</a>. They filtered out compounds with the lowest probability of being antibiotics and the highest probability of being toxic to humans, leaving 3,646 antibiotic, low-toxicity compounds.&nbsp;</li><li>Within these compounds, they found the minimal chemical structure responsible for the antibiotic properties. To do this, they removed atoms or rings of atoms from a molecule‚Äôs edges, predicted the probability that the modified molecule was an active antibiotic, and repeated these steps until the probability fell below a threshold. Compounds that share a chemical structure are likely to work in similar ways within the body, giving scientists a pathway to discover further compounds with similar benefits.</li></ul><p><strong>Results:&nbsp;</strong>Of the compounds predicted to be likely antibiotics and nontoxic, the authors lab-tested 241 that were not known to work against MRSA. Of those, 8.7 percent inhibited the bacterium‚Äôs growth. This exceeds the percentage of antibiotics in the training set (1.3 percent), suggesting that the authors‚Äô approach could be a useful first step in finding new antibiotics. The authors also tested 30 compounds predicted not to be antibiotics. None of them (0 percent) inhibited the bacterium‚Äôs growth ‚Äî further evidence that their approach could be a useful first step. Two of the compounds that inhibited MRSA share a similar and novel mechanism of action against bacteria and also inhibited other antibiotic-resistant infections in lab tests. One of them proved effective against MRSA infections in mice.</p><p><strong>Behind the news:&nbsp;</strong>Most antibiotics currently in use were discovered in the mid-20th century, a golden age of antibiotics, which brought many formerly deadly pathogens under control. Modern techniques, including genomics and synthetic antibiotics, extended discoveries through the end of the century by identifying variants on existing drugs. However, in the 21st century, new antibiotics have either been redundant or haven‚Äôt been clinically successful, a report by the National Institutes of Health&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6627412/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">noted</a>. At the same time, widespread use of antibiotics has pushed many dangerous bacteria to evolve resistance. Pathogens chiefly responsible for a variety of ailments are generally resistant even to antibiotics reserved for use as a last resort.<br><br><strong>Why it matters:&nbsp;</strong>Antibiotic-resistant infections are among the top global public health threats directly responsible for 1.27 million deaths in 2019,&nbsp;<a href="https://www.who.int/news-room/fact-sheets/detail/antimicrobial-resistance?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">according to</a>&nbsp;the World Health Organization.<strong>&nbsp;</strong>New options, as well as efforts to fight the emergence of resistant strains, are needed.</p><p><strong>We‚Äôre thinking:&nbsp;</strong>If neural networks can&nbsp;<a href="https://www.deeplearning.ai/the-batch/treatment-the-elusive-molecule/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">identify</a>&nbsp;new classes of medicines, AI could bring a golden age of medical discovery. That hope helps to explain why pharmaceutical companies are&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-pharma-jobs/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">hiring</a>&nbsp;machine learning engineers at unprecedented rates.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150551.860.gif" class="kg-image" alt="" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/unnamed---2024-01-10T150551.860.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/unnamed---2024-01-10T150551.860.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150551.860.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="openai-revamps-safety-protocol">OpenAI Revamps Safety Protocol</h1><p>Retrenching after its November leadership shakeup, OpenAI unveiled a new framework for evaluating risks posed by its models and deciding whether to limit their use.&nbsp;</p><p><strong>What‚Äôs new:</strong>&nbsp;OpenAI‚Äôs&nbsp;<a href="https://openai.com/safety/preparedness?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">safety framework</a>&nbsp;reorganizes pre-existing teams and forms new ones to establish a hierarchy of authority with the company‚Äôs board of directors at the top. It defines four categories of risk to be considered in decisions about how to use new models.&nbsp;</p><p><strong>How it works:</strong>&nbsp;OpenAI‚Äôs&nbsp;<a href="https://openai.com/blog/frontier-risk-and-preparedness?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Preparedness Team</a>&nbsp;is responsible for evaluating models. The Safety Advisory Group, whose members are appointed by the CEO for year-long terms, reviews the Preparedness Team‚Äôs work and recommends approaches to deploying models and mitigating risks, if necessary. The CEO has the authority to approve and oversee recommendations, overriding the Safety Authority Group if needed. OpenAI‚Äôs board of directors can overrule the CEO.</p><ul><li>The Preparedness Team scores each model in four categories of risk: enabling or enhancing cybersecurity threats, helping to create weapons of mass destruction, generating outputs that affect users‚Äô beliefs, and operating autonomously without human supervision. The team can modify these risk categories or add new categories in response to emerging research.</li><li>The team scores models in each category using four levels: low, medium, high, or critical. Critical indicates a model with superhuman capabilities or, in the autonomy category, one that can resist efforts to shut it down. A model‚Äôs score is its highest risk level in any category.</li><li>The team scores each model twice: once after training and fine-tuning, and a second time after developers have tried to mitigate risks.</li><li>OpenAI will not release models that earn a score of high or critical prior to mitigation, or a medium, high, or critical after mitigation.</li></ul><p><strong>Behind the news:</strong>&nbsp;The Preparedness Team and Safety Advisory Group join a number of safety-focused groups within OpenAI. The&nbsp;<a href="https://openai.com/safety/safety-systems?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Safety Systems Team</a>&nbsp;focuses on mitigating risks after a model has been deployed; for instance, ensuring user privacy and preventing language models from providing false information. The&nbsp;<a href="https://openai.com/blog/introducing-superalignment?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Superalignment Team</a>, led by Ilya Sutskever and Jan Leike, is charged with making sure hypothetical superintelligent systems, whose capabilities would surpass humans, adhere to values that benefit humans.<br><br><strong>Why it matters:</strong>&nbsp;AI is an extraordinarily powerful technology whose ultimate impacts are difficult to foresee. OpenAI has invested consistently in AI safety since its inception ‚Äî even if purportedly cautious moves like keeping its GPT-2 large language model under wraps often looked as much like publicity stunts as safety measures ‚Äî and its practices are likely to influence those of other AI companies. Furthermore, OpenAI has faced internal&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-leadership-shakeup-at-openai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">chaos</a>&nbsp;partly over concerns about safety and governance. Clear protocols in these areas could prevent future strife and stabilize the company to the benefit of its users, employees, and investors.&nbsp;</p><p><strong>We‚Äôre thinking:&nbsp;</strong>OpenAI‚Äôs safety framework looks like a step forward, but its risk categories focus on long-term, low-likelihood outcomes (though they stop short of considering AI‚Äôs hypothetical, and likely mythical, existential risk to humanity). Meanwhile, clear and present safety issues, such as social bias and factual accuracy, are well known to afflict current models including OpenAI‚Äôs. We hope that the Preparedness Team promptly adds categories that represent safety issues presented by today‚Äôs models.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2"><img src="https://dl-staging-website.ghost.io/content/images/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png" class="kg-image" alt="" loading="lazy" width="2000" height="1040" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png 2000w" sizes="(min-width: 720px) 720px"></a></figure><p>In this short course, you‚Äôll dive into LangChain.js, a JavaScript framework for building applications based on large language models, and learn how to craft powerful, context-aware apps. Elevate your machine learning-powered development skills using JavaScript.&nbsp;<a href="https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Sign up today</a></p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--48-.jpg" class="kg-image" alt="" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/unnamed--48-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/unnamed--48-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--48-.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="agi-defined">AGI Defined</h1><p>How will we know if someone succeeds in building artificial general intelligence (AGI)? A recent paper defines milestones on the road from calculator to superintelligence.</p><p><strong>What‚Äôs new:</strong>&nbsp;Researchers at Google led by Meredith Ringel Morris&nbsp;<a href="https://arxiv.org/abs/2311.02462?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">propose</a>&nbsp;a taxonomy of AI systems according to their degree of generality and ability to perform cognitive tasks. They consider today‚Äôs large multimodal models to be ‚Äúemerging AGI.‚Äù</p><p><strong>AGI basics:</strong>&nbsp;Artificial general intelligence is commonly defined as AI that can perform any intellectual task a human can. Shane Legg (who co-founded DeepMind) and Ben Goertzel (co-founder and CEO of&nbsp;<a href="https://singularitynet.io/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">SingularityNet</a>) coined the term AGI for a 2007 collection of&nbsp;<a href="https://link.springer.com/book/10.1007/978-3-540-68677-4?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">essays</a>. Subsequently, companies like DeepMind and OpenAI, which explicitly aim to develop AGI, propelled the idea into the mainstream.</p><p><strong>How it works:</strong>&nbsp;The taxonomy categorizes systems as possessing narrow skills (not AGI) or general capabilities (AGI). It divides both narrow and general systems into five levels of performance beyond calculator-grade Level 0. It also includes a metric for degree of autonomy.</p><ul><li>Narrow systems perform one distinct task; they may perform at one of the five levels, but they are not AGI. General systems perform a range of tasks (which the authors don‚Äôt specify) that align with real-world activities of broad value to people, including but not limited to linguistic, mathematical, logical, spatial reasoning, social, learning, and creative tasks. Crucially, they can learn how to learn new skills and when to ask humans for more information. The authors classify general systems as AGI at various levels of performance.</li><li>Level 1 (‚Äúemerging‚Äù) matches or slightly exceeds unskilled humans. Levels 2 (‚Äúcompetent‚Äù), 3 (‚Äúexpert‚Äù), and 4 (‚Äúvirtuoso‚Äù) systems surpass the 50th, 90th and 99th percentiles of skilled human performance, respectively. Level 5 (‚Äúsuperhuman‚Äù or ‚Äúartificial superintelligence‚Äù) outperforms 100 percent of skilled humans.</li><li>Most current systems that perform at Level 2 or higher are narrow. For example,&nbsp;<a href="https://www.deeplearning.ai/the-batch/protein-shapes-revealed/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">AlphaFold</a>, which finds the shapes of protein molecules, achieves Level 5 performance but only in a single task. On the other hand, the authors consider large language models like Bard, ChatGPT, and Lama 2 to be general systems at Level 1 (although their performance may achieve Level 2 in some tasks).&nbsp;</li><li>The authors‚Äô autonomy scale ranges from tools for which humans control the task while the system automates subtasks (the first level of autonomy) to agents that act independently (the fifth). Higher levels of performance can unlock higher levels of autonomy. For instance, Level 4 AGI may be necessary to enable fully autonomous vehicles that are safe and trustworthy.</li></ul><p><strong>Yes, but:&nbsp;</strong>The authors‚Äô definition identifies some classes of tasks that contribute to generality, but it includes neither a list of tasks a system must perform to be considered general nor&nbsp;a method for selecting them. Rather, the authors call on the research community to develop a ‚Äúliving benchmark‚Äù for generality that includes a mechanism for adding novel tasks.</p><p><strong>Why it matters:&nbsp;</strong>AGI is one of the tech world‚Äôs hottest buzzwords, yet it has had no clear definition, and various organizations propose different definitions. This lack of specificity makes it hard to talk about related technology, regulation, and other topics. The authors‚Äô framework, on the other hand, supports a more nuanced discussion of the path toward AGI. And it may have high-stakes business implications: Under the terms of their partnership, OpenAI can withhold from Microsoft models that attain AGI. Applying the authors‚Äô taxonomy would make it harder for one of the parties to move the goalposts.&nbsp;</p><p><strong>We‚Äôre thinking:</strong>&nbsp;Defining AGI is tricky! For instance, OpenAI defines AGI as ‚Äúa highly autonomous system that outperforms humans at most economically valuable work.‚Äù This definition, had it been formulated in the early 1900s, when agriculture accounted for 70 percent of work globally, would have described the internal combustion engine.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150942.421.gif" class="kg-image" alt="" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150942.421.gif 600w"></figure><h1 id="text-or-images-input-or-output">Text or Images, Input or Output</h1><p>GPT-4V introduced a large multimodal model that generates text from images and, with help from DALL-E 3, generates images from text. However, OpenAI hasn‚Äôt fully explained how it built the system. A separate group of researchers described their own method.</p><p><strong>What's new:&nbsp;</strong>Jing Yu Koh, Daniel Fried, and Ruslan Salakhutdinov at Carnegie Mellon University proposed&nbsp;<a href="https://arxiv.org/abs/2305.17216?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Generating Images with Large Language Models</a>&nbsp;(GILL), a training method that enables a large language model and a text-to-image generator to use both text and images as either input or output. Given text and/or image input, it decides whether to retrieve existing images or generate new ones.</p><p><strong>Key insight:</strong>&nbsp;Models like CLIP and ImageBind map text and image inputs to a similar embedding space, so closely related text and images have similar embeddings. This approach enables a large multimodal model to process both data types. Text outputs, too, can be mapped to the same embedding space, so an image decoder, such as a diffusion model, can use them to produce images or an image retriever to retrieve images.</p><p><strong>How it works:</strong>&nbsp;The authors used a pretrained&nbsp;<a href="https://arxiv.org/abs/2205.01068?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">OPT</a>&nbsp;large language model,&nbsp;<a href="https://arxiv.org/abs/2010.11929v2?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">ViT-L</a>&nbsp;image encoder (taken from CLIP), and pretrained Stable Diffusion text-to-image generator. The authors trained ViT-L to map its embeddings to those produced by OPT. They trained OPT to recognize prompts that request an image and enabled the system to either generate or retrieve images. Finally, a separate linear classifier learned whether to retrieve or generate images.&nbsp;</p><ul><li>The authors froze the ViT-L, added a linear layer, and trained it as follows: Given an image, the ViT-L-plus-linear-layer produced an image embedding, as usual. Given the image embedding and the first part of the corresponding caption, OPT iteratively tried to predict the next word. The linear layer learned how to modify the embedding so OPT could complete the caption. This enabled OPT to take images as input.</li><li>They added 8 tokens to OPT‚Äôs vocabulary and trained the model to emit them at the end of every image caption ‚Äî a signal that an image should be either retrieved or generated. (Typically a single token is sufficient to denote the end of a caption. However, these tokens corresponded to embeddings that, later, would be used to generate an image, and the authors found that a single token was not sufficiently expressive.)</li><li>Then they enabled Stable Diffusion to produce an image when OPT generated the 8 new tokens. They trained a separate transformer to map OPT‚Äôs embeddings associated with the 8 tokens (that is, embeddings produced by the layer before the one that generated the tokens) to those produced by Stable Diffusion‚Äôs text encoder.</li><li>Next they enabled the system to retrieve images when OPT generated the 8 tokens. They added linear layers to ViT-L and OPT and trained them to map the ViT-L‚Äôs embeddings to the OPT embedding associated with the first token. Specifically, the linear layers learned to minimize the difference between their outputs.</li><li>The authors trained a linear classifier, given the 8 OPT embeddings associated with the tokens, to decide whether to retrieve or generate an image. To build the classifier‚Äôs training set, they selected captions from a&nbsp;<a href="https://arxiv.org/abs/2206.10789?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">collection</a>&nbsp;of diverse human-written prompts and, for each one, both generated an image and retrieved the most similar image from CC3M. 5 human judges selected the image that best matched the prompt. This process yielded 900 examples annotated according to whether the image was retrieved or generated.</li><li>At inference, OPT generated tokens and fed the associated embeddings directly to the classifier, which activated the pipeline for either the generation or retrieval.</li></ul><p><strong>Results:&nbsp;</strong><a href="https://arxiv.org/abs/1604.03968?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">VIST</a>&nbsp;is a dataset of 20,000 visual stories, each of which comprises five captioned images. The authors evaluated GILL‚Äôs and Stable Diffusion‚Äôs abilities, given the final caption or all five captions, to generate the final image in each story based on CLIP similarity scores between generated and ground-truth images. Given one caption, GILL achieved 0.581 similarity and Stable Diffusion achieved 0.592 similarity. Given five captions, GILL achieved 0.612 similarity and Stable Diffusion scored 0.598 similarity, highlighting GILL‚Äôs ability to use the context afforded by more extensive input. It did even better (0.641 similarity) given both captions and images, which Stable Diffusion couldn‚Äôt handle. The authors also evaluated how well their system retrieved the correct last image from VIST given the 5 captions and the first 4 images. GILL retrieved the correct image 20.3 percent of the time, while their own&nbsp;<a href="https://arxiv.org/abs/2301.13823?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">FROMAGe</a>&nbsp;retrieved the correct image 18.2 percent of the time. In comparison, CLIP, given the 5 captions (without the images), retrieved the correct image 8.8 percent of the time.</p><p><strong>Why it matters:</strong>&nbsp;Models that wed text and images are advancing rapidly. GILL and other recent models extend single-image input and/or output to any combination of images and text. This capability ‚Äî which GILL achieves by mapping embeddings of image and text to one another ‚Äî gives the models more context to generate more appropriate output.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;The authors add an interesting twist: Rather than generating images, the system can choose to retrieve them. Sometimes an existing image will do.</p><hr><h2 id="a-message-from-landing-ai">A MESSAGE FROM LANDING AI</h2><figure class="kg-card kg-image-card"><a href="https://www.snowflake.com/webinars/thought-leadership/the-future-of-enterprise-ai-apps-with-large-vision-models-lvms-in-snowflake-2024-01-11/?utm_source=landing-ai&utm_medium=partner&utm_campaign=na-us-en-no-ind-unkwn-ai-ml&utm_content=wb&utm_cta=html-no-ind-unkwn"><img src="https://dl-staging-website.ghost.io/content/images/2024/01/image--10-.png" class="kg-image" alt="" loading="lazy" width="1260" height="709" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/image--10-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/image--10-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/01/image--10-.png 1260w" sizes="(min-width: 720px) 720px"></a></figure><p>Join a free webinar on January 11, 2024, featuring experts from Snowflake and Landing AI to explore how large vision models (LVMs) are transforming the image processing landscape.&nbsp;<a href="https://www.snowflake.com/webinars/thought-leadership/the-future-of-enterprise-ai-apps-with-large-vision-models-lvms-in-snowflake-2024-01-11/?utm_source=landing-ai&utm_medium=partner&utm_campaign=na-us-en-no-ind-unkwn-ai-ml&utm_content=wb&utm_cta=html-no-ind-unkwn" rel="noreferrer">Learn more about the session and register here</a></p><hr><h1 id="data-points">Data Points</h1><p>What happens when beloved cartoon Mickey Mouse enters the public domain in the era of generative AI? What‚Äôs the latest AI-driven addition to PC keyboards?&nbsp;</p><p>These items and other AI news are explored in a new edition of Data Points, a spinoff of our weekly newsletter, The Batch.&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-231/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read it here</a></p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://bit.ly/3YX9G3n"><div class="absolute inset-0" data-gtm-event-title="AI Python for Beginners"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-231/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-231/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-231/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm113" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-231","id":"659ed9826fc2690001a4e52e","uuid":"c7f39942-7bcc-4189-beac-449905cc9f2b","title":"AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, LLMs Go Multimodal","html":"\u003cp\u003e\u003cem\u003eDear friends,\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eIt is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt that way after finishing\u0026nbsp;\u003c/em\u003e\u003ca href=\"https://arxiv.org/abs/2305.18290?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003e\u003cem\u003eDirect Preference Optimization\u003c/em\u003e\u003c/a\u003e\u003cem\u003e\u0026nbsp;(DPO) by Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Chris Manning, and Chelsea Finn. (I didn't actually stand up and clap, since I was in a crowded coffee shop when I read it and would have gotten weird looks!\u003c/em\u003e\u0026nbsp;üòÄ\u003cem\u003e)\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eThis beautiful work proposes a much simpler alternative to RLHF (reinforcement learning from human feedback) for aligning language models to human preferences. Further, people often ask if universities ‚Äî which don't have the massive compute resources of big tech ‚Äî can still do cutting-edge research on large language models (LLMs). The answer, to me, is obviously yes! This article is a beautiful example of algorithmic and mathematical insight arrived at by an academic group thinking deeply.\u0026nbsp;\u003cbr\u003e\u003cbr\u003eRLHF became a key algorithm for LLM training thanks to the\u0026nbsp;\u003c/em\u003e\u003ca href=\"https://www.deeplearning.ai/the-batch/a-kinder-gentler-language-model/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003e\u003cem\u003eInstructGPT\u003c/em\u003e\u003c/a\u003e\u003cem\u003e\u0026nbsp;paper, which adapted the technique to that purpose. A typical implementation of the algorithm works as follows:\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003eGet humans to compare pairs of LLM outputs, generated in response to the same prompt, to specify which one they prefer. For example, humans typically prefer the more helpful, less toxic output.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eUse the human preferences to learn a reward function. The reward function, typically represented using a transformer network, is trained to give a higher reward (or score) to the outputs that the humans preferred.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eFinally, using the learned reward, run a reinforcement learning algorithm to tune the LLM to (i) maximize the reward of the answers generated, while (ii) not letting the LLM change too much (as a form of regularization).\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cem\u003eThis is a relatively complex algorithm. It needs to separately represent a reward function and an LLM. Also, the final, reinforcement learning step is well known to be finicky to the choice of hyperparameters.\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--99-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1125\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/The-Batch-ads-and-exclusive-banners--99-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/The-Batch-ads-and-exclusive-banners--99-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/01/The-Batch-ads-and-exclusive-banners--99-.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--99-.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eDPO dramatically simplifies the whole thing. Rather than needing separate transformer networks to represent a reward function and an LLM, the authors show how, given an LLM, you can figure out the reward function (plus regularization term) that that LLM is best at maximizing. This collapses the two transformer networks into one. Thus, you now need to train only the LLM and no longer have to deal with a separately trained reward function. The DPO algorithm trains the LLM directly, so as to make the reward function (which is implicitly defined by the LLM) consistent with the human preferences. Further, the authors show that DPO is better at achieving RLHF's optimization objective (that is, (i) and (ii) above) than most implementations of RLHF itself.\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eRLHF is a key building block of the most advanced LLMs. It‚Äôs fantastic that these Stanford authors ‚Äî through clever thinking and mathematical insight ‚Äî seem to have replaced it with something simpler and more elegant. While it's easy to get excited about a piece of research before it has stood the test of time, I am cautiously optimistic that DPO will have a huge impact on LLMs and beyond in the next few years. Indeed, it is already making its way into some top-performing models, such as Mistral‚Äôs\u0026nbsp;\u003c/em\u003e\u003ca href=\"https://mistral.ai/news/mixtral-of-experts?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003e\u003cem\u003eMixtral\u003c/em\u003e\u003c/a\u003e\u003cem\u003e.\u0026nbsp;\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eThat we can replace such fundamental building blocks of LLMs is a sign that the field is still new and much innovation lies ahead. Also, while it's always nice to have massive numbers of NVIDIA H100 or AMD MI300X GPUs, this work is another illustration ‚Äî out of many, I want to emphasize ‚Äî that deep thinking with only modest computational resources can carry you far.\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eA few weeks ago at NeurIPS (where DPO was published), I found it remarkable both (i) how much highly innovative research there is coming out of academic labs, independent labs, and companies small and large, and (ii) how much our media landscape skews attention toward work published by the big tech companies. I suspect that if DPO had been published by one of the big LLM companies, it would have made a huge PR splash and been announced as a massive breakthrough. Let us all, as builders of AI systems, make sure we recognize the breakthroughs wherever they occur.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eP.S. We just launched our first short course that uses JavaScript! In ‚Äã‚Äã‚ÄúBuild LLM Apps with LangChain.js,‚Äù taught by LangChain‚Äôs founding engineer Jacob Lee, you‚Äôll learn many steps that are common in AI development, including how to use (i) data loaders to pull data from common sources such as PDFs, websites, and databases; (ii) different models to write applications that are not vendor-specific; and (iii) parsers that extract and format the output for your downstream code to process. You‚Äôll also use the LangChain Expression Language (LCEL), which makes it easy to compose chains of modules to perform complex tasks. Putting it all together, you‚Äôll build a conversational question-answering LLM application capable of using external data as context. Please sign up\u0026nbsp;\u003c/em\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003e\u003cem\u003ehere\u003c/em\u003e\u003c/a\u003e\u003cem\u003e!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--89-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/unnamed--89-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/unnamed--89-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--89-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"deep-learning-discovers-antibiotics\"\u003eDeep Learning Discovers Antibiotics\u003c/h1\u003e\u003cp\u003eBiologists used neural networks to find a new class of antibiotics.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u0026nbsp;\u003c/strong\u003eResearchers at MIT and Harvard\u0026nbsp;\u003ca href=\"https://www.nature.com/articles/s41586-023-06887-8?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003etrained\u003c/a\u003e\u0026nbsp;models to screen chemical compounds for those that kill methicillin-resistant\u0026nbsp;\u003cem\u003eStaphylococcus aureus\u003c/em\u003e\u0026nbsp;(MRSA), the deadliest among bacteria that have evolved to be invulnerable to common antibiotics, and aren‚Äôt toxic to humans.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The authors built a training set of 39,312 compounds including most known antibiotics and a diverse selection of other molecules. In a lab, they tested each compound for its ability to inhibit growth of MRSA and its toxicity to human liver, skeletal muscle, and lung cells. Using the resulting data, they trained four ensembles of 20 graph neural networks each to classify compounds for (i) antibiotic properties, (ii) toxicity to the liver, (iii) toxicity to skeletal muscles, and (iv) toxicity to the lungs.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eThey ran their four ensembles on 12 million compounds from the\u0026nbsp;\u003ca href=\"https://mcule.com/database/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eMcule\u003c/a\u003e\u0026nbsp;database and a Broad Institute\u0026nbsp;\u003ca href=\"https://github.com/felixjwong/antibioticsai?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003edatabase\u003c/a\u003e. They filtered out compounds with the lowest probability of being antibiotics and the highest probability of being toxic to humans, leaving 3,646 antibiotic, low-toxicity compounds.\u0026nbsp;\u003c/li\u003e\u003cli\u003eWithin these compounds, they found the minimal chemical structure responsible for the antibiotic properties. To do this, they removed atoms or rings of atoms from a molecule‚Äôs edges, predicted the probability that the modified molecule was an active antibiotic, and repeated these steps until the probability fell below a threshold. Compounds that share a chemical structure are likely to work in similar ways within the body, giving scientists a pathway to discover further compounds with similar benefits.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u0026nbsp;\u003c/strong\u003eOf the compounds predicted to be likely antibiotics and nontoxic, the authors lab-tested 241 that were not known to work against MRSA. Of those, 8.7 percent inhibited the bacterium‚Äôs growth. This exceeds the percentage of antibiotics in the training set (1.3 percent), suggesting that the authors‚Äô approach could be a useful first step in finding new antibiotics. The authors also tested 30 compounds predicted not to be antibiotics. None of them (0 percent) inhibited the bacterium‚Äôs growth ‚Äî further evidence that their approach could be a useful first step. Two of the compounds that inhibited MRSA share a similar and novel mechanism of action against bacteria and also inhibited other antibiotic-resistant infections in lab tests. One of them proved effective against MRSA infections in mice.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u0026nbsp;\u003c/strong\u003eMost antibiotics currently in use were discovered in the mid-20th century, a golden age of antibiotics, which brought many formerly deadly pathogens under control. Modern techniques, including genomics and synthetic antibiotics, extended discoveries through the end of the century by identifying variants on existing drugs. However, in the 21st century, new antibiotics have either been redundant or haven‚Äôt been clinically successful, a report by the National Institutes of Health\u0026nbsp;\u003ca href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6627412/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003enoted\u003c/a\u003e. At the same time, widespread use of antibiotics has pushed many dangerous bacteria to evolve resistance. Pathogens chiefly responsible for a variety of ailments are generally resistant even to antibiotics reserved for use as a last resort.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u0026nbsp;\u003c/strong\u003eAntibiotic-resistant infections are among the top global public health threats directly responsible for 1.27 million deaths in 2019,\u0026nbsp;\u003ca href=\"https://www.who.int/news-room/fact-sheets/detail/antimicrobial-resistance?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eaccording to\u003c/a\u003e\u0026nbsp;the World Health Organization.\u003cstrong\u003e\u0026nbsp;\u003c/strong\u003eNew options, as well as efforts to fight the emergence of resistant strains, are needed.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u0026nbsp;\u003c/strong\u003eIf neural networks can\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/treatment-the-elusive-molecule/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eidentify\u003c/a\u003e\u0026nbsp;new classes of medicines, AI could bring a golden age of medical discovery. That hope helps to explain why pharmaceutical companies are\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/ai-pharma-jobs/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003ehiring\u003c/a\u003e\u0026nbsp;machine learning engineers at unprecedented rates.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150551.860.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/unnamed---2024-01-10T150551.860.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/unnamed---2024-01-10T150551.860.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150551.860.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"openai-revamps-safety-protocol\"\u003eOpenAI Revamps Safety Protocol\u003c/h1\u003e\u003cp\u003eRetrenching after its November leadership shakeup, OpenAI unveiled a new framework for evaluating risks posed by its models and deciding whether to limit their use.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u003c/strong\u003e\u0026nbsp;OpenAI‚Äôs\u0026nbsp;\u003ca href=\"https://openai.com/safety/preparedness?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003esafety framework\u003c/a\u003e\u0026nbsp;reorganizes pre-existing teams and forms new ones to establish a hierarchy of authority with the company‚Äôs board of directors at the top. It defines four categories of risk to be considered in decisions about how to use new models.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;OpenAI‚Äôs\u0026nbsp;\u003ca href=\"https://openai.com/blog/frontier-risk-and-preparedness?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003ePreparedness Team\u003c/a\u003e\u0026nbsp;is responsible for evaluating models. The Safety Advisory Group, whose members are appointed by the CEO for year-long terms, reviews the Preparedness Team‚Äôs work and recommends approaches to deploying models and mitigating risks, if necessary. The CEO has the authority to approve and oversee recommendations, overriding the Safety Authority Group if needed. OpenAI‚Äôs board of directors can overrule the CEO.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe Preparedness Team scores each model in four categories of risk: enabling or enhancing cybersecurity threats, helping to create weapons of mass destruction, generating outputs that affect users‚Äô beliefs, and operating autonomously without human supervision. The team can modify these risk categories or add new categories in response to emerging research.\u003c/li\u003e\u003cli\u003eThe team scores models in each category using four levels: low, medium, high, or critical. Critical indicates a model with superhuman capabilities or, in the autonomy category, one that can resist efforts to shut it down. A model‚Äôs score is its highest risk level in any category.\u003c/li\u003e\u003cli\u003eThe team scores each model twice: once after training and fine-tuning, and a second time after developers have tried to mitigate risks.\u003c/li\u003e\u003cli\u003eOpenAI will not release models that earn a score of high or critical prior to mitigation, or a medium, high, or critical after mitigation.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;The Preparedness Team and Safety Advisory Group join a number of safety-focused groups within OpenAI. The\u0026nbsp;\u003ca href=\"https://openai.com/safety/safety-systems?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eSafety Systems Team\u003c/a\u003e\u0026nbsp;focuses on mitigating risks after a model has been deployed; for instance, ensuring user privacy and preventing language models from providing false information. The\u0026nbsp;\u003ca href=\"https://openai.com/blog/introducing-superalignment?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eSuperalignment Team\u003c/a\u003e, led by Ilya Sutskever and Jan Leike, is charged with making sure hypothetical superintelligent systems, whose capabilities would surpass humans, adhere to values that benefit humans.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;AI is an extraordinarily powerful technology whose ultimate impacts are difficult to foresee. OpenAI has invested consistently in AI safety since its inception ‚Äî even if purportedly cautious moves like keeping its GPT-2 large language model under wraps often looked as much like publicity stunts as safety measures ‚Äî and its practices are likely to influence those of other AI companies. Furthermore, OpenAI has faced internal\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/all-about-the-leadership-shakeup-at-openai/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003echaos\u003c/a\u003e\u0026nbsp;partly over concerns about safety and governance. Clear protocols in these areas could prevent future strife and stabilize the company to the benefit of its users, employees, and investors.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u0026nbsp;\u003c/strong\u003eOpenAI‚Äôs safety framework looks like a step forward, but its risk categories focus on long-term, low-likelihood outcomes (though they stop short of considering AI‚Äôs hypothetical, and likely mythical, existential risk to humanity). Meanwhile, clear and present safety issues, such as social bias and factual accuracy, are well known to afflict current models including OpenAI‚Äôs. We hope that the Preparedness Team promptly adds categories that represent safety issues presented by today‚Äôs models.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"2000\" height=\"1040\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png 2000w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eIn this short course, you‚Äôll dive into LangChain.js, a JavaScript framework for building applications based on large language models, and learn how to craft powerful, context-aware apps. Elevate your machine learning-powered development skills using JavaScript.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eSign up today\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--48-.jpg\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/unnamed--48-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/unnamed--48-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--48-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"agi-defined\"\u003eAGI Defined\u003c/h1\u003e\u003cp\u003eHow will we know if someone succeeds in building artificial general intelligence (AGI)? A recent paper defines milestones on the road from calculator to superintelligence.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u003c/strong\u003e\u0026nbsp;Researchers at Google led by Meredith Ringel Morris\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2311.02462?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003epropose\u003c/a\u003e\u0026nbsp;a taxonomy of AI systems according to their degree of generality and ability to perform cognitive tasks. They consider today‚Äôs large multimodal models to be ‚Äúemerging AGI.‚Äù\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAGI basics:\u003c/strong\u003e\u0026nbsp;Artificial general intelligence is commonly defined as AI that can perform any intellectual task a human can. Shane Legg (who co-founded DeepMind) and Ben Goertzel (co-founder and CEO of\u0026nbsp;\u003ca href=\"https://singularitynet.io/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eSingularityNet\u003c/a\u003e) coined the term AGI for a 2007 collection of\u0026nbsp;\u003ca href=\"https://link.springer.com/book/10.1007/978-3-540-68677-4?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eessays\u003c/a\u003e. Subsequently, companies like DeepMind and OpenAI, which explicitly aim to develop AGI, propelled the idea into the mainstream.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The taxonomy categorizes systems as possessing narrow skills (not AGI) or general capabilities (AGI). It divides both narrow and general systems into five levels of performance beyond calculator-grade Level 0. It also includes a metric for degree of autonomy.\u003c/p\u003e\u003cul\u003e\u003cli\u003eNarrow systems perform one distinct task; they may perform at one of the five levels, but they are not AGI. General systems perform a range of tasks (which the authors don‚Äôt specify) that align with real-world activities of broad value to people, including but not limited to linguistic, mathematical, logical, spatial reasoning, social, learning, and creative tasks. Crucially, they can learn how to learn new skills and when to ask humans for more information. The authors classify general systems as AGI at various levels of performance.\u003c/li\u003e\u003cli\u003eLevel 1 (‚Äúemerging‚Äù) matches or slightly exceeds unskilled humans. Levels 2 (‚Äúcompetent‚Äù), 3 (‚Äúexpert‚Äù), and 4 (‚Äúvirtuoso‚Äù) systems surpass the 50th, 90th and 99th percentiles of skilled human performance, respectively. Level 5 (‚Äúsuperhuman‚Äù or ‚Äúartificial superintelligence‚Äù) outperforms 100 percent of skilled humans.\u003c/li\u003e\u003cli\u003eMost current systems that perform at Level 2 or higher are narrow. For example,\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/protein-shapes-revealed/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eAlphaFold\u003c/a\u003e, which finds the shapes of protein molecules, achieves Level 5 performance but only in a single task. On the other hand, the authors consider large language models like Bard, ChatGPT, and Lama 2 to be general systems at Level 1 (although their performance may achieve Level 2 in some tasks).\u0026nbsp;\u003c/li\u003e\u003cli\u003eThe authors‚Äô autonomy scale ranges from tools for which humans control the task while the system automates subtasks (the first level of autonomy) to agents that act independently (the fifth). Higher levels of performance can unlock higher levels of autonomy. For instance, Level 4 AGI may be necessary to enable fully autonomous vehicles that are safe and trustworthy.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eYes, but:\u0026nbsp;\u003c/strong\u003eThe authors‚Äô definition identifies some classes of tasks that contribute to generality, but it includes neither a list of tasks a system must perform to be considered general nor\u0026nbsp;a method for selecting them. Rather, the authors call on the research community to develop a ‚Äúliving benchmark‚Äù for generality that includes a mechanism for adding novel tasks.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u0026nbsp;\u003c/strong\u003eAGI is one of the tech world‚Äôs hottest buzzwords, yet it has had no clear definition, and various organizations propose different definitions. This lack of specificity makes it hard to talk about related technology, regulation, and other topics. The authors‚Äô framework, on the other hand, supports a more nuanced discussion of the path toward AGI. And it may have high-stakes business implications: Under the terms of their partnership, OpenAI can withhold from Microsoft models that attain AGI. Applying the authors‚Äô taxonomy would make it harder for one of the parties to move the goalposts.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;Defining AGI is tricky! For instance, OpenAI defines AGI as ‚Äúa highly autonomous system that outperforms humans at most economically valuable work.‚Äù This definition, had it been formulated in the early 1900s, when agriculture accounted for 70 percent of work globally, would have described the internal combustion engine.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150942.421.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150942.421.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"text-or-images-input-or-output\"\u003eText or Images, Input or Output\u003c/h1\u003e\u003cp\u003eGPT-4V introduced a large multimodal model that generates text from images and, with help from DALL-E 3, generates images from text. However, OpenAI hasn‚Äôt fully explained how it built the system. A separate group of researchers described their own method.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat's new:\u0026nbsp;\u003c/strong\u003eJing Yu Koh, Daniel Fried, and Ruslan Salakhutdinov at Carnegie Mellon University proposed\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2305.17216?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eGenerating Images with Large Language Models\u003c/a\u003e\u0026nbsp;(GILL), a training method that enables a large language model and a text-to-image generator to use both text and images as either input or output. Given text and/or image input, it decides whether to retrieve existing images or generate new ones.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;Models like CLIP and ImageBind map text and image inputs to a similar embedding space, so closely related text and images have similar embeddings. This approach enables a large multimodal model to process both data types. Text outputs, too, can be mapped to the same embedding space, so an image decoder, such as a diffusion model, can use them to produce images or an image retriever to retrieve images.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The authors used a pretrained\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2205.01068?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eOPT\u003c/a\u003e\u0026nbsp;large language model,\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2010.11929v2?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eViT-L\u003c/a\u003e\u0026nbsp;image encoder (taken from CLIP), and pretrained Stable Diffusion text-to-image generator. The authors trained ViT-L to map its embeddings to those produced by OPT. They trained OPT to recognize prompts that request an image and enabled the system to either generate or retrieve images. Finally, a separate linear classifier learned whether to retrieve or generate images.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe authors froze the ViT-L, added a linear layer, and trained it as follows: Given an image, the ViT-L-plus-linear-layer produced an image embedding, as usual. Given the image embedding and the first part of the corresponding caption, OPT iteratively tried to predict the next word. The linear layer learned how to modify the embedding so OPT could complete the caption. This enabled OPT to take images as input.\u003c/li\u003e\u003cli\u003eThey added 8 tokens to OPT‚Äôs vocabulary and trained the model to emit them at the end of every image caption ‚Äî a signal that an image should be either retrieved or generated. (Typically a single token is sufficient to denote the end of a caption. However, these tokens corresponded to embeddings that, later, would be used to generate an image, and the authors found that a single token was not sufficiently expressive.)\u003c/li\u003e\u003cli\u003eThen they enabled Stable Diffusion to produce an image when OPT generated the 8 new tokens. They trained a separate transformer to map OPT‚Äôs embeddings associated with the 8 tokens (that is, embeddings produced by the layer before the one that generated the tokens) to those produced by Stable Diffusion‚Äôs text encoder.\u003c/li\u003e\u003cli\u003eNext they enabled the system to retrieve images when OPT generated the 8 tokens. They added linear layers to ViT-L and OPT and trained them to map the ViT-L‚Äôs embeddings to the OPT embedding associated with the first token. Specifically, the linear layers learned to minimize the difference between their outputs.\u003c/li\u003e\u003cli\u003eThe authors trained a linear classifier, given the 8 OPT embeddings associated with the tokens, to decide whether to retrieve or generate an image. To build the classifier‚Äôs training set, they selected captions from a\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2206.10789?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003ecollection\u003c/a\u003e\u0026nbsp;of diverse human-written prompts and, for each one, both generated an image and retrieved the most similar image from CC3M. 5 human judges selected the image that best matched the prompt. This process yielded 900 examples annotated according to whether the image was retrieved or generated.\u003c/li\u003e\u003cli\u003eAt inference, OPT generated tokens and fed the associated embeddings directly to the classifier, which activated the pipeline for either the generation or retrieval.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u0026nbsp;\u003c/strong\u003e\u003ca href=\"https://arxiv.org/abs/1604.03968?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eVIST\u003c/a\u003e\u0026nbsp;is a dataset of 20,000 visual stories, each of which comprises five captioned images. The authors evaluated GILL‚Äôs and Stable Diffusion‚Äôs abilities, given the final caption or all five captions, to generate the final image in each story based on CLIP similarity scores between generated and ground-truth images. Given one caption, GILL achieved 0.581 similarity and Stable Diffusion achieved 0.592 similarity. Given five captions, GILL achieved 0.612 similarity and Stable Diffusion scored 0.598 similarity, highlighting GILL‚Äôs ability to use the context afforded by more extensive input. It did even better (0.641 similarity) given both captions and images, which Stable Diffusion couldn‚Äôt handle. The authors also evaluated how well their system retrieved the correct last image from VIST given the 5 captions and the first 4 images. GILL retrieved the correct image 20.3 percent of the time, while their own\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2301.13823?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2\" rel=\"noopener\"\u003eFROMAGe\u003c/a\u003e\u0026nbsp;retrieved the correct image 18.2 percent of the time. In comparison, CLIP, given the 5 captions (without the images), retrieved the correct image 8.8 percent of the time.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Models that wed text and images are advancing rapidly. GILL and other recent models extend single-image input and/or output to any combination of images and text. This capability ‚Äî which GILL achieves by mapping embeddings of image and text to one another ‚Äî gives the models more context to generate more appropriate output.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;The authors add an interesting twist: Rather than generating images, the system can choose to retrieve them. Sometimes an existing image will do.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-landing-ai\"\u003eA MESSAGE FROM LANDING AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.snowflake.com/webinars/thought-leadership/the-future-of-enterprise-ai-apps-with-large-vision-models-lvms-in-snowflake-2024-01-11/?utm_source=landing-ai\u0026utm_medium=partner\u0026utm_campaign=na-us-en-no-ind-unkwn-ai-ml\u0026utm_content=wb\u0026utm_cta=html-no-ind-unkwn\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/01/image--10-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1260\" height=\"709\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/01/image--10-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/01/image--10-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/01/image--10-.png 1260w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eJoin a free webinar on January 11, 2024, featuring experts from Snowflake and Landing AI to explore how large vision models (LVMs) are transforming the image processing landscape.\u0026nbsp;\u003ca href=\"https://www.snowflake.com/webinars/thought-leadership/the-future-of-enterprise-ai-apps-with-large-vision-models-lvms-in-snowflake-2024-01-11/?utm_source=landing-ai\u0026utm_medium=partner\u0026utm_campaign=na-us-en-no-ind-unkwn-ai-ml\u0026utm_content=wb\u0026utm_cta=html-no-ind-unkwn\" rel=\"noreferrer\"\u003eLearn more about the session and register here\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003ch1 id=\"data-points\"\u003eData Points\u003c/h1\u003e\u003cp\u003eWhat happens when beloved cartoon Mickey Mouse enters the public domain in the era of generative AI? What‚Äôs the latest AI-driven addition to PC keyboards?\u0026nbsp;\u003c/p\u003e\u003cp\u003eThese items and other AI news are explored in a new edition of Data Points, a spinoff of our weekly newsletter, The Batch.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.deeplearning.ai/the-batch/data-points-issue-231/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eRead it here\u003c/a\u003e\u003c/p\u003e","comment_id":"659ed9826fc2690001a4e52e","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--100-.png","featured":false,"visibility":"public","created_at":"2024-01-10T09:53:06.000-08:00","updated_at":"2024-03-11T08:47:49.000-07:00","published_at":"2024-01-10T12:15:13.000-08:00","custom_excerpt":"The Batch AI News and Insights: It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt that way after finishing¬†Direct Preference Optimization¬†(DPO) by...","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"659ef0db6fc2690001a4e55c","name":"issue-231","slug":"issue-231","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-231/"},{"id":"659ef0db6fc2690001a4e55d","name":"Jan 10, 2024","slug":"jan-10-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/jan-10-2024/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-231/","excerpt":"The Batch AI News and Insights: It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt that way after finishing¬†Direct Preference Optimization¬†(DPO) by...","reading_time":15,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, and more","meta_description":"The Batch AI News and Insights: It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt...","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--100-.png","dimensions":{"width":1680,"height":945}},"banner":{"title":"AI Python for Beginners","databaseId":35163,"id":"cG9zdDozNTE2Mw==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/08/1-9.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3YX9G3n","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"‚ú® Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-231"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>