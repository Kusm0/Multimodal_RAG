<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Job Growth in Machine Learning, Amazon&#x27;s AI-Driven Store...</title><meta name="description" content="The Batch - AI News &amp; Insights: Job Growth in Machine Learning | Amazon&#x27;s AI-Driven Clothing Store | Transformers for Robot Vision | Hiring Algorithms Under Scrutiny" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-129/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Job Growth in Machine Learning, Amazon&#x27;s AI-Driven Store..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: Job Growth in Machine Learning | Amazon&#x27;s AI-Driven Clothing Store | Transformers for Robot Vision | Hiring Algorithms Under Scrutiny" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Job Growth in Machine Learning, Amazon&#x27;s AI-Driven Store..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-129/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2022-01-26T12:00:00.000-08:00"/><meta property="article:modified_time" content="2024-02-26T17:08:20.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-129"/><meta property="article:tag" content="Jan 26, 2022"/><meta property="article:tag" content="#laura"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Job Growth in Machine Learning, Amazon&#x27;s AI-Driven Store..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: Job Growth in Machine Learning | Amazon&#x27;s AI-Driven Clothing Store | Transformers for Robot Vision | Hiring Algorithms Under Scrutiny" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-129/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2022/01/Screen-Shot-2022-01-25-at-4.22.34-PM.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2022/01/Screen-Shot-2022-01-25-at-4.22.34-PM.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="675"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2022-01-26T12:00:00.000-08:00","dateModified":"2024-02-26T17:08:20.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object], [object Object]","headline":"Job Growth in Machine Learning, Amazon's AI-Driven Store...","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2022/01/Screen-Shot-2022-01-25-at-4.22.34-PM.png","width":1200,"height":675},"publisher":{"@type":"Organization","name":"Job Growth in Machine Learning, Amazon's AI-Driven Store...","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: Job Growth in Machine Learning | Amazon's AI-Driven Clothing Store | Transformers for Robot Vision | Hiring Algorithms Under Scrutiny"}</script><meta name="next-head-count" content="32"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-129/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 129</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Jan 26, 2022</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">12<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/jan-26-2022-2/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Jan 26, 2022</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">12<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-129/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-129/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-129/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,</em></p><p><em>If you want to build a career in AI, it’s no longer necessary to be located in one of a few tech hubs such as Silicon Valley or Beijing. Tech hubs are emerging in many parts of the world, and cities large and small offer opportunities both for local talent and companies worldwide.</em><br><br><em>Colombia is an inspiring example. In 2019, several of my teams (including Landing AI and other AI Fund portfolio companies) made a bet on Latin America. I set up an engineering hub in <a href="https://techcrunch.com/2019/08/21/andrew-ngs-ai-companies-expand-to-medellin-colombia/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">Medellín</a>, Colombia, because I was impressed by the tech scene, educational institutions, enthusiastic engineers, and supportive partners we found there. (You can see in the photo below what a good time we had there! Non-Spanish speakers: Can you read the phrase on the t-shirts?)</em><br><br><em>Judging by record venture investments and successful IPOs in Latin America, the secret is out about the caliber of the region’s technical talent, entrepreneurial spirit, and ability to build high-quality systems. For U.S. teams, in particular, its proximity in terms of time zones and geography makes it one of the most interesting emerging ecosystems in tech. Several AI Fund portfolio companies now have a significant presence there.</em></p><p><em>Our fastest-growing Latin American team is <a href="https://www.factored.ai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">Factored</a>, which helps companies build world-class AI and data engineering teams. Factored’s Latin American operation grew from 24 engineers to well over 100 in the past year. Its projects have ranged from developing MLOps pipelines for one of the largest financial-tech companies in Silicon Valley to <a href="https://openreview.net/forum?id=c20jiJ5K2H&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">presenting</a> <a href="https://arxiv.org/abs/2111.09344?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">papers</a> at NeurIPS.</em></p><!--kg-card-begin: html--><table class="hse-image-wrapper" role="presentation" width="100%" cellpadding="0" cellspacing="0" style="border-collapse: collapse; border-spacing: 0px !important;"><tbody><tr><td align="center" valign="top" style="border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 10px 0px; font-size: 0px;"><img alt="Screen Shot 2022-01-25 at 4.22.34 PM" src="https://cdn2.hubspot.net/hub/5871640/hubfs/Screen%20Shot%202022-01-25%20at%204.22.34%20PM.png?upscale=true&amp;width=1200&amp;upscale=true&amp;name=Screen%20Shot%202022-01-25%20at%204.22.34%20PM.png" width="600" align="middle" class="stretch-on-mobile" style="outline: none; text-decoration: none; max-width: 100%; font-size: 16px;"></td></tr></tbody></table><!--kg-card-end: html--><p><em>The rise of opportunities in Latin America is part of the broader trend toward working from home. I can collaborate as easily with someone in Palo Alto, California, as with someone in Buenos Aires, Argentina. In fact, I’ve been spending more time in Washington State (where I enjoy the benefit of free babysitting by my wonderful in-laws) instead of my Palo Alto headquarters.</em><br><br><em>Remote work highlights a fact that should have been obvious: Talent is everywhere, even if access to opportunity has not been. Whatever city you live in, today you’ll find more opportunities than ever to learn, find an exciting job, and do meaningful work.</em><br><br><em>It has been over two years since I visited Colombia. While I appreciate the excellence of Colombian engineers, I also love the local culture. I enjoy the sculptures of <a href="https://en.wikipedia.org/wiki/Fernando_Botero?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">Fernando Botero</a>, and <a href="https://en.wikipedia.org/wiki/Bandeja_paisa?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">bandeja paisa</a> is a favorite dish that I haven’t managed to find in the U.S. I hope the pandemic will allow me to return before long.</em><br><br><em>No matter where you’re located, I will continue to think about how DeepLearning.AI can do more to support you in developing your talent and building the career you want.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h2 id="news">News</h2><!--kg-card-begin: html--><table class="hse-image-wrapper" role="presentation" width="100%" cellpadding="0" cellspacing="0" style="border-collapse: collapse; border-spacing: 0px !important;"><tbody><tr><td align="center" valign="top" style="border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;"><img alt="LINKEDIN" src="https://cdn2.hubspot.net/hub/5871640/hubfs/LINKEDIN.jpg?upscale=true&amp;width=1200&amp;upscale=true&amp;name=LINKEDIN.jpg" width="600" align="middle" class="stretch-on-mobile" style="outline: none; text-decoration: none; max-width: 100%; font-size: 16px;"></td></tr></tbody></table><!--kg-card-end: html--><h2 id="machine-learning-jobs-on-the-rise">Machine Learning Jobs on the Rise</h2><p>Jobs for machine learning engineers are growing fast, according to an analysis by LinkedIn.<br><br><strong>What’s new:</strong> Machine learning engineer ranks fourth among the 25 fastest-growing job titles in the United States, according to the professional social network’s annual <a href="https://www.linkedin.com/pulse/linkedin-jobs-rise-2022-25-us-roles-growing-demand-linkedin-news/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener"><em>Jobs on the Rise</em></a> report. (The top three were vaccine specialist, diversity and inclusion manager, and customer marketing manager.)<br><br><strong>What the data says:</strong> LinkedIn analyzed job openings listed on its site between January 2017 and July 2021 and ranked those that showed consistent growth over the entire period. The analysis counted open positions at different levels of seniority as a single position. It didn’t count positions occupied by interns, volunteers, or students.</p><ul><li>Salaries for machine learning engineers generally ranged from $72,600 to $170,000.</li><li>Applicants were expected to have a median of four years of prior experience. Skills requested most often included deep learning, natural language processing, and TensorFlow.</li><li>Most jobs were located in San Francisco, Seattle, and Los Angeles, and nearly 20 percent of them allowed remote work.</li><li>Of machine learning engineers who previously held a different title, most had been software engineers, data scientists, or AI specialists.</li><li>Of machine learning engineers whose gender was known, 22.3 percent were women.</li></ul><p><strong>Behind the news:</strong> While LinkedIn’s analysis was confined to the U.S., evidence suggests that machine learning jobs are growing worldwide.</p><ul><li>In the Philippines, where automation is replacing call center jobs, the outsourcing industry has <a href="https://read.deeplearning.ai/the-batch/workers-get-the-jump-on-automation/?ref=dl-staging-website.ghost.io">launched</a> a massive effort to train professionals in machine learning and data analytics.</li><li>A survey by <em>MIT Technology Review</em> found that <a href="https://read.deeplearning.ai/the-batch/asias-ai-advantage/?ref=dl-staging-website.ghost.io">96 percent</a> of Asian executives and <a href="https://read.deeplearning.ai/the-batch/ai-in-regions-rich-and-poor/?ref=dl-staging-website.ghost.io">82 percent</a> of executives in Africa and the Middle East said their companies had deployed at least one machine learning algorithm as of 2019.</li></ul><p><strong>Why it matters:</strong> North America is the world’s largest AI market, accounting for around <a href="https://www.grandviewresearch.com/industry-analysis/artificial-intelligence-ai-market?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo#:~:text=Regional%20Insights,(AI)%20across%20various%20industries" rel="noopener">40 percent</a> of AI revenue globally. The fact that remote work is an option for one in five U.S. machine learning jobs suggests a huge opportunity for applicants located in other parts of the world.<br><br><strong>We’re thinking:</strong> The world needs more AI practitioners! If you’re wondering whether to pursue a career in the field, this is a good time to jump in.</p><hr><!--kg-card-begin: html--><table class="hse-image-wrapper" role="presentation" width="100%" cellpadding="0" cellspacing="0" style="border-collapse: collapse; border-spacing: 0px !important;"><tbody><tr><td align="center" valign="top" style="border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;"><img alt="AMAZON (1)" src="https://cdn2.hubspot.net/hub/5871640/hubfs/AMAZON%20(1).gif?upscale=true&amp;width=1200&amp;upscale=true&amp;name=AMAZON%20(1).gif" width="600" align="middle" class="stretch-on-mobile" style="outline: none; text-decoration: none; max-width: 100%; font-size: 16px;"></td></tr></tbody></table><!--kg-card-end: html--><h2 id="let-the-model-choose-your-outfit">Let the Model Choose Your Outfit</h2><p>Amazon’s first brick-and-mortar clothing store is getting ready to deliver automated outfit recommendations.<br><br><strong>What’s new: </strong>The ecommerce giant <a href="https://www.aboutamazon.com/news/retail/amazon-reimagines-in-store-shopping-with-amazon-style?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">announced</a> plans to open a flagship Amazon Style location at a Los Angeles-area mall this year.<br><br><strong>How it works:</strong> The 30,000 square-foot store will feature aisles and racks like a traditional clothing store, but customers will be able to scan QR codes using their phones to see variations in color and size as well as items recommended by machine learning models. A touchscreen in each fitting room will enable customers to request such items to try on.<br><br><strong>Proposed innovations:</strong> Research papers provide glimpses of Amazon’s ideas for AI-driven fashion retailing. The company declined to comment on whether it plans to implement them. For instance:</p><ul><li><a href="https://read.deeplearning.ai/the-batch/which-shoes-go-with-that-outfit/?ref=dl-staging-website.ghost.io">CSA-Net</a> finds items that fit an existing outfit using convolutional neural networks and attention. A customer can enter a shirt and shoes, and the model might choose a matching handbag.</li><li><a href="https://read.deeplearning.ai/the-batch/that-online-boutique-but-smarter/?ref=dl-staging-website.ghost.io">VAL</a> uses a transformer network to interpret an image-and-text pair and searches for matching products. A customer might, say, select a picture of a shirt and request a different color.</li><li><a href="https://read.deeplearning.ai/the-batch/clothes-make-the-model/?ref=dl-staging-website.ghost.io">Outfit-Viton</a> turns a full-body photo of a customer into a 3D model, then uses a generative adversarial network to generate images of the person wearing selected outfits.</li></ul><p><strong>Behind the news: </strong>Last summer, Amazon opened its first brick-and-mortar grocery store, where customers can take merchandise off a shelf and exit without interacting with a clerk for payment. Computer vision identifies them at the door and identifies the products to charge their account automatically.<br><br><strong>Why it matters:</strong> The fashion retailing market is crowded, but Amazon’s considerable AI expertise puts it at the forefront of low-friction retailing.<br><br><strong>We’re thinking:</strong> Fashion companies such as Stitch Fix and Wantable have used AI to recommend clothing and build valuable businesses. There are good reasons to believe that future fashion leaders will be sophisticated AI players.</p><hr><!--kg-card-begin: html--><table class="hse-image-wrapper" role="presentation" width="100%" cellpadding="0" cellspacing="0" style="border-collapse: collapse; border-spacing: 0px !important;"><tbody><tr><td align="center" valign="top" style="border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;"><img alt="ezgif.com-gif-maker - 2021-11-16T124131.535" src="https://cdn2.hubspot.net/hub/5871640/hubfs/ezgif.com-gif-maker%20-%202021-11-16T124131.535.gif?upscale=true&amp;width=1200&amp;upscale=true&amp;name=ezgif.com-gif-maker%20-%202021-11-16T124131.535.gif" width="600" align="middle" class="stretch-on-mobile" style="outline: none; text-decoration: none; max-width: 100%; font-size: 16px;"></td></tr></tbody></table><!--kg-card-end: html--><h2 id="high-accuracy-at-low-power">High Accuracy at Low Power</h2><p>Equipment that relies on computer vision while unplugged — mobile phones, drones, satellites, autonomous cars — need power-efficient models. A new architecture set a record for accuracy per computation.<br><br><strong>What's new:</strong> Yinpeng Chen and colleagues at Microsoft devised <a href="https://arxiv.org/abs/2108.05895?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">Mobile-Former</a>, an image recognition system that efficiently weds a <a href="https://arxiv.org/abs/1704.04861?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">MobileNet</a>’s convolutional eye for detail with a <a href="https://arxiv.org/abs/2010.11929?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">Vision Transformer</a>’s attention-driven grasp of the big picture.<br><br><strong>Key insight:</strong> Convolutional neural networks process images in patches, which makes them computationally efficient but ignores global features that span multiple patches. Transformers represent global features but they’re inefficient. A transformer’s self-attention mechanism compares each part of an input to each other part, so the amount of computation requires grows quadratically with the size of the input. Mobile-Former combines the two architectures, but instead of using self-attention, its transformers compare each part of an input to a small learned vector. This gives the system information about global features without the computational burden.<br><br><strong>How it works:</strong> Mobile-Former is a stack of layers, each made up of three components: a <a href="https://www.coursera.org/learn/convolutional-neural-networks/lecture/B1kPZ/mobilenet?ref=dl-staging-website.ghost.io">MobileNet block</a> and <a href="https://www.coursera.org/learn/nlp-sequence-models/lecture/Kf5Y3/transformer-network?ref=dl-staging-website.ghost.io">transformer block</a> joined by a two-way bridge of two attention layers (one for each direction of communication). The MobileNet blocks refine an image representation, the transformer blocks refine a set of six tokens (randomly initiated vectors that are learned over training), and the bridge further refines the image representation according to the tokens and vice versa. The authors trained the system on ImageNet.</p><ul><li>Given an image, a convolutional layer generates a representation. Given the representation and the tokens, the bridge updates the tokens to represent the image. This starts an iterative process:</li><li>A MobileNet block refines the image representation and passes it to the bridge.</li><li>A transformer block refines the tokens based on the relationships between them and passes them to the bridge.</li><li>The bridge updates the image representation according to the tokens, and the tokens according to the image representation, and passes them all to the next series of blocks.</li><li>The process repeats until, at the end of the line, two fully connected layers render a classification.</li></ul><p><strong>Results:</strong> Mobile-Former beat competitors at a similar computational budget and at much larger budgets as well. In ImageNet classification, it achieved 77.9 percent accuracy using 294 megaflops (a measure of computational operations), beating transformers that required much more computation. The nearest competitor under 1.5 gigaflops, <a href="https://arxiv.org/abs/2103.14030?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">Swin</a>, scored 77.3 percent using 1 gigaflop. At a comparable budget of 299 megaflops, a variation on the <a href="https://arxiv.org/abs/1807.11164?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">ShuffleNetV2</a> convolutional network scored 72.6 percent accuracy.<br><br><strong>Yes, but:</strong> The system is not efficient in terms of the number of parameters and thus memory requirements. Mobile-Former-294M encompasses 11.4 million parameters, while Swin has 7.3 million and ShuffleNetV2 has 3.5 million. One reason: Parameters in the MobileNet blocks, transformer blocks, and bridge aren’t shared.<br><br><strong>Why it matters:</strong> Transformers have strengths that have propelled them into an ever wider range of applications. Integrating them with other architectures makes it possible to take advantage of the strengths of both.<br><br><strong>We're thinking:</strong> Using more than six tokens didn’t result in better performance. It appears that the need for attention in image tasks is limited — at least for images of 224x224 resolution.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM <strong><a href="http://deeplearning.ai/?ref=dl-staging-website.ghost.io">DEEPLEARNING.AI</a></strong></h2><!--kg-card-begin: html--><table class="hse-image-wrapper" role="presentation" width="100%" cellpadding="0" cellspacing="0" style="border-collapse: collapse; border-spacing: 0px !important;"><tbody><tr><td align="center" valign="top" style="border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;"><img alt="Thumbnail 1 Logo" src="https://cdn2.hubspot.net/hub/5871640/hubfs/Thumbnail%201%20Logo.png?upscale=true&amp;width=1200&amp;upscale=true&amp;name=Thumbnail%201%20Logo.png" width="600" align="middle" class="stretch-on-mobile" style="outline: none; text-decoration: none; max-width: 100%; font-size: 16px;"></td></tr></tbody></table><!--kg-card-end: html--><p>We’re highlighting our global deep learner community. Read their stories, get inspired to take the next step in your AI journey, and #BeADeepLearner! <a href="https://www.deeplearning.ai/program/deep-learning-specialization/?ref=dl-staging-website.ghost.io">Learn more</a></p><hr><!--kg-card-begin: html--><table class="hse-image-wrapper" role="presentation" width="100%" cellpadding="0" cellspacing="0" style="border-collapse: collapse; border-spacing: 0px !important;"><tbody><tr><td align="center" valign="top" style="border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;"><img alt="ALLIANCE" src="https://cdn2.hubspot.net/hub/5871640/hubfs/ALLIANCE.gif?upscale=true&amp;width=1200&amp;upscale=true&amp;name=ALLIANCE.gif" width="600" align="middle" class="stretch-on-mobile" style="outline: none; text-decoration: none; max-width: 100%; font-size: 16px;"></td></tr></tbody></table><!--kg-card-end: html--><h2 id="standards-for-hiring-algorithms">Standards for Hiring Algorithms</h2><p>Some of the world’s largest corporations will use standardized criteria to evaluate AI systems that influence hiring and other personnel decisions.<br><br><strong>What’s new:</strong> The Data and Trust Alliance, a nonprofit group devoted to mitigating tech-induced bias in workplaces, <a href="https://dataandtrustalliance.org/our-initiatives?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">introduced</a> resources for evaluating fairness in algorithms for personnel management. Twenty-two companies have agreed to use them worldwide including IBM, Meta, and Walmart.<br><br><strong>What it says:</strong> Algorithmic Bias Safeguards for Workforce includes a <a href="https://dataandtrustalliance.org/Overview_Algorithmic_Bias_Safeguards_for_Workforce.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">questionnaire</a> for evaluating AI system vendors, a scoring system for comparing one vendor to another, and materials for educating human-resources teams about AI.</p><ul><li>The questionnaire addresses three themes: the business case for a given algorithm; vetting for bias during data collection, training, and deployment; and organizational biases arising from poor governance or lack of transparency. Answers can be shared between the developer and customer only, not with the rest of the group.</li><li>Answers are converted into scores, then added to scorecards that alliance members can use to compare vendors.</li><li>A primer is available to help human-resources staff, lawyers, and other stakeholders in interpreting the results of the survey. Other educational materials define key vocabulary and explain how algorithmic bias impacts hiring and personnel decisions.</li><li>Alliance members are not required to use the materials.</li></ul><p><strong>Behind the news:</strong> Algorithms for hiring and managing employees have been at the center of several high-profile controversies.</p><ul><li>Earlier this year, drivers for Amazon’s Flex, the online retailer’s delivery-crowdsourcing program, <a href="https://read.deeplearning.ai/the-batch/when-algorithms-manage-humans/?ref=dl-staging-website.ghost.io">criticized</a> the company’s algorithm for scoring their performance, saying it unjustly penalized them for unavoidable delays due to bad weather and other factors outside their control. In 2018, Amazon abandoned a hiring algorithm that was found to penalize female candidates.</li><li>An analysis by <em>MIT Technology Review</em> <a href="https://read.deeplearning.ai/the-batch/danke-for-the-interview/?ref=dl-staging-website.ghost.io">found</a> that hiring systems from Curious Thing and MyInterview gave high scores in English proficiency to an applicant who spoke entirely in German.</li><li>In January, hiring software developer HireVue stopped using face recognition, which purportedly analyzed facial expressions to judge traits such as dependability, in response to a lawsuit from the nonprofit Electronic Privacy Information Center that challenged the company’s use of AI for being unfair and deceptive.</li></ul><p><strong>Why it matters:</strong> Companies need ways to find and retain top talent amid widening global competition. However, worries over biased AI systems have spurred laws that limit algorithmic hiring in New York City and the United Kingdom. Similar regulations in China, the European Union, and the United States may follow.<br><br><strong>We’re thinking:</strong> We welcome consistent standards for AI systems of all kinds. This looks like a good first step in products for human resources.</p><hr><!--kg-card-begin: html--><table class="hse-image-wrapper" role="presentation" width="100%" cellpadding="0" cellspacing="0" style="border-collapse: collapse; border-spacing: 0px !important;"><tbody><tr><td align="center" valign="top" style="border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;"><img alt="FUSIONv3" src="https://cdn2.hubspot.net/hub/5871640/hubfs/FUSIONv3.gif?upscale=true&amp;width=1200&amp;upscale=true&amp;name=FUSIONv3.gif" width="600" align="middle" class="stretch-on-mobile" style="outline: none; text-decoration: none; max-width: 100%; font-size: 16px;"></td></tr></tbody></table><!--kg-card-end: html--><h2 id="transformers-see-in-3d">Transformers See in 3D</h2><p>Visual robots typically perceive the three-dimensional world through sequences of two-dimensional images, but they don’t always know what they’re looking at. For instance, Tesla’s self-driving system has been known to <a href="https://www.youtube.com/watch?v=7UF-S2czdCk&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">mistake a full moon for a traffic light</a>. New research aims to clear up such confusion.<br><br><strong>What's new:</strong> Aljaž Božic and colleagues at Technical University of Munich released <a href="https://aljazbozic.github.io/transformerfusion/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">TransformerFusion</a>, which set a new state of the art in deriving 3D scenes from 2D video.<br><br><strong>Key Insight:</strong> The authors teamed two architectures and a novel approach to estimating the positions of points in space:</p><ul><li>Transformers excel at learning which features are most relevant to completing a particular task. In a video, they can learn which frames, and which parts of a frame, reveal the role of a given point in space: whether it’s empty or filled by an object.</li><li>However, while transformers do well at selecting the best views, they’re not great at identifying points in space. The authors addressed this shortfall by refining the representations using 3D convolutional neural networks.</li><li>To position the points in space, they generated representations at both course and fine scales. The coarse representations enabled the system to place points coherently across relatively large distances, while the fine representations enabled the system to reproduce details.</li></ul><p><strong>How it works:</strong> Given a series of 2D frames, TransformerFusion learned to reconstruct the 3D space they depicted by classifying whether each 3D pixel, or voxel, belonged (or was very close) to an object’s surface. The authors trained the system on <a href="https://arxiv.org/abs/1702.04405?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">ScanNet</a>, a dataset that contains RGB-D (video plus depth) clips shot in indoor settings like bedrooms, offices, and libraries; object segmentations; and 3D scene reconstructions.</p><ul><li>Given a 2D frame, a <a href="https://arxiv.org/abs/1512.03385?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">ResNet-18</a> pretrained on ImageNet produced a coarse representation and a fine representation.</li><li>A transformer mapped the coarse representations, along with information derived from the images such as viewing direction, to a 3D grid with 30-centimeter resolution and produced a new representation for each point. A second transformer mapped fine representations and other information to a 3D grid with 10-centimeter resolution and, likewise, produced a new representation for each point.</li><li>Given the coarse representations, a 3D convolutional neural network learned to classify whether a point was near an object’s surface and refined the representations accordingly. If the point was near a surface, the system continued; otherwise, it classified the point as not near a surface and stopped to save computation.</li><li>A second 3D CNN used both fine and coarse representations to learn how to classify, refine, and filter the representations of points on the fine grid.</li><li>The system interpolated the remaining coarse and fine representations onto a 3D grid of even higher resolution (2 centimeters) and generated another set of point representations. Given each new point, a vanilla neural network classified whether there was an object at that point.</li><li>The authors trained the system using three loss terms: one that encouraged the coarse CNN’s classifications to match ground truth, a similar one for the fine CNN, and a similar one for the higher-resolution CNN.</li></ul><p><strong>Results:</strong> The authors measured distances between TransformerFusion’s estimated points in space and ground truth. They considered an estimation correct if it matched ground truth within 5 centimeters. The system achieved an F-1 score, a balance of precision and recall where higher is better, of 0.655. The best competing method, <a href="https://arxiv.org/abs/1803.08673?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo" rel="noopener">Atlas</a>, achieved 0.636. Without the 3D CNNs, TransformerFusion achieved 0.361.<br><br><strong>Yes, but:</strong> Despite setting a new state of the art, TransformerFusion’s ability to visualize 3D scenes falls far short of human-level performance. Its scene reconstructions are distorted, and it has trouble recognizing transparent objects.<br><br><strong>Why it matters:</strong> Transformers have gone from strength to strength — in language, 2D vision, molecular biology, and other areas — and this work shows their utility in a new domain. Yet, despite their capabilities, they can’t do the whole job. The authors took advantage of transformers where they could do well and then refined their output using an architecture more appropriate to 3D modeling.<br><br><strong>We're thinking:</strong> Training systems on both low- and high-resolution versions of an image could improve other vision tasks as well.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/"><div class="absolute inset-0" data-gtm-event-title="ChatGPT Prompt Engineering for Developers"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-129/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-129/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-129/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm76" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-129","id":"61f1be240c0d0b003b5fe6fb","uuid":"3293db84-7876-4423-9802-ebd44d12f22c","title":"The Batch: Job Growth in Machine Learning, Amazon's AI-Driven Clothing Store, Transformers for Robot Vision, Hiring Algorithms Under Scrutiny","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eIf you want to build a career in AI, it’s no longer necessary to be located in one of a few tech hubs such as Silicon Valley or Beijing. Tech hubs are emerging in many parts of the world, and cities large and small offer opportunities both for local talent and companies worldwide.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eColombia is an inspiring example. In 2019, several of my teams (including Landing AI and other AI Fund portfolio companies) made a bet on Latin America. I set up an engineering hub in \u003ca href=\"https://techcrunch.com/2019/08/21/andrew-ngs-ai-companies-expand-to-medellin-colombia/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eMedellín\u003c/a\u003e, Colombia, because I was impressed by the tech scene, educational institutions, enthusiastic engineers, and supportive partners we found there. (You can see in the photo below what a good time we had there! Non-Spanish speakers: Can you read the phrase on the t-shirts?)\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eJudging by record venture investments and successful IPOs in Latin America, the secret is out about the caliber of the region’s technical talent, entrepreneurial spirit, and ability to build high-quality systems. For U.S. teams, in particular, its proximity in terms of time zones and geography makes it one of the most interesting emerging ecosystems in tech. Several AI Fund portfolio companies now have a significant presence there.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eOur fastest-growing Latin American team is \u003ca href=\"https://www.factored.ai/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eFactored\u003c/a\u003e, which helps companies build world-class AI and data engineering teams. Factored’s Latin American operation grew from 24 engineers to well over 100 in the past year. Its projects have ranged from developing MLOps pipelines for one of the largest financial-tech companies in Silicon Valley to \u003ca href=\"https://openreview.net/forum?id=c20jiJ5K2H\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003epresenting\u003c/a\u003e \u003ca href=\"https://arxiv.org/abs/2111.09344?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003epapers\u003c/a\u003e at NeurIPS.\u003c/em\u003e\u003c/p\u003e\u003c!--kg-card-begin: html--\u003e\u003ctable class=\"hse-image-wrapper\" role=\"presentation\" width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" style=\"border-collapse: collapse; border-spacing: 0px !important;\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd align=\"center\" valign=\"top\" style=\"border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 10px 0px; font-size: 0px;\"\u003e\u003cimg alt=\"Screen Shot 2022-01-25 at 4.22.34 PM\" src=\"https://cdn2.hubspot.net/hub/5871640/hubfs/Screen%20Shot%202022-01-25%20at%204.22.34%20PM.png?upscale=true\u0026amp;width=1200\u0026amp;upscale=true\u0026amp;name=Screen%20Shot%202022-01-25%20at%204.22.34%20PM.png\" width=\"600\" align=\"middle\" class=\"stretch-on-mobile\" style=\"outline: none; text-decoration: none; max-width: 100%; font-size: 16px;\"\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c!--kg-card-end: html--\u003e\u003cp\u003e\u003cem\u003eThe rise of opportunities in Latin America is part of the broader trend toward working from home. I can collaborate as easily with someone in Palo Alto, California, as with someone in Buenos Aires, Argentina. In fact, I’ve been spending more time in Washington State (where I enjoy the benefit of free babysitting by my wonderful in-laws) instead of my Palo Alto headquarters.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eRemote work highlights a fact that should have been obvious: Talent is everywhere, even if access to opportunity has not been. Whatever city you live in, today you’ll find more opportunities than ever to learn, find an exciting job, and do meaningful work.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eIt has been over two years since I visited Colombia. While I appreciate the excellence of Colombian engineers, I also love the local culture. I enjoy the sculptures of \u003ca href=\"https://en.wikipedia.org/wiki/Fernando_Botero?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eFernando Botero\u003c/a\u003e, and \u003ca href=\"https://en.wikipedia.org/wiki/Bandeja_paisa?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003ebandeja paisa\u003c/a\u003e is a favorite dish that I haven’t managed to find in the U.S. I hope the pandemic will allow me to return before long.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eNo matter where you’re located, I will continue to think about how DeepLearning.AI can do more to support you in developing your talent and building the career you want.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"news\"\u003eNews\u003c/h2\u003e\u003c!--kg-card-begin: html--\u003e\u003ctable class=\"hse-image-wrapper\" role=\"presentation\" width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" style=\"border-collapse: collapse; border-spacing: 0px !important;\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd align=\"center\" valign=\"top\" style=\"border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;\"\u003e\u003cimg alt=\"LINKEDIN\" src=\"https://cdn2.hubspot.net/hub/5871640/hubfs/LINKEDIN.jpg?upscale=true\u0026amp;width=1200\u0026amp;upscale=true\u0026amp;name=LINKEDIN.jpg\" width=\"600\" align=\"middle\" class=\"stretch-on-mobile\" style=\"outline: none; text-decoration: none; max-width: 100%; font-size: 16px;\"\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c!--kg-card-end: html--\u003e\u003ch2 id=\"machine-learning-jobs-on-the-rise\"\u003eMachine Learning Jobs on the Rise\u003c/h2\u003e\u003cp\u003eJobs for machine learning engineers are growing fast, according to an analysis by LinkedIn.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Machine learning engineer ranks fourth among the 25 fastest-growing job titles in the United States, according to the professional social network’s annual \u003ca href=\"https://www.linkedin.com/pulse/linkedin-jobs-rise-2022-25-us-roles-growing-demand-linkedin-news/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003e\u003cem\u003eJobs on the Rise\u003c/em\u003e\u003c/a\u003e report. (The top three were vaccine specialist, diversity and inclusion manager, and customer marketing manager.)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat the data says:\u003c/strong\u003e LinkedIn analyzed job openings listed on its site between January 2017 and July 2021 and ranked those that showed consistent growth over the entire period. The analysis counted open positions at different levels of seniority as a single position. It didn’t count positions occupied by interns, volunteers, or students.\u003c/p\u003e\u003cul\u003e\u003cli\u003eSalaries for machine learning engineers generally ranged from $72,600 to $170,000.\u003c/li\u003e\u003cli\u003eApplicants were expected to have a median of four years of prior experience. Skills requested most often included deep learning, natural language processing, and TensorFlow.\u003c/li\u003e\u003cli\u003eMost jobs were located in San Francisco, Seattle, and Los Angeles, and nearly 20 percent of them allowed remote work.\u003c/li\u003e\u003cli\u003eOf machine learning engineers who previously held a different title, most had been software engineers, data scientists, or AI specialists.\u003c/li\u003e\u003cli\u003eOf machine learning engineers whose gender was known, 22.3 percent were women.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e While LinkedIn’s analysis was confined to the U.S., evidence suggests that machine learning jobs are growing worldwide.\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn the Philippines, where automation is replacing call center jobs, the outsourcing industry has \u003ca href=\"https://read.deeplearning.ai/the-batch/workers-get-the-jump-on-automation/?ref=dl-staging-website.ghost.io\"\u003elaunched\u003c/a\u003e a massive effort to train professionals in machine learning and data analytics.\u003c/li\u003e\u003cli\u003eA survey by \u003cem\u003eMIT Technology Review\u003c/em\u003e found that \u003ca href=\"https://read.deeplearning.ai/the-batch/asias-ai-advantage/?ref=dl-staging-website.ghost.io\"\u003e96 percent\u003c/a\u003e of Asian executives and \u003ca href=\"https://read.deeplearning.ai/the-batch/ai-in-regions-rich-and-poor/?ref=dl-staging-website.ghost.io\"\u003e82 percent\u003c/a\u003e of executives in Africa and the Middle East said their companies had deployed at least one machine learning algorithm as of 2019.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e North America is the world’s largest AI market, accounting for around \u003ca href=\"https://www.grandviewresearch.com/industry-analysis/artificial-intelligence-ai-market?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo#:~:text=Regional%20Insights,(AI)%20across%20various%20industries\" rel=\"noopener\"\u003e40 percent\u003c/a\u003e of AI revenue globally. The fact that remote work is an option for one in five U.S. machine learning jobs suggests a huge opportunity for applicants located in other parts of the world.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e The world needs more AI practitioners! If you’re wondering whether to pursue a career in the field, this is a good time to jump in.\u003c/p\u003e\u003chr\u003e\u003c!--kg-card-begin: html--\u003e\u003ctable class=\"hse-image-wrapper\" role=\"presentation\" width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" style=\"border-collapse: collapse; border-spacing: 0px !important;\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd align=\"center\" valign=\"top\" style=\"border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;\"\u003e\u003cimg alt=\"AMAZON (1)\" src=\"https://cdn2.hubspot.net/hub/5871640/hubfs/AMAZON%20(1).gif?upscale=true\u0026amp;width=1200\u0026amp;upscale=true\u0026amp;name=AMAZON%20(1).gif\" width=\"600\" align=\"middle\" class=\"stretch-on-mobile\" style=\"outline: none; text-decoration: none; max-width: 100%; font-size: 16px;\"\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c!--kg-card-end: html--\u003e\u003ch2 id=\"let-the-model-choose-your-outfit\"\u003eLet the Model Choose Your Outfit\u003c/h2\u003e\u003cp\u003eAmazon’s first brick-and-mortar clothing store is getting ready to deliver automated outfit recommendations.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new: \u003c/strong\u003eThe ecommerce giant \u003ca href=\"https://www.aboutamazon.com/news/retail/amazon-reimagines-in-store-shopping-with-amazon-style?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eannounced\u003c/a\u003e plans to open a flagship Amazon Style location at a Los Angeles-area mall this year.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The 30,000 square-foot store will feature aisles and racks like a traditional clothing store, but customers will be able to scan QR codes using their phones to see variations in color and size as well as items recommended by machine learning models. A touchscreen in each fitting room will enable customers to request such items to try on.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eProposed innovations:\u003c/strong\u003e Research papers provide glimpses of Amazon’s ideas for AI-driven fashion retailing. The company declined to comment on whether it plans to implement them. For instance:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://read.deeplearning.ai/the-batch/which-shoes-go-with-that-outfit/?ref=dl-staging-website.ghost.io\"\u003eCSA-Net\u003c/a\u003e finds items that fit an existing outfit using convolutional neural networks and attention. A customer can enter a shirt and shoes, and the model might choose a matching handbag.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://read.deeplearning.ai/the-batch/that-online-boutique-but-smarter/?ref=dl-staging-website.ghost.io\"\u003eVAL\u003c/a\u003e uses a transformer network to interpret an image-and-text pair and searches for matching products. A customer might, say, select a picture of a shirt and request a different color.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://read.deeplearning.ai/the-batch/clothes-make-the-model/?ref=dl-staging-website.ghost.io\"\u003eOutfit-Viton\u003c/a\u003e turns a full-body photo of a customer into a 3D model, then uses a generative adversarial network to generate images of the person wearing selected outfits.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news: \u003c/strong\u003eLast summer, Amazon opened its first brick-and-mortar grocery store, where customers can take merchandise off a shelf and exit without interacting with a clerk for payment. Computer vision identifies them at the door and identifies the products to charge their account automatically.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e The fashion retailing market is crowded, but Amazon’s considerable AI expertise puts it at the forefront of low-friction retailing.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Fashion companies such as Stitch Fix and Wantable have used AI to recommend clothing and build valuable businesses. There are good reasons to believe that future fashion leaders will be sophisticated AI players.\u003c/p\u003e\u003chr\u003e\u003c!--kg-card-begin: html--\u003e\u003ctable class=\"hse-image-wrapper\" role=\"presentation\" width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" style=\"border-collapse: collapse; border-spacing: 0px !important;\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd align=\"center\" valign=\"top\" style=\"border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;\"\u003e\u003cimg alt=\"ezgif.com-gif-maker - 2021-11-16T124131.535\" src=\"https://cdn2.hubspot.net/hub/5871640/hubfs/ezgif.com-gif-maker%20-%202021-11-16T124131.535.gif?upscale=true\u0026amp;width=1200\u0026amp;upscale=true\u0026amp;name=ezgif.com-gif-maker%20-%202021-11-16T124131.535.gif\" width=\"600\" align=\"middle\" class=\"stretch-on-mobile\" style=\"outline: none; text-decoration: none; max-width: 100%; font-size: 16px;\"\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c!--kg-card-end: html--\u003e\u003ch2 id=\"high-accuracy-at-low-power\"\u003eHigh Accuracy at Low Power\u003c/h2\u003e\u003cp\u003eEquipment that relies on computer vision while unplugged — mobile phones, drones, satellites, autonomous cars — need power-efficient models. A new architecture set a record for accuracy per computation.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat's new:\u003c/strong\u003e Yinpeng Chen and colleagues at Microsoft devised \u003ca href=\"https://arxiv.org/abs/2108.05895?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eMobile-Former\u003c/a\u003e, an image recognition system that efficiently weds a \u003ca href=\"https://arxiv.org/abs/1704.04861?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eMobileNet\u003c/a\u003e’s convolutional eye for detail with a \u003ca href=\"https://arxiv.org/abs/2010.11929?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eVision Transformer\u003c/a\u003e’s attention-driven grasp of the big picture.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e Convolutional neural networks process images in patches, which makes them computationally efficient but ignores global features that span multiple patches. Transformers represent global features but they’re inefficient. A transformer’s self-attention mechanism compares each part of an input to each other part, so the amount of computation requires grows quadratically with the size of the input. Mobile-Former combines the two architectures, but instead of using self-attention, its transformers compare each part of an input to a small learned vector. This gives the system information about global features without the computational burden.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e Mobile-Former is a stack of layers, each made up of three components: a \u003ca href=\"https://www.coursera.org/learn/convolutional-neural-networks/lecture/B1kPZ/mobilenet?ref=dl-staging-website.ghost.io\"\u003eMobileNet block\u003c/a\u003e and \u003ca href=\"https://www.coursera.org/learn/nlp-sequence-models/lecture/Kf5Y3/transformer-network?ref=dl-staging-website.ghost.io\"\u003etransformer block\u003c/a\u003e joined by a two-way bridge of two attention layers (one for each direction of communication). The MobileNet blocks refine an image representation, the transformer blocks refine a set of six tokens (randomly initiated vectors that are learned over training), and the bridge further refines the image representation according to the tokens and vice versa. The authors trained the system on ImageNet.\u003c/p\u003e\u003cul\u003e\u003cli\u003eGiven an image, a convolutional layer generates a representation. Given the representation and the tokens, the bridge updates the tokens to represent the image. This starts an iterative process:\u003c/li\u003e\u003cli\u003eA MobileNet block refines the image representation and passes it to the bridge.\u003c/li\u003e\u003cli\u003eA transformer block refines the tokens based on the relationships between them and passes them to the bridge.\u003c/li\u003e\u003cli\u003eThe bridge updates the image representation according to the tokens, and the tokens according to the image representation, and passes them all to the next series of blocks.\u003c/li\u003e\u003cli\u003eThe process repeats until, at the end of the line, two fully connected layers render a classification.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e Mobile-Former beat competitors at a similar computational budget and at much larger budgets as well. In ImageNet classification, it achieved 77.9 percent accuracy using 294 megaflops (a measure of computational operations), beating transformers that required much more computation. The nearest competitor under 1.5 gigaflops, \u003ca href=\"https://arxiv.org/abs/2103.14030?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eSwin\u003c/a\u003e, scored 77.3 percent using 1 gigaflop. At a comparable budget of 299 megaflops, a variation on the \u003ca href=\"https://arxiv.org/abs/1807.11164?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eShuffleNetV2\u003c/a\u003e convolutional network scored 72.6 percent accuracy.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eYes, but:\u003c/strong\u003e The system is not efficient in terms of the number of parameters and thus memory requirements. Mobile-Former-294M encompasses 11.4 million parameters, while Swin has 7.3 million and ShuffleNetV2 has 3.5 million. One reason: Parameters in the MobileNet blocks, transformer blocks, and bridge aren’t shared.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Transformers have strengths that have propelled them into an ever wider range of applications. Integrating them with other architectures makes it possible to take advantage of the strengths of both.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe're thinking:\u003c/strong\u003e Using more than six tokens didn’t result in better performance. It appears that the need for attention in image tasks is limited — at least for images of 224x224 resolution.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM \u003cstrong\u003e\u003ca href=\"http://deeplearning.ai/?ref=dl-staging-website.ghost.io\"\u003eDEEPLEARNING.AI\u003c/a\u003e\u003c/strong\u003e\u003c/h2\u003e\u003c!--kg-card-begin: html--\u003e\u003ctable class=\"hse-image-wrapper\" role=\"presentation\" width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" style=\"border-collapse: collapse; border-spacing: 0px !important;\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd align=\"center\" valign=\"top\" style=\"border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;\"\u003e\u003cimg alt=\"Thumbnail 1 Logo\" src=\"https://cdn2.hubspot.net/hub/5871640/hubfs/Thumbnail%201%20Logo.png?upscale=true\u0026amp;width=1200\u0026amp;upscale=true\u0026amp;name=Thumbnail%201%20Logo.png\" width=\"600\" align=\"middle\" class=\"stretch-on-mobile\" style=\"outline: none; text-decoration: none; max-width: 100%; font-size: 16px;\"\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c!--kg-card-end: html--\u003e\u003cp\u003eWe’re highlighting our global deep learner community. Read their stories, get inspired to take the next step in your AI journey, and #BeADeepLearner! \u003ca href=\"https://www.deeplearning.ai/program/deep-learning-specialization/?ref=dl-staging-website.ghost.io\"\u003eLearn more\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003c!--kg-card-begin: html--\u003e\u003ctable class=\"hse-image-wrapper\" role=\"presentation\" width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" style=\"border-collapse: collapse; border-spacing: 0px !important;\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd align=\"center\" valign=\"top\" style=\"border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;\"\u003e\u003cimg alt=\"ALLIANCE\" src=\"https://cdn2.hubspot.net/hub/5871640/hubfs/ALLIANCE.gif?upscale=true\u0026amp;width=1200\u0026amp;upscale=true\u0026amp;name=ALLIANCE.gif\" width=\"600\" align=\"middle\" class=\"stretch-on-mobile\" style=\"outline: none; text-decoration: none; max-width: 100%; font-size: 16px;\"\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c!--kg-card-end: html--\u003e\u003ch2 id=\"standards-for-hiring-algorithms\"\u003eStandards for Hiring Algorithms\u003c/h2\u003e\u003cp\u003eSome of the world’s largest corporations will use standardized criteria to evaluate AI systems that influence hiring and other personnel decisions.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e The Data and Trust Alliance, a nonprofit group devoted to mitigating tech-induced bias in workplaces, \u003ca href=\"https://dataandtrustalliance.org/our-initiatives?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eintroduced\u003c/a\u003e resources for evaluating fairness in algorithms for personnel management. Twenty-two companies have agreed to use them worldwide including IBM, Meta, and Walmart.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat it says:\u003c/strong\u003e Algorithmic Bias Safeguards for Workforce includes a \u003ca href=\"https://dataandtrustalliance.org/Overview_Algorithmic_Bias_Safeguards_for_Workforce.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003equestionnaire\u003c/a\u003e for evaluating AI system vendors, a scoring system for comparing one vendor to another, and materials for educating human-resources teams about AI.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe questionnaire addresses three themes: the business case for a given algorithm; vetting for bias during data collection, training, and deployment; and organizational biases arising from poor governance or lack of transparency. Answers can be shared between the developer and customer only, not with the rest of the group.\u003c/li\u003e\u003cli\u003eAnswers are converted into scores, then added to scorecards that alliance members can use to compare vendors.\u003c/li\u003e\u003cli\u003eA primer is available to help human-resources staff, lawyers, and other stakeholders in interpreting the results of the survey. Other educational materials define key vocabulary and explain how algorithmic bias impacts hiring and personnel decisions.\u003c/li\u003e\u003cli\u003eAlliance members are not required to use the materials.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Algorithms for hiring and managing employees have been at the center of several high-profile controversies.\u003c/p\u003e\u003cul\u003e\u003cli\u003eEarlier this year, drivers for Amazon’s Flex, the online retailer’s delivery-crowdsourcing program, \u003ca href=\"https://read.deeplearning.ai/the-batch/when-algorithms-manage-humans/?ref=dl-staging-website.ghost.io\"\u003ecriticized\u003c/a\u003e the company’s algorithm for scoring their performance, saying it unjustly penalized them for unavoidable delays due to bad weather and other factors outside their control. In 2018, Amazon abandoned a hiring algorithm that was found to penalize female candidates.\u003c/li\u003e\u003cli\u003eAn analysis by \u003cem\u003eMIT Technology Review\u003c/em\u003e \u003ca href=\"https://read.deeplearning.ai/the-batch/danke-for-the-interview/?ref=dl-staging-website.ghost.io\"\u003efound\u003c/a\u003e that hiring systems from Curious Thing and MyInterview gave high scores in English proficiency to an applicant who spoke entirely in German.\u003c/li\u003e\u003cli\u003eIn January, hiring software developer HireVue stopped using face recognition, which purportedly analyzed facial expressions to judge traits such as dependability, in response to a lawsuit from the nonprofit Electronic Privacy Information Center that challenged the company’s use of AI for being unfair and deceptive.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Companies need ways to find and retain top talent amid widening global competition. However, worries over biased AI systems have spurred laws that limit algorithmic hiring in New York City and the United Kingdom. Similar regulations in China, the European Union, and the United States may follow.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e We welcome consistent standards for AI systems of all kinds. This looks like a good first step in products for human resources.\u003c/p\u003e\u003chr\u003e\u003c!--kg-card-begin: html--\u003e\u003ctable class=\"hse-image-wrapper\" role=\"presentation\" width=\"100%\" cellpadding=\"0\" cellspacing=\"0\" style=\"border-collapse: collapse; border-spacing: 0px !important;\"\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd align=\"center\" valign=\"top\" style=\"border-collapse: collapse; font-family: Helvetica, Arial, sans-serif; color: rgb(59, 59, 59); word-break: break-word; text-align: center; padding: 5px 0px 10px; font-size: 0px;\"\u003e\u003cimg alt=\"FUSIONv3\" src=\"https://cdn2.hubspot.net/hub/5871640/hubfs/FUSIONv3.gif?upscale=true\u0026amp;width=1200\u0026amp;upscale=true\u0026amp;name=FUSIONv3.gif\" width=\"600\" align=\"middle\" class=\"stretch-on-mobile\" style=\"outline: none; text-decoration: none; max-width: 100%; font-size: 16px;\"\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c!--kg-card-end: html--\u003e\u003ch2 id=\"transformers-see-in-3d\"\u003eTransformers See in 3D\u003c/h2\u003e\u003cp\u003eVisual robots typically perceive the three-dimensional world through sequences of two-dimensional images, but they don’t always know what they’re looking at. For instance, Tesla’s self-driving system has been known to \u003ca href=\"https://www.youtube.com/watch?v=7UF-S2czdCk\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003emistake a full moon for a traffic light\u003c/a\u003e. New research aims to clear up such confusion.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat's new:\u003c/strong\u003e Aljaž Božic and colleagues at Technical University of Munich released \u003ca href=\"https://aljazbozic.github.io/transformerfusion/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eTransformerFusion\u003c/a\u003e, which set a new state of the art in deriving 3D scenes from 2D video.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey Insight:\u003c/strong\u003e The authors teamed two architectures and a novel approach to estimating the positions of points in space:\u003c/p\u003e\u003cul\u003e\u003cli\u003eTransformers excel at learning which features are most relevant to completing a particular task. In a video, they can learn which frames, and which parts of a frame, reveal the role of a given point in space: whether it’s empty or filled by an object.\u003c/li\u003e\u003cli\u003eHowever, while transformers do well at selecting the best views, they’re not great at identifying points in space. The authors addressed this shortfall by refining the representations using 3D convolutional neural networks.\u003c/li\u003e\u003cli\u003eTo position the points in space, they generated representations at both course and fine scales. The coarse representations enabled the system to place points coherently across relatively large distances, while the fine representations enabled the system to reproduce details.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e Given a series of 2D frames, TransformerFusion learned to reconstruct the 3D space they depicted by classifying whether each 3D pixel, or voxel, belonged (or was very close) to an object’s surface. The authors trained the system on \u003ca href=\"https://arxiv.org/abs/1702.04405?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eScanNet\u003c/a\u003e, a dataset that contains RGB-D (video plus depth) clips shot in indoor settings like bedrooms, offices, and libraries; object segmentations; and 3D scene reconstructions.\u003c/p\u003e\u003cul\u003e\u003cli\u003eGiven a 2D frame, a \u003ca href=\"https://arxiv.org/abs/1512.03385?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eResNet-18\u003c/a\u003e pretrained on ImageNet produced a coarse representation and a fine representation.\u003c/li\u003e\u003cli\u003eA transformer mapped the coarse representations, along with information derived from the images such as viewing direction, to a 3D grid with 30-centimeter resolution and produced a new representation for each point. A second transformer mapped fine representations and other information to a 3D grid with 10-centimeter resolution and, likewise, produced a new representation for each point.\u003c/li\u003e\u003cli\u003eGiven the coarse representations, a 3D convolutional neural network learned to classify whether a point was near an object’s surface and refined the representations accordingly. If the point was near a surface, the system continued; otherwise, it classified the point as not near a surface and stopped to save computation.\u003c/li\u003e\u003cli\u003eA second 3D CNN used both fine and coarse representations to learn how to classify, refine, and filter the representations of points on the fine grid.\u003c/li\u003e\u003cli\u003eThe system interpolated the remaining coarse and fine representations onto a 3D grid of even higher resolution (2 centimeters) and generated another set of point representations. Given each new point, a vanilla neural network classified whether there was an object at that point.\u003c/li\u003e\u003cli\u003eThe authors trained the system using three loss terms: one that encouraged the coarse CNN’s classifications to match ground truth, a similar one for the fine CNN, and a similar one for the higher-resolution CNN.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The authors measured distances between TransformerFusion’s estimated points in space and ground truth. They considered an estimation correct if it matched ground truth within 5 centimeters. The system achieved an F-1 score, a balance of precision and recall where higher is better, of 0.655. The best competing method, \u003ca href=\"https://arxiv.org/abs/1803.08673?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_Mla8bhwxs9CSlEBQF14AOumcBHP3GQludEGF_7a7lIib7WES4i4f28ou5wMv6NHd8bALo\" rel=\"noopener\"\u003eAtlas\u003c/a\u003e, achieved 0.636. Without the 3D CNNs, TransformerFusion achieved 0.361.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eYes, but:\u003c/strong\u003e Despite setting a new state of the art, TransformerFusion’s ability to visualize 3D scenes falls far short of human-level performance. Its scene reconstructions are distorted, and it has trouble recognizing transparent objects.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Transformers have gone from strength to strength — in language, 2D vision, molecular biology, and other areas — and this work shows their utility in a new domain. Yet, despite their capabilities, they can’t do the whole job. The authors took advantage of transformers where they could do well and then refined their output using an architecture more appropriate to 3D modeling.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe're thinking:\u003c/strong\u003e Training systems on both low- and high-resolution versions of an image could improve other vision tasks as well.\u003c/p\u003e","comment_id":"61f1be240c0d0b003b5fe6fb","feature_image":"https://dl-staging-website.ghost.io/content/images/2022/01/Screen-Shot-2022-01-25-at-4.22.34-PM.png","featured":false,"visibility":"public","created_at":"2022-01-26T13:33:24.000-08:00","updated_at":"2024-02-26T17:08:20.000-08:00","published_at":"2022-01-26T12:00:00.000-08:00","custom_excerpt":"If you want to build a career in AI, it’s no longer necessary to be located in one of a few tech hubs such as Silicon Valley or Beijing. Tech hubs are emerging in many parts of the world, and cities large and small offer opportunities both for local talent and companies worldwide.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"61f1bf220c0d0b003b5fe718","name":"issue-129","slug":"issue-129","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-129/"},{"id":"63374be3e11ff8003db98126","name":"Jan 26, 2022","slug":"jan-26-2022-2","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/jan-26-2022-2/"},{"id":"65dd3604d8d0900001aca035","name":"#laura","slug":"hash-laura","description":null,"feature_image":null,"visibility":"internal","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/404/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-129/","excerpt":"If you want to build a career in AI, it’s no longer necessary to be located in one of a few tech hubs such as Silicon Valley or Beijing. Tech hubs are emerging in many parts of the world, and cities large and small offer opportunities both for local talent and companies worldwide.","reading_time":12,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Job Growth in Machine Learning, Amazon's AI-Driven Store...","meta_description":"The Batch - AI News \u0026 Insights: Job Growth in Machine Learning | Amazon's AI-Driven Clothing Store | Transformers for Robot Vision | Hiring Algorithms Under Scrutiny","email_subject":null,"frontmatter":null,"feature_image_alt":"Andrew Ng with a group of engineers in Medellin, Colombia","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2022/01/Screen-Shot-2022-01-25-at-4.22.34-PM.png","dimensions":{"width":1200,"height":675}},"banner":{"title":"ChatGPT Prompt Engineering for Developers","databaseId":29452,"id":"cG9zdDoyOTQ1Mg==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/05/cgpt-2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-129"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>