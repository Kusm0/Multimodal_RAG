<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Standing Up for Ethical AI, Efficient Transformers, Up-Rezzing</title><meta name="description" content="The Batch - AI News &amp; Insights: A prominent AI researcher has turned his back on computer vision over ethical issues | Reformer - New transformers version" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-29/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Standing Up for Ethical AI, Efficient Transformers, Up-Rezzing" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: A prominent AI researcher has turned his back on computer vision over ethical issues | Reformer - New transformers version" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Standing Up for Ethical AI, Efficient Transformers, Up-Rezzing" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-29/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2020-03-04T12:00:00.000-08:00"/><meta property="article:modified_time" content="2022-10-07T10:08:58.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-29"/><meta property="article:tag" content="Mar 04, 2020"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Standing Up for Ethical AI, Efficient Transformers, Up-Rezzing" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: A prominent AI researcher has turned his back on computer vision over ethical issues | Reformer - New transformers version" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-29/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter20220ASPECT201.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter20220ASPECT201.png"/><meta property="og:image:width" content="576"/><meta property="og:image:height" content="324"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2020-03-04T12:00:00.000-08:00","dateModified":"2022-10-07T10:08:58.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Standing Up for Ethical AI, Efficient Transformers, Up-Rezzing","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter20220ASPECT201.png","width":576,"height":324},"publisher":{"@type":"Organization","name":"Standing Up for Ethical AI, Efficient Transformers, Up-Rezzing","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: A prominent AI researcher has turned his back on computer vision over ethical issues | Reformer - New transformers version"}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-29/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 29</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Mar 4, 2020</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">10<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/mar-04-2020/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Mar 04, 2020</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">10<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-29/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-29/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-29/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,</em></p><p><em>In addition to creating tremendous value, AI is creating tremendous concentrations of power. Our community is wrestling with what constitutes fair use of that power.</em></p><p><em><a href="https://themarkup.org/allstates-algorithm/2020/02/25/car-insurance-suckers-list?ref=dl-staging-website.ghost.io" rel=" noopener">The Markup</a> published an article criticizing car insurance giant Allstate for price discrimination — charging different fees to different customers — based not only on their risk but also on their predicted willingness to pay. Is this behavior okay?</em></p><p><em>Digital technology enables online comparison shopping, which shifts pricing power toward consumers. But it also enables companies to create unique products for individual customers — say, a ride from point A to point B at a particular time, or a health insurance plan tailored to the customer’s personal history — and AI can help optimize prices to maximize profit for vendors. That can lead to both better products and worse price transparency.</em></p><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/Andrews20Letter20220ASPECT201.png" class="kg-image" alt="Economic surplus " loading="lazy"></figure><p><em>If an online store sells the same hammer to different people for different prices,</em> <em>customers eventually will notice. That helps keep this form of price discrimination in check. But the temptation for sellers is still there. In 2016, Uber revealed that customers <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/uber-knows-when-your-phone-is-about-to-run-out-of-battery-a7042416.html]?ref=dl-staging-website.ghost.io" rel=" noopener">pay higher prices when their phone battery is low</a>. (The company said it didn’t take advantage of this phenomenon.)</em></p><p><em>I wonder sometimes if I should comparison-shop more frequently than I do. Less because I’m anxious to save a few dollars on one purchase, but because I want to train vendors’ AI systems to think I’m sensitive to price and thus to offer me lower prices.</em></p><p><em>In college, my Economics 101 professor taught about supply and demand, and how our economy creates surpluses for both producers and consumers. But AI is prompting us to revisit old economic theories — along with our sense of what’s fair.</em></p><p><em>These are hard questions. I hope we can work on them together to give the world great products and services at even better prices.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><h2></h2><h2 id="deeplearningai-exclusive"><a href="https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io" rel="noopener">DeepLearning.ai </a>Exclusive</h2><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/TheBatchFeaturedImageBreakingIntoAICherifJazra.png" class="kg-image" alt loading="lazy"></figure><h3 id="breaking-into-ai-a-learning-journey">Breaking Into AI: A Learning Journey</h3><p>After a decade in wireless communications, Cherif was ready for a change. Online courses, textbooks, and meetups helped him build his skills and land a Machine Learning Engineer role at Postmates. Learn how he overcame obstacles, aced job interviews, and started applying ML in the real world in the latest installment of our “Breaking Into AI” series. <a href="https://www.deeplearning.ai/blog/breaking-into-ai-advocating-for-machine-learning-in-the-real-world?ref=dl-staging-website.ghost.io">Read more</a></p><hr><h2 id="news"><strong>News</strong></h2><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-optimize208.gif" class="kg-image" alt="Film from 1911 colored" loading="lazy"></figure><h3 id="history-in-hi-res">History in Hi Res</h3><p>While deep learning is taking us into the future, it’s also opening windows into the past.<br><br><strong>What’s new: </strong>Machine learning-savvy <a href="https://old.reddit.com/r/Futurology/comments/ezs4cv/youtuber_uses_neural_networks_to_upscale_1896/fgr4yy2/?context=3&ref=dl-staging-website.ghost.io" rel=" noopener">Redditor</a> Denis Shiryaev brought 100-year-old silent film footage of New York City into the 21st century by automatically sharpening the picture, boosting the frame rate, and adding color.<br><br><strong>How he did it:</strong> Shiryaev obtained eight minutes of <a href="https://www.moma.org/calendar/exhibitions/3858?ref=dl-staging-website.ghost.io" rel=" noopener">footage</a> shot by <a href="https://sv.wikipedia.org/wiki/Svenska_Biografteatern?ref=dl-staging-website.ghost.io" rel=" noopener">a Swedish film maker</a> in 1911. He spent five days running the movie through a gauntlet of neural nets.</p><ul><li>Shiryaev used <a href="https://arxiv.org/abs/1809.00219?ref=dl-staging-website.ghost.io" rel=" noopener">Enhanced Super-Resolution Generative Adversarial Networks</a> to compute additional pixels, boosting resolution to 4K (approximately 4,000 pixels horizontally).</li><li>He used <a href="https://sites.google.com/view/wenbobao/dain?ref=dl-staging-website.ghost.io" rel=" noopener">Depth-Aware Video Frame Interpolation</a> to generate in-between frames, raising the frame rate to 60 per second. Film shot in the early 1900s typically had much <a href="https://vanillavideo.com/blog/2012/history-frame-rates-why-speeds-vary?ref=dl-staging-website.ghost.io" rel=" noopener">lower frame rates</a>, making them look sped-up and jerky.</li><li>He applied <a href="https://app.wandb.ai/borisd13/DeOldify/reports/DeOldify--Vmlldzo0NDU3OA?ref=dl-staging-website.ghost.io" rel=" noopener">DeOldify</a> to colorize the imagery. He noted on Reddit that he isn’t completely sold on that process, because the colors aren’t historically accurate.</li><li>The sound effects were digital audio clips. Several <a href="https://www.reddit.com/r/videos/comments/f8qw32/oc_i_have_made_a_60_fps_4k_version_of_new_york/fines4d/?ref=dl-staging-website.ghost.io" rel=" noopener">commenters</a> said they recognized horse whinnies from the video game Age of Empires II.</li></ul><p><strong>Behind the news:</strong> Shiryaev has used these procedures to update footage of <a href="https://www.youtube.com/watch?v=6FN06Hf1iFk&ref=dl-staging-website.ghost.io" rel=" noopener">Moscow in 1896</a>, an iconic film from the same year that shows a <a href="https://petapixel.com/2020/02/05/youtuber-used-ai-to-upscale-a-classic-1896-short-film-to-4k-and-60fps/?ref=dl-staging-website.ghost.io" rel=" noopener">French train pulling into station</a> and <a href="https://www.youtube.com/watch?v=az9nFrnCK60&ref=dl-staging-website.ghost.io" rel=" noopener">Apollo 16 astronauts</a> driving their moon buggy across the lunar surface in 1972.<br><br><strong>Why it matters:</strong> Shiryaev’s work brings these pieces of the past to life, overcoming the poor image quality, jerky movements, and lack of colors that diminish so much historic film. Similar treatment no doubt would perk up careworn Hollywood classics as well.<br><br><strong>We’re thinking:</strong> We can’t wait to up-res old home videos. It’s about time our parents’ 1980s hairstyles were revealed in high def.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/Reformer.png" class="kg-image" alt="Simplified depiction of LSH Attention " loading="lazy"></figure><h3 id="transformers-transformed">Transformers Transformed</h3><p>Transformer networks have revolutionized natural language processing, but they hog processor cycles and memory. New research demonstrates a more frugal variation.<br><br><strong>What’s new:</strong> Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya at UC Berkeley and Google modified the transformer architecture to run faster while requiring orders of magnitude less memory during training. They call the new version <a href="https://arxiv.org/abs/2001.04451?ref=dl-staging-website.ghost.io" rel=" noopener">Reformer</a>.<br><br><strong>Key insight:</strong> The transformer architecture is inherently inefficient: It tracks relationships among all input tokens, whether or not they matter to the output, and training requires a lot of memory. A few simple tweaks can rein in these excesses.<br><br><strong>How it works:</strong> The researchers replaced the transformer’s feed-forward network with a <a href="https://arxiv.org/abs/1707.04585?ref=dl-staging-website.ghost.io" rel=" noopener">reversible residual network</a>. They modified the attention mechanism with <a href="https://www.mit.edu/~andoni/LSH/?ref=dl-staging-website.ghost.io" rel=" noopener">locality-sensitive hashing</a>.</p><ul><li>Typically, a transformer must keep all feed-forward layers in memory during training. In Reformer, each layer of the reversible residual network stores information that enables backpropagation to occur one layer at a time, rather than storing information about the entire network. That way, the network requires only enough memory to store one layer.</li><li>A transformer’s attention mechanism encodes relationships between the current token and previous tokens, but usually only a few are important. Locality-sensitive hashing sorts the previous tokens into buckets according to similarity. Then Reformer computes attention relationships only within buckets.</li></ul><p><strong>Results:</strong> The authors ran experiments on Wikipedia <a href="https://cs.fit.edu/~mmahoney/compression/textdata.html?ref=dl-staging-website.ghost.io" rel=" noopener">text</a> parceled into sequences of 64,000 tokens (more than double the number in the original transformer <a href="https://arxiv.org/abs/1706.03762?ref=dl-staging-website.ghost.io" rel=" noopener">paper</a>) in 16GB of memory. Reformer achieved almost the same performance as a transformer with an identical number of parameters while consuming less memory. Furthermore, the time required to compute LSH attention scaled more efficiently with increased sequence length.<br><br><strong>Why it matters: </strong>Researchers seeking better performance are pumping up transformer-based models to immense sizes — Microsoft’s latest language model has <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/?ref=dl-staging-website.ghost.io" rel=" noopener">17 billion parameters</a>. Running such behemoths can be out of reach for all but the largest corporate research labs. Reformer offers a more efficient alternative.<br><br><strong>We’re thinking:</strong> Reformer’s improvements equip the transformer architecture for reading and generating long sequences — not only text, but also long-form video and audio. This capability could lead to larger-scale benchmarks to propel transformers into new tasks.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-optimize207.gif" class="kg-image" alt="Functioning of system that trackes the productivity of industrial workers" loading="lazy"></figure><h3 id="eyes-on-the-assembly-line">Eyes on the Assembly Line</h3><p>AI may not steal your job, but it can tell the boss when you’re slacking.<br><br><strong>What’s new:</strong> Drishti, a startup based in Palo Alto and Bengaluru, tracks the productivity of industrial workers by recognizing their actions on the assembly line. Automotive parts giant Denso is using the technology to eliminate bottlenecks in its factory in Battle Creek, Michigan, according to <em><a href="https://www.wired.com/story/when-ai-cant-replace-worker-watches-them-instead/?ref=dl-staging-website.ghost.io" rel=" noopener">Wired</a></em>.<br><br><strong>How it works:</strong> Drishti trains the system to recognize standardized actions in the client’s industrial processes.</p><ul><li>The training data includes video of many different people from a variety of angles, so the software can classify actions regardless of who is performing them.</li><li>Cameras watch employees as they assemble auto components. The system tracks how long it takes them to complete their tasks and alerts managers of significant deviations from the norm. Workers see a live display of their performance metrics. It shows them a smiley face if they’re ahead of schedule, a frown if they fall behind.</li><li>The system has helped factories achieve double-digit improvements in several productivity indicators, a Denso executive told <em><a href="https://www.forbes.com/sites/amyfeldman/2020/02/12/manufacturing-automation-startup-drishti-backed-by-andreessen-signs-on-more-than-10-clients-including--auto-parts-giant-denso/?ref=dl-staging-website.ghost.io#3cb34695795f" rel=" noopener">Forbes</a></em>.</li></ul><p><strong>Behind the news:</strong> Drishti’s founders include Prasad Akella, who led General Motors’ efforts to develop <a href="https://www.engineering.com/AdvancedManufacturing/ArticleID/13540/A-History-of-Collaborative-Robots-From-Intelligent-Lift-Assists-to-Cobots.aspx?ref=dl-staging-website.ghost.io" rel=" noopener">collaborative robots</a>, and computer vision expert Krishnendu Chadbury, who led teams at Google, Adobe, and Flipkart.<br><br><strong>Why it matters:</strong> Manufacturing is a <a href="https://data.worldbank.org/indicator/NV.IND.MANF.CD?ref=dl-staging-website.ghost.io" rel=" noopener">$14 trillion industry</a>. According to <a href="https://drishti.com/wp-content/uploads/2018/11/The-State-of-Human-Factory-Analytics.pdf?ref=dl-staging-website.ghost.io" rel=" noopener">research</a> sponsored by Drishti, humans perform 72 percent of the work, and human error causes 68 percent of defects. Using AI to help people work more efficiently could yield substantial gains.<br><br><strong>Yes, but: </strong>Workers in some industries are pushing back against automated management. Last year, dozens of employees <a href="https://www.wired.com/story/meet-the-immigrants-who-took-on-amazon/?ref=dl-staging-website.ghost.io" rel=" noopener">walked out</a> of Amazon warehouses to protest the pace of work demanded by AI-powered supervisors, which they said led to dangerous conditions.<br><br><strong>We’re thinking:</strong> Complaining about the quality of others’ work while not doing any yourself? Computers are becoming more like humans all the time!</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM <a href="https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io" rel="noopener">DEEPLEARNING.AI</a></h2><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-resize-3.gif" class="kg-image" alt loading="lazy"></figure><p>Want to deploy a TensorFlow model in your web browser or on your smartphone? The <a href="https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io" rel="noopener">deeplearning.ai</a> TensorFlow: Data and Deployment Specialization will teach you how. <a href="https://www.coursera.org/specializations/tensorflow-data-and-deployment?ref=dl-staging-website.ghost.io">Enroll now</a></p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/Redmon.png" class="kg-image" alt="Text &quot;You only live once. #YOLO&quot; written over an orange background" loading="lazy"></figure><h3 id="code-no-evil">Code No Evil</h3><p>A prominent AI researcher has turned his back on computer vision over ethical issues.<br><br><strong>What happened:</strong> The co-creator of the popular object-recognition network <a href="https://pjreddie.com/darknet/yolo/?ref=dl-staging-website.ghost.io" rel=" noopener">You Only Look Once</a> (YOLO) <a href="https://twitter.com/pjreddie/status/1230523827446091776?ref=dl-staging-website.ghost.io" rel=" noopener">said</a> he no longer works on computer vision because the technology has “almost no upside and enormous downside risk.”<br><br><strong>Why he quit:</strong> Joseph Redmon, a graduate student at the University of Washington with a charmingly unorthodox <a href="https://pjreddie.com/static/Redmon%20Resume.pdf?ref=dl-staging-website.ghost.io" rel=" noopener">résumé</a>, said on Twitter, “I stopped doing CV research because I saw the impact my work was having.” He didn’t respond to a request for an interview.</p><ul><li>“I loved the work but the military applications and privacy concerns eventually became impossible to ignore,” he said.</li><li>Redmon disclosed his decision in a discussion sparked by a <a href="https://nips.cc/Conferences/2020/CallForPapers?ref=dl-staging-website.ghost.io" rel=" noopener">call for papers</a> from NeurIPS requiring authors to include a statement discussing “ethical aspects and future societal consequences” of their work.</li><li>He previously aired his concerns in a 2018 <a href="https://www.youtube.com/watch?v=XS2UWYuh5u0&ref=dl-staging-website.ghost.io" rel=" noopener">TEDx talk</a>. He had been “horrified” to learn that the U.S. Army used his algorithms to help battlefield drones track targets, he said, urging the audience to make sure technology is used for good.</li></ul><p><strong>Behind the news:</strong> Redmon and his faculty advisor Ali Farhudi devised YOLO in 2016 to classify objects in real time, funded partly by Google and the U.S. Office of Naval Research. The work won a <a href="https://news.cs.washington.edu/2018/04/05/allen-schools-joseph-redmon-wins-google-ph-d-fellowship/?ref=dl-staging-website.ghost.io" rel=" noopener">People’s Choice Award</a> at that year’s Computer Vision and Pattern Recognition conference. The last <a href="https://arxiv.org/abs/1804.02767?ref=dl-staging-website.ghost.io" rel=" noopener">update</a> came in April 2018.<br><br><strong>Why it matters:</strong> Concerns are <a href="https://www.nature.com/articles/d41586-020-00160-y?ref=dl-staging-website.ghost.io" rel=" noopener">mounting</a> over a number of ethical concerns in machine learning including <a href="https://www.mckinsey.com/featured-insights/artificial-intelligence/tackling-bias-in-artificial-intelligence-and-in-humans?ref=dl-staging-website.ghost.io" rel=" noopener">biased output</a>, <a href="https://medium.com/@MKGOfficial/the-misuse-of-artificial-intelligence-machine-learning-7381b752dd8f?ref=dl-staging-website.ghost.io" rel=" noopener">potential misuse</a>, and <a href="https://www.theatlantic.com/technology/archive/2018/01/black-workers-and-the-driverless-bus/550535/?ref=dl-staging-website.ghost.io" rel=" noopener">adverse social impacts</a>. The field stands to lose more talented researchers if it doesn’t come to grips with issues like this.<br><br><strong>We’re thinking:</strong> Researchers need to recognize the ethical implications of their work and guide it toward beneficial uses. Many technologies have both civilian and military uses, and opting out may not be as powerful as helping to shape the field from within.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/Radar.gif" class="kg-image" alt="Fragment of a video explaining a model that extracts landmarks on the fly from radar scans " loading="lazy"></figure><h3 id="locating-landmarks-on-the-fly">Locating Landmarks on the Fly</h3><p>Directions such as “turn left at the big tree, go three blocks, and stop at the big red house on your left” can get you to your destination because they refer to stationary landmarks. New research enables self-driving cars to identify such stable indicators on their own.<br><br><strong>What’s new:</strong> Dan Barnes and Ingmar Posner of Oxford University built a <a href="https://arxiv.org/abs/2001.10789?ref=dl-staging-website.ghost.io" rel=" noopener">model</a> that extracts landmarks on the fly from radar scans to build maps for autonomous vehicles. Radar is challenging in this application because it generates noise and ghost images, but it has the benefits of long range, high refresh rate, and robustness to environmental conditions. This <a href="https://www.youtube.com/watch?v=L-PO7nxWpJU&ref=dl-staging-website.ghost.io" rel=" noopener">video</a> explains.<br><br><strong>Key insight:</strong> Self-driving cars often navigate by recognizing landmarks. The researchers realized that neural networks can discover them by reversing the task: The radar signals most valuable to navigation are likely stable features of the landscape.<br><br><strong>How it works:</strong> The system learns to identify keypoints that best predict a car’s motion. The training <a href="https://ori.ox.ac.uk/oxford-radar-robotcar-dataset/?ref=dl-staging-website.ghost.io" rel=" noopener">data</a> specifies a vehicle’s motion from radar frame to radar frame.</p><ul><li>A U-Net architecture transforms each radar frame into potentially useful keypoints. It predicts vectors for each one representing its position, description, and usefulness for navigation.</li><li>A separate algorithm compares the position of keypoints with similar descriptions in successive frames. It uses the differences in their positions to predict the car’s motion. The keypoints that are most useful in performing this task are likely to be stable.</li><li>Using the description vector, the system can match keypoints from different perspectives. This enables it to map loops in a route, a challenging problem for earlier methods that process entire radar frames rather than keypoints.</li></ul><p><strong>Results:</strong> The system’s error in predicting the car’s position after driving a fixed distance was 2.06 percent, compared to the previous state of the art, 3.72 percent. Similarly, the error in the car’s predicted orientation fell from 0.0141 to 0.0067 degrees per meter driven. The new system ran an order of magnitude faster. For routes that didn’t include a loop, an earlier <a href="https://arxiv.org/pdf/1909.03752.pdf?ref=dl-staging-website.ghost.io" rel=" noopener">whole-frame approach</a> cut the predicted position error to 1.59 percent and rotation error to 0.0044 degrees per meter.<br><br><strong>Why it matters:</strong> The ability to generate keypoints automatically is making waves in other <a href="https://arxiv.org/abs/1910.10750?ref=dl-staging-website.ghost.io" rel=" noopener">computer</a> <a href="https://arxiv.org/abs/1906.11883?ref=dl-staging-website.ghost.io" rel=" noopener">vision</a> <a href="https://arxiv.org/abs/1910.02027?ref=dl-staging-website.ghost.io" rel=" noopener">tasks</a>. Combining keypoints with vector descriptions makes it possible to learn valuable things about them, from whether they indicate a loop in the route to recognizing a habitual parking space.<br><br><strong>We’re thinking:</strong> Our surroundings are always changing: Outdoors, trees fall down and buildings go up, while indoors objects are moved all the time. Algorithms that detect landmarks on the fly will be useful for mapping and navigating such dynamic environments.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/Tempo.gif" class="kg-image" alt="Exercise training system working" loading="lazy"></figure><h3 id="personal-trainer">Personal TrAIner</h3><p>No more sloppy workouts: AI can correct your form.<br><br><strong>What’s new:</strong> A home exercise system uses neural nets to analyze your motions and tell you when you perform a move properly, reports <em><a href="https://www.theverge.com/2020/2/26/21154185/tempo-smart-home-gym-kinect-computer-vision-ai-form-correction?ref=dl-staging-website.ghost.io" rel=" noopener">The Verge</a></em>.<br><br><strong>How it works: </strong><a href="https://tempo.fit/product?ref=dl-staging-website.ghost.io" rel=" noopener">Tempo</a> is a six-foot-tall easel with a giant screen on the front and storage for weights on the back. The system’s motion tracking capability is built around Microsoft’s <a href="https://azure.microsoft.com/en-us/services/kinect-dk/?ref=dl-staging-website.ghost.io#getting-started" rel=" noopener">Azure Kinect</a>. A <a href="https://docs.microsoft.com/en-us/azure/kinect-dk/depth-camera?ref=dl-staging-website.ghost.io" rel=" noopener">depth-sensing camera</a> emits infrared light and indirectly measures the time it takes for photons to zip from the camera to your body and back again, creating a continuous 3D image.</p><ul><li>Azure Kinect’s development kit comes with AI software that tracks body motion. Tempo didn’t respond to a question about whether it uses this model in its product.</li><li>The model is trained to judge good and bad form across a variety of exercises. If your knees are off center during a squat, for example, the machine will tell you.</li><li>The system also delivers live training sessions. Instructors can see your machine’s data and call you out if your form isn’t up to snuff.</li></ul><p><strong>Behind the news:</strong> Tempo is the first at-home exercise machine that monitors form, but it has plenty of competition in the world of <a href="https://nymag.com/strategist/article/smart-home-gym-equipment-mirror-tonal-peloton-review.html?ref=dl-staging-website.ghost.io" rel=" noopener">Internet-connected exercise equipment</a>. Peloton makes treadmills and exercise bikes with screens that stream live classes, while <a href="https://joinfightcamp.com/experience/?ref=dl-staging-website.ghost.io" rel=" noopener">FightCamp Gym</a> offers a connected punching bag.<br><br><strong>Why it matters:</strong> Exercising well is exercising efficiently. Proper form can help you avoid injuries and get better results from your routine.<br><br><strong>We’re thinking: </strong>We’re weighing the benefits of a system like this against the fact that we’d have no excuse not to go to the gym if it were in the next room.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="Generative AI for Everyone" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="Generative AI for Everyone" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F10%2FGenAI4E_sidebanner.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F10%2FGenAI4E_sidebanner.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F10%2FGenAI4E_sidebanner.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F10%2FGenAI4E_sidebanner.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F10%2FGenAI4E_sidebanner.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F10%2FGenAI4E_sidebanner.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F10%2FGenAI4E_sidebanner.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F10%2FGenAI4E_sidebanner.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F10%2FGenAI4E_sidebanner.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://bit.ly/3Moa97R"><div class="absolute inset-0" data-gtm-event-title="Generative AI for Everyone"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-29/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-29/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-29/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm10" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-29","id":"60c0540f274d5b003b10673b","uuid":"e4668767-7c37-4793-a69d-8b93e54e5839","title":"The Batch: Standing Up for Ethical AI, Efficient Transformers, Up-Rezzing Old Movies, Watching the Factory Floor, Pumping Iron","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eIn addition to creating tremendous value, AI is creating tremendous concentrations of power. Our community is wrestling with what constitutes fair use of that power.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003e\u003ca href=\"https://themarkup.org/allstates-algorithm/2020/02/25/car-insurance-suckers-list?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eThe Markup\u003c/a\u003e published an article criticizing car insurance giant Allstate for price discrimination — charging different fees to different customers — based not only on their risk but also on their predicted willingness to pay. Is this behavior okay?\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eDigital technology enables online comparison shopping, which shifts pricing power toward consumers. But it also enables companies to create unique products for individual customers — say, a ride from point A to point B at a particular time, or a health insurance plan tailored to the customer’s personal history — and AI can help optimize prices to maximize profit for vendors. That can lead to both better products and worse price transparency.\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/Andrews20Letter20220ASPECT201.png\" class=\"kg-image\" alt=\"Economic surplus \" loading=\"lazy\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eIf an online store sells the same hammer to different people for different prices,\u003c/em\u003e \u003cem\u003ecustomers eventually will notice. That helps keep this form of price discrimination in check. But the temptation for sellers is still there. In 2016, Uber revealed that customers \u003ca href=\"https://www.independent.co.uk/life-style/gadgets-and-tech/news/uber-knows-when-your-phone-is-about-to-run-out-of-battery-a7042416.html]?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003epay higher prices when their phone battery is low\u003c/a\u003e. (The company said it didn’t take advantage of this phenomenon.)\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eI wonder sometimes if I should comparison-shop more frequently than I do. Less because I’m anxious to save a few dollars on one purchase, but because I want to train vendors’ AI systems to think I’m sensitive to price and thus to offer me lower prices.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eIn college, my Economics 101 professor taught about supply and demand, and how our economy creates surpluses for both producers and consumers. But AI is prompting us to revisit old economic theories — along with our sense of what’s fair.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eThese are hard questions. I hope we can work on them together to give the world great products and services at even better prices.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003ch2\u003e\u003c/h2\u003e\u003ch2 id=\"deeplearningai-exclusive\"\u003e\u003ca href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eDeepLearning.ai \u003c/a\u003eExclusive\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/TheBatchFeaturedImageBreakingIntoAICherifJazra.png\" class=\"kg-image\" alt loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"breaking-into-ai-a-learning-journey\"\u003eBreaking Into AI: A Learning Journey\u003c/h3\u003e\u003cp\u003eAfter a decade in wireless communications, Cherif was ready for a change. Online courses, textbooks, and meetups helped him build his skills and land a Machine Learning Engineer role at Postmates. Learn how he overcame obstacles, aced job interviews, and started applying ML in the real world in the latest installment of our “Breaking Into AI” series. \u003ca href=\"https://www.deeplearning.ai/blog/breaking-into-ai-advocating-for-machine-learning-in-the-real-world?ref=dl-staging-website.ghost.io\"\u003eRead more\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"news\"\u003e\u003cstrong\u003eNews\u003c/strong\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-optimize208.gif\" class=\"kg-image\" alt=\"Film from 1911 colored\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"history-in-hi-res\"\u003eHistory in Hi Res\u003c/h3\u003e\u003cp\u003eWhile deep learning is taking us into the future, it’s also opening windows into the past.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new: \u003c/strong\u003eMachine learning-savvy \u003ca href=\"https://old.reddit.com/r/Futurology/comments/ezs4cv/youtuber_uses_neural_networks_to_upscale_1896/fgr4yy2/?context=3\u0026ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eRedditor\u003c/a\u003e Denis Shiryaev brought 100-year-old silent film footage of New York City into the 21st century by automatically sharpening the picture, boosting the frame rate, and adding color.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow he did it:\u003c/strong\u003e Shiryaev obtained eight minutes of \u003ca href=\"https://www.moma.org/calendar/exhibitions/3858?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003efootage\u003c/a\u003e shot by \u003ca href=\"https://sv.wikipedia.org/wiki/Svenska_Biografteatern?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ea Swedish film maker\u003c/a\u003e in 1911. He spent five days running the movie through a gauntlet of neural nets.\u003c/p\u003e\u003cul\u003e\u003cli\u003eShiryaev used \u003ca href=\"https://arxiv.org/abs/1809.00219?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eEnhanced Super-Resolution Generative Adversarial Networks\u003c/a\u003e to compute additional pixels, boosting resolution to 4K (approximately 4,000 pixels horizontally).\u003c/li\u003e\u003cli\u003eHe used \u003ca href=\"https://sites.google.com/view/wenbobao/dain?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eDepth-Aware Video Frame Interpolation\u003c/a\u003e to generate in-between frames, raising the frame rate to 60 per second. Film shot in the early 1900s typically had much \u003ca href=\"https://vanillavideo.com/blog/2012/history-frame-rates-why-speeds-vary?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003elower frame rates\u003c/a\u003e, making them look sped-up and jerky.\u003c/li\u003e\u003cli\u003eHe applied \u003ca href=\"https://app.wandb.ai/borisd13/DeOldify/reports/DeOldify--Vmlldzo0NDU3OA?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eDeOldify\u003c/a\u003e to colorize the imagery. He noted on Reddit that he isn’t completely sold on that process, because the colors aren’t historically accurate.\u003c/li\u003e\u003cli\u003eThe sound effects were digital audio clips. Several \u003ca href=\"https://www.reddit.com/r/videos/comments/f8qw32/oc_i_have_made_a_60_fps_4k_version_of_new_york/fines4d/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ecommenters\u003c/a\u003e said they recognized horse whinnies from the video game Age of Empires II.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Shiryaev has used these procedures to update footage of \u003ca href=\"https://www.youtube.com/watch?v=6FN06Hf1iFk\u0026ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eMoscow in 1896\u003c/a\u003e, an iconic film from the same year that shows a \u003ca href=\"https://petapixel.com/2020/02/05/youtuber-used-ai-to-upscale-a-classic-1896-short-film-to-4k-and-60fps/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eFrench train pulling into station\u003c/a\u003e and \u003ca href=\"https://www.youtube.com/watch?v=az9nFrnCK60\u0026ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eApollo 16 astronauts\u003c/a\u003e driving their moon buggy across the lunar surface in 1972.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Shiryaev’s work brings these pieces of the past to life, overcoming the poor image quality, jerky movements, and lack of colors that diminish so much historic film. Similar treatment no doubt would perk up careworn Hollywood classics as well.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e We can’t wait to up-res old home videos. It’s about time our parents’ 1980s hairstyles were revealed in high def.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/Reformer.png\" class=\"kg-image\" alt=\"Simplified depiction of LSH Attention \" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"transformers-transformed\"\u003eTransformers Transformed\u003c/h3\u003e\u003cp\u003eTransformer networks have revolutionized natural language processing, but they hog processor cycles and memory. New research demonstrates a more frugal variation.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya at UC Berkeley and Google modified the transformer architecture to run faster while requiring orders of magnitude less memory during training. They call the new version \u003ca href=\"https://arxiv.org/abs/2001.04451?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eReformer\u003c/a\u003e.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e The transformer architecture is inherently inefficient: It tracks relationships among all input tokens, whether or not they matter to the output, and training requires a lot of memory. A few simple tweaks can rein in these excesses.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The researchers replaced the transformer’s feed-forward network with a \u003ca href=\"https://arxiv.org/abs/1707.04585?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ereversible residual network\u003c/a\u003e. They modified the attention mechanism with \u003ca href=\"https://www.mit.edu/~andoni/LSH/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003elocality-sensitive hashing\u003c/a\u003e.\u003c/p\u003e\u003cul\u003e\u003cli\u003eTypically, a transformer must keep all feed-forward layers in memory during training. In Reformer, each layer of the reversible residual network stores information that enables backpropagation to occur one layer at a time, rather than storing information about the entire network. That way, the network requires only enough memory to store one layer.\u003c/li\u003e\u003cli\u003eA transformer’s attention mechanism encodes relationships between the current token and previous tokens, but usually only a few are important. Locality-sensitive hashing sorts the previous tokens into buckets according to similarity. Then Reformer computes attention relationships only within buckets.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The authors ran experiments on Wikipedia \u003ca href=\"https://cs.fit.edu/~mmahoney/compression/textdata.html?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003etext\u003c/a\u003e parceled into sequences of 64,000 tokens (more than double the number in the original transformer \u003ca href=\"https://arxiv.org/abs/1706.03762?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003epaper\u003c/a\u003e) in 16GB of memory. Reformer achieved almost the same performance as a transformer with an identical number of parameters while consuming less memory. Furthermore, the time required to compute LSH attention scaled more efficiently with increased sequence length.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters: \u003c/strong\u003eResearchers seeking better performance are pumping up transformer-based models to immense sizes — Microsoft’s latest language model has \u003ca href=\"https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003e17 billion parameters\u003c/a\u003e. Running such behemoths can be out of reach for all but the largest corporate research labs. Reformer offers a more efficient alternative.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Reformer’s improvements equip the transformer architecture for reading and generating long sequences — not only text, but also long-form video and audio. This capability could lead to larger-scale benchmarks to propel transformers into new tasks.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-optimize207.gif\" class=\"kg-image\" alt=\"Functioning of system that trackes the productivity of industrial workers\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"eyes-on-the-assembly-line\"\u003eEyes on the Assembly Line\u003c/h3\u003e\u003cp\u003eAI may not steal your job, but it can tell the boss when you’re slacking.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Drishti, a startup based in Palo Alto and Bengaluru, tracks the productivity of industrial workers by recognizing their actions on the assembly line. Automotive parts giant Denso is using the technology to eliminate bottlenecks in its factory in Battle Creek, Michigan, according to \u003cem\u003e\u003ca href=\"https://www.wired.com/story/when-ai-cant-replace-worker-watches-them-instead/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eWired\u003c/a\u003e\u003c/em\u003e.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e Drishti trains the system to recognize standardized actions in the client’s industrial processes.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe training data includes video of many different people from a variety of angles, so the software can classify actions regardless of who is performing them.\u003c/li\u003e\u003cli\u003eCameras watch employees as they assemble auto components. The system tracks how long it takes them to complete their tasks and alerts managers of significant deviations from the norm. Workers see a live display of their performance metrics. It shows them a smiley face if they’re ahead of schedule, a frown if they fall behind.\u003c/li\u003e\u003cli\u003eThe system has helped factories achieve double-digit improvements in several productivity indicators, a Denso executive told \u003cem\u003e\u003ca href=\"https://www.forbes.com/sites/amyfeldman/2020/02/12/manufacturing-automation-startup-drishti-backed-by-andreessen-signs-on-more-than-10-clients-including--auto-parts-giant-denso/?ref=dl-staging-website.ghost.io#3cb34695795f\" rel=\" noopener\"\u003eForbes\u003c/a\u003e\u003c/em\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Drishti’s founders include Prasad Akella, who led General Motors’ efforts to develop \u003ca href=\"https://www.engineering.com/AdvancedManufacturing/ArticleID/13540/A-History-of-Collaborative-Robots-From-Intelligent-Lift-Assists-to-Cobots.aspx?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ecollaborative robots\u003c/a\u003e, and computer vision expert Krishnendu Chadbury, who led teams at Google, Adobe, and Flipkart.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Manufacturing is a \u003ca href=\"https://data.worldbank.org/indicator/NV.IND.MANF.CD?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003e$14 trillion industry\u003c/a\u003e. According to \u003ca href=\"https://drishti.com/wp-content/uploads/2018/11/The-State-of-Human-Factory-Analytics.pdf?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eresearch\u003c/a\u003e sponsored by Drishti, humans perform 72 percent of the work, and human error causes 68 percent of defects. Using AI to help people work more efficiently could yield substantial gains.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eYes, but: \u003c/strong\u003eWorkers in some industries are pushing back against automated management. Last year, dozens of employees \u003ca href=\"https://www.wired.com/story/meet-the-immigrants-who-took-on-amazon/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ewalked out\u003c/a\u003e of Amazon warehouses to protest the pace of work demanded by AI-powered supervisors, which they said led to dangerous conditions.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Complaining about the quality of others’ work while not doing any yourself? Computers are becoming more like humans all the time!\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM \u003ca href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eDEEPLEARNING.AI\u003c/a\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-resize-3.gif\" class=\"kg-image\" alt loading=\"lazy\"\u003e\u003c/figure\u003e\u003cp\u003eWant to deploy a TensorFlow model in your web browser or on your smartphone? The \u003ca href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003edeeplearning.ai\u003c/a\u003e TensorFlow: Data and Deployment Specialization will teach you how. \u003ca href=\"https://www.coursera.org/specializations/tensorflow-data-and-deployment?ref=dl-staging-website.ghost.io\"\u003eEnroll now\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/Redmon.png\" class=\"kg-image\" alt=\"Text \u0026quot;You only live once. #YOLO\u0026quot; written over an orange background\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"code-no-evil\"\u003eCode No Evil\u003c/h3\u003e\u003cp\u003eA prominent AI researcher has turned his back on computer vision over ethical issues.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat happened:\u003c/strong\u003e The co-creator of the popular object-recognition network \u003ca href=\"https://pjreddie.com/darknet/yolo/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eYou Only Look Once\u003c/a\u003e (YOLO) \u003ca href=\"https://twitter.com/pjreddie/status/1230523827446091776?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003esaid\u003c/a\u003e he no longer works on computer vision because the technology has “almost no upside and enormous downside risk.”\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy he quit:\u003c/strong\u003e Joseph Redmon, a graduate student at the University of Washington with a charmingly unorthodox \u003ca href=\"https://pjreddie.com/static/Redmon%20Resume.pdf?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003erésumé\u003c/a\u003e, said on Twitter, “I stopped doing CV research because I saw the impact my work was having.” He didn’t respond to a request for an interview.\u003c/p\u003e\u003cul\u003e\u003cli\u003e“I loved the work but the military applications and privacy concerns eventually became impossible to ignore,” he said.\u003c/li\u003e\u003cli\u003eRedmon disclosed his decision in a discussion sparked by a \u003ca href=\"https://nips.cc/Conferences/2020/CallForPapers?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ecall for papers\u003c/a\u003e from NeurIPS requiring authors to include a statement discussing “ethical aspects and future societal consequences” of their work.\u003c/li\u003e\u003cli\u003eHe previously aired his concerns in a 2018 \u003ca href=\"https://www.youtube.com/watch?v=XS2UWYuh5u0\u0026ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eTEDx talk\u003c/a\u003e. He had been “horrified” to learn that the U.S. Army used his algorithms to help battlefield drones track targets, he said, urging the audience to make sure technology is used for good.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Redmon and his faculty advisor Ali Farhudi devised YOLO in 2016 to classify objects in real time, funded partly by Google and the U.S. Office of Naval Research. The work won a \u003ca href=\"https://news.cs.washington.edu/2018/04/05/allen-schools-joseph-redmon-wins-google-ph-d-fellowship/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ePeople’s Choice Award\u003c/a\u003e at that year’s Computer Vision and Pattern Recognition conference. The last \u003ca href=\"https://arxiv.org/abs/1804.02767?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eupdate\u003c/a\u003e came in April 2018.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Concerns are \u003ca href=\"https://www.nature.com/articles/d41586-020-00160-y?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003emounting\u003c/a\u003e over a number of ethical concerns in machine learning including \u003ca href=\"https://www.mckinsey.com/featured-insights/artificial-intelligence/tackling-bias-in-artificial-intelligence-and-in-humans?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ebiased output\u003c/a\u003e, \u003ca href=\"https://medium.com/@MKGOfficial/the-misuse-of-artificial-intelligence-machine-learning-7381b752dd8f?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003epotential misuse\u003c/a\u003e, and \u003ca href=\"https://www.theatlantic.com/technology/archive/2018/01/black-workers-and-the-driverless-bus/550535/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eadverse social impacts\u003c/a\u003e. The field stands to lose more talented researchers if it doesn’t come to grips with issues like this.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Researchers need to recognize the ethical implications of their work and guide it toward beneficial uses. Many technologies have both civilian and military uses, and opting out may not be as powerful as helping to shape the field from within.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/Radar.gif\" class=\"kg-image\" alt=\"Fragment of a video explaining a model that extracts landmarks on the fly from radar scans \" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"locating-landmarks-on-the-fly\"\u003eLocating Landmarks on the Fly\u003c/h3\u003e\u003cp\u003eDirections such as “turn left at the big tree, go three blocks, and stop at the big red house on your left” can get you to your destination because they refer to stationary landmarks. New research enables self-driving cars to identify such stable indicators on their own.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Dan Barnes and Ingmar Posner of Oxford University built a \u003ca href=\"https://arxiv.org/abs/2001.10789?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003emodel\u003c/a\u003e that extracts landmarks on the fly from radar scans to build maps for autonomous vehicles. Radar is challenging in this application because it generates noise and ghost images, but it has the benefits of long range, high refresh rate, and robustness to environmental conditions. This \u003ca href=\"https://www.youtube.com/watch?v=L-PO7nxWpJU\u0026ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003evideo\u003c/a\u003e explains.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e Self-driving cars often navigate by recognizing landmarks. The researchers realized that neural networks can discover them by reversing the task: The radar signals most valuable to navigation are likely stable features of the landscape.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The system learns to identify keypoints that best predict a car’s motion. The training \u003ca href=\"https://ori.ox.ac.uk/oxford-radar-robotcar-dataset/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003edata\u003c/a\u003e specifies a vehicle’s motion from radar frame to radar frame.\u003c/p\u003e\u003cul\u003e\u003cli\u003eA U-Net architecture transforms each radar frame into potentially useful keypoints. It predicts vectors for each one representing its position, description, and usefulness for navigation.\u003c/li\u003e\u003cli\u003eA separate algorithm compares the position of keypoints with similar descriptions in successive frames. It uses the differences in their positions to predict the car’s motion. The keypoints that are most useful in performing this task are likely to be stable.\u003c/li\u003e\u003cli\u003eUsing the description vector, the system can match keypoints from different perspectives. This enables it to map loops in a route, a challenging problem for earlier methods that process entire radar frames rather than keypoints.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The system’s error in predicting the car’s position after driving a fixed distance was 2.06 percent, compared to the previous state of the art, 3.72 percent. Similarly, the error in the car’s predicted orientation fell from 0.0141 to 0.0067 degrees per meter driven. The new system ran an order of magnitude faster. For routes that didn’t include a loop, an earlier \u003ca href=\"https://arxiv.org/pdf/1909.03752.pdf?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ewhole-frame approach\u003c/a\u003e cut the predicted position error to 1.59 percent and rotation error to 0.0044 degrees per meter.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e The ability to generate keypoints automatically is making waves in other \u003ca href=\"https://arxiv.org/abs/1910.10750?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003ecomputer\u003c/a\u003e \u003ca href=\"https://arxiv.org/abs/1906.11883?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003evision\u003c/a\u003e \u003ca href=\"https://arxiv.org/abs/1910.02027?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003etasks\u003c/a\u003e. Combining keypoints with vector descriptions makes it possible to learn valuable things about them, from whether they indicate a loop in the route to recognizing a habitual parking space.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Our surroundings are always changing: Outdoors, trees fall down and buildings go up, while indoors objects are moved all the time. Algorithms that detect landmarks on the fly will be useful for mapping and navigating such dynamic environments.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/Tempo.gif\" class=\"kg-image\" alt=\"Exercise training system working\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"personal-trainer\"\u003ePersonal TrAIner\u003c/h3\u003e\u003cp\u003eNo more sloppy workouts: AI can correct your form.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e A home exercise system uses neural nets to analyze your motions and tell you when you perform a move properly, reports \u003cem\u003e\u003ca href=\"https://www.theverge.com/2020/2/26/21154185/tempo-smart-home-gym-kinect-computer-vision-ai-form-correction?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eThe Verge\u003c/a\u003e\u003c/em\u003e.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works: \u003c/strong\u003e\u003ca href=\"https://tempo.fit/product?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eTempo\u003c/a\u003e is a six-foot-tall easel with a giant screen on the front and storage for weights on the back. The system’s motion tracking capability is built around Microsoft’s \u003ca href=\"https://azure.microsoft.com/en-us/services/kinect-dk/?ref=dl-staging-website.ghost.io#getting-started\" rel=\" noopener\"\u003eAzure Kinect\u003c/a\u003e. A \u003ca href=\"https://docs.microsoft.com/en-us/azure/kinect-dk/depth-camera?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003edepth-sensing camera\u003c/a\u003e emits infrared light and indirectly measures the time it takes for photons to zip from the camera to your body and back again, creating a continuous 3D image.\u003c/p\u003e\u003cul\u003e\u003cli\u003eAzure Kinect’s development kit comes with AI software that tracks body motion. Tempo didn’t respond to a question about whether it uses this model in its product.\u003c/li\u003e\u003cli\u003eThe model is trained to judge good and bad form across a variety of exercises. If your knees are off center during a squat, for example, the machine will tell you.\u003c/li\u003e\u003cli\u003eThe system also delivers live training sessions. Instructors can see your machine’s data and call you out if your form isn’t up to snuff.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Tempo is the first at-home exercise machine that monitors form, but it has plenty of competition in the world of \u003ca href=\"https://nymag.com/strategist/article/smart-home-gym-equipment-mirror-tonal-peloton-review.html?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eInternet-connected exercise equipment\u003c/a\u003e. Peloton makes treadmills and exercise bikes with screens that stream live classes, while \u003ca href=\"https://joinfightcamp.com/experience/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eFightCamp Gym\u003c/a\u003e offers a connected punching bag.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Exercising well is exercising efficiently. Proper form can help you avoid injuries and get better results from your routine.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking: \u003c/strong\u003eWe’re weighing the benefits of a system like this against the fact that we’d have no excuse not to go to the gym if it were in the next room.\u003c/p\u003e","comment_id":"60c0540f274d5b003b10673b","feature_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter20220ASPECT201.png","featured":false,"visibility":"public","created_at":"2021-06-08T22:39:27.000-07:00","updated_at":"2022-10-07T10:08:58.000-07:00","published_at":"2020-03-04T12:00:00.000-08:00","custom_excerpt":"In addition to creating tremendous value, AI is creating tremendous concentrations of power. Our community is wrestling with what constitutes fair use of that power.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"60c0543b274d5b003b106742","name":"issue-29","slug":"issue-29","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-29/"},{"id":"632463b662c694003d31425f","name":"Mar 04, 2020","slug":"mar-04-2020","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/mar-04-2020/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-29/","excerpt":"In addition to creating tremendous value, AI is creating tremendous concentrations of power. Our community is wrestling with what constitutes fair use of that power.","reading_time":10,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Standing Up for Ethical AI, Efficient Transformers, Up-Rezzing","meta_description":"The Batch - AI News \u0026 Insights: A prominent AI researcher has turned his back on computer vision over ethical issues | Reformer - New transformers version","email_subject":null,"frontmatter":null,"feature_image_alt":"Economic surplus ","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter20220ASPECT201.png","dimensions":{"width":576,"height":324}},"banner":{"title":"Generative AI for Everyone","databaseId":32549,"id":"cG9zdDozMjU0OQ==","featuredImage":{"node":{"altText":"Generative AI for Everyone","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/10/GenAI4E_sidebanner.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3Moa97R","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-29"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>