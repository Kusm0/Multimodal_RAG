<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>DALL·E for Video, AI Startup Funding Falls, What the Dark Side of the Moon Looks Like and more</title><meta name="description" content="The Batch - AI News &amp; Insights. When I wrote recently about how to build a career in AI, several readers wrote to ask specifically about AI..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-165/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="DALL·E for Video, AI Startup Funding Falls, What the Dark Side of the Moon Looks Like and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights. When I wrote recently about how to build a career in AI, several readers wrote to ask specifically about AI..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="DALL·E for Video, AI Startup Funding Falls, What the Dark Side of the Moon Looks Like and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-165/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2022-10-05T12:47:53.000-07:00"/><meta property="article:modified_time" content="2023-02-06T13:11:42.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-165"/><meta property="article:tag" content="Oct 05, 2022"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="DALL·E for Video, AI Startup Funding Falls, What the Dark Side of the Moon Looks Like and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights. When I wrote recently about how to build a career in AI, several readers wrote to ask specifically about AI..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-165/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="676"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2022-10-05T12:47:53.000-07:00","dateModified":"2023-02-06T13:11:42.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"DALL·E for Video, AI Startup Funding Falls, What the Dark Side of the Moon Looks Like and more","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM.png","width":1200,"height":676},"publisher":{"@type":"Organization","name":"DALL·E for Video, AI Startup Funding Falls, What the Dark Side of the Moon Looks Like and more","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights. When I wrote recently about how to build a career in AI, several readers wrote to ask specifically about AI..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-165/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 165</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Oct 5, 2022</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">11<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/oct-05-2022/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Oct 05, 2022</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">11<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-165/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-165/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-165/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends, </em></p><p><em>When I wrote recently about <a href="https://www.deeplearning.ai/the-batch/how-to-build-a-career-in-ai-part-1-three-steps-to-career-growth/?ref=dl-staging-website.ghost.io">how to build a career in AI</a>, several readers wrote to ask specifically about AI product management: the art and science of designing compelling AI products. I’ll share lessons I’ve learned about this here and in future letters.</em><br><br><em>A key concept in building AI products is iteration. As I’ve explained in <a href="https://www.deeplearning.ai/the-batch/iteration-in-ai-development/?ref=dl-staging-website.ghost.io">past</a> <a href="https://www.deeplearning.ai/the-batch/data-centric-ai-development-part-3-limit-data-collection-time/?ref=dl-staging-website.ghost.io">letters</a>, developing a machine learning system is a highly iterative process. First you build something, then run experiments to see how it performs, then analyze the results, which enables you to build a better version based on what you’ve learned. You may go through this loop several times in various phases of development — collecting data, training a model, deploying the system — before you have a finished product.</em><br><br><em>Why is development of machine learning systems so iterative? Because (i) when starting on a project, you almost never know what strange and wonderful things you’ll find in the data, and discoveries along the way will help you to make better decisions on how to improve the model; and (ii) it’s relatively quick and inexpensive to try out different models.</em></p><p><em>Not all projects are iterative. For example, if you’re preparing a medical drug for approval by the U.S. government — an expensive process that can cost tens of millions of dollars and take years — you’d usually want to get the drug formulation and experimental design right the first time, since repeating the process to correct a mistake would be costly in time and money. Or if you’re building a space telescope (such as the wonderful <a href="https://webbtelescope.org/news/first-images/gallery?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">Webb Space Telescope</a>) that’s intended to operate far from Earth with little hope of repair if something goes wrong, you’d think through every detail carefully before you hit the launch button on your rocket.</em></p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM-1.png" class="kg-image" alt="Iteration process chart" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM-1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM-1.png 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><em>Iterating on projects tends to be beneficial when (i) you face uncertainty or risk, and building or launching something can provide valuable feedback that helps you reduce the uncertainty or risk, and (ii) the cost of each attempt is modest.</em></p><p><em>This is why </em><a href="https://www.amazon.com/Lean-Startup-Entrepreneurs-Continuous-Innovation/dp/0307887898?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">The Lean Startup</a><em>, a book that has significantly influenced my thinking, advocates building a minimum viable product (MVP) and launching it quickly. Developing software products often involves uncertainty about how users will react, which creates risk for the success of the product. Making a quick-and-dirty, low-cost implementation helps you to get valuable user feedback before you’ve invested too much in building features that users don’t want. An MVP lets you resolve questions about what users want quickly and inexpensively, so you can make decisions and investments with greater confidence.</em></p><p><em>When building AI products, I often see two major sources of uncertainty, which in turn creates risk:</em></p><ul><li><em><strong>Users.</strong> The considerations here are similar to those that apply to building software products. Will they like it? Are the features you’re prioritizing the ones they’ll find most valuable? Is the user interface confusing?</em></li><li><em><strong>Data.</strong> Does your dataset have enough examples of each class? Which classes are hardest to detect? What is <a href="https://www.youtube.com/watch?v=NUmbgp1h64E&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">human-level performance</a> on the task, and what level of AI performance is reasonable to expect?</em></li></ul><p><em>A quick MVP or proof of concept, built at low cost, helps to reduce uncertainty about users and/or data. This enables you to uncover and address hidden issues that may hinder your success.</em></p><p><em>Many product managers are used to thinking through user uncertainty and using iteration to manage risk in that dimension. AI product managers should also consider the data uncertainty and decide on the appropriate pace and nature of iteration to enable the development team to learn the needed lessons about the data and, given the data, what level of AI functionality and performance is possible.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h2 id="news">News</h2><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/VIDEO.gif" class="kg-image" alt="Panda on a swing" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2022/10/VIDEO.gif 600w"></figure><h1 id="text-to-video-without-text-video-data">Text to Video Without Text-Video Data</h1><p>Text-to-image generators like DALL·E 2, Midjourney, and Stable Diffusion are <a href="https://www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">winning art contests</a> and <a href="https://www.forbes.com/sites/robsalkowitz/2022/09/16/ai-is-coming-for-commercial-art-jobs-can-it-be-stopped/?sh=5957d5b254b0&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">worrying artists</a>. A new approach brings the magic of text-to-image generation to video.</p><p><strong>What's new:</strong> <a href="https://arxiv.org/pdf/2209.14792.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">Make-A-Video</a>, a system built by Uriel Singer and colleagues at Meta, turns text prompts into high-resolution videos without training on text-video pairs. You can see its output <a href="https://make-a-video.github.io/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">here</a>.</p><p><strong>Key insight:</strong> While billions of text-image pairs are available to train a <a href="https://www.deeplearning.ai/the-batch/more-realistic-pictures-from-text/?ref=dl-staging-website.ghost.io">text-to-image generator</a>, text-video pairs are too scarce to train a video equivalent. A model can learn relationships between words and pictures via pretraining on text-image pairs. Then it can be adapted for video by adding further layers that process image patches across frames and — while keeping the pretrained layers fixed — fine-tuning the new layers on videos, which are plentiful. In this way, a system can generate videos using knowledge it learned from text-image pairs.</p><p><strong>How it works:</strong> The authors pretrained a series of models (one transformer and four <a href="https://arxiv.org/abs/1505.04597?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">U-Net</a> diffusion models) to generate images from text, generate in-between video frames, and boost image resolution. To pretrain the text-to-image models, they used <a href="https://openreview.net/pdf?id=M3Y74vmsMcY&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">2.3 billion text-image pairs</a>. After pretraining, they modified some of the models to process sequences of video frames: On top of each pretrained convolutional layer, the authors stacked a 1D convolutional layer that processed a grid of pixels in each frame; and on top of each pretrained attention layer, they stacked a 1D attention layer that, likewise, processed a grid of pixels in each frame. To fine-tune or train the modified models on video, they used 20 million <a href="https://arxiv.org/abs/2104.00650?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">internet</a> <a href="https://arxiv.org/abs/2111.10337?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">videos</a>.</p><ul><li>Given a piece of text, the pretrained transformer converted it into an embedding.</li><li>The authors pretrained a diffusion model to take the embeddings and generate a 64x64 image. Then they modified the model as described above and fine-tuned it to generate sequences of 16 frames of 64x64 resolution.</li><li>They added a second diffusion model. Given a 76-frame video made up of 16 frames, each followed by four masked (blacked-out) frames, it learned to regenerate the masked frames.</li><li>They added a third diffusion model and pretrained it, given a 64x64 image, to increase the image’s resolution to 256x256. After modifying the model, they fine-tuned it to increase the resolution 76 successive frames to 256x256.</li><li>Given a 256x256 image, a fourth diffusion model learned to increase its resolution to 768x768. Due to memory restrictions, this model was not modified for video or further trained on videos. At inference, given the 76-frame video, it increased the resolution of each frame without reference to other frames.</li></ul><p><strong>Results:</strong> The authors compared their system’s output to that of the previous state of the art, <a href="https://arxiv.org/abs/2205.15868?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">CogVideo</a>, which takes a similar approach but requires training on text-video pairs. Crowdworkers supplied 300 prompts and judged the output of the author’s system to be of higher quality 77.15 percent of the time and to better fit the text 71.19 percent of the time.</p><p><strong>Why it matters:</strong> Text-to-image generators already transform text into high-quality images, so there’s no need to train a video generator to do the same thing. The authors’ approach enabled their system to learn about things in the world from text-image pairs, and then to learn how those things move from unlabeled videos.</p><p><strong>We're thinking:</strong> The Ng family’s penchant for <a href="https://www.deeplearning.ai/the-batch/text-to-image-generation-and-the-path-to-truly-open-ai/?ref=dl-staging-website.ghost.io">drawing pandas</a> is about to undergo another revolution!</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/ezgif.com-gif-maker--5--3.gif" class="kg-image" alt="Charts from the Artificial Intelligence &amp; Machine Learning Report" loading="lazy" width="1200" height="674" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/ezgif.com-gif-maker--5--3.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/ezgif.com-gif-maker--5--3.gif 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/ezgif.com-gif-maker--5--3.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="tough-economy-hits-ai-startups">Tough Economy Hits AI Startups</h1><p>Venture investors are tapping the brakes on AI amid rising economic uncertainty.</p><p><strong>What’s new:</strong> In their latest <em>Artificial Intelligence &amp; Machine Learning Report</em>, market research firm PitchBook <a href="https://pitchbook.com/news/reports/q2-2022-artificial-intelligence-machine-learning-report?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">documents</a> a sharp reduction in investment in AI startups in the first half of 2022, a time of rising inflation and interest rates. <br><br><strong>What it says: </strong>The report delivers bad news and highlights categories that have continued to hold venture investors’ interest — and those that haven’t.</p><ul><li>Funding for AI startups during the first two quarters of 2022 dropped 20.9 percent from the same period last year. It fell 27.8 percent from the first quarter — faster than information technology as a whole, which fell 21.6 percent. On the bright side, funding for the year ($48.2 billion in the first half) is on pace to beat the total for 2020 ($65.3 billion).</li><li>Exits in the first half of the year totaled $27 billion. 2021 saw $144.2 billion in the same period and $200 billion for the full year.</li><li>Over half of venture investment in AI in the second quarter — $11 billion out of the $20.2 billion total — went to applications such as drug discovery, security, and sales and marketing.</li><li>Startups that specialize in cloud-based AI were hit hardest. That category’s funding is on pace to tumble 87.7 percent in 2022 relative to 2021.</li></ul><p><strong>Future forecasts:</strong> Despite the grim numbers, the authors reject characterizing the current period as an <a href="https://www.deeplearning.ai/the-batch/ai-winter-sets-in/?ref=dl-staging-website.ghost.io">AI winter</a>. They expect investments to rebound from around $175 billion in 2022 to over $350 billion in 2025, driven primarily by advances in multimodal AI, general-purpose models, and synthetic data.</p><p><strong>Behind the news:</strong> In a separate analysis, CB Insights <a href="https://www.cbinsights.com/research/report/ai-trends-q2-2022/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">determined</a> that AI funding would fall by 21 percent each quarter in 2022. Similarly, it found that the losses were not uniform: AI startups in healthcare, financial technology, and retail — areas that have a solid track record — have maintained their funding levels better than other, more speculative fields.</p><p><strong>Why it matters:</strong> When credit is harder to obtain, investors tend to <a href="https://www.deeplearning.ai/the-batch/what-rising-interest-rates-mean-for-ai-part-2-why-it-still-makes-sense-to-forge-ahead/?ref=dl-staging-website.ghost.io">back away</a>​​ from riskier investments. Given rising interest rates, inflation, and the threat of recession, that explains the falloff in funding for startups without proven market value. Companies that focus on proven applications and markets should continue to prosper, although competition is bound to stiffen as vendors are pressed to demonstrate that their offering is superior.<br><br><strong>We’re thinking:</strong> As we noted in <a href="https://www.deeplearning.ai/the-batch/what-rising-interest-rates-mean-for-ai-part-1-whats-likely-to-happen/?ref=dl-staging-website.ghost.io">previous</a> <a href="https://www.deeplearning.ai/the-batch/what-rising-interest-rates-mean-for-ai-part-2-why-it-still-makes-sense-to-forge-ahead/?ref=dl-staging-website.ghost.io">issues</a> of <em>The Batch</em>, rising interest rates and falling stock indices signal that AI developers should be ready for increased pressure to develop projects that demonstrate near-term, tangible value. We continue to believe this is a good time to invest in long-term bets on AI, as the real interest rate (adjusted for inflation) remains very low and the transformative value of AI is more financially powerful than interest rates.</p><hr><h2 id="a-message-from-our-partner">A MESSAGE FROM <strong>OUR PARTNER</strong></h2><figure class="kg-card kg-image-card"><a href="https://fourthbrain.ai/?utm_campaign=2%20year%20birthday%20celebration&utm_source=The-Batch-10522&utm_medium=The-Batch-10522&utm_term=The-Batch-10522&utm_content=The-Batch-10522&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/FourthBrain-banner-ad--1-.png" class="kg-image" alt="FourthBrain 2 year anniversary banner" loading="lazy" width="595" height="337"></a></figure><p>Join FourthBrain’s Machine Learning Engineer program for access to live, instructor-led classes and dedicated career services. Our graduates have seen an average salary increase of $27,000! Applications are due by October 10, 2022. The next cohort starts on October 18. <a href="https://fourthbrain.ai/?utm_campaign=2%20year%20birthday%20celebration&utm_source=The-Batch-10522&utm_medium=The-Batch-10522&utm_term=The-Batch-10522&utm_content=The-Batch-10522&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener noreferrer">Learn more</a></p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/MOON_600px.webp" class="kg-image" alt="Photographs of the Moon" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2022/10/MOON_600px.webp 600w"></figure><h1 id="the-dark-side-of-the-moon-%E2%80%94-lit-up">The Dark Side of the Moon — Lit Up!</h1><p>Neural networks are making it possible to view parts of the Moon that are perpetually shrouded by darkness.</p><p><strong>What’s new:</strong> Valentin Bickel at ETH Zürich and colleagues devised a method called <a href="https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL099530?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">Hyper-effective Noise Removal U-net Software</a> (HORUS) to remove noise from images of the Moon’s south pole, where direct sunlight never falls. The National Aeronautics and Space Administration (NASA) is using the denoised images to plan lunar missions that will put humans on the Moon for the first time in decades.</p><p><strong>The challenge:</strong> The only light that strikes the lunar south pole’s craters, boulders, mounds, and crevasses comes from scant photons that reflect off Earth or nearby lunar landforms or arrive from faraway stars. An imaging system aboard NASA’s Lunar Reconnaissance Orbiter can capture features that are lit this way, but it has a tendency to <a href="https://en.wikipedia.org/wiki/Dark_current_(physics)?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">detect photons where none exist</a>. Transmitting and processing the images introduces more noise, further blurring details in the already-dim images. Removing noise optimizes the available light, making it possible to see the landscape.</p><p><strong>How it works:</strong> The authors <a href="https://www.nature.com/articles/s41467-021-25882-z?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">trained</a> two neural networks to remove the noise from lunar images.</p><ul><li>Using 70,000 calibration images collected during the Lunar Reconnaissance Orbiter’s mission, a convolutional neural network (CNN) called DeStripeNet learned to generate an array of pixels that simulates camera-produced noise for a given image when fed metadata associated with that image, such as the temperature of the camera and various other pieces of hardware. Then it removed this noise by overlaying the generated pixels on the original image and subtracting their values.</li><li>A <a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">U-Net</a> CNN called PhotonNet was trained on modified image pairs of sunlit lunar regions. The images were artificially darkened, and one in each pair was further modified by adding noise generated by a mathematical model. This noise represented errors arising from sources such as data compression applied when transmitting images to Earth. PhotonNet learned to simulate these errors and subtracted them from the output of DeStripeNet, producing a cleaner image.</li></ul><p><strong>Results:</strong> HORUS removed noise from 200,000 images of the lunar surface. The authors identified possible landing sites, hazards to avoid, and evidence that some areas may contain water ice beneath the surface.</p><p><strong>Behind the news:</strong> The Moon’s south pole is the target for NASA’s upcoming Artemis program. Artemis 1, scheduled to launch in late September, will be fully automated. Artemis 2, scheduled for 2024, aims to land humans on the Moon for the first time since NASA’s final Apollo mission in 1972.</p><p><strong>Why it matters:</strong> NASA chose the Moon’s south pole as the target for future missions because water may be frozen at the bottoms of craters there. Water on the Moon could provide clues about the heavenly body’s origin as well as hydration, radiation shielding, and propellant for missions further out in the solar system.</p><p><strong>We’re thinking:</strong> This AI project is out of this world!</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/DIALOG.gif" class="kg-image" alt="Illustration of the Dialogue Transformer Language Model (DLM)" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2022/10/DIALOG.gif 600w"></figure><h1 id="the-sound-of-conversation">The Sound of Conversation</h1><p>In spoken conversation, people naturally take turns amid interjections, overlaps, and other patterns that aren’t strictly verbal. A new approach generated natural-sounding — though not necessarily semantically coherent — audio dialogs without training on text transcriptions that mark when one party should stop speaking and the other should chime in.</p><p><strong>What's new:</strong> Tu Anh Nguyen and colleagues at Meta, France’s National Institute for Research in Digital Science and Technology, and École des Hautes Études en Sciences Sociales introduced <a href="https://arxiv.org/abs/2203.16502?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">Dialogue Transformer Language Model</a> (DLM), a system that learned to incorporate the interruptions, pauses, and inflections of conversational speech into audio dialogues. You can listen to examples <a href="https://speechbot.github.io/dgslm/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">here</a>.</p><p><strong>Key insight:</strong> Prior efforts to model dialogue were based on text, but text datasets omit information that’s unique to spoken interactions. Training directly on recordings of spoken dialogue can enable models to learn this additional mode of expression so they can mimic face-to-face conversation more naturally.</p><p><strong>How it works:</strong> The system encoded two audio signals — two sides of a spoken conversation — into tokens. It processed each token stream through a separate transformer and decoded the tokens back to audio signals. The transformers were trained on <a href="https://doi.org/10.35111/w4bk-9b14?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">Fisher English Training Speech</a>, a dataset that comprises over 10,000 telephone conversations, an average of 10 minutes long, recorded using a separate audio channel for each participant.</p><ul><li><a href="https://arxiv.org/abs/2106.07447?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">HuBERT</a>, a self-supervised system that produces speech representations, tokenized the audio signals using a convolutional neural network (CNN) and transformer, which reduced 16,000 samples per second to 50. To adapt it to the Fisher dataset, the authors trained it to generate masked tokens.</li><li>Given tokens from HuBERT, <a href="https://arxiv.org/abs/2010.05646?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5" rel="noopener">HiFi-GAN</a>, a generative adversarial network with CNN architecture, learned to generate the audio waveform of one speaker.</li><li>Given the token streams, two transformers with shared weights learned to predict new tokens. The authors modified the transformers by adding, between the usual self-attention and fully connected layers, a cross-attention layer that attended to tokens from both signals. Estimating each token’s duration meant the authors could remove repetitions of the same token from the training data to avoid generating overly elongated sounds (such as a “hmm” that never ends).</li><li>At inference, the transformers repeatedly added the next predicted tokens to two sequences, each of which started with a preset starting token. HiFi-GAN converted the sequence into audio.</li></ul><p><strong>Results:</strong> Crowdsourced evaluators compared DLM to a similar approach that used a single transformer to process both channels of conversation. They rated naturalness of turn-taking and meaningfulness on a 1 to 5 scale. (Ground-truth dialogs scored around 4.25 for both criteria.) DLM performed relatively well in turn-taking though poorly in meaningful output. For turn-taking, DLM achieved 3.86 while the single transformer achieved 3.46. For meaningfulness, DLM achieved 2.71, while the single transformer achieved 2.46.</p><p><strong>Why it matters:</strong> Two transformers can model a pair of participants in conversation (or other interaction) more effectively than one. Connecting them via cross attention layers enables them to be aware of one another’s activity without needing to predict it. This simplifies the task of modeling their interactions while avoiding potentially confounding variables such as who said what.</p><p><strong>We're thinking:</strong> The system’s ability to mimic the ebb and flow of conversation is impressive, but its verbal output is largely gibberish. To be fair, training on only 1,700 hours of audio conversation may not be expected to impart much about semantics. We look forward to an update that produces more cogent spoken conversation.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook." data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook." data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/resources/#ebooks"><div class="absolute inset-0" data-gtm-event-title="AI is the new electricity"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-165/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-165/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-165/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm4" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-165","id":"633dd705bd09e0003d62fc0d","uuid":"cb3d64d5-667c-4e4a-8a7b-264502c2b58b","title":"The Batch: DALL·E for Video, AI Startup Funding Falls, What the Dark Side of the Moon Looks Like, Modeling Spoken Conversation","html":"\u003cp\u003e\u003cem\u003eDear friends, \u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWhen I wrote recently about \u003ca href=\"https://www.deeplearning.ai/the-batch/how-to-build-a-career-in-ai-part-1-three-steps-to-career-growth/?ref=dl-staging-website.ghost.io\"\u003ehow to build a career in AI\u003c/a\u003e, several readers wrote to ask specifically about AI product management: the art and science of designing compelling AI products. I’ll share lessons I’ve learned about this here and in future letters.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eA key concept in building AI products is iteration. As I’ve explained in \u003ca href=\"https://www.deeplearning.ai/the-batch/iteration-in-ai-development/?ref=dl-staging-website.ghost.io\"\u003epast\u003c/a\u003e \u003ca href=\"https://www.deeplearning.ai/the-batch/data-centric-ai-development-part-3-limit-data-collection-time/?ref=dl-staging-website.ghost.io\"\u003eletters\u003c/a\u003e, developing a machine learning system is a highly iterative process. First you build something, then run experiments to see how it performs, then analyze the results, which enables you to build a better version based on what you’ve learned. You may go through this loop several times in various phases of development — collecting data, training a model, deploying the system — before you have a finished product.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eWhy is development of machine learning systems so iterative? Because (i) when starting on a project, you almost never know what strange and wonderful things you’ll find in the data, and discoveries along the way will help you to make better decisions on how to improve the model; and (ii) it’s relatively quick and inexpensive to try out different models.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eNot all projects are iterative. For example, if you’re preparing a medical drug for approval by the U.S. government — an expensive process that can cost tens of millions of dollars and take years — you’d usually want to get the drug formulation and experimental design right the first time, since repeating the process to correct a mistake would be costly in time and money. Or if you’re building a space telescope (such as the wonderful \u003ca href=\"https://webbtelescope.org/news/first-images/gallery?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eWebb Space Telescope\u003c/a\u003e) that’s intended to operate far from Earth with little hope of repair if something goes wrong, you’d think through every detail carefully before you hit the launch button on your rocket.\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM-1.png\" class=\"kg-image\" alt=\"Iteration process chart\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM-1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM-1.png 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM-1.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eIterating on projects tends to be beneficial when (i) you face uncertainty or risk, and building or launching something can provide valuable feedback that helps you reduce the uncertainty or risk, and (ii) the cost of each attempt is modest.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eThis is why \u003c/em\u003e\u003ca href=\"https://www.amazon.com/Lean-Startup-Entrepreneurs-Continuous-Innovation/dp/0307887898?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eThe Lean Startup\u003c/a\u003e\u003cem\u003e, a book that has significantly influenced my thinking, advocates building a minimum viable product (MVP) and launching it quickly. Developing software products often involves uncertainty about how users will react, which creates risk for the success of the product. Making a quick-and-dirty, low-cost implementation helps you to get valuable user feedback before you’ve invested too much in building features that users don’t want. An MVP lets you resolve questions about what users want quickly and inexpensively, so you can make decisions and investments with greater confidence.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWhen building AI products, I often see two major sources of uncertainty, which in turn creates risk:\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003eUsers.\u003c/strong\u003e The considerations here are similar to those that apply to building software products. Will they like it? Are the features you’re prioritizing the ones they’ll find most valuable? Is the user interface confusing?\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003eData.\u003c/strong\u003e Does your dataset have enough examples of each class? Which classes are hardest to detect? What is \u003ca href=\"https://www.youtube.com/watch?v=NUmbgp1h64E\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003ehuman-level performance\u003c/a\u003e on the task, and what level of AI performance is reasonable to expect?\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cem\u003eA quick MVP or proof of concept, built at low cost, helps to reduce uncertainty about users and/or data. This enables you to uncover and address hidden issues that may hinder your success.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eMany product managers are used to thinking through user uncertainty and using iteration to manage risk in that dimension. AI product managers should also consider the data uncertainty and decide on the appropriate pace and nature of iteration to enable the development team to learn the needed lessons about the data and, given the data, what level of AI functionality and performance is possible.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"news\"\u003eNews\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/VIDEO.gif\" class=\"kg-image\" alt=\"Panda on a swing\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2022/10/VIDEO.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"text-to-video-without-text-video-data\"\u003eText to Video Without Text-Video Data\u003c/h1\u003e\u003cp\u003eText-to-image generators like DALL·E 2, Midjourney, and Stable Diffusion are \u003ca href=\"https://www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003ewinning art contests\u003c/a\u003e and \u003ca href=\"https://www.forbes.com/sites/robsalkowitz/2022/09/16/ai-is-coming-for-commercial-art-jobs-can-it-be-stopped/?sh=5957d5b254b0\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eworrying artists\u003c/a\u003e. A new approach brings the magic of text-to-image generation to video.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat's new:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/pdf/2209.14792.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eMake-A-Video\u003c/a\u003e, a system built by Uriel Singer and colleagues at Meta, turns text prompts into high-resolution videos without training on text-video pairs. You can see its output \u003ca href=\"https://make-a-video.github.io/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e While billions of text-image pairs are available to train a \u003ca href=\"https://www.deeplearning.ai/the-batch/more-realistic-pictures-from-text/?ref=dl-staging-website.ghost.io\"\u003etext-to-image generator\u003c/a\u003e, text-video pairs are too scarce to train a video equivalent. A model can learn relationships between words and pictures via pretraining on text-image pairs. Then it can be adapted for video by adding further layers that process image patches across frames and — while keeping the pretrained layers fixed — fine-tuning the new layers on videos, which are plentiful. In this way, a system can generate videos using knowledge it learned from text-image pairs.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The authors pretrained a series of models (one transformer and four \u003ca href=\"https://arxiv.org/abs/1505.04597?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eU-Net\u003c/a\u003e diffusion models) to generate images from text, generate in-between video frames, and boost image resolution. To pretrain the text-to-image models, they used \u003ca href=\"https://openreview.net/pdf?id=M3Y74vmsMcY\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003e2.3 billion text-image pairs\u003c/a\u003e. After pretraining, they modified some of the models to process sequences of video frames: On top of each pretrained convolutional layer, the authors stacked a 1D convolutional layer that processed a grid of pixels in each frame; and on top of each pretrained attention layer, they stacked a 1D attention layer that, likewise, processed a grid of pixels in each frame. To fine-tune or train the modified models on video, they used 20 million \u003ca href=\"https://arxiv.org/abs/2104.00650?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003einternet\u003c/a\u003e \u003ca href=\"https://arxiv.org/abs/2111.10337?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003evideos\u003c/a\u003e.\u003c/p\u003e\u003cul\u003e\u003cli\u003eGiven a piece of text, the pretrained transformer converted it into an embedding.\u003c/li\u003e\u003cli\u003eThe authors pretrained a diffusion model to take the embeddings and generate a 64x64 image. Then they modified the model as described above and fine-tuned it to generate sequences of 16 frames of 64x64 resolution.\u003c/li\u003e\u003cli\u003eThey added a second diffusion model. Given a 76-frame video made up of 16 frames, each followed by four masked (blacked-out) frames, it learned to regenerate the masked frames.\u003c/li\u003e\u003cli\u003eThey added a third diffusion model and pretrained it, given a 64x64 image, to increase the image’s resolution to 256x256. After modifying the model, they fine-tuned it to increase the resolution 76 successive frames to 256x256.\u003c/li\u003e\u003cli\u003eGiven a 256x256 image, a fourth diffusion model learned to increase its resolution to 768x768. Due to memory restrictions, this model was not modified for video or further trained on videos. At inference, given the 76-frame video, it increased the resolution of each frame without reference to other frames.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The authors compared their system’s output to that of the previous state of the art, \u003ca href=\"https://arxiv.org/abs/2205.15868?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eCogVideo\u003c/a\u003e, which takes a similar approach but requires training on text-video pairs. Crowdworkers supplied 300 prompts and judged the output of the author’s system to be of higher quality 77.15 percent of the time and to better fit the text 71.19 percent of the time.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Text-to-image generators already transform text into high-quality images, so there’s no need to train a video generator to do the same thing. The authors’ approach enabled their system to learn about things in the world from text-image pairs, and then to learn how those things move from unlabeled videos.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe're thinking:\u003c/strong\u003e The Ng family’s penchant for \u003ca href=\"https://www.deeplearning.ai/the-batch/text-to-image-generation-and-the-path-to-truly-open-ai/?ref=dl-staging-website.ghost.io\"\u003edrawing pandas\u003c/a\u003e is about to undergo another revolution!\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/ezgif.com-gif-maker--5--3.gif\" class=\"kg-image\" alt=\"Charts from the Artificial Intelligence \u0026amp; Machine Learning Report\" loading=\"lazy\" width=\"1200\" height=\"674\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/ezgif.com-gif-maker--5--3.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/ezgif.com-gif-maker--5--3.gif 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/ezgif.com-gif-maker--5--3.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"tough-economy-hits-ai-startups\"\u003eTough Economy Hits AI Startups\u003c/h1\u003e\u003cp\u003eVenture investors are tapping the brakes on AI amid rising economic uncertainty.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e In their latest \u003cem\u003eArtificial Intelligence \u0026amp; Machine Learning Report\u003c/em\u003e, market research firm PitchBook \u003ca href=\"https://pitchbook.com/news/reports/q2-2022-artificial-intelligence-machine-learning-report?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003edocuments\u003c/a\u003e a sharp reduction in investment in AI startups in the first half of 2022, a time of rising inflation and interest rates. \u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat it says: \u003c/strong\u003eThe report delivers bad news and highlights categories that have continued to hold venture investors’ interest — and those that haven’t.\u003c/p\u003e\u003cul\u003e\u003cli\u003eFunding for AI startups during the first two quarters of 2022 dropped 20.9 percent from the same period last year. It fell 27.8 percent from the first quarter — faster than information technology as a whole, which fell 21.6 percent. On the bright side, funding for the year ($48.2 billion in the first half) is on pace to beat the total for 2020 ($65.3 billion).\u003c/li\u003e\u003cli\u003eExits in the first half of the year totaled $27 billion. 2021 saw $144.2 billion in the same period and $200 billion for the full year.\u003c/li\u003e\u003cli\u003eOver half of venture investment in AI in the second quarter — $11 billion out of the $20.2 billion total — went to applications such as drug discovery, security, and sales and marketing.\u003c/li\u003e\u003cli\u003eStartups that specialize in cloud-based AI were hit hardest. That category’s funding is on pace to tumble 87.7 percent in 2022 relative to 2021.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eFuture forecasts:\u003c/strong\u003e Despite the grim numbers, the authors reject characterizing the current period as an \u003ca href=\"https://www.deeplearning.ai/the-batch/ai-winter-sets-in/?ref=dl-staging-website.ghost.io\"\u003eAI winter\u003c/a\u003e. They expect investments to rebound from around $175 billion in 2022 to over $350 billion in 2025, driven primarily by advances in multimodal AI, general-purpose models, and synthetic data.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e In a separate analysis, CB Insights \u003ca href=\"https://www.cbinsights.com/research/report/ai-trends-q2-2022/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003edetermined\u003c/a\u003e that AI funding would fall by 21 percent each quarter in 2022. Similarly, it found that the losses were not uniform: AI startups in healthcare, financial technology, and retail — areas that have a solid track record — have maintained their funding levels better than other, more speculative fields.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e When credit is harder to obtain, investors tend to \u003ca href=\"https://www.deeplearning.ai/the-batch/what-rising-interest-rates-mean-for-ai-part-2-why-it-still-makes-sense-to-forge-ahead/?ref=dl-staging-website.ghost.io\"\u003eback away\u003c/a\u003e​​ from riskier investments. Given rising interest rates, inflation, and the threat of recession, that explains the falloff in funding for startups without proven market value. Companies that focus on proven applications and markets should continue to prosper, although competition is bound to stiffen as vendors are pressed to demonstrate that their offering is superior.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e As we noted in \u003ca href=\"https://www.deeplearning.ai/the-batch/what-rising-interest-rates-mean-for-ai-part-1-whats-likely-to-happen/?ref=dl-staging-website.ghost.io\"\u003eprevious\u003c/a\u003e \u003ca href=\"https://www.deeplearning.ai/the-batch/what-rising-interest-rates-mean-for-ai-part-2-why-it-still-makes-sense-to-forge-ahead/?ref=dl-staging-website.ghost.io\"\u003eissues\u003c/a\u003e of \u003cem\u003eThe Batch\u003c/em\u003e, rising interest rates and falling stock indices signal that AI developers should be ready for increased pressure to develop projects that demonstrate near-term, tangible value. We continue to believe this is a good time to invest in long-term bets on AI, as the real interest rate (adjusted for inflation) remains very low and the transformative value of AI is more financially powerful than interest rates.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-our-partner\"\u003eA MESSAGE FROM \u003cstrong\u003eOUR PARTNER\u003c/strong\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://fourthbrain.ai/?utm_campaign=2%20year%20birthday%20celebration\u0026utm_source=The-Batch-10522\u0026utm_medium=The-Batch-10522\u0026utm_term=The-Batch-10522\u0026utm_content=The-Batch-10522\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/FourthBrain-banner-ad--1-.png\" class=\"kg-image\" alt=\"FourthBrain 2 year anniversary banner\" loading=\"lazy\" width=\"595\" height=\"337\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eJoin FourthBrain’s Machine Learning Engineer program for access to live, instructor-led classes and dedicated career services. Our graduates have seen an average salary increase of $27,000! Applications are due by October 10, 2022. The next cohort starts on October 18. \u003ca href=\"https://fourthbrain.ai/?utm_campaign=2%20year%20birthday%20celebration\u0026utm_source=The-Batch-10522\u0026utm_medium=The-Batch-10522\u0026utm_term=The-Batch-10522\u0026utm_content=The-Batch-10522\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener noreferrer\"\u003eLearn more\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/MOON_600px.webp\" class=\"kg-image\" alt=\"Photographs of the Moon\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2022/10/MOON_600px.webp 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"the-dark-side-of-the-moon-%E2%80%94-lit-up\"\u003eThe Dark Side of the Moon — Lit Up!\u003c/h1\u003e\u003cp\u003eNeural networks are making it possible to view parts of the Moon that are perpetually shrouded by darkness.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Valentin Bickel at ETH Zürich and colleagues devised a method called \u003ca href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL099530?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eHyper-effective Noise Removal U-net Software\u003c/a\u003e (HORUS) to remove noise from images of the Moon’s south pole, where direct sunlight never falls. The National Aeronautics and Space Administration (NASA) is using the denoised images to plan lunar missions that will put humans on the Moon for the first time in decades.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe challenge:\u003c/strong\u003e The only light that strikes the lunar south pole’s craters, boulders, mounds, and crevasses comes from scant photons that reflect off Earth or nearby lunar landforms or arrive from faraway stars. An imaging system aboard NASA’s Lunar Reconnaissance Orbiter can capture features that are lit this way, but it has a tendency to \u003ca href=\"https://en.wikipedia.org/wiki/Dark_current_(physics)?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003edetect photons where none exist\u003c/a\u003e. Transmitting and processing the images introduces more noise, further blurring details in the already-dim images. Removing noise optimizes the available light, making it possible to see the landscape.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The authors \u003ca href=\"https://www.nature.com/articles/s41467-021-25882-z?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003etrained\u003c/a\u003e two neural networks to remove the noise from lunar images.\u003c/p\u003e\u003cul\u003e\u003cli\u003eUsing 70,000 calibration images collected during the Lunar Reconnaissance Orbiter’s mission, a convolutional neural network (CNN) called DeStripeNet learned to generate an array of pixels that simulates camera-produced noise for a given image when fed metadata associated with that image, such as the temperature of the camera and various other pieces of hardware. Then it removed this noise by overlaying the generated pixels on the original image and subtracting their values.\u003c/li\u003e\u003cli\u003eA \u003ca href=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eU-Net\u003c/a\u003e CNN called PhotonNet was trained on modified image pairs of sunlit lunar regions. The images were artificially darkened, and one in each pair was further modified by adding noise generated by a mathematical model. This noise represented errors arising from sources such as data compression applied when transmitting images to Earth. PhotonNet learned to simulate these errors and subtracted them from the output of DeStripeNet, producing a cleaner image.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e HORUS removed noise from 200,000 images of the lunar surface. The authors identified possible landing sites, hazards to avoid, and evidence that some areas may contain water ice beneath the surface.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e The Moon’s south pole is the target for NASA’s upcoming Artemis program. Artemis 1, scheduled to launch in late September, will be fully automated. Artemis 2, scheduled for 2024, aims to land humans on the Moon for the first time since NASA’s final Apollo mission in 1972.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e NASA chose the Moon’s south pole as the target for future missions because water may be frozen at the bottoms of craters there. Water on the Moon could provide clues about the heavenly body’s origin as well as hydration, radiation shielding, and propellant for missions further out in the solar system.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e This AI project is out of this world!\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/DIALOG.gif\" class=\"kg-image\" alt=\"Illustration of the Dialogue Transformer Language Model (DLM)\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2022/10/DIALOG.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"the-sound-of-conversation\"\u003eThe Sound of Conversation\u003c/h1\u003e\u003cp\u003eIn spoken conversation, people naturally take turns amid interjections, overlaps, and other patterns that aren’t strictly verbal. A new approach generated natural-sounding — though not necessarily semantically coherent — audio dialogs without training on text transcriptions that mark when one party should stop speaking and the other should chime in.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat's new:\u003c/strong\u003e Tu Anh Nguyen and colleagues at Meta, France’s National Institute for Research in Digital Science and Technology, and École des Hautes Études en Sciences Sociales introduced \u003ca href=\"https://arxiv.org/abs/2203.16502?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eDialogue Transformer Language Model\u003c/a\u003e (DLM), a system that learned to incorporate the interruptions, pauses, and inflections of conversational speech into audio dialogues. You can listen to examples \u003ca href=\"https://speechbot.github.io/dgslm/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e Prior efforts to model dialogue were based on text, but text datasets omit information that’s unique to spoken interactions. Training directly on recordings of spoken dialogue can enable models to learn this additional mode of expression so they can mimic face-to-face conversation more naturally.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The system encoded two audio signals — two sides of a spoken conversation — into tokens. It processed each token stream through a separate transformer and decoded the tokens back to audio signals. The transformers were trained on \u003ca href=\"https://doi.org/10.35111/w4bk-9b14?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eFisher English Training Speech\u003c/a\u003e, a dataset that comprises over 10,000 telephone conversations, an average of 10 minutes long, recorded using a separate audio channel for each participant.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2106.07447?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eHuBERT\u003c/a\u003e, a self-supervised system that produces speech representations, tokenized the audio signals using a convolutional neural network (CNN) and transformer, which reduced 16,000 samples per second to 50. To adapt it to the Fisher dataset, the authors trained it to generate masked tokens.\u003c/li\u003e\u003cli\u003eGiven tokens from HuBERT, \u003ca href=\"https://arxiv.org/abs/2010.05646?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_TYKhuzGUlx4OZtJCltNp_bdr7sT9KULumb_ZUyX__oLKmDhHFRh6msnan2gwLu0_jUKB5\" rel=\"noopener\"\u003eHiFi-GAN\u003c/a\u003e, a generative adversarial network with CNN architecture, learned to generate the audio waveform of one speaker.\u003c/li\u003e\u003cli\u003eGiven the token streams, two transformers with shared weights learned to predict new tokens. The authors modified the transformers by adding, between the usual self-attention and fully connected layers, a cross-attention layer that attended to tokens from both signals. Estimating each token’s duration meant the authors could remove repetitions of the same token from the training data to avoid generating overly elongated sounds (such as a “hmm” that never ends).\u003c/li\u003e\u003cli\u003eAt inference, the transformers repeatedly added the next predicted tokens to two sequences, each of which started with a preset starting token. HiFi-GAN converted the sequence into audio.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e Crowdsourced evaluators compared DLM to a similar approach that used a single transformer to process both channels of conversation. They rated naturalness of turn-taking and meaningfulness on a 1 to 5 scale. (Ground-truth dialogs scored around 4.25 for both criteria.) DLM performed relatively well in turn-taking though poorly in meaningful output. For turn-taking, DLM achieved 3.86 while the single transformer achieved 3.46. For meaningfulness, DLM achieved 2.71, while the single transformer achieved 2.46.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Two transformers can model a pair of participants in conversation (or other interaction) more effectively than one. Connecting them via cross attention layers enables them to be aware of one another’s activity without needing to predict it. This simplifies the task of modeling their interactions while avoiding potentially confounding variables such as who said what.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe're thinking:\u003c/strong\u003e The system’s ability to mimic the ebb and flow of conversation is impressive, but its verbal output is largely gibberish. To be fair, training on only 1,700 hours of audio conversation may not be expected to impart much about semantics. We look forward to an update that produces more cogent spoken conversation.\u003c/p\u003e","comment_id":"633dd705bd09e0003d62fc0d","feature_image":"https://dl-staging-website.ghost.io/content/images/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM.png","featured":false,"visibility":"public","created_at":"2022-10-05T12:12:05.000-07:00","updated_at":"2023-02-06T13:11:42.000-08:00","published_at":"2022-10-05T12:47:53.000-07:00","custom_excerpt":"The Batch - AI News \u0026 Insights. When I wrote recently about how to build a career in AI, several readers wrote to ask specifically about AI product management: the art and science of designing compelling AI products. I’ll share lessons I’ve learned about this here and in future letters.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"633ddef6bd09e0003d62fc5d","name":"issue-165","slug":"issue-165","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-165/"},{"id":"633dddd1bd09e0003d62fc38","name":"Oct 05, 2022","slug":"oct-05-2022","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/oct-05-2022/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-165/","excerpt":"The Batch - AI News \u0026 Insights. When I wrote recently about how to build a career in AI, several readers wrote to ask specifically about AI product management: the art and science of designing compelling AI products. I’ll share lessons I’ve learned about this here and in future letters.","reading_time":11,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"DALL·E for Video, AI Startup Funding Falls, What the Dark Side of the Moon Looks Like and more","meta_description":"The Batch - AI News \u0026 Insights. When I wrote recently about how to build a career in AI, several readers wrote to ask specifically about AI...","email_subject":null,"frontmatter":null,"feature_image_alt":"Iteration process chart","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2022/10/Screen-Shot-2022-10-05-at-10.58.31-AM.png","dimensions":{"width":1200,"height":676}},"banner":{"title":"AI is the new electricity","databaseId":29050,"id":"cG9zdDoyOTA1MA==","featuredImage":{"node":{"altText":"AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook.","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/resources/#ebooks","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-165"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>