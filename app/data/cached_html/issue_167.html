<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually) and more</title><meta name="description" content="The Batch - AI News &amp; Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-167/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually) and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually) and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-167/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2022-10-19T13:19:02.000-07:00"/><meta property="article:modified_time" content="2023-02-06T13:10:43.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-167"/><meta property="article:tag" content="Oct 19, 2022"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually) and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-167/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2-.jpg"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2-.jpg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="676"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2022-10-19T13:19:02.000-07:00","dateModified":"2023-02-06T13:10:43.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually) and more","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2-.jpg","width":1200,"height":676},"publisher":{"@type":"Organization","name":"U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually) and more","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-167/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 167</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Oct 19, 2022</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">11<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/oct-19-2022/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Oct 19, 2022</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">11<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-167/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-167/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-167/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends, </em><br><br><em>Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going to be a dominant user interface for AI? With the rise of text generators such as GPT-3 and Jurassic and image generators such as DALL·E, Midjourney, and Stable Diffusion, which take text input and produce output to match, there has been growing interest in how to craft prompts to get the output you want. For example, when generating an image of a panda, how does adding an adjective such as “beautiful” or a phrase like “trending on <a href="https://www.artstation.com/?sort_by=community&ref=dl-staging-website.ghost.io">artstation</a>” influence the output? The response to a particular prompt can be hard to predict and varies from system to system.</em></p><p><em>So is prompt engineering an important direction for AI, or is it a hack?</em></p><p><em>Here’s how we got to this point:</em></p><ul><li><em>The availability of large amounts of text or text-image data enabled researchers to train text-to-text or text-to-image models.</em></li><li><em>Because of this, our models expect text as input.</em></li><li><em>So many people have started experimenting with more sophisticated prompts.</em></li></ul><p><em>Some people have predicted that prompt engineering jobs would be plentiful in the future. I do believe that text prompts will be an important way to tell machines what we want — after all, they’re a dominant way to tell other humans what we want. But I think that prompt engineering will be only a small piece of the puzzle, and breathless predictions about <a href="https://medium.com/nerd-for-tech/prompt-engineering-the-career-of-future-2fb93f90f117?ref=dl-staging-website.ghost.io">the rise of professional prompt engineers</a> are missing the full picture.</em></p><p><em>Just as a TV has switches that allow you to precisely control the brightness and contrast of the image — which is more convenient than trying to use language to describe the image quality you want — I look forward to a user interface (UI) that enables us to tell computers what we want in a more intuitive and controllable way.</em></p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2--1.jpg" class="kg-image" alt="Illustration of Andrew Ng on a computer searching for &quot;Panda bear&quot; and getting a Paddington instead" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/unnamed--2--1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/unnamed--2--1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2--1.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><p><em>Take speech synthesis (also called text-to-speech). Researchers have developed systems that allow users to specify which part of a sentence should be spoken with what emotion. Virtual knobs allow you to dial up or down the degree of different emotions. This provides fine control over the output that would be difficult to express in language. By examining an output and then fine-tuning the controls, you can iteratively improve the output until you get the effect you want.</em></p><p><em>So, while I expect text prompts to remain an important part of how we communicate with image generators, I look forward to more efficient and understandable ways for us to control their output. For example, could a set of virtual knobs enable you to generate an image that is 30 percent in the style of Studio Ghibli and 70 percent the style of Disney? Drawing sketches is another good way to communicate, and I’m excited by <a href="https://huggingface.co/spaces/fffiloni/stable-diffusion-color-sketch?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--gi3MRLgMq231cJCbVhy_KlPOqT6dwzcRwTNEM6D9A0LSVcWODttwPI95II3mrGZn2FnYnjHNu2FBM3AVMs4nCdAM5ApDQrBVQlFW8QJG1BFRQs18&utm_content=2&utm_source=hs_email">img-to-img</a> UIs that help turn a sketch into a drawing.</em></p><p><em>Likewise, controlling large language models remains an important problem. If you want to generate empathetic, concise, or some other type of prose, is there an easier way than searching (sometimes haphazardly) among different prompts until you chance upon a good one?</em></p><p><em>When I’m just playing with these models, I find prompt engineering a creative and fun activity; but when I’m trying to get to a specific result, I find it frustratingly opaque. Text prompts are good at specifying a loose concept such as “a picture of a panda eating bamboo,” but new UIs will make it easier to get the results we want. And this will help open up generative algorithms to even more applications; say, text editors that can adjust a piece of writing to a specific style, or graphics editors that can make images that look a certain way.</em></p><p><em>Lots of exciting research ahead! I look forward to UIs that complement writing text prompts.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h2 id="news">News</h2><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/CHIPS.jpg" class="kg-image" alt="Shot of Computer Processor Production Line at Advanced Semiconductor Foundry in Bright Environment" loading="lazy" width="2000" height="1125" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/CHIPS.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/CHIPS.jpg 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2022/10/CHIPS.jpg 1600w, https://dl-staging-website.ghost.io/content/images/size/w2400/2022/10/CHIPS.jpg 2400w" sizes="(min-width: 720px) 720px"></figure><h1 id="ai-chips-spark-international-tension">AI Chips Spark International Tension</h1><p>New U.S. restrictions on chip sales aim to hamper China’s AI efforts.</p><p><strong>What’s new:</strong> The U.S. government <a href="https://www.federalregister.gov/documents/2022/10/13/2022-21658/implementation-of-additional-export-controls-certain-advanced-computing-and-semiconductor?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_MBaJXD7glmkayjRjT7zdSY7uczHVO9hFYit7jG2j-1NVaSu-nwz84skkeHBC8Huu_yIsmCMfeG942gFw3cnxBTIZroMjgTKrWsl7b3WorDiKm_gQ&utm_content=2&utm_source=hs_email">published</a> sweeping limits on sales of processors that involve U.S. designs and technology to Chinese businesses. U.S. officials <a href="https://www.nytimes.com/2022/10/07/business/economy/biden-chip-technology.html?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8imCFA70ZSL2pQ8YC4-65Y555FPewFc8zON8hPoN3gCX_feqAaWxnDs0s1DrlxVmHRnwsRPZTM8BHU5HsAyzFKjYSIv9W0GVFOGpDTdYyFyW6kA4A&utm_content=2&utm_source=hs_email">stated</a> that the restrictions are meant to prevent China from militarizing AI.</p><p><strong>New rules:</strong> The rules block sales of certain processors as well as U.S.-made equipment used to design and manufacture them. This includes high-end graphics processing units (GPUs) and other processors optimized for machine learning.</p><ul><li>The rules apply to chips capable of processing and interconnection speeds on par with Nvidia’s flagship <a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--jMG1OxWVbW-1u_5pmvL5dREIi_Zv_CiFA1EbjNUEzz2A_bbpoCE7ylaXOR4vBJTuuvPP7DRrFvgdrcVlCDdQpWF6bf8vLg6OO3XYC8Jsszz2mMBA&utm_content=2&utm_source=hs_email">A100</a> GPU, which is designed to be used in data centers. (Nvidia <a href="https://www.barchart.com/story/news/10006245/u-s-ramps-up-restrictions-on-chinese-tech?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_TBZOM4yvKTGcOdHiLWsBs_QFrEGMq2hNxtP3oQDIZslQnvibBMM3FuTlhe8tctpii4E6AiqKE403ZMFyrOAOLlE9KFTHPURJLozXhS0U1t3_3WHo&utm_content=2&utm_source=hs_email">supplies</a> 95 percent of China’s AI chips.) The less-capable chips typically found in personal computers and video game consoles are not restricted.</li><li>The restrictions prohibit sales to Chinese companies of advanced chips produced using U.S.-made software and hardware as well as sales of the equipment itself. This goes for companies anywhere in the world.</li><li>They also bar U.S. citizens and permanent residents from supporting development or manufacturing of advanced chips without permission from the U.S. government.</li></ul><p><strong>China’s response:</strong> A spokesperson for China’s foreign ministry <a href="https://www.fmprc.gov.cn/mfa_eng/xwfw_665399/s2510_665401/2511_665403/202210/t20221008_10779756.html?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9CSbX4gywNI-B_JykPxmJtEfUb6ZaSfhWgcf9xJUWCQgcv3mD5QhmVuPaDCy_jTG88wjsgRX5EfAjyPIdqR0gsalMG1fW6WHmKLKxKPC1GMgn2Woo&utm_content=2&utm_source=hs_email">accused</a> the U.S. of abusing export-control measures to target Chinese firms, stating that it would hinder global cooperation and supply chains.<br><br><strong>Behind the news:</strong> The restrictions initially came to light in September, when Nvidia and AMD independently <a href="https://www.deeplearning.ai/the-batch/gpu-china/?ref=dl-staging-website.ghost.io">alerted</a> shareholders that the U.S. had imposed controls on their most advanced products. However, their details became publicly available only last week. They represent a significant escalation of earlier U.S. efforts to thwart China’s ambitions in advanced technology.</p><ul><li>In May 2020, the U.S. <a href="https://www.theverge.com/2020/5/15/21259814/us-commerce-huawei-chip-manufacturers-5g?_hsmi=2&_hsenc=p2ANqtz--3RSBQBM4SfKt7ARFSwSQri9jUaDU98wDEJ6iGuP8DtYlL9ooElIDFkklmKMQLA0YJz8xs4NjMNka1t065VtWId2e42jPfNd3Fh1cgzcU_DHWt00U&ref=dl-staging-website.ghost.io">required</a> foreign chipmakers that use U.S. equipment to obtain permission to do business with the Chinese tech giant Huawei.</li><li>In 2019, the government <a href="https://www.theverge.com/2019/5/15/18216988/white-house-huawei-china-equipment-ban-trump-executive-order?_hsmi=2&_hsenc=p2ANqtz--25nb-92mQA2V-r5FGRNOjiCwwz0vaYCxCRvV5clXHuOFzd2WsEtJV5LKb-_ZZIepWKpK5vf5TRDlRaq5ZKS4gKJNh_igxQvrVw6uDOxKycKBP_vM&ref=dl-staging-website.ghost.io">blocked</a> U.S. firms from selling equipment to Huawei and 114 of its affiliates.</li><li>In 2015, the country <a href="https://www.pcworld.com/article/426879/us-blocks-intel-from-selling-xeon-chips-to-chinese-supercomputer-projects.html?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8tvA67B8Tx0-lIZkL6JBUBy6gzCPWoHV2cx6BIBCpe5RaXVnVozwj7IEneuT35pFJI2pLB3UDkVdhNhlo9pUWbTA2YlzjIBJ9PVtary-WG1tnAR9w&utm_content=2&utm_source=hs_email">barred</a> Intel from selling high-end chips to the Chinese military.</li></ul><p><strong>Why it matters:</strong> China has announced its <a href="https://www.nytimes.com/2017/07/20/business/china-artificial-intelligence.html?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_xtAENFKAea8iV9eeCpaMrDZNqOQzzVsDyJQ-2idSXg-svONQ8NRAqQqKPfGkj_2SKOFEqDirO0SMX23WZubcK3Z6q3IDphhwCDMrEdR4D3Ui-fCw&utm_content=2&utm_source=hs_email">ambition</a> to become the global leader in AI by 2030, and this requires access to cutting-edge processing power. The most advanced chips are manufactured in Taiwan and South Korea using chip-fabrication equipment made by U.S. companies, and the leading chip designers and makers of chip-design software reside in the U.S. This gives U.S. authorities a tight grip on other countries’ ability to buy and make chips. China’s effort to build domestic capacity to produce advanced semiconductors — which are hampered by the sheer difficulty and expense of etching features on silicon measured in nanometers  — now faces additional hardware, software, business, and talent hurdles.</p><p><strong>We’re thinking:</strong> International cooperation has been essential to recent progress in AI. As barriers rise between the U.S. and China, the AI community must navigate a world where geography will have a much bigger impact on access to ideas and resources.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--4-.gif" class="kg-image" alt="Series of images showing different AI tools for farmers " loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--4-.gif 600w"></figure><h1 id="smarts-for-farms">Smarts for Farms</h1><p>The next green revolution may be happening in the server room.</p><p><strong>What’s new:</strong> Microsoft <a href="https://blogs.microsoft.com/ai/microsoft-open-sources-its-farm-of-the-future-toolkit/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--IWjT_hBZRv52ENBdOKwOJsWN6UT2CP-IWWDyCO7WDEA_l2Bi0KDoLuqdEKafu4H7OgFIrNC7uTwXo9yhZ4fBnbcQD2KbtN_eg34NlL9dVoQ2Snm0&utm_content=2&utm_source=hs_email">open-sourced</a> a set of AI tools designed to help farmers cut costs and improve yields.</p><p><strong>How it works:</strong> <a href="https://github.com/microsoft/farmvibes-ai?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8kwvUlR3XvM0naUHcS4boU6Ka5Me7AkON1FQ4HeXopHpmshY1ncuRMmiDnOH2jRqtaHTP2xTQYkd_m9AjFAF9thZNoLtpha0mBgDG3536GPyq0jg0&utm_content=2&utm_source=hs_email">FarmVibes-AI</a> includes systems that analyze overhead imagery and sensor data to guide farm operations.</p><ul><li><a href="https://www.microsoft.com/en-us/research/publication/democratizing-data-driven-agriculture-using-affordable-hardware/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_B8AMjgYviZIU26lpiZP58faXBvUbi8qhNZcEJ2j5no1B9-0_F7GiPlaaNxDQ9Ax_sXFQmT1f0VJWxb4BQd9dYi_bKwcTXBLsKkAF7XQUxerQdluA&utm_content=2&utm_source=hs_email">AsyncFusion</a> uses drone imagery, satellite imagery, and data from soil sensors to map soil conditions in real time. Farmers can use the output to plan where and when they should plant their fields.</li><li><a href="https://www.microsoft.com/en-us/research/publication/micro-climate-prediction-multi-scale-encoder-decoder-based-deep-learning-framework/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9CxHIxcVjetbie-netuNl_6UpQMrPfwjvtNa7L_w4zpExKBUOybywAv7VPXMV6VsXmHtefESADfFDkZgKGvx5Ym9h_OYtfIGwJEZqWOkC2rrhrUWE&utm_content=2&utm_source=hs_email">DeepMC</a> is a neural network that combines data from soil sensors, climate sensors, and weather predictions to forecast field temperature, precipitation, and soil moisture up to 120 hours ahead. Its output can enable farmers to prepare for extreme temperatures and other events.</li><li><a href="https://arxiv.org/abs/2106.08408?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_xrO97qfmPDL-Y7qinZUWpXtioxzR72g8eIlIvivzCt3n6QgOO0IbTid953JR3M_H41oFOk-9itdb1aYthETJMb8w4rtLi1KObW3RxTBmYgpF-Cb8&utm_content=2&utm_source=hs_email">SpaceEye</a>, another neural network, filters clouds from satellite imagery for use by AsyncFusion and DeepMC. Microsoft engineers trained the network via an adversarial method using infrared and visible-light images partly covered with synthetic clouds.</li></ul><p><strong>Behind the news:</strong> Nonprofits and academic institutions provide other open-source AI systems to increase food production in collaboration with large agribusiness firms, independent farmers, and rural communities.</p><ul><li>Last year, the Linux Foundation <a href="https://agstack.org/news/the-linux-foundation-launches-agstack-an-open-source-digital-infrastructure-project-for-agriculture-to-enable-a-global-collaboration-of-industry-government-and-academia/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8m8POjv1pqUoC5Kh2peyTBug3KsXlzymx-AmygBxcrse5z5FyoF01xin6XaHdYPcNffRwIYXLSFvHfOayKsIof3jGFShrEJUls_yWFF7haPyHF_fA&utm_content=2&utm_source=hs_email">launched</a> Agstack, a partnership among universities, nonprofits, and IBM. The effort provides code, data, and frameworks to developers of open-source AI projects for agriculture.</li><li>MIT’s now-defunct <a href="https://www.media.mit.edu/groups/open-agriculture-openag/overview/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9fPkd0uFkDrOM2fJNxqZsGXuuAkz7kzZ40sDYxP2e7T7JN6ji_FPlvHa1K6iIaFIDnhoC96vw8kzKad7ewd3pwycLVoTomp6Il49viDRNoqXexB-8&utm_content=2&utm_source=hs_email">OpenAg</a> included <a href="https://evolution.ml/cases/openag/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--irFTxhVsLh176LT2dzohow6T-1esoLkvvCy_w2uhJtdaVitxS3bG78sTTv-7C9pH5hL57vkRT58I1OD1fjtl-xhOz5CsnfGTcs63cxBMZk4ytfIg&utm_content=2&utm_source=hs_email">models</a> that predicted how plants would grow under various environmental conditions.</li></ul><p><strong>Why it matters:</strong> The emerging practice of <a href="https://ispag.org/about/definition?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_EG-queNAOJNyroQk_NunSFz3oRKgs1-Mtts8HsThYrSEv3mUmrojgFNlmrfVtuU9mWWvMoqK4V69osAe8Q9ccK4e2oDbaaMDRDj9TAHaiX60bm4E&utm_content=2&utm_source=hs_email">precision agriculture</a>, which seeks to take into account not only entire fields but also local conditions down to the level of individual plants, could help farmers sow seeds, grow crops, fight pests, and harvest produce more efficiently. Off-the-shelf systems may not serve farmers who work in different parts of the world or grow niche crops. Open-source projects can expand their options effectively and inexpensively.</p><p><strong>We’re thinking:</strong> Farmers tend to welcome innovations that improve yields and cut costs. They’re also famously self-sufficient, performing repairs and installing upgrades to their equipment. As self-driving tractors and precision-ag systems take root, they’re great candidates to become early adopters of industry-focused <a href="https://www.deeplearning.ai/the-batch/coding-ai-is-the-new-literacy/?ref=dl-staging-website.ghost.io">platforms</a> that make it easy for anyone to build useful AI applications.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM <strong><a href="https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io">DEEPLEARNING.AI</a></strong></h2><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/MLS-TheBatch-ad.png" class="kg-image" alt="Machine Learning Specialization banner ad" loading="lazy" width="2000" height="1047" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/MLS-TheBatch-ad.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/MLS-TheBatch-ad.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2022/10/MLS-TheBatch-ad.png 1600w, https://dl-staging-website.ghost.io/content/images/size/w2400/2022/10/MLS-TheBatch-ad.png 2400w" sizes="(min-width: 720px) 720px"></figure><p><strong>Looking for a career that inspires you? Break into AI! </strong>The <em>Machine Learning Specialization</em> teaches foundational AI concepts through an intuitive visual approach. This beginner-friendly program, created by Andrew Ng and Stanford Online, makes it easier than ever to start your AI career. <a href="https://www.deeplearning.ai/courses/machine-learning-specialization/?ref=dl-staging-website.ghost.io" rel="noopener">Learn more</a></p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/ROGAN.jpg" class="kg-image" alt="AI-generated image of Joe Rogan interviewing Steve Jobs" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/ROGAN.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/ROGAN.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/ROGAN.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="all-synthetic-all-the-time">All Synthetic, All the Time</h1><p>Joe Rogan meets Steve Jobs in an AI-generated podcast.</p><p><strong>What’s new:</strong> For the debut episode of a new podcast series, Play.ht synthesized a 19-minute interview between the rock-star podcaster and late Apple CEO. You can hear it <a href="https://podcast.ai/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8vwWIsI1L8w_xCxcGrfR9kpKsp0OdvcEuHJXpjiRpl6LNFzYw1zz1WVaPLR5s63Ffo9ZFPEvrr3ChVJPd_LG9RxuzC33BwrocGA2L2NuDPxXit4yU&utm_content=2&utm_source=hs_email">here</a> and propose computer-generated participants in future episodes <a href="https://podcastio.canny.io/episode-ideas?_hsenc=p2ANqtz-8h7Qcy0VO3isHogRLNL1V871yywAZejhOmTHmWRpO-zViUnV_9CY9vl1UitfpQWT-cK3ESsqL40o1hx9CBqAgznUhAxMs3sA_unEMnBxQkjEIwJ6c&_hsmi=2&utm_campaign=The+Batch&utm_content=2&utm_medium=email&utm_source=hs_email">here</a>.</p><p><strong>How it works:</strong> The Dubai-based startup created the episode using text generation and voice cloning.</p><ul><li>Play.ht generated the script using an unnamed natural language model that it fine-tuned on Jobs’ biography, interviews, and other sources.</li><li>It rendered the transcript into audio using proprietary synthetic voices trained on audio recordings of each speaker. Play.ht’s voice editor <a href="https://play.ht/text-to-ai-voice-editor/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9EYQ3fnCEvwlcQjqd7f_s7hzpRo9bEorHx2026ZKWKQpZR6_NDc5B_d_iVypMArNSbt08CuQwwsjpJJyNFScIYbiKHsmgkAQWRiDtrhC0FMmSourI&utm_content=2&utm_source=hs_email">synthesizes</a> voices in over 120 languages with phonetic control over pronunciation.</li><li>The production is the first in a series called Podcast.ai. The public can <a href="https://podcastio.canny.io/episode-ideas?_hsenc=p2ANqtz-8DLmK9FwR9Qp-R2yVvUxYCXuASuOm835szsAC4s8ZavpTQxGpSush7vRsq5sAHGqKvcCK-tAvMkPBwpS1eyi1pqmDmyae8fU31NZreXIlgyj7_UwY&_hsmi=2&utm_campaign=The+Batch&utm_content=2&utm_medium=email&utm_source=hs_email">propose</a> meetings of the virtual minds for future episodes.</li></ul><p><strong>Behind the news:</strong> Rogan was also the subject of an early experiment in voice cloning. In 2019, Toronto-based Dessa <a href="https://www.deeplearning.ai/the-batch/issue-vi/?ref=dl-staging-website.ghost.io">released</a> ersatz Rogan audio clips — the first of a parade of fake celebrity voices.</p><ul><li>Earlier this year, James Earl Jones, the voice of Darth Vader, <a href="https://www.vanityfair.com/hollywood/2022/09/darth-vaders-voice-emanated-from-war-torn-ukraine?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--OcESTiwv6cSyTw5GU8keQ3ED3_Ad820upNwsEnCQHNMB3DhN7Jc4QM8mCr5S9F8-EOV6c51StKKhJkCBvzO1tXR4iFdfaOaqgPkhdHlRe2d97tkk&utm_content=2&utm_source=hs_email">signed</a> a deal that permits Disney to recreate the Star Wars villain’s speech using technology from Ukrainian startup ReSpeecher.</li><li>Two documentary filmmakers separately generated vocal facsimiles of deceased celebrity chef <a href="https://www.newyorker.com/culture/annals-of-gastronomy/the-ethics-of-a-deepfake-anthony-bourdain-voice?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8pHYq17MpqRIH_9-LemE5QpwYD-uBGQJFlnZYm-pMUrlyYTxLTL4pG_H7CyguNWasU73Y5pmW4zXdtHJi8XhDRi19VyhPGIctI5uDbMOYVwc8UWFQ&utm_content=2&utm_source=hs_email">Anthony Bourdain</a> and iconic artist <a href="https://www.resemble.ai/andy-warhol/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9vrGpD8oeC0oJkEO8TaAlpQp6_mXG1-uuqOZjtRnTcgIFT5poC7me4k-cFbu4442QAcFbgOyFeJD8c7THpBFU6dMSJvzXf1xY9vB-jdIYcOg8rncs&utm_content=2&utm_source=hs_email">Andy Warhol</a>. The Bourdain imitation sparked controversy when his widow revealed that she had not given the filmmaker permission to recreate her husband’s voice.</li></ul><p><strong>Why it matters:</strong> The declamation is occasionally stilted and the script meandering (with occasional lapses into incoherence), but the rapid progress of generative audio combined with the entertainment world’s appetite for novelty suggests that satisfying synthetic productions may not be far off.<br><br><strong>We’re thinking:</strong> How long before we can produce <em><a href="https://www.youtube.com/playlist?list=PLkDaE6sCZn6FcbHlDzbVzf3TVgxzxK7lr&ref=dl-staging-website.ghost.io">Heroes of Deep Learning</a></em> without actually talking with any of the heroes of deep learning?</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--5-.gif" class="kg-image" alt="Technical components of No Language Left Behind and how they fit together" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--5-.gif 600w"></figure><h1 id="massively-multilingual-translation">Massively Multilingual Translation</h1><p>Sentence pairs that have equivalent meanings in different languages — typically used to train machine translation systems — have been available in sufficient quantities for only around 100 languages. New work doubled that number and produced a more capable model.</p><p><strong>What’s new:</strong> Marta R. Costa-jussà and colleagues at Meta, Johns Hopkins, and UC Berkeley developed an automated process for scraping multilingual sentence pairs from the web. They released <a href="https://arxiv.org/abs/2207.04672?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--M99m5uj8I2DxSdY_SmnerMuM3FcLFlH-ksnLZfAhKN9J-No-X2NSiBFPuGdNUj1pm-Z0Zk_e_iwER3T5sfPypFZqqoUBn_XkXRP7gjjY5HpPXHzI&utm_content=2&utm_source=hs_email">No Language Left Behind</a> (NLLB-200), a machine translation model that handles 200 languages. They also released the <a href="https://github.com/facebookresearch/fairseq/tree/nllb?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9gNxuxHnCNV9qE2WiGoX13Uvnr5tB5G7UdDr4SG-Z9p-tEhQfgRr527AWV_2hmHq2H4JdZKC-lY1i0r3mghX683XiFqbLNV-D26tdAl2qj5SnZjAo&utm_content=2&utm_source=hs_email">models, code, and data</a> used to build it.</p><p><strong>Key insight:</strong> The web is full of text in various languages, including sentences that have the same meaning in different languages. For instance, unrelated pages in different languages may say the equivalent of, “Manchester United defeated Melbourne in yesterday’s match,” or “A long time ago in a galaxy far, far away.” An automated system can recognize such parallel sentences by learning to produce similar representations of sentences that have similar meaning regardless of their language. A teacher/student arrangement — with a multilingual teacher trained on languages with plentiful data to produce embeddings, and a separate monolingual student for each language scraped from the web — can align representations produced by the students.</p><p><strong>How they built the dataset:</strong> The authors identified languages in text scraped from the web, trained a teacher model on pre-existing multilingual data, and used it to train a student model to produce similar representations for similar meanings in the web text.</p><ul><li>The authors trained <a href="https://aclanthology.org/L18-1550/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-97f_99RZxBbjKsWapOmxZ1nSImhv2vq2fqVRspH7W65XR24BmzImgOA_rwWnSJSBHKoGGC7IdKz1cUgfhLcIN1mB9EMlAP4tctjGUcmRVAe7GU1fo&utm_content=2&utm_source=hs_email">fasttext</a>, a linear classifier, to classify text according to its language. They trained it on publicly available datasets and their own corpus of 6,000 human-translated sentence pairs in 39 languages (released with this paper).</li><li>Fasttext classified the language of individual sentences and full paragraphs in web-text corpora such as <a href="https://commoncrawl.org/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--GEsxyWFFfSulLs4wmAdD3xU1RaQQrDp3sa5aYYbOMUkICicqnRX5WJCDCnoc0DqtIwJDmgCCNWuIGU47S2NO8OtHsLAYnCPPiwx9W4sa0CNCU3o0&utm_content=2&utm_source=hs_email">Common Crawl</a> and <a href="https://aclanthology.org/2020.acl-main.417/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--c5wime8KVO9vame9Alp-ZvUq0d_8MYmI3Xcg6wgnF-jYiknILwQ4OVPZrDxFhcr_zyNwII7xSR0hkzIef8pXvsuiUAU-gt_uuQNES1fcrYZM_hlY&utm_content=2&utm_source=hs_email">ParaCrawl</a>. The authors discarded sentences if their classification didn’t match that of the paragraph and removed sentences in languages for which they already had a lot of parallel data. After deleting duplicates, they had 43.7 billion sentences, each labeled as one of 148 languages.</li><li>They trained a separate transformer — a student — on each language (or several similar languages) to produce similar representations for sentences with similar meanings. To do this, they trained a Bidirectional LSTM — the teacher — to translate between the 93 languages in the <a href="https://aclanthology.org/L12-1246/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz--7uTch3FXVlyrN9IEnpie-LoI2ZvnEYkt6RNMN67GMq_bwE1NX54r0AerME6VRtY3KsAtQ2Y6pMbv43O-rSNDj-OUImO_Gm-K-MQfLA8UWGbemfao&utm_content=2&utm_source=hs_email">OPUS</a> dataset. This model learned similar representations of equivalent sentences in different languages. Using publicly available datasets of parallel sentences, the teacher received a sentence in one language (usually English) while a student received the equivalent sentence in its designated language(s). The students learned to maximize the cosine similarity between the teacher’s and students’ representations. Simultaneously, the students were trained to fill in missing words of sentences in their designated language(s).</li><li>The authors discarded sentence pairs if their representations’ cosine similarities were too different, leaving 1.1 billion parallel sentence pairs. Combined with pre-existing datasets, the parallel sentences represented 202 languages.</li></ul><p><strong>How they built the translator:</strong> NLLB-200 is a transformer encoder-decoder that comprises 54.5 billion parameters.</p><ul><li>In every fourth transformer layer (made up of a self-attention sublayer and a fully connected sublayer), the authors exchanged the fully connected sublayer with a <a href="https://arxiv.org/abs/1701.06538?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-9lgY7xQO9RQph_wmKLl5taqk1xbmwcvCiMLQFXlqzHNHN3bfuHoJfiotD-g6Q7Z7dVj3zmsWChrtN7nLmKzLzex9HDAPQgGCgMaPm04Et5ipBO9HM&utm_content=2&utm_source=hs_email">Sparsely Gated Mixture-of-Experts</a> (MoE) sublayer that activated only a subnetwork of neurons for each input. This enabled the network to learn to activate different portions depending on the language, which may have helped to prevent learning about languages that had many examples from interfering with learning about languages that had few.</li><li>Training proceeded in two stages. In the first stage, NLLB-200 filled in missing words in sentences and translated between pairs of sentences in different languages. In the second, it trained only on translations. In both stages, the paired sentences included human-translated sentence pairs, sentences scraped from the web and paired automatically, and back translations in which the model converted its own translations back to the original language.</li></ul><p><strong>Results:</strong> The authors’ NLLB-200 model achieved 24.0 average <a href="https://aclanthology.org/2022.tacl-1.30/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-8iUoLYm6tbUXe5Eyk7L8_vRAQstaMwWnnVmy0gt9VRN0CrG2DitUXddVBUfJbscq8_dxF0ByyVWIhr2UmIQJ6nayJHa8TkYdqpiQQcYQwZOKnSa4c&utm_content=2&utm_source=hs_email">spBLEU</a> across all 202 languages, while the earlier <a href="https://arxiv.org/abs/2106.13736?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_GE1ZyOML7uWGl5w4g-91pBfHquWTfTsmpMeNmpwfjiBBJ48_zg70IO7cpua7LEPdPgR7SkUNkZt-udMdFmdzZurY3vM5-9Hbx-se2_5aSnrW0qu4&utm_content=2&utm_source=hs_email">DeltaLM</a> achieved a 101-language average 16.7 spBLEU (which measures the overlap of word fragments between machine translations and ground truth, higher is better). A sparse NLLB-200 that used MoE rather than fully connected layers generally performed better than a dense version. For example, evaluated on Akan, a language spoken in Ghana for which little training data was available, the sparse model scored 36.2 <a href="https://aclanthology.org/W15-3049/?utm_campaign=The%20Batch&utm_medium=email&_hsmi=2&_hsenc=p2ANqtz-_ThKnXiBO2UMkqH7RUgaDYMdiihHCaYKQYzSOgx0geHm_Cfj-Op3uFPGiQroIFqmEDhBRbpa5J1TxpIASan3Taq6RWrc9DqIUuNopLTuKtRja3_sg&utm_content=2&utm_source=hs_email">chrF</a>, while a dense version scored 35.6 chrF (which measures overlapping groups of consecutive characters between machine translations and ground truth, higher is better). NLLB-200 performed inconsistently compared to bilingual models: It achieved 36.2 chrF compared to an English-to-Akan model’s 16.8 chrF, but 51.4 chrF compared to an English-to-Gujarati model’s 51.7 chrF. A possible explanation: Languages that are dissimilar to other languages in the training data may not benefit as much from multilingual training.</p><p><strong>Why it matters:</strong> Faced with an apparent scarcity of data, the authors extracted it from the web. The data didn’t need to be perfect: To compensate for flaws such as typographical and grammatical errors, the model learned to convert its own translations — of flawed sentences but presumably many more correct ones — into good sentences.</p><p><strong>We’re thinking:</strong> University of Texas machine learning professor Raymond Mooney <a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWH3P35RgQvpW9l9y2Y38dytHW6hm-BV4Rl4n_N3JhCG33q3npV1-WJV7CgHfqM9y5zFL2C-BW6N5VsV8CvWT2W8C3X5V839nFrN1MjyXHRVcdkW6JLDt47618bQW7jsgsc19hmFsW1m9RNq51tz-bN8164tNq8ybQW9jq5Mr72-CgjN86qWLFF0bVqW3CWlb25SR_G2W5vncQW5f5dyrW790cbF1Kwz6YW46dm5y4bR4CtW6wHgZ73_s6xpW5ymk8Z5T25XlW6Q9s374dpd05W5ntmJj4yN7Q2W1QqlY387gn2PW5Kq9F469pdPQVmbtDs6LqlkDVK4N7m13_9lQ31YL1?ref=dl-staging-website.ghost.io" rel="noopener">said</a>, “You can’t cram the meaning of a whole %&amp;!$# sentence into a single $&amp;!#* vector.” Apparently these researchers did it!</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="Become an AI professional with one of the world&#x27;s most popular Machine Learning courses. #BreakIntoAI with Machine Learning Specialization" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="Become an AI professional with one of the world&#x27;s most popular Machine Learning courses. #BreakIntoAI with Machine Learning Specialization" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/courses/machine-learning-specialization/"><div class="absolute inset-0" data-gtm-event-title="BreakIntoAI with Machine Learning Specialization"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-167/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-167/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-167/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm236" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-167","id":"634f0e72be967a003dce2467","uuid":"7b87c533-6a94-4202-a7b0-8d9b31002eb6","title":"The Batch: U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually), Massively Multilingual Translation, Smart Farms","html":"\u003cp\u003e\u003cem\u003eDear friends, \u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eIs prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going to be a dominant user interface for AI? With the rise of text generators such as GPT-3 and Jurassic and image generators such as DALL·E, Midjourney, and Stable Diffusion, which take text input and produce output to match, there has been growing interest in how to craft prompts to get the output you want. For example, when generating an image of a panda, how does adding an adjective such as “beautiful” or a phrase like “trending on \u003ca href=\"https://www.artstation.com/?sort_by=community\u0026ref=dl-staging-website.ghost.io\"\u003eartstation\u003c/a\u003e” influence the output? The response to a particular prompt can be hard to predict and varies from system to system.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eSo is prompt engineering an important direction for AI, or is it a hack?\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eHere’s how we got to this point:\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003eThe availability of large amounts of text or text-image data enabled researchers to train text-to-text or text-to-image models.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eBecause of this, our models expect text as input.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eSo many people have started experimenting with more sophisticated prompts.\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cem\u003eSome people have predicted that prompt engineering jobs would be plentiful in the future. I do believe that text prompts will be an important way to tell machines what we want — after all, they’re a dominant way to tell other humans what we want. But I think that prompt engineering will be only a small piece of the puzzle, and breathless predictions about \u003ca href=\"https://medium.com/nerd-for-tech/prompt-engineering-the-career-of-future-2fb93f90f117?ref=dl-staging-website.ghost.io\"\u003ethe rise of professional prompt engineers\u003c/a\u003e are missing the full picture.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eJust as a TV has switches that allow you to precisely control the brightness and contrast of the image — which is more convenient than trying to use language to describe the image quality you want — I look forward to a user interface (UI) that enables us to tell computers what we want in a more intuitive and controllable way.\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2--1.jpg\" class=\"kg-image\" alt=\"Illustration of Andrew Ng on a computer searching for \u0026quot;Panda bear\u0026quot; and getting a Paddington instead\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/unnamed--2--1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/unnamed--2--1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2--1.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eTake speech synthesis (also called text-to-speech). Researchers have developed systems that allow users to specify which part of a sentence should be spoken with what emotion. Virtual knobs allow you to dial up or down the degree of different emotions. This provides fine control over the output that would be difficult to express in language. By examining an output and then fine-tuning the controls, you can iteratively improve the output until you get the effect you want.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eSo, while I expect text prompts to remain an important part of how we communicate with image generators, I look forward to more efficient and understandable ways for us to control their output. For example, could a set of virtual knobs enable you to generate an image that is 30 percent in the style of Studio Ghibli and 70 percent the style of Disney? Drawing sketches is another good way to communicate, and I’m excited by \u003ca href=\"https://huggingface.co/spaces/fffiloni/stable-diffusion-color-sketch?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz--gi3MRLgMq231cJCbVhy_KlPOqT6dwzcRwTNEM6D9A0LSVcWODttwPI95II3mrGZn2FnYnjHNu2FBM3AVMs4nCdAM5ApDQrBVQlFW8QJG1BFRQs18\u0026utm_content=2\u0026utm_source=hs_email\"\u003eimg-to-img\u003c/a\u003e UIs that help turn a sketch into a drawing.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eLikewise, controlling large language models remains an important problem. If you want to generate empathetic, concise, or some other type of prose, is there an easier way than searching (sometimes haphazardly) among different prompts until you chance upon a good one?\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWhen I’m just playing with these models, I find prompt engineering a creative and fun activity; but when I’m trying to get to a specific result, I find it frustratingly opaque. Text prompts are good at specifying a loose concept such as “a picture of a panda eating bamboo,” but new UIs will make it easier to get the results we want. And this will help open up generative algorithms to even more applications; say, text editors that can adjust a piece of writing to a specific style, or graphics editors that can make images that look a certain way.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eLots of exciting research ahead! I look forward to UIs that complement writing text prompts.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"news\"\u003eNews\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/CHIPS.jpg\" class=\"kg-image\" alt=\"Shot of Computer Processor Production Line at Advanced Semiconductor Foundry in Bright Environment\" loading=\"lazy\" width=\"2000\" height=\"1125\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/CHIPS.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/CHIPS.jpg 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2022/10/CHIPS.jpg 1600w, https://dl-staging-website.ghost.io/content/images/size/w2400/2022/10/CHIPS.jpg 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"ai-chips-spark-international-tension\"\u003eAI Chips Spark International Tension\u003c/h1\u003e\u003cp\u003eNew U.S. restrictions on chip sales aim to hamper China’s AI efforts.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e The U.S. government \u003ca href=\"https://www.federalregister.gov/documents/2022/10/13/2022-21658/implementation-of-additional-export-controls-certain-advanced-computing-and-semiconductor?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-_MBaJXD7glmkayjRjT7zdSY7uczHVO9hFYit7jG2j-1NVaSu-nwz84skkeHBC8Huu_yIsmCMfeG942gFw3cnxBTIZroMjgTKrWsl7b3WorDiKm_gQ\u0026utm_content=2\u0026utm_source=hs_email\"\u003epublished\u003c/a\u003e sweeping limits on sales of processors that involve U.S. designs and technology to Chinese businesses. U.S. officials \u003ca href=\"https://www.nytimes.com/2022/10/07/business/economy/biden-chip-technology.html?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-8imCFA70ZSL2pQ8YC4-65Y555FPewFc8zON8hPoN3gCX_feqAaWxnDs0s1DrlxVmHRnwsRPZTM8BHU5HsAyzFKjYSIv9W0GVFOGpDTdYyFyW6kA4A\u0026utm_content=2\u0026utm_source=hs_email\"\u003estated\u003c/a\u003e that the restrictions are meant to prevent China from militarizing AI.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eNew rules:\u003c/strong\u003e The rules block sales of certain processors as well as U.S.-made equipment used to design and manufacture them. This includes high-end graphics processing units (GPUs) and other processors optimized for machine learning.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe rules apply to chips capable of processing and interconnection speeds on par with Nvidia’s flagship \u003ca href=\"https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz--jMG1OxWVbW-1u_5pmvL5dREIi_Zv_CiFA1EbjNUEzz2A_bbpoCE7ylaXOR4vBJTuuvPP7DRrFvgdrcVlCDdQpWF6bf8vLg6OO3XYC8Jsszz2mMBA\u0026utm_content=2\u0026utm_source=hs_email\"\u003eA100\u003c/a\u003e GPU, which is designed to be used in data centers. (Nvidia \u003ca href=\"https://www.barchart.com/story/news/10006245/u-s-ramps-up-restrictions-on-chinese-tech?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-_TBZOM4yvKTGcOdHiLWsBs_QFrEGMq2hNxtP3oQDIZslQnvibBMM3FuTlhe8tctpii4E6AiqKE403ZMFyrOAOLlE9KFTHPURJLozXhS0U1t3_3WHo\u0026utm_content=2\u0026utm_source=hs_email\"\u003esupplies\u003c/a\u003e 95 percent of China’s AI chips.) The less-capable chips typically found in personal computers and video game consoles are not restricted.\u003c/li\u003e\u003cli\u003eThe restrictions prohibit sales to Chinese companies of advanced chips produced using U.S.-made software and hardware as well as sales of the equipment itself. This goes for companies anywhere in the world.\u003c/li\u003e\u003cli\u003eThey also bar U.S. citizens and permanent residents from supporting development or manufacturing of advanced chips without permission from the U.S. government.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eChina’s response:\u003c/strong\u003e A spokesperson for China’s foreign ministry \u003ca href=\"https://www.fmprc.gov.cn/mfa_eng/xwfw_665399/s2510_665401/2511_665403/202210/t20221008_10779756.html?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-9CSbX4gywNI-B_JykPxmJtEfUb6ZaSfhWgcf9xJUWCQgcv3mD5QhmVuPaDCy_jTG88wjsgRX5EfAjyPIdqR0gsalMG1fW6WHmKLKxKPC1GMgn2Woo\u0026utm_content=2\u0026utm_source=hs_email\"\u003eaccused\u003c/a\u003e the U.S. of abusing export-control measures to target Chinese firms, stating that it would hinder global cooperation and supply chains.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e The restrictions initially came to light in September, when Nvidia and AMD independently \u003ca href=\"https://www.deeplearning.ai/the-batch/gpu-china/?ref=dl-staging-website.ghost.io\"\u003ealerted\u003c/a\u003e shareholders that the U.S. had imposed controls on their most advanced products. However, their details became publicly available only last week. They represent a significant escalation of earlier U.S. efforts to thwart China’s ambitions in advanced technology.\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn May 2020, the U.S. \u003ca href=\"https://www.theverge.com/2020/5/15/21259814/us-commerce-huawei-chip-manufacturers-5g?_hsmi=2\u0026_hsenc=p2ANqtz--3RSBQBM4SfKt7ARFSwSQri9jUaDU98wDEJ6iGuP8DtYlL9ooElIDFkklmKMQLA0YJz8xs4NjMNka1t065VtWId2e42jPfNd3Fh1cgzcU_DHWt00U\u0026ref=dl-staging-website.ghost.io\"\u003erequired\u003c/a\u003e foreign chipmakers that use U.S. equipment to obtain permission to do business with the Chinese tech giant Huawei.\u003c/li\u003e\u003cli\u003eIn 2019, the government \u003ca href=\"https://www.theverge.com/2019/5/15/18216988/white-house-huawei-china-equipment-ban-trump-executive-order?_hsmi=2\u0026_hsenc=p2ANqtz--25nb-92mQA2V-r5FGRNOjiCwwz0vaYCxCRvV5clXHuOFzd2WsEtJV5LKb-_ZZIepWKpK5vf5TRDlRaq5ZKS4gKJNh_igxQvrVw6uDOxKycKBP_vM\u0026ref=dl-staging-website.ghost.io\"\u003eblocked\u003c/a\u003e U.S. firms from selling equipment to Huawei and 114 of its affiliates.\u003c/li\u003e\u003cli\u003eIn 2015, the country \u003ca href=\"https://www.pcworld.com/article/426879/us-blocks-intel-from-selling-xeon-chips-to-chinese-supercomputer-projects.html?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-8tvA67B8Tx0-lIZkL6JBUBy6gzCPWoHV2cx6BIBCpe5RaXVnVozwj7IEneuT35pFJI2pLB3UDkVdhNhlo9pUWbTA2YlzjIBJ9PVtary-WG1tnAR9w\u0026utm_content=2\u0026utm_source=hs_email\"\u003ebarred\u003c/a\u003e Intel from selling high-end chips to the Chinese military.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e China has announced its \u003ca href=\"https://www.nytimes.com/2017/07/20/business/china-artificial-intelligence.html?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-_xtAENFKAea8iV9eeCpaMrDZNqOQzzVsDyJQ-2idSXg-svONQ8NRAqQqKPfGkj_2SKOFEqDirO0SMX23WZubcK3Z6q3IDphhwCDMrEdR4D3Ui-fCw\u0026utm_content=2\u0026utm_source=hs_email\"\u003eambition\u003c/a\u003e to become the global leader in AI by 2030, and this requires access to cutting-edge processing power. The most advanced chips are manufactured in Taiwan and South Korea using chip-fabrication equipment made by U.S. companies, and the leading chip designers and makers of chip-design software reside in the U.S. This gives U.S. authorities a tight grip on other countries’ ability to buy and make chips. China’s effort to build domestic capacity to produce advanced semiconductors — which are hampered by the sheer difficulty and expense of etching features on silicon measured in nanometers  — now faces additional hardware, software, business, and talent hurdles.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e International cooperation has been essential to recent progress in AI. As barriers rise between the U.S. and China, the AI community must navigate a world where geography will have a much bigger impact on access to ideas and resources.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--4-.gif\" class=\"kg-image\" alt=\"Series of images showing different AI tools for farmers \" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--4-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"smarts-for-farms\"\u003eSmarts for Farms\u003c/h1\u003e\u003cp\u003eThe next green revolution may be happening in the server room.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Microsoft \u003ca href=\"https://blogs.microsoft.com/ai/microsoft-open-sources-its-farm-of-the-future-toolkit/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz--IWjT_hBZRv52ENBdOKwOJsWN6UT2CP-IWWDyCO7WDEA_l2Bi0KDoLuqdEKafu4H7OgFIrNC7uTwXo9yhZ4fBnbcQD2KbtN_eg34NlL9dVoQ2Snm0\u0026utm_content=2\u0026utm_source=hs_email\"\u003eopen-sourced\u003c/a\u003e a set of AI tools designed to help farmers cut costs and improve yields.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e \u003ca href=\"https://github.com/microsoft/farmvibes-ai?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-8kwvUlR3XvM0naUHcS4boU6Ka5Me7AkON1FQ4HeXopHpmshY1ncuRMmiDnOH2jRqtaHTP2xTQYkd_m9AjFAF9thZNoLtpha0mBgDG3536GPyq0jg0\u0026utm_content=2\u0026utm_source=hs_email\"\u003eFarmVibes-AI\u003c/a\u003e includes systems that analyze overhead imagery and sensor data to guide farm operations.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://www.microsoft.com/en-us/research/publication/democratizing-data-driven-agriculture-using-affordable-hardware/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-_B8AMjgYviZIU26lpiZP58faXBvUbi8qhNZcEJ2j5no1B9-0_F7GiPlaaNxDQ9Ax_sXFQmT1f0VJWxb4BQd9dYi_bKwcTXBLsKkAF7XQUxerQdluA\u0026utm_content=2\u0026utm_source=hs_email\"\u003eAsyncFusion\u003c/a\u003e uses drone imagery, satellite imagery, and data from soil sensors to map soil conditions in real time. Farmers can use the output to plan where and when they should plant their fields.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.microsoft.com/en-us/research/publication/micro-climate-prediction-multi-scale-encoder-decoder-based-deep-learning-framework/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-9CxHIxcVjetbie-netuNl_6UpQMrPfwjvtNa7L_w4zpExKBUOybywAv7VPXMV6VsXmHtefESADfFDkZgKGvx5Ym9h_OYtfIGwJEZqWOkC2rrhrUWE\u0026utm_content=2\u0026utm_source=hs_email\"\u003eDeepMC\u003c/a\u003e is a neural network that combines data from soil sensors, climate sensors, and weather predictions to forecast field temperature, precipitation, and soil moisture up to 120 hours ahead. Its output can enable farmers to prepare for extreme temperatures and other events.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2106.08408?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-_xrO97qfmPDL-Y7qinZUWpXtioxzR72g8eIlIvivzCt3n6QgOO0IbTid953JR3M_H41oFOk-9itdb1aYthETJMb8w4rtLi1KObW3RxTBmYgpF-Cb8\u0026utm_content=2\u0026utm_source=hs_email\"\u003eSpaceEye\u003c/a\u003e, another neural network, filters clouds from satellite imagery for use by AsyncFusion and DeepMC. Microsoft engineers trained the network via an adversarial method using infrared and visible-light images partly covered with synthetic clouds.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Nonprofits and academic institutions provide other open-source AI systems to increase food production in collaboration with large agribusiness firms, independent farmers, and rural communities.\u003c/p\u003e\u003cul\u003e\u003cli\u003eLast year, the Linux Foundation \u003ca href=\"https://agstack.org/news/the-linux-foundation-launches-agstack-an-open-source-digital-infrastructure-project-for-agriculture-to-enable-a-global-collaboration-of-industry-government-and-academia/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-8m8POjv1pqUoC5Kh2peyTBug3KsXlzymx-AmygBxcrse5z5FyoF01xin6XaHdYPcNffRwIYXLSFvHfOayKsIof3jGFShrEJUls_yWFF7haPyHF_fA\u0026utm_content=2\u0026utm_source=hs_email\"\u003elaunched\u003c/a\u003e Agstack, a partnership among universities, nonprofits, and IBM. The effort provides code, data, and frameworks to developers of open-source AI projects for agriculture.\u003c/li\u003e\u003cli\u003eMIT’s now-defunct \u003ca href=\"https://www.media.mit.edu/groups/open-agriculture-openag/overview/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-9fPkd0uFkDrOM2fJNxqZsGXuuAkz7kzZ40sDYxP2e7T7JN6ji_FPlvHa1K6iIaFIDnhoC96vw8kzKad7ewd3pwycLVoTomp6Il49viDRNoqXexB-8\u0026utm_content=2\u0026utm_source=hs_email\"\u003eOpenAg\u003c/a\u003e included \u003ca href=\"https://evolution.ml/cases/openag/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz--irFTxhVsLh176LT2dzohow6T-1esoLkvvCy_w2uhJtdaVitxS3bG78sTTv-7C9pH5hL57vkRT58I1OD1fjtl-xhOz5CsnfGTcs63cxBMZk4ytfIg\u0026utm_content=2\u0026utm_source=hs_email\"\u003emodels\u003c/a\u003e that predicted how plants would grow under various environmental conditions.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e The emerging practice of \u003ca href=\"https://ispag.org/about/definition?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-_EG-queNAOJNyroQk_NunSFz3oRKgs1-Mtts8HsThYrSEv3mUmrojgFNlmrfVtuU9mWWvMoqK4V69osAe8Q9ccK4e2oDbaaMDRDj9TAHaiX60bm4E\u0026utm_content=2\u0026utm_source=hs_email\"\u003eprecision agriculture\u003c/a\u003e, which seeks to take into account not only entire fields but also local conditions down to the level of individual plants, could help farmers sow seeds, grow crops, fight pests, and harvest produce more efficiently. Off-the-shelf systems may not serve farmers who work in different parts of the world or grow niche crops. Open-source projects can expand their options effectively and inexpensively.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Farmers tend to welcome innovations that improve yields and cut costs. They’re also famously self-sufficient, performing repairs and installing upgrades to their equipment. As self-driving tractors and precision-ag systems take root, they’re great candidates to become early adopters of industry-focused \u003ca href=\"https://www.deeplearning.ai/the-batch/coding-ai-is-the-new-literacy/?ref=dl-staging-website.ghost.io\"\u003eplatforms\u003c/a\u003e that make it easy for anyone to build useful AI applications.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM \u003cstrong\u003e\u003ca href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\"\u003eDEEPLEARNING.AI\u003c/a\u003e\u003c/strong\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/MLS-TheBatch-ad.png\" class=\"kg-image\" alt=\"Machine Learning Specialization banner ad\" loading=\"lazy\" width=\"2000\" height=\"1047\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/MLS-TheBatch-ad.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/MLS-TheBatch-ad.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2022/10/MLS-TheBatch-ad.png 1600w, https://dl-staging-website.ghost.io/content/images/size/w2400/2022/10/MLS-TheBatch-ad.png 2400w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cstrong\u003eLooking for a career that inspires you? Break into AI! \u003c/strong\u003eThe \u003cem\u003eMachine Learning Specialization\u003c/em\u003e teaches foundational AI concepts through an intuitive visual approach. This beginner-friendly program, created by Andrew Ng and Stanford Online, makes it easier than ever to start your AI career. \u003ca href=\"https://www.deeplearning.ai/courses/machine-learning-specialization/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eLearn more\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/ROGAN.jpg\" class=\"kg-image\" alt=\"AI-generated image of Joe Rogan interviewing Steve Jobs\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2022/10/ROGAN.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2022/10/ROGAN.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2022/10/ROGAN.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"all-synthetic-all-the-time\"\u003eAll Synthetic, All the Time\u003c/h1\u003e\u003cp\u003eJoe Rogan meets Steve Jobs in an AI-generated podcast.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e For the debut episode of a new podcast series, Play.ht synthesized a 19-minute interview between the rock-star podcaster and late Apple CEO. You can hear it \u003ca href=\"https://podcast.ai/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-8vwWIsI1L8w_xCxcGrfR9kpKsp0OdvcEuHJXpjiRpl6LNFzYw1zz1WVaPLR5s63Ffo9ZFPEvrr3ChVJPd_LG9RxuzC33BwrocGA2L2NuDPxXit4yU\u0026utm_content=2\u0026utm_source=hs_email\"\u003ehere\u003c/a\u003e and propose computer-generated participants in future episodes \u003ca href=\"https://podcastio.canny.io/episode-ideas?_hsenc=p2ANqtz-8h7Qcy0VO3isHogRLNL1V871yywAZejhOmTHmWRpO-zViUnV_9CY9vl1UitfpQWT-cK3ESsqL40o1hx9CBqAgznUhAxMs3sA_unEMnBxQkjEIwJ6c\u0026_hsmi=2\u0026utm_campaign=The+Batch\u0026utm_content=2\u0026utm_medium=email\u0026utm_source=hs_email\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The Dubai-based startup created the episode using text generation and voice cloning.\u003c/p\u003e\u003cul\u003e\u003cli\u003ePlay.ht generated the script using an unnamed natural language model that it fine-tuned on Jobs’ biography, interviews, and other sources.\u003c/li\u003e\u003cli\u003eIt rendered the transcript into audio using proprietary synthetic voices trained on audio recordings of each speaker. Play.ht’s voice editor \u003ca href=\"https://play.ht/text-to-ai-voice-editor/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-9EYQ3fnCEvwlcQjqd7f_s7hzpRo9bEorHx2026ZKWKQpZR6_NDc5B_d_iVypMArNSbt08CuQwwsjpJJyNFScIYbiKHsmgkAQWRiDtrhC0FMmSourI\u0026utm_content=2\u0026utm_source=hs_email\"\u003esynthesizes\u003c/a\u003e voices in over 120 languages with phonetic control over pronunciation.\u003c/li\u003e\u003cli\u003eThe production is the first in a series called Podcast.ai. The public can \u003ca href=\"https://podcastio.canny.io/episode-ideas?_hsenc=p2ANqtz-8DLmK9FwR9Qp-R2yVvUxYCXuASuOm835szsAC4s8ZavpTQxGpSush7vRsq5sAHGqKvcCK-tAvMkPBwpS1eyi1pqmDmyae8fU31NZreXIlgyj7_UwY\u0026_hsmi=2\u0026utm_campaign=The+Batch\u0026utm_content=2\u0026utm_medium=email\u0026utm_source=hs_email\"\u003epropose\u003c/a\u003e meetings of the virtual minds for future episodes.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Rogan was also the subject of an early experiment in voice cloning. In 2019, Toronto-based Dessa \u003ca href=\"https://www.deeplearning.ai/the-batch/issue-vi/?ref=dl-staging-website.ghost.io\"\u003ereleased\u003c/a\u003e ersatz Rogan audio clips — the first of a parade of fake celebrity voices.\u003c/p\u003e\u003cul\u003e\u003cli\u003eEarlier this year, James Earl Jones, the voice of Darth Vader, \u003ca href=\"https://www.vanityfair.com/hollywood/2022/09/darth-vaders-voice-emanated-from-war-torn-ukraine?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz--OcESTiwv6cSyTw5GU8keQ3ED3_Ad820upNwsEnCQHNMB3DhN7Jc4QM8mCr5S9F8-EOV6c51StKKhJkCBvzO1tXR4iFdfaOaqgPkhdHlRe2d97tkk\u0026utm_content=2\u0026utm_source=hs_email\"\u003esigned\u003c/a\u003e a deal that permits Disney to recreate the Star Wars villain’s speech using technology from Ukrainian startup ReSpeecher.\u003c/li\u003e\u003cli\u003eTwo documentary filmmakers separately generated vocal facsimiles of deceased celebrity chef \u003ca href=\"https://www.newyorker.com/culture/annals-of-gastronomy/the-ethics-of-a-deepfake-anthony-bourdain-voice?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-8pHYq17MpqRIH_9-LemE5QpwYD-uBGQJFlnZYm-pMUrlyYTxLTL4pG_H7CyguNWasU73Y5pmW4zXdtHJi8XhDRi19VyhPGIctI5uDbMOYVwc8UWFQ\u0026utm_content=2\u0026utm_source=hs_email\"\u003eAnthony Bourdain\u003c/a\u003e and iconic artist \u003ca href=\"https://www.resemble.ai/andy-warhol/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-9vrGpD8oeC0oJkEO8TaAlpQp6_mXG1-uuqOZjtRnTcgIFT5poC7me4k-cFbu4442QAcFbgOyFeJD8c7THpBFU6dMSJvzXf1xY9vB-jdIYcOg8rncs\u0026utm_content=2\u0026utm_source=hs_email\"\u003eAndy Warhol\u003c/a\u003e. The Bourdain imitation sparked controversy when his widow revealed that she had not given the filmmaker permission to recreate her husband’s voice.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e The declamation is occasionally stilted and the script meandering (with occasional lapses into incoherence), but the rapid progress of generative audio combined with the entertainment world’s appetite for novelty suggests that satisfying synthetic productions may not be far off.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e How long before we can produce \u003cem\u003e\u003ca href=\"https://www.youtube.com/playlist?list=PLkDaE6sCZn6FcbHlDzbVzf3TVgxzxK7lr\u0026ref=dl-staging-website.ghost.io\"\u003eHeroes of Deep Learning\u003c/a\u003e\u003c/em\u003e without actually talking with any of the heroes of deep learning?\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--5-.gif\" class=\"kg-image\" alt=\"Technical components of No Language Left Behind and how they fit together\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--5-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"massively-multilingual-translation\"\u003eMassively Multilingual Translation\u003c/h1\u003e\u003cp\u003eSentence pairs that have equivalent meanings in different languages — typically used to train machine translation systems — have been available in sufficient quantities for only around 100 languages. New work doubled that number and produced a more capable model.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Marta R. Costa-jussà and colleagues at Meta, Johns Hopkins, and UC Berkeley developed an automated process for scraping multilingual sentence pairs from the web. They released \u003ca href=\"https://arxiv.org/abs/2207.04672?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz--M99m5uj8I2DxSdY_SmnerMuM3FcLFlH-ksnLZfAhKN9J-No-X2NSiBFPuGdNUj1pm-Z0Zk_e_iwER3T5sfPypFZqqoUBn_XkXRP7gjjY5HpPXHzI\u0026utm_content=2\u0026utm_source=hs_email\"\u003eNo Language Left Behind\u003c/a\u003e (NLLB-200), a machine translation model that handles 200 languages. They also released the \u003ca href=\"https://github.com/facebookresearch/fairseq/tree/nllb?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-9gNxuxHnCNV9qE2WiGoX13Uvnr5tB5G7UdDr4SG-Z9p-tEhQfgRr527AWV_2hmHq2H4JdZKC-lY1i0r3mghX683XiFqbLNV-D26tdAl2qj5SnZjAo\u0026utm_content=2\u0026utm_source=hs_email\"\u003emodels, code, and data\u003c/a\u003e used to build it.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e The web is full of text in various languages, including sentences that have the same meaning in different languages. For instance, unrelated pages in different languages may say the equivalent of, “Manchester United defeated Melbourne in yesterday’s match,” or “A long time ago in a galaxy far, far away.” An automated system can recognize such parallel sentences by learning to produce similar representations of sentences that have similar meaning regardless of their language. A teacher/student arrangement — with a multilingual teacher trained on languages with plentiful data to produce embeddings, and a separate monolingual student for each language scraped from the web — can align representations produced by the students.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow they built the dataset:\u003c/strong\u003e The authors identified languages in text scraped from the web, trained a teacher model on pre-existing multilingual data, and used it to train a student model to produce similar representations for similar meanings in the web text.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe authors trained \u003ca href=\"https://aclanthology.org/L18-1550/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-97f_99RZxBbjKsWapOmxZ1nSImhv2vq2fqVRspH7W65XR24BmzImgOA_rwWnSJSBHKoGGC7IdKz1cUgfhLcIN1mB9EMlAP4tctjGUcmRVAe7GU1fo\u0026utm_content=2\u0026utm_source=hs_email\"\u003efasttext\u003c/a\u003e, a linear classifier, to classify text according to its language. They trained it on publicly available datasets and their own corpus of 6,000 human-translated sentence pairs in 39 languages (released with this paper).\u003c/li\u003e\u003cli\u003eFasttext classified the language of individual sentences and full paragraphs in web-text corpora such as \u003ca href=\"https://commoncrawl.org/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz--GEsxyWFFfSulLs4wmAdD3xU1RaQQrDp3sa5aYYbOMUkICicqnRX5WJCDCnoc0DqtIwJDmgCCNWuIGU47S2NO8OtHsLAYnCPPiwx9W4sa0CNCU3o0\u0026utm_content=2\u0026utm_source=hs_email\"\u003eCommon Crawl\u003c/a\u003e and \u003ca href=\"https://aclanthology.org/2020.acl-main.417/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz--c5wime8KVO9vame9Alp-ZvUq0d_8MYmI3Xcg6wgnF-jYiknILwQ4OVPZrDxFhcr_zyNwII7xSR0hkzIef8pXvsuiUAU-gt_uuQNES1fcrYZM_hlY\u0026utm_content=2\u0026utm_source=hs_email\"\u003eParaCrawl\u003c/a\u003e. The authors discarded sentences if their classification didn’t match that of the paragraph and removed sentences in languages for which they already had a lot of parallel data. After deleting duplicates, they had 43.7 billion sentences, each labeled as one of 148 languages.\u003c/li\u003e\u003cli\u003eThey trained a separate transformer — a student — on each language (or several similar languages) to produce similar representations for sentences with similar meanings. To do this, they trained a Bidirectional LSTM — the teacher — to translate between the 93 languages in the \u003ca href=\"https://aclanthology.org/L12-1246/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz--7uTch3FXVlyrN9IEnpie-LoI2ZvnEYkt6RNMN67GMq_bwE1NX54r0AerME6VRtY3KsAtQ2Y6pMbv43O-rSNDj-OUImO_Gm-K-MQfLA8UWGbemfao\u0026utm_content=2\u0026utm_source=hs_email\"\u003eOPUS\u003c/a\u003e dataset. This model learned similar representations of equivalent sentences in different languages. Using publicly available datasets of parallel sentences, the teacher received a sentence in one language (usually English) while a student received the equivalent sentence in its designated language(s). The students learned to maximize the cosine similarity between the teacher’s and students’ representations. Simultaneously, the students were trained to fill in missing words of sentences in their designated language(s).\u003c/li\u003e\u003cli\u003eThe authors discarded sentence pairs if their representations’ cosine similarities were too different, leaving 1.1 billion parallel sentence pairs. Combined with pre-existing datasets, the parallel sentences represented 202 languages.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eHow they built the translator:\u003c/strong\u003e NLLB-200 is a transformer encoder-decoder that comprises 54.5 billion parameters.\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn every fourth transformer layer (made up of a self-attention sublayer and a fully connected sublayer), the authors exchanged the fully connected sublayer with a \u003ca href=\"https://arxiv.org/abs/1701.06538?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-9lgY7xQO9RQph_wmKLl5taqk1xbmwcvCiMLQFXlqzHNHN3bfuHoJfiotD-g6Q7Z7dVj3zmsWChrtN7nLmKzLzex9HDAPQgGCgMaPm04Et5ipBO9HM\u0026utm_content=2\u0026utm_source=hs_email\"\u003eSparsely Gated Mixture-of-Experts\u003c/a\u003e (MoE) sublayer that activated only a subnetwork of neurons for each input. This enabled the network to learn to activate different portions depending on the language, which may have helped to prevent learning about languages that had many examples from interfering with learning about languages that had few.\u003c/li\u003e\u003cli\u003eTraining proceeded in two stages. In the first stage, NLLB-200 filled in missing words in sentences and translated between pairs of sentences in different languages. In the second, it trained only on translations. In both stages, the paired sentences included human-translated sentence pairs, sentences scraped from the web and paired automatically, and back translations in which the model converted its own translations back to the original language.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The authors’ NLLB-200 model achieved 24.0 average \u003ca href=\"https://aclanthology.org/2022.tacl-1.30/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-8iUoLYm6tbUXe5Eyk7L8_vRAQstaMwWnnVmy0gt9VRN0CrG2DitUXddVBUfJbscq8_dxF0ByyVWIhr2UmIQJ6nayJHa8TkYdqpiQQcYQwZOKnSa4c\u0026utm_content=2\u0026utm_source=hs_email\"\u003espBLEU\u003c/a\u003e across all 202 languages, while the earlier \u003ca href=\"https://arxiv.org/abs/2106.13736?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-_GE1ZyOML7uWGl5w4g-91pBfHquWTfTsmpMeNmpwfjiBBJ48_zg70IO7cpua7LEPdPgR7SkUNkZt-udMdFmdzZurY3vM5-9Hbx-se2_5aSnrW0qu4\u0026utm_content=2\u0026utm_source=hs_email\"\u003eDeltaLM\u003c/a\u003e achieved a 101-language average 16.7 spBLEU (which measures the overlap of word fragments between machine translations and ground truth, higher is better). A sparse NLLB-200 that used MoE rather than fully connected layers generally performed better than a dense version. For example, evaluated on Akan, a language spoken in Ghana for which little training data was available, the sparse model scored 36.2 \u003ca href=\"https://aclanthology.org/W15-3049/?utm_campaign=The%20Batch\u0026utm_medium=email\u0026_hsmi=2\u0026_hsenc=p2ANqtz-_ThKnXiBO2UMkqH7RUgaDYMdiihHCaYKQYzSOgx0geHm_Cfj-Op3uFPGiQroIFqmEDhBRbpa5J1TxpIASan3Taq6RWrc9DqIUuNopLTuKtRja3_sg\u0026utm_content=2\u0026utm_source=hs_email\"\u003echrF\u003c/a\u003e, while a dense version scored 35.6 chrF (which measures overlapping groups of consecutive characters between machine translations and ground truth, higher is better). NLLB-200 performed inconsistently compared to bilingual models: It achieved 36.2 chrF compared to an English-to-Akan model’s 16.8 chrF, but 51.4 chrF compared to an English-to-Gujarati model’s 51.7 chrF. A possible explanation: Languages that are dissimilar to other languages in the training data may not benefit as much from multilingual training.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Faced with an apparent scarcity of data, the authors extracted it from the web. The data didn’t need to be perfect: To compensate for flaws such as typographical and grammatical errors, the model learned to convert its own translations — of flawed sentences but presumably many more correct ones — into good sentences.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e University of Texas machine learning professor Raymond Mooney \u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VWH3P35RgQvpW9l9y2Y38dytHW6hm-BV4Rl4n_N3JhCG33q3npV1-WJV7CgHfqM9y5zFL2C-BW6N5VsV8CvWT2W8C3X5V839nFrN1MjyXHRVcdkW6JLDt47618bQW7jsgsc19hmFsW1m9RNq51tz-bN8164tNq8ybQW9jq5Mr72-CgjN86qWLFF0bVqW3CWlb25SR_G2W5vncQW5f5dyrW790cbF1Kwz6YW46dm5y4bR4CtW6wHgZ73_s6xpW5ymk8Z5T25XlW6Q9s374dpd05W5ntmJj4yN7Q2W1QqlY387gn2PW5Kq9F469pdPQVmbtDs6LqlkDVK4N7m13_9lQ31YL1?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003esaid\u003c/a\u003e, “You can’t cram the meaning of a whole %\u0026amp;!$# sentence into a single $\u0026amp;!#* vector.” Apparently these researchers did it!\u003c/p\u003e","comment_id":"634f0e72be967a003dce2467","feature_image":"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2-.jpg","featured":false,"visibility":"public","created_at":"2022-10-18T13:37:06.000-07:00","updated_at":"2023-02-06T13:10:43.000-08:00","published_at":"2022-10-19T13:19:02.000-07:00","custom_excerpt":"The Batch - AI News \u0026 Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going to be a dominant user interface for AI?","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"634f1b6abe967a003dce251a","name":"issue-167","slug":"issue-167","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-167/"},{"id":"634f1b6abe967a003dce251b","name":"Oct 19, 2022","slug":"oct-19-2022","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/oct-19-2022/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-167/","excerpt":"The Batch - AI News \u0026 Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going to be a dominant user interface for AI?","reading_time":11,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"U.S. Blocks AI Chip Sales to China, Joe Rogan Meets Steve Jobs (Virtually) and more","meta_description":"The Batch - AI News \u0026 Insights. Is prompt engineering — the art of writing text prompts to get an AI system to generate the output you want — going...","email_subject":null,"frontmatter":null,"feature_image_alt":"Illustration of Andrew Ng on a computer searching for \"Panda bear\" and getting a Paddington instead","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2022/10/unnamed--2-.jpg","dimensions":{"width":1200,"height":676}},"banner":{"title":"BreakIntoAI with Machine Learning Specialization","databaseId":28989,"id":"cG9zdDoyODk4OQ==","featuredImage":{"node":{"altText":"Become an AI professional with one of the world's most popular Machine Learning courses. #BreakIntoAI with Machine Learning Specialization","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/4.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/courses/machine-learning-specialization/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-167"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>