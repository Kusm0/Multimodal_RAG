<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Autonomous Weapons Used in Combat, Tesla Doubles Down on Computer</title><meta name="description" content="The Batch - AI News &amp; Insights: Deadly Drones Act Alone | One Model for Vision-Language | Radiologists Eye AI | Tesla All-In For Computer Vision..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-94/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Autonomous Weapons Used in Combat, Tesla Doubles Down on Computer" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: Deadly Drones Act Alone | One Model for Vision-Language | Radiologists Eye AI | Tesla All-In For Computer Vision..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Autonomous Weapons Used in Combat, Tesla Doubles Down on Computer" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-94/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2021-06-02T12:00:00.000-07:00"/><meta property="article:modified_time" content="2022-10-06T07:28:29.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-94"/><meta property="article:tag" content="Jun 02, 2021"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Autonomous Weapons Used in Combat, Tesla Doubles Down on Computer" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: Deadly Drones Act Alone | One Model for Vision-Language | Radiologists Eye AI | Tesla All-In For Computer Vision..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-94/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-06-01-at-5.57.29-PM-copy--1--2.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-06-01-at-5.57.29-PM-copy--1--2.png"/><meta property="og:image:width" content="600"/><meta property="og:image:height" content="338"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2021-06-02T12:00:00.000-07:00","dateModified":"2022-10-06T07:28:29.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Autonomous Weapons Used in Combat, Tesla Doubles Down on Computer","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-06-01-at-5.57.29-PM-copy--1--2.png","width":600,"height":338},"publisher":{"@type":"Organization","name":"Autonomous Weapons Used in Combat, Tesla Doubles Down on Computer","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: Deadly Drones Act Alone | One Model for Vision-Language | Radiologists Eye AI | Tesla All-In For Computer Vision..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-94/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 94</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Jun 2, 2021</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">11<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/jun-02-2021/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Jun 02, 2021</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">11<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-94/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-94/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-94/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,</em></p><p><em>In school, most questions have only one right answer. But elsewhere, decisions often come down to a difficult choice among imperfect options. I’d like to share with you some approaches that have helped me make such decisions.</em></p><p><em>When I was deciding where to set up a satellite office outside the U.S., there were many options. My team and I started by listing important criteria such as supply of talent, availability of local partners, safety and rule of law, availability of visas, and cost. Then we evaluated different options against these criteria and built a matrix with cities along one axis and our criteria along the other. That clarified which country would make a great choice.</em></p><p><em>When I feel stuck, I find it helpful to write out my thoughts:</em></p><ul><li><em>What options am I choosing among?</em></li><li><em>What criteria are driving the choice?</em></li><li><em>How does each option rate with respect to the criteria?</em></li><li><em>if I need more information, how can I get it?</em></li></ul><figure class="kg-card kg-image-card kg-width-full"><img src="https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-06-01-at-5.57.29-PM-copy--1-.png" class="kg-image" alt="Photograph of a two-way road in the woods" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-06-01-at-5.57.29-PM-copy--1-.png 600w"></figure><p><em>Documenting decisions in this way also builds a foundation for further choices. For example, over the years, I’ve collected training data for many different kinds of problems. When I need to select among tactics for acquiring data, having been through the process many times, I know that some of the most important criteria are (i) the time needed, (ii) the number of examples, (iii) accuracy of the labels, (iv) how representative the input distribution is, and (v) cost.</em></p><p><em>If I’m making a decision as part of a team, I check with teammates at each step to make sure we’re accurately capturing the top options, criteria, and so on. (The comments feature in Google Docs is a great way to facilitate open debate within a team.) This helps me avoid losing track of some criteria and acting based on an incomplete set; for example, picking the satellite office’s location based only on the availability of talent. It also helps align everyone on the final decision.</em></p><p><em>As you may know, I wound up setting up a satellite office in Colombia because of the availability of talent and a supportive ecosystem of partners. The team there has become a key part of many projects. Lately I’ve worried about their wellbeing amid Covid-19 and widespread unrest. But in hindsight, setting up in Colombia was one of my best decisions, and I remain as committed as ever to supporting my friends there.</em></p><p><em>Keep learning!</em><br><em><br>Andrew</em></p><p></p><h2 id="news">News</h2><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2021/06/Kargu-Redo-2.gif" class="kg-image" alt="A group of drones flying over a field" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2021/06/Kargu-Redo-2.gif 600w"></figure><h2 id="deadly-drones-act-alone">Deadly Drones Act Alone</h2><p>Autonomous weapons are often viewed as an alarming potential consequence of advances in AI — but they may already have been used in combat.</p><p><strong>What’s new:</strong> Libyan forces unleashed armed drones capable of choosing their own targets against a breakaway rebel faction last year, said a recent United Nations (UN) <a href="https://undocs.org/S/2021/229?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">report</a>. The document, a letter from the organization’s Panel of Experts on Libya to the president of the Security Council, does not specify whether the drones targeted, attacked, or killed anyone. It was brought to light by <a href="https://www.newscientist.com/article/2278852-drones-may-have-attacked-humans-fully-autonomously-for-the-first-time/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek"><em>New Scientist</em></a>.</p><p><strong>Killer robots:</strong> In March of 2020, amid Libya’s ongoing civil war, the UN-supported Government of National Accord allegedly attacked retreating rebel forces using <a href="https://www.stm.com.tr/en/kargu-autonomous-tactical-multi-rotor-attack-uav?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">Kargu-2</a> quadcopters manufactured by Turkish company STM.</p><ul><li>The fliers are equipped with object-detection and face-recognition algorithms to find and strike targets without explicit human direction.</li><li>Upon acquiring a target, the drone flies directly at it and detonates a small warhead just before impact.</li><li>STM <a href="https://www.newscientist.com/article/2217171-autonomous-killer-drones-set-to-be-used-by-turkey-in-syria/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">claims</a> that its systems can distinguish soldiers from civilians.</li><li>The Turkish military bought at least 500 such units for use in its border conflict with Syria. STM is negotiating sales to three other nations, according to <a href="https://www.forbes.com/sites/davidhambling/2020/06/17/turkish-military-to-receive-500-swarming-kamikaze-drones/?sh=1e718075251a&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek"><em>Forbes</em></a>.</li></ul><p><strong>Behind the news:</strong> Many nations use machine learning in their armed forces, usually to bolster existing systems, typically with a human in the loop.</p><ul><li>In the most recent battle between Israel and Palestinians in Gaza, the Israeli Defense Force <a href="https://www.jpost.com/arab-israeli-conflict/gaza-news/guardian-of-the-walls-the-first-ai-war-669371?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">deployed</a> machine learning systems that analyzed streams of incoming intelligence. The analysis helped its air force identify targets and warn ground troops about incoming attacks.</li><li>The U.S. Army is <a href="https://www.thedefensepost.com/2021/01/26/ssci-ai-enabled-drone/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">testing</a> a drone that uses computer vision to identify targets up to a kilometer away and determine whether they’re armed.</li><li>The European Union has <a href="https://www.sciencemag.org/news/2020/12/europe-hopes-new-rd-fund-will-boost-meager-defense-capabilities-and-create?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">funded</a> several AI-powered military projects including <a href="https://ec.europa.eu/commission/presscorner/detail/en/fs_20_1094?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">explosive device detection</a> and <a href="https://ec.europa.eu/commission/presscorner/detail/en/fs_20_1095?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">small unmanned ground vehicles</a> that follow foot soldiers through rough terrain.</li></ul><p><strong>Why it matters:</strong> Observers have long warned that deploying lethal autonomous weapons  on the battlefield could ignite an arms race of deadly machines that decide for themselves who to kill. Assuming the UN report is accurate, the skirmish in Libya appears to have set a precedent.</p><p><strong>We’re thinking:</strong> Considering the problems that have emerged in using today’s AI for critical processes like deploying police, sentencing convicts, and making loans, it’s clear that the technology simply should not be used to make life-and-death decisions. We urge all nations and the UN to develop <a href="https://www.hrw.org/report/2020/08/10/stopping-killer-robots/country-positions-banning-fully-autonomous-weapons-and?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek#">rules</a> to ensure that the world never sees a real AI war.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2021/06/ezgif.com-gif-maker---2021-05-04T162716.343-2.gif" class="kg-image" alt="Architecture of vision-language tasks" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2021/06/ezgif.com-gif-maker---2021-05-04T162716.343-2.gif 600w"></figure><h2 id="one-model-for-vision-language">One Model for Vision-Language</h2><p>Researchers have proposed task-agnostic architectures for <a href="https://arxiv.org/abs/2103.00020?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">image classification tasks</a> and <a href="https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">language tasks</a>. New work proposes a single architecture for vision-language tasks.<br><br><strong>What’s new:</strong> Led by Tanmay Gupta, researchers at the Allen Institute for AI and University of Illinois at Urbana-Champaign designed a general-purpose vision architecture and built a system, <a href="https://arxiv.org/abs/2104.00743?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">GPV-I</a>, that can perform visual question answering, image captioning, object localization, and image classification.<br><br><strong>Key insight:</strong> Model architectures usually are designed for specific tasks, which implies certain types of output. To classify ImageNet, for instance, you need 1,000 outputs, one for each class. But text can describe both tasks and outputs. Take classification: the task “Describe this image” leads to the output, “this image is a dog.” By generating a representation of text that describes a task, a model can learn to perform a variety of tasks and output text that completes it without task-specific alterations in its architecture.<br><br><strong>How it works:</strong> Given a text description of a task — say, “describe the image” — and an image, GPV-I generates separate representations of the text and image, determines their relative importance to one another, and outputs a relevant text response and a copy of the image with bounding boxes. The authors trained it on <a href="https://cocodataset.org/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">COCO</a> image captioning, <a href="https://visualqa.org/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">VQA</a> question answering, and <a href="https://arxiv.org/abs/1608.00272v3?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">RefCOCO+</a> object localization datasets.</p><ul><li>The system uses <a href="https://arxiv.org/abs/1810.04805?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">BERT</a> to produce a representation of the task. It extracts an initial image representation using a <a href="https://arxiv.org/abs/1512.03385?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">ResNet-50</a> and passes it to a transformer borrowed from <a href="https://arxiv.org/abs/2005.12872?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">DETR</a>. The transformer splits the representation into a grid, each cell of which contains a representation for the corresponding location in the image.</li><li>A so-called cross-modal module accepts the representations of the image (one for each grid cell) and text (that is, the task) and produces new ones that reflect their relationship. It uses <a href="https://arxiv.org/abs/1908.02265?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">co-attention</a> between transformer layers to compare image and text representations and a sigmoid layer to compute the relevance of the image representations to the task. Then it weights each image representation by its relevance.</li><li>An image decoder uses the DETR representations to generate a bounding box for each object detected and the relevance scores to select which boxes to draw over the image. The text decoder (a transformer) uses the BERT representations and weighted representations to generate text output.</li></ul><p><strong>Results:</strong> The researchers evaluated GPV-I on COCO classification, COCO captioning, and VQA question answering. They compared its performance with models trained for those tasks. On classification, GPV-I achieved accuracy of 83.6 percent, while a ResNet-50 achieved 83.3 percent. On captioning, GPV-I achieved 1.023 <a href="https://arxiv.org/abs/1411.5726?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">CIDEr-D</a> — a measure of the similarity of generated and ground-truth captions, higher is better — compared to a <a href="https://arxiv.org/abs/1909.11059?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">VLP</a>’s 0.961 CIDEr-D. On question answering, GPV-I achieved 62.5 percent accuracy compared to ViLBERT’s score of 60.1 percent, based on the output’s similarity to a human answer.<br><br><strong>Why it matters:</strong> A single architecture that can learn several tasks should be able to share concepts between tasks. For example, a model trained both to detect iguanas in images and to answer questions about other topics might be able to describe what these creatures look like even if they weren’t represented in the question-answering portion of the training data.<br><br><strong>We’re thinking:</strong> Visual classification, image captioning, and visual questioning answering are a start. We look forward to seeing how this approach performs on more varied tasks.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2021/06/radiology-redo-2.gif" class="kg-image" alt="X-rays and charts about AI use in radiology" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2021/06/radiology-redo-2.gif 600w"></figure><h2 id="radiologists-eye-ai">Radiologists Eye AI</h2><p>AI lately has achieved dazzling success interpreting X-rays and other medical imagery in the lab. Now it’s catching on in the clinic.</p><p><strong>What’s new:</strong> Roughly one-third of U.S. radiologists use AI in some form in their work, according to a <a href="https://www.jacr.org/article/S1546-1440(21)00293-3/fulltext?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">survey</a> by the American College of Radiology. One caveat: Many who responded positively may use older — and <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2443369?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">questionable</a> — computer-aided detection, a technique for diagnosing breast cancer that dates to the 1980s, rather than newer methods.</p><p><strong>What they found:</strong> The organization queried its membership via email and received 1,861 responses.</p><ul><li>Of respondents who said they use AI, just over half use it to interpret images, and another 11 percent for image enhancement. The most common applications were breast (45.7 percent), thoracic (36.2 percent), and neurological (30.1 percent) imaging.</li><li>12 percent of AI users said they use the technology to manage work lists, 11 percent to manage operations.</li><li>Nearly 10 percent of AI users built their own algorithms rather than buying from outside vendors.</li><li>94 percent of AI users said their systems perform inconsistently. Around 6 percent said they always work, and 2 percent said they never work.</li><li>More than two thirds of respondents said they don’t use AI, and 80 percent of those said they see no benefit in it. Many believe that the technology is too expensive to implement, would hamper productivity, or wouldn’t be reimbursed.</li></ul><p><strong>Behind the news:</strong> AI’s role in medical imaging is still taking shape, as <a href="https://pubs.rsna.org/doi/full/10.1148/ryai.2019190058?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">detailed</a> by Stanford radiology professor Curtis Langlotz in the journal <em>Radiology: Artificial Intelligence</em>. In 2016, a prominent oncologist <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5070532/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">wrote</a> in the <em>New England Journal of Medicine</em>, “machine learning will displace much of the work of radiologists.” Two years later, <a href="https://hbr.org/2018/03/ai-will-change-radiology-but-it-wont-replace-radiologists?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener"><em>Harvard Business Review</em></a> published a doctor-penned essay headlined, “AI Will Change Radiology, but It Won’t Replace Radiologists.” <em>Radiology Business</em> recently asked, “Will AI replace radiologists?” and <a href="https://www.radiologybusiness.com/topics/artificial-intelligence/wait-will-ai-replace-radiologists-after-all?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">concluded</a>, “Yes. No. Maybe. It depends.”</p><p><strong>Why it matters:</strong> AI’s recent progress in medical imaging is impressive. Although the reported 30 percent penetration rate probably includes approaches that have been uses for decades, radiologists are on their way to realizing the technology’s promise.</p><p><strong>We’re thinking:</strong> One-third down, two-thirds to go! Machine learning engineers can use such findings to understand what radiologists need and develop better systems for them.</p><hr><h3 id="a-message-from-deeplearningai">A MESSAGE FROM <a href="https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io">DEEPLEARNING.AI</a></h3><figure class="kg-card kg-image-card"><a href="https://www.coursera.org/specializations/practical-data-science?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2021/06/Specialization-Name--1-.png" class="kg-image" alt loading="lazy" width="1200" height="630" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2021/06/Specialization-Name--1-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2021/06/Specialization-Name--1-.png 1000w, https://dl-staging-website.ghost.io/content/images/2021/06/Specialization-Name--1-.png 1200w" sizes="(min-width: 720px) 720px"></a></figure><p>We’re proud to launch <em>Practical Data Science</em>, in partnership with Amazon Web Services (AWS)! This new specialization will help you develop the practical skills to deploy data science projects effectively and overcome machine learning challenges using Amazon SageMaker. <a href="https://www.coursera.org/specializations/practical-data-science?ref=dl-staging-website.ghost.io">Enroll now</a></p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2021/06/tesla-redo_orange-background-2.gif" class="kg-image" alt="Animation showing Tesla car's vision system" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2021/06/tesla-redo_orange-background-2.gif 600w"></figure><h2 id="tesla-all-in-for-computer-vision">Tesla All-In For Computer Vision</h2><p>Tesla is abandoning radar in favor of a self-driving system that relies entirely on cameras.</p><p><strong>What’s new:</strong> The electric car maker <a href="https://www.tesla.com/support/transitioning-tesla-vision?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">announced</a> it will no longer include radar sensors on Model 3 sedans and Model Y compact SUVs sold in North America. Tesla is the only major manufacturer of autonomous vehicles to bet solely on computer vision. Most others rely on a combination of lidar, radar, and cameras.</p><p><strong>How it works:</strong> Tesla has dropped radar only in the U.S. and only in its two most popular models. It aims to gather data and refine the technology before making the change in Model S, Model X, and vehicles sold outside the U.S.</p><ul><li>The eight-camera system called Tesla Vision will provide sensory input for Autopilot driver-assistance features such as lane controls as well as the Full Self-Driving upgrade, which automatically parks and summons vehicles, slows for stop signals, and automates highway driving. Such features will be “limited or inactive” during the transition.</li><li>The move comes on the heels of earlier statements that touted cameras. “When radar and vision disagree, which one do you believe?” Musk said in a <a href="https://twitter.com/elonmusk/status/1380796939151704071?s=20&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">tweet</a> on April 10. “Vision has much more precision, so better to double down on vision than do sensor fusion.”</li><li>CEO Elon Musk <a href="https://electrek.co/2021/04/29/elon-musk-tesla-next-full-self-driving-beta-update-will-blow-your-mind/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">predicted</a> that Tesla Vision would help the company’s vehicles achieve full autonomy by the end of 2021. (Musk has a <a href="https://www.roadandtrack.com/news/a35350331/checking-in-on-all-the-promises-elon-musk-and-tesla-have-made/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">history</a> of declaring ambitious goals his company has failed to meet.)</li></ul><p><strong>Behind the news:</strong> Some people in the self-driving car industry favor using relatively expensive lidar and radar sensors in addition to low-cost cameras because they provide more information and thus greater safety. Camera-only advocates counter that humans can drive safely perceiving only images, so we should build AI that does the same. Most companies working on autonomous vehicles have chosen the more expensive route  as the fastest way to reach full autonomy safely. Once they get there, the thinking goes, they can attend to bringing the cost down.</p><p><strong>Why it matters:</strong> If Tesla’s bet on cameras pays off, it could have an outsize influence on future self-driving technology.</p><p><strong>We’re thinking:</strong> While it’s great to see ambitious plans to commercialize computer vision, Tesla’s initiative will require tests on public streets. That means countless drivers will be the company’s unwitting test subjects — a situation that, as ever, demands strong oversight by road-safety authorities.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2021/06/PROTEIN-1-2.gif" class="kg-image" alt="Protein structures" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2021/06/PROTEIN-1-2.gif 600w"></figure><h2 id="what-ai-knows-about-proteins">What AI Knows About Proteins</h2><p>Transformer models trained on sequences of amino acids that form proteins have had success <a href="https://arxiv.org/abs/1906.08230?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">classifying</a> and <a href="https://www.biorxiv.org/content/10.1101/2020.07.12.199554v1?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">generating</a> viable sequences. New research shows that they also capture information about protein structure.</p><p><strong>What’s new:</strong> Transformers can encode the grammar of amino acids in a sequence the same way they do the grammar of words in a language. Jesse Vig and colleagues at Salesforce Research and University of Illinois at Urbana-Champaign developed <a href="https://openreview.net/forum?id=YWtLZvLmud7&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">methods</a> to interpret such models that reveal biologically relevant properties.</p><p><strong>Key insight:</strong>  When amino acids bind to one another, the sequence folds into a shape that determines the resulting protein’s biological functions. In a transformer trained on such sequences, a high self-attention value between two amino acids can indicate that they play a significant role in the protein’s structure. For instance, the protein’s folds may bring them into contact.</p><p><strong><strong>How it works: </strong></strong>The authors studied a <a href="https://arxiv.org/abs/1810.04805?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">BERT</a> pretrained on a <a href="https://academic.oup.com/nar/article/47/D1/D427/5144153?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">database of amino acid sequences</a> to predict masked amino acids based on others in the sequence. Given a sequence, they studied the self-attention values in each layer of the model.</p><ul><li>For each sequence in the dataset, the authors filtered out self-attention values below a threshold to find amino acid pairs with strong relationships. Consulting information in the database, they tallied the number of relationships associated with a given property of the protein’s shape (for example, pairs of amino acids in contact).</li><li>Some properties depended on only one amino acid in a pair. For example, an amino acid may be part of the protein site that binds to molecules such as drugs. (The authors counted such relationships if the second amino acid had the property in question.)</li></ul><p><strong>Results:</strong> The authors compared their model’s findings with those reported in other <a href="https://papers.nips.cc/paper/2019/hash/37f65c068b7723cd7809ee2d31d7861c-Abstract.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">protein</a> <a href="https://papers.nips.cc/paper/2019/hash/37f65c068b7723cd7809ee2d31d7861c-Abstract.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek">databases</a>. The deeper layers of the model showed an increasing proportion of related pairs in which the amino acids actually were in contact, up to 44.7 percent, while the proportion of all amino acids in contact was 1.3 percent. The chance that the second amino acid in a related pair was part of a binding site didn’t rise steadily across layers, but it reached 48.2 percent, compared to a 4.8 percent chance that any amino acid was part of a binding site.</p><p><strong>Why it matters:</strong> A transformer model trained only to predict missing amino acids in a sequence learned important things about how amino acids form a larger structure. Interpreting self-attention values reveals not only how a model works but also how nature works.</p><p><strong>We’re thinking:</strong> Such tools might provide insight into the structure of viral proteins, helping biologists discover ways to fight viruses including SARS-CoV-2 more effectively.</p><hr><h3 id="a-message-from-deeplearningai-1">A MESSAGE FROM <a href="https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io">DEEPLEARNING.AI</a></h3><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2021/06/The-Batch-Image--3--1.png" class="kg-image" alt loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2021/06/The-Batch-Image--3--1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2021/06/The-Batch-Image--3--1.png 1000w, https://dl-staging-website.ghost.io/content/images/2021/06/The-Batch-Image--3--1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><a href="https://aixrealworld.eventbrite.com/?aff=batch&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">Join us</a> for a live virtual event on June 9, 2021! Experts from <a href="https://omdena.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek" rel="noopener">Omdena</a> will walk through two AI case studies: “Real Life: Understanding the Causes and Effects of Student Debt through Machine Learning” and “AI for Energy: Transitioning Toward a Sustainable Energy System.”</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://bit.ly/3YTVMir"><div class="absolute inset-0" data-gtm-event-title="Generative AI for Software Development"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-94/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-94/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-94/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm223" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-94","id":"60bfddae274d5b003b1062f2","uuid":"2b0e4b26-7b0e-4e7e-8604-2a0afbbbd48c","title":"The Batch: Autonomous Weapons Used in Combat, Tesla Doubles Down on Computer Vision, Transformers Decipher Proteins","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eIn school, most questions have only one right answer. But elsewhere, decisions often come down to a difficult choice among imperfect options. I’d like to share with you some approaches that have helped me make such decisions.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWhen I was deciding where to set up a satellite office outside the U.S., there were many options. My team and I started by listing important criteria such as supply of talent, availability of local partners, safety and rule of law, availability of visas, and cost. Then we evaluated different options against these criteria and built a matrix with cities along one axis and our criteria along the other. That clarified which country would make a great choice.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWhen I feel stuck, I find it helpful to write out my thoughts:\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003eWhat options am I choosing among?\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eWhat criteria are driving the choice?\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eHow does each option rate with respect to the criteria?\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eif I need more information, how can I get it?\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card kg-width-full\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-06-01-at-5.57.29-PM-copy--1-.png\" class=\"kg-image\" alt=\"Photograph of a two-way road in the woods\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-06-01-at-5.57.29-PM-copy--1-.png 600w\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eDocumenting decisions in this way also builds a foundation for further choices. For example, over the years, I’ve collected training data for many different kinds of problems. When I need to select among tactics for acquiring data, having been through the process many times, I know that some of the most important criteria are (i) the time needed, (ii) the number of examples, (iii) accuracy of the labels, (iv) how representative the input distribution is, and (v) cost.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eIf I’m making a decision as part of a team, I check with teammates at each step to make sure we’re accurately capturing the top options, criteria, and so on. (The comments feature in Google Docs is a great way to facilitate open debate within a team.) This helps me avoid losing track of some criteria and acting based on an incomplete set; for example, picking the satellite office’s location based only on the availability of talent. It also helps align everyone on the final decision.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAs you may know, I wound up setting up a satellite office in Colombia because of the availability of talent and a supportive ecosystem of partners. The team there has become a key part of many projects. Lately I’ve worried about their wellbeing amid Covid-19 and widespread unrest. But in hindsight, setting up in Colombia was one of my best decisions, and I remain as committed as ever to supporting my friends there.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003cbr\u003e\u003cem\u003e\u003cbr\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"news\"\u003eNews\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2021/06/Kargu-Redo-2.gif\" class=\"kg-image\" alt=\"A group of drones flying over a field\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2021/06/Kargu-Redo-2.gif 600w\"\u003e\u003c/figure\u003e\u003ch2 id=\"deadly-drones-act-alone\"\u003eDeadly Drones Act Alone\u003c/h2\u003e\u003cp\u003eAutonomous weapons are often viewed as an alarming potential consequence of advances in AI — but they may already have been used in combat.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Libyan forces unleashed armed drones capable of choosing their own targets against a breakaway rebel faction last year, said a recent United Nations (UN) \u003ca href=\"https://undocs.org/S/2021/229?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003ereport\u003c/a\u003e. The document, a letter from the organization’s Panel of Experts on Libya to the president of the Security Council, does not specify whether the drones targeted, attacked, or killed anyone. It was brought to light by \u003ca href=\"https://www.newscientist.com/article/2278852-drones-may-have-attacked-humans-fully-autonomously-for-the-first-time/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003e\u003cem\u003eNew Scientist\u003c/em\u003e\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKiller robots:\u003c/strong\u003e In March of 2020, amid Libya’s ongoing civil war, the UN-supported Government of National Accord allegedly attacked retreating rebel forces using \u003ca href=\"https://www.stm.com.tr/en/kargu-autonomous-tactical-multi-rotor-attack-uav?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003eKargu-2\u003c/a\u003e quadcopters manufactured by Turkish company STM.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe fliers are equipped with object-detection and face-recognition algorithms to find and strike targets without explicit human direction.\u003c/li\u003e\u003cli\u003eUpon acquiring a target, the drone flies directly at it and detonates a small warhead just before impact.\u003c/li\u003e\u003cli\u003eSTM \u003ca href=\"https://www.newscientist.com/article/2217171-autonomous-killer-drones-set-to-be-used-by-turkey-in-syria/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003eclaims\u003c/a\u003e that its systems can distinguish soldiers from civilians.\u003c/li\u003e\u003cli\u003eThe Turkish military bought at least 500 such units for use in its border conflict with Syria. STM is negotiating sales to three other nations, according to \u003ca href=\"https://www.forbes.com/sites/davidhambling/2020/06/17/turkish-military-to-receive-500-swarming-kamikaze-drones/?sh=1e718075251a\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003e\u003cem\u003eForbes\u003c/em\u003e\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Many nations use machine learning in their armed forces, usually to bolster existing systems, typically with a human in the loop.\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn the most recent battle between Israel and Palestinians in Gaza, the Israeli Defense Force \u003ca href=\"https://www.jpost.com/arab-israeli-conflict/gaza-news/guardian-of-the-walls-the-first-ai-war-669371?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003edeployed\u003c/a\u003e machine learning systems that analyzed streams of incoming intelligence. The analysis helped its air force identify targets and warn ground troops about incoming attacks.\u003c/li\u003e\u003cli\u003eThe U.S. Army is \u003ca href=\"https://www.thedefensepost.com/2021/01/26/ssci-ai-enabled-drone/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003etesting\u003c/a\u003e a drone that uses computer vision to identify targets up to a kilometer away and determine whether they’re armed.\u003c/li\u003e\u003cli\u003eThe European Union has \u003ca href=\"https://www.sciencemag.org/news/2020/12/europe-hopes-new-rd-fund-will-boost-meager-defense-capabilities-and-create?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003efunded\u003c/a\u003e several AI-powered military projects including \u003ca href=\"https://ec.europa.eu/commission/presscorner/detail/en/fs_20_1094?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003eexplosive device detection\u003c/a\u003e and \u003ca href=\"https://ec.europa.eu/commission/presscorner/detail/en/fs_20_1095?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003esmall unmanned ground vehicles\u003c/a\u003e that follow foot soldiers through rough terrain.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Observers have long warned that deploying lethal autonomous weapons  on the battlefield could ignite an arms race of deadly machines that decide for themselves who to kill. Assuming the UN report is accurate, the skirmish in Libya appears to have set a precedent.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Considering the problems that have emerged in using today’s AI for critical processes like deploying police, sentencing convicts, and making loans, it’s clear that the technology simply should not be used to make life-and-death decisions. We urge all nations and the UN to develop \u003ca href=\"https://www.hrw.org/report/2020/08/10/stopping-killer-robots/country-positions-banning-fully-autonomous-weapons-and?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek#\"\u003erules\u003c/a\u003e to ensure that the world never sees a real AI war.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2021/06/ezgif.com-gif-maker---2021-05-04T162716.343-2.gif\" class=\"kg-image\" alt=\"Architecture of vision-language tasks\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2021/06/ezgif.com-gif-maker---2021-05-04T162716.343-2.gif 600w\"\u003e\u003c/figure\u003e\u003ch2 id=\"one-model-for-vision-language\"\u003eOne Model for Vision-Language\u003c/h2\u003e\u003cp\u003eResearchers have proposed task-agnostic architectures for \u003ca href=\"https://arxiv.org/abs/2103.00020?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eimage classification tasks\u003c/a\u003e and \u003ca href=\"https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003elanguage tasks\u003c/a\u003e. New work proposes a single architecture for vision-language tasks.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Led by Tanmay Gupta, researchers at the Allen Institute for AI and University of Illinois at Urbana-Champaign designed a general-purpose vision architecture and built a system, \u003ca href=\"https://arxiv.org/abs/2104.00743?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eGPV-I\u003c/a\u003e, that can perform visual question answering, image captioning, object localization, and image classification.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e Model architectures usually are designed for specific tasks, which implies certain types of output. To classify ImageNet, for instance, you need 1,000 outputs, one for each class. But text can describe both tasks and outputs. Take classification: the task “Describe this image” leads to the output, “this image is a dog.” By generating a representation of text that describes a task, a model can learn to perform a variety of tasks and output text that completes it without task-specific alterations in its architecture.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e Given a text description of a task — say, “describe the image” — and an image, GPV-I generates separate representations of the text and image, determines their relative importance to one another, and outputs a relevant text response and a copy of the image with bounding boxes. The authors trained it on \u003ca href=\"https://cocodataset.org/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eCOCO\u003c/a\u003e image captioning, \u003ca href=\"https://visualqa.org/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eVQA\u003c/a\u003e question answering, and \u003ca href=\"https://arxiv.org/abs/1608.00272v3?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eRefCOCO+\u003c/a\u003e object localization datasets.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe system uses \u003ca href=\"https://arxiv.org/abs/1810.04805?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eBERT\u003c/a\u003e to produce a representation of the task. It extracts an initial image representation using a \u003ca href=\"https://arxiv.org/abs/1512.03385?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eResNet-50\u003c/a\u003e and passes it to a transformer borrowed from \u003ca href=\"https://arxiv.org/abs/2005.12872?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eDETR\u003c/a\u003e. The transformer splits the representation into a grid, each cell of which contains a representation for the corresponding location in the image.\u003c/li\u003e\u003cli\u003eA so-called cross-modal module accepts the representations of the image (one for each grid cell) and text (that is, the task) and produces new ones that reflect their relationship. It uses \u003ca href=\"https://arxiv.org/abs/1908.02265?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eco-attention\u003c/a\u003e between transformer layers to compare image and text representations and a sigmoid layer to compute the relevance of the image representations to the task. Then it weights each image representation by its relevance.\u003c/li\u003e\u003cli\u003eAn image decoder uses the DETR representations to generate a bounding box for each object detected and the relevance scores to select which boxes to draw over the image. The text decoder (a transformer) uses the BERT representations and weighted representations to generate text output.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The researchers evaluated GPV-I on COCO classification, COCO captioning, and VQA question answering. They compared its performance with models trained for those tasks. On classification, GPV-I achieved accuracy of 83.6 percent, while a ResNet-50 achieved 83.3 percent. On captioning, GPV-I achieved 1.023 \u003ca href=\"https://arxiv.org/abs/1411.5726?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eCIDEr-D\u003c/a\u003e — a measure of the similarity of generated and ground-truth captions, higher is better — compared to a \u003ca href=\"https://arxiv.org/abs/1909.11059?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eVLP\u003c/a\u003e’s 0.961 CIDEr-D. On question answering, GPV-I achieved 62.5 percent accuracy compared to ViLBERT’s score of 60.1 percent, based on the output’s similarity to a human answer.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e A single architecture that can learn several tasks should be able to share concepts between tasks. For example, a model trained both to detect iguanas in images and to answer questions about other topics might be able to describe what these creatures look like even if they weren’t represented in the question-answering portion of the training data.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Visual classification, image captioning, and visual questioning answering are a start. We look forward to seeing how this approach performs on more varied tasks.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2021/06/radiology-redo-2.gif\" class=\"kg-image\" alt=\"X-rays and charts about AI use in radiology\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2021/06/radiology-redo-2.gif 600w\"\u003e\u003c/figure\u003e\u003ch2 id=\"radiologists-eye-ai\"\u003eRadiologists Eye AI\u003c/h2\u003e\u003cp\u003eAI lately has achieved dazzling success interpreting X-rays and other medical imagery in the lab. Now it’s catching on in the clinic.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Roughly one-third of U.S. radiologists use AI in some form in their work, according to a \u003ca href=\"https://www.jacr.org/article/S1546-1440(21)00293-3/fulltext?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003esurvey\u003c/a\u003e by the American College of Radiology. One caveat: Many who responded positively may use older — and \u003ca href=\"https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2443369?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003equestionable\u003c/a\u003e — computer-aided detection, a technique for diagnosing breast cancer that dates to the 1980s, rather than newer methods.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat they found:\u003c/strong\u003e The organization queried its membership via email and received 1,861 responses.\u003c/p\u003e\u003cul\u003e\u003cli\u003eOf respondents who said they use AI, just over half use it to interpret images, and another 11 percent for image enhancement. The most common applications were breast (45.7 percent), thoracic (36.2 percent), and neurological (30.1 percent) imaging.\u003c/li\u003e\u003cli\u003e12 percent of AI users said they use the technology to manage work lists, 11 percent to manage operations.\u003c/li\u003e\u003cli\u003eNearly 10 percent of AI users built their own algorithms rather than buying from outside vendors.\u003c/li\u003e\u003cli\u003e94 percent of AI users said their systems perform inconsistently. Around 6 percent said they always work, and 2 percent said they never work.\u003c/li\u003e\u003cli\u003eMore than two thirds of respondents said they don’t use AI, and 80 percent of those said they see no benefit in it. Many believe that the technology is too expensive to implement, would hamper productivity, or wouldn’t be reimbursed.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e AI’s role in medical imaging is still taking shape, as \u003ca href=\"https://pubs.rsna.org/doi/full/10.1148/ryai.2019190058?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003edetailed\u003c/a\u003e by Stanford radiology professor Curtis Langlotz in the journal \u003cem\u003eRadiology: Artificial Intelligence\u003c/em\u003e. In 2016, a prominent oncologist \u003ca href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5070532/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003ewrote\u003c/a\u003e in the \u003cem\u003eNew England Journal of Medicine\u003c/em\u003e, “machine learning will displace much of the work of radiologists.” Two years later, \u003ca href=\"https://hbr.org/2018/03/ai-will-change-radiology-but-it-wont-replace-radiologists?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003e\u003cem\u003eHarvard Business Review\u003c/em\u003e\u003c/a\u003e published a doctor-penned essay headlined, “AI Will Change Radiology, but It Won’t Replace Radiologists.” \u003cem\u003eRadiology Business\u003c/em\u003e recently asked, “Will AI replace radiologists?” and \u003ca href=\"https://www.radiologybusiness.com/topics/artificial-intelligence/wait-will-ai-replace-radiologists-after-all?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003econcluded\u003c/a\u003e, “Yes. No. Maybe. It depends.”\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e AI’s recent progress in medical imaging is impressive. Although the reported 30 percent penetration rate probably includes approaches that have been uses for decades, radiologists are on their way to realizing the technology’s promise.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e One-third down, two-thirds to go! Machine learning engineers can use such findings to understand what radiologists need and develop better systems for them.\u003c/p\u003e\u003chr\u003e\u003ch3 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM \u003ca href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\"\u003eDEEPLEARNING.AI\u003c/a\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.coursera.org/specializations/practical-data-science?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2021/06/Specialization-Name--1-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1200\" height=\"630\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2021/06/Specialization-Name--1-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2021/06/Specialization-Name--1-.png 1000w, https://dl-staging-website.ghost.io/content/images/2021/06/Specialization-Name--1-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eWe’re proud to launch \u003cem\u003ePractical Data Science\u003c/em\u003e, in partnership with Amazon Web Services (AWS)! This new specialization will help you develop the practical skills to deploy data science projects effectively and overcome machine learning challenges using Amazon SageMaker. \u003ca href=\"https://www.coursera.org/specializations/practical-data-science?ref=dl-staging-website.ghost.io\"\u003eEnroll now\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2021/06/tesla-redo_orange-background-2.gif\" class=\"kg-image\" alt=\"Animation showing Tesla car's vision system\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2021/06/tesla-redo_orange-background-2.gif 600w\"\u003e\u003c/figure\u003e\u003ch2 id=\"tesla-all-in-for-computer-vision\"\u003eTesla All-In For Computer Vision\u003c/h2\u003e\u003cp\u003eTesla is abandoning radar in favor of a self-driving system that relies entirely on cameras.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e The electric car maker \u003ca href=\"https://www.tesla.com/support/transitioning-tesla-vision?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003eannounced\u003c/a\u003e it will no longer include radar sensors on Model 3 sedans and Model Y compact SUVs sold in North America. Tesla is the only major manufacturer of autonomous vehicles to bet solely on computer vision. Most others rely on a combination of lidar, radar, and cameras.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e Tesla has dropped radar only in the U.S. and only in its two most popular models. It aims to gather data and refine the technology before making the change in Model S, Model X, and vehicles sold outside the U.S.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe eight-camera system called Tesla Vision will provide sensory input for Autopilot driver-assistance features such as lane controls as well as the Full Self-Driving upgrade, which automatically parks and summons vehicles, slows for stop signals, and automates highway driving. Such features will be “limited or inactive” during the transition.\u003c/li\u003e\u003cli\u003eThe move comes on the heels of earlier statements that touted cameras. “When radar and vision disagree, which one do you believe?” Musk said in a \u003ca href=\"https://twitter.com/elonmusk/status/1380796939151704071?s=20\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003etweet\u003c/a\u003e on April 10. “Vision has much more precision, so better to double down on vision than do sensor fusion.”\u003c/li\u003e\u003cli\u003eCEO Elon Musk \u003ca href=\"https://electrek.co/2021/04/29/elon-musk-tesla-next-full-self-driving-beta-update-will-blow-your-mind/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003epredicted\u003c/a\u003e that Tesla Vision would help the company’s vehicles achieve full autonomy by the end of 2021. (Musk has a \u003ca href=\"https://www.roadandtrack.com/news/a35350331/checking-in-on-all-the-promises-elon-musk-and-tesla-have-made/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003ehistory\u003c/a\u003e of declaring ambitious goals his company has failed to meet.)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Some people in the self-driving car industry favor using relatively expensive lidar and radar sensors in addition to low-cost cameras because they provide more information and thus greater safety. Camera-only advocates counter that humans can drive safely perceiving only images, so we should build AI that does the same. Most companies working on autonomous vehicles have chosen the more expensive route  as the fastest way to reach full autonomy safely. Once they get there, the thinking goes, they can attend to bringing the cost down.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e If Tesla’s bet on cameras pays off, it could have an outsize influence on future self-driving technology.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e While it’s great to see ambitious plans to commercialize computer vision, Tesla’s initiative will require tests on public streets. That means countless drivers will be the company’s unwitting test subjects — a situation that, as ever, demands strong oversight by road-safety authorities.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2021/06/PROTEIN-1-2.gif\" class=\"kg-image\" alt=\"Protein structures\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2021/06/PROTEIN-1-2.gif 600w\"\u003e\u003c/figure\u003e\u003ch2 id=\"what-ai-knows-about-proteins\"\u003eWhat AI Knows About Proteins\u003c/h2\u003e\u003cp\u003eTransformer models trained on sequences of amino acids that form proteins have had success \u003ca href=\"https://arxiv.org/abs/1906.08230?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003eclassifying\u003c/a\u003e and \u003ca href=\"https://www.biorxiv.org/content/10.1101/2020.07.12.199554v1?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003egenerating\u003c/a\u003e viable sequences. New research shows that they also capture information about protein structure.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Transformers can encode the grammar of amino acids in a sequence the same way they do the grammar of words in a language. Jesse Vig and colleagues at Salesforce Research and University of Illinois at Urbana-Champaign developed \u003ca href=\"https://openreview.net/forum?id=YWtLZvLmud7\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003emethods\u003c/a\u003e to interpret such models that reveal biologically relevant properties.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e  When amino acids bind to one another, the sequence folds into a shape that determines the resulting protein’s biological functions. In a transformer trained on such sequences, a high self-attention value between two amino acids can indicate that they play a significant role in the protein’s structure. For instance, the protein’s folds may bring them into contact.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e\u003cstrong\u003eHow it works: \u003c/strong\u003e\u003c/strong\u003eThe authors studied a \u003ca href=\"https://arxiv.org/abs/1810.04805?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003eBERT\u003c/a\u003e pretrained on a \u003ca href=\"https://academic.oup.com/nar/article/47/D1/D427/5144153?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003edatabase of amino acid sequences\u003c/a\u003e to predict masked amino acids based on others in the sequence. Given a sequence, they studied the self-attention values in each layer of the model.\u003c/p\u003e\u003cul\u003e\u003cli\u003eFor each sequence in the dataset, the authors filtered out self-attention values below a threshold to find amino acid pairs with strong relationships. Consulting information in the database, they tallied the number of relationships associated with a given property of the protein’s shape (for example, pairs of amino acids in contact).\u003c/li\u003e\u003cli\u003eSome properties depended on only one amino acid in a pair. For example, an amino acid may be part of the protein site that binds to molecules such as drugs. (The authors counted such relationships if the second amino acid had the property in question.)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The authors compared their model’s findings with those reported in other \u003ca href=\"https://papers.nips.cc/paper/2019/hash/37f65c068b7723cd7809ee2d31d7861c-Abstract.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003eprotein\u003c/a\u003e \u003ca href=\"https://papers.nips.cc/paper/2019/hash/37f65c068b7723cd7809ee2d31d7861c-Abstract.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\"\u003edatabases\u003c/a\u003e. The deeper layers of the model showed an increasing proportion of related pairs in which the amino acids actually were in contact, up to 44.7 percent, while the proportion of all amino acids in contact was 1.3 percent. The chance that the second amino acid in a related pair was part of a binding site didn’t rise steadily across layers, but it reached 48.2 percent, compared to a 4.8 percent chance that any amino acid was part of a binding site.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e A transformer model trained only to predict missing amino acids in a sequence learned important things about how amino acids form a larger structure. Interpreting self-attention values reveals not only how a model works but also how nature works.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Such tools might provide insight into the structure of viral proteins, helping biologists discover ways to fight viruses including SARS-CoV-2 more effectively.\u003c/p\u003e\u003chr\u003e\u003ch3 id=\"a-message-from-deeplearningai-1\"\u003eA MESSAGE FROM \u003ca href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\"\u003eDEEPLEARNING.AI\u003c/a\u003e\u003c/h3\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2021/06/The-Batch-Image--3--1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2021/06/The-Batch-Image--3--1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2021/06/The-Batch-Image--3--1.png 1000w, https://dl-staging-website.ghost.io/content/images/2021/06/The-Batch-Image--3--1.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003ca href=\"https://aixrealworld.eventbrite.com/?aff=batch\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eJoin us\u003c/a\u003e for a live virtual event on June 9, 2021! Experts from \u003ca href=\"https://omdena.com/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8rPiUKAGj2EQ7PgIpZWy_iTw2M4VPGg3DXbElMRU95WB-xeSv0l5NgxduJtvNu5L0kVbek\" rel=\"noopener\"\u003eOmdena\u003c/a\u003e will walk through two AI case studies: “Real Life: Understanding the Causes and Effects of Student Debt through Machine Learning” and “AI for Energy: Transitioning Toward a Sustainable Energy System.”\u003c/p\u003e","comment_id":"60b8702b41c1d6004ba45230","feature_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-06-01-at-5.57.29-PM-copy--1--2.png","featured":false,"visibility":"public","created_at":"2021-06-02T23:01:15.000-07:00","updated_at":"2022-10-06T07:28:29.000-07:00","published_at":"2021-06-02T12:00:00.000-07:00","custom_excerpt":"In school, most questions have only one right answer. But elsewhere, decisions often come down to a difficult choice among imperfect options. I’d like to share with you some approaches that have helped me make such decisions.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"60bfddad274d5b003b1062af","name":"issue-94","slug":"issue-94","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-94/"},{"id":"63125964a679c0004d519c3d","name":"Jun 02, 2021","slug":"jun-02-2021","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/jun-02-2021/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-94/","excerpt":"In school, most questions have only one right answer. But elsewhere, decisions often come down to a difficult choice among imperfect options. I’d like to share with you some approaches that have helped me make such decisions.","reading_time":11,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Autonomous Weapons Used in Combat, Tesla Doubles Down on Computer","meta_description":"The Batch - AI News \u0026 Insights: Deadly Drones Act Alone | One Model for Vision-Language | Radiologists Eye AI | Tesla All-In For Computer Vision...","email_subject":null,"frontmatter":null,"feature_image_alt":"Photograph of a two-way road in the woods","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/06/Screen-Shot-2021-06-01-at-5.57.29-PM-copy--1--2.png","dimensions":{"width":600,"height":338}},"banner":{"title":"Generative AI for Software Development","databaseId":35156,"id":"cG9zdDozNTE1Ng==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/08/Vertical-side-banner-ads-5.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3YTVMir","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-94"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>