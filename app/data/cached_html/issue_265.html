<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Hallucination Index, AI-Powered Policing Goes National, Explainable LLMs, and more...</title><meta name="description" content="The Batch AI News and Insights: Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-265/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Hallucination Index, AI-Powered Policing Goes National, Explainable LLMs, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch AI News and Insights: Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Hallucination Index, AI-Powered Policing Goes National, Explainable LLMs, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-265/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2024-09-04T17:02:00.000-07:00"/><meta property="article:modified_time" content="2024-09-05T15:40:51.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-265"/><meta property="article:tag" content="Sep 04, 2024"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Hallucination Index, AI-Powered Policing Goes National, Explainable LLMs, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch AI News and Insights: Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-265/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5-.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5-.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="675"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2024-09-04T17:02:00.000-07:00","dateModified":"2024-09-05T15:40:51.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Hallucination Index, AI-Powered Policing Goes National, Explainable LLMs, and more...","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5-.png","width":1200,"height":675},"publisher":{"@type":"Organization","name":"Hallucination Index, AI-Powered Policing Goes National, Explainable LLMs, and more...","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch AI News and Insights: Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-265/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 265</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Sep 5, 2024</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">13<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/sep-04-2024/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Sep 04, 2024</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">13<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-265/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-265/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-265/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p>Dear friends,</p><p>Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw there in government, business, and academia, the nation is well positioned to become a strong AI hub. When he asked me if I would advise South Korea as a member of the Global AI Strategy Steering Group of the country’s National AI Committee, I agreed on the spot. I was delighted to learn this week that Yann LeCun has also joined.&nbsp;I’ve been consistently impressed by the thoughtful approach the Korean government has taken toward AI, with an emphasis on investment and innovation and a realistic understanding of risks without being distracted by science-fiction scenarios of harm.</p><p>I’ve advised many countries to build AI for the sectors where they’re strong. For example, I felt that by investing in sectors like tourism and certain industries,&nbsp;<a href="https://www.deeplearning.ai/the-batch/thailands-ai-push/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener">Thailand</a>&nbsp;can do projects more efficiently than I can in Silicon Valley. South Korea’s tech ecosystem gives it a foundation to move even faster across multiple sectors. This emphasizes the long-term value for countries to become good at tech, because tech is now pervasive and affects all industries.</p><p>Korea has a very strong local software ecosystem. For example, the dominant search engine is not Google or Bing, but Naver (a Korean company). The dominant messaging system is not WhatsApp or WeChat, but KakaoTalk. With local tech giants Naver and Kakao offering email, mobile payment, cloud computing, ride sharing, and other services, the country has many sophisticated tech businesses. Additionally, SK hynix and Samsung are advanced semiconductor manufacturers. It also has a thriving entrepreneurship ecosystem, including Upstage, a language modeling startup, which taught a course with us on “<a href="https://www.deeplearning.ai/short-courses/pretraining-llms/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener">Pretraining LLMs</a>.” Finally, the Korean institutions Seoul National University, which I visited last year, and KAIST have global reputations.</p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5--1.png" class="kg-image" alt="NG YEOL" loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/09/unnamed--5--1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/09/unnamed--5--1.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5--1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Korea has a highly educated population, highly skilled software engineers, and a thriving set of software products. This gives it a fantastic foundation to embrace the next generation of AI. After meeting with businesses in retail, construction, insurance, cosmetics, telecoms, and other industries, I was delighted by the wide variety of opportunities many companies are pursuing across different industry sectors.</p><p>Lastly, Korea is known globally for its K-pop. Meeting&nbsp;<a href="https://n.news.naver.com/article/011/0004386078?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener">Bang Si-Hyuk</a>, the chairman of HYBE, which manages the superstar singing group BTS, and learning how the company operates was a real treat! (Another treat was eating at a Korean eel house, where the seafood was unforgettable.)</p><p>That’s why I’ve traveled to South Korea four times since last year. My venture studio AI Fund, which collaborates with many Korean companies, has benefited tremendously from the advice of many South Koreans, including Taizo Son, Changmook Kang, Hyungjun Kim, Sung Kim, JP Lee, Ian Park, and Alice Oh. I look forward to doing more in, and with, South Korea!</p><p>화이팅 (Let’s go)!</p><p>Andrew</p><p>P.S. We just released the final two courses of&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener"><em>AI Python for Beginners</em></a>! The complete set of four courses is now available and remains free for a limited time. If you know someone who is considering learning to code, please recommend these courses! They teach how to (a) write code using AI-assistance, which is where the field is going, and (b) take advantage of generative AI, which allows you to do valuable things quickly.&nbsp;Since releasing the first two courses, I’ve been inspired by many learner stories like&nbsp;<a href="https://www.linkedin.com/pulse/my-first-python-programs-ai-beginners-course-julia-kryuchkova-2ft9e/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74" rel="noopener">this one</a>. Julia K. started with&nbsp;<em>AI Python for Beginners</em>&nbsp;and shortly afterward wrote useful program after useful program. (She accomplished this before we had even finished releasing all four courses!)&nbsp;I hope many others will have similar stories to tell.</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74"><img src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--6-.png" class="kg-image" alt="AI Python for Beginners." loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/09/unnamed--6-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/09/unnamed--6-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--6-.png 1200w" sizes="(min-width: 720px) 720px"></a></figure><p>The final courses of Andrew Ng’s&nbsp;<em>AI Python for Beginners</em>&nbsp;are live! Work on hands-on projects to analyze data, automate tasks, create reusable functions, and extend Python with third-party tools.&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Join for free today!</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed.gif" class="kg-image" alt="Throughput and latency at different context lengths" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed.gif 600w"></figure><h1 id="long-context-gets-up-to-speed">Long Context Gets Up to Speed</h1><p>A new open weights model generates tokens faster than current transformers, especially when processing long inputs.<br><br><strong>What’s new:&nbsp;</strong>AI21 Labs released&nbsp;<a href="https://arxiv.org/pdf/2408.12570?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Jamba 1.5</a>, an update of its earlier&nbsp;<a href="https://arxiv.org/pdf/2403.19887?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Jamba</a>. It comes in&nbsp;<a href="https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Mini</a>&nbsp;and&nbsp;<a href="https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Large</a>&nbsp;versions and boasts a relatively large (and validated) input context length of 256,000 tokens. The model weights are&nbsp;<a href="https://www.ai21.com/licenses/jamba-open-model-license?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">free</a>&nbsp;to users who have annual recurring revenue under $50 million and available on several cloud platforms including Google Cloud Vertex AI, Hugging Face, and Microsoft Azure.<br><br><strong>How it works:</strong>&nbsp;Jamba 1.5 is a hybrid architecture made up of transformer,&nbsp;<a href="https://www.deeplearning.ai/the-batch/mamba-a-new-approach-that-may-outperform-transformers/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">mamba</a>, and&nbsp;<a href="https://arxiv.org/abs/1701.06538?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">mixture of experts</a>&nbsp;(MoE) layers. Unlike transformer layers, in which processing power scales quadratically as input length increases, the mamba layers enable the required processing power to scale linearly as input length increases without requiring workarounds like sparse attention and sliding windows. The MoE layers are composed of many fully connected sublayers, of which only a small number are used to process a given input. Jamba 1.5 Mini has roughly 50 billion parameters but uses only 12 billion at a time, while Jamba 1.5 Large has around 400 billion parameters but uses only 94 billion at a time.&nbsp;</p><ul><li>The authors pretrained Jamba 1.5 on a proprietary dataset of web documents, code, books, and scientific articles. They further pretrained it on a higher proportion of longer documents to increase its ability to process long-text inputs.</li><li>They fine-tuned Jamba 1.5 on generated data to handle specific types of input such as instructions, conversations, longer documents, question-answer pairs, and calls to external tools.&nbsp;</li><li>Unlike transformer-based models, Jamba 1.5 showed no benefit from positional embeddings of input tokens, so it doesn’t use them.</li></ul><p><strong>Results:</strong>&nbsp;Both versions of Jamba 1.5 produced output tokens faster than other models (running on identical hardware), especially given longer inputs. However, the larger version achieved lower performance on popular benchmarks than other open models.</p><ul><li>With 262,144 tokens as input, Jamba 1.5 Mini generated about 62 tokens per second, LLaMA 3.1 8B generated about 41, and Mixtral generated about 39. The difference became narrower as input length decreased.&nbsp;With 4,096 tokens as input, Jamba 1.5 Mini generated around 78 tokens per second, LLaMA 3.1 8B generated about 79, and Mixtral 8x7B generated about 60.&nbsp;</li><li>Both models performed extraordinarily well on&nbsp;<a href="https://arxiv.org/abs/2404.06654?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">RULER</a>, a suite of 13 tasks that assess the ability of large language models to take advantage of input context at various lengths. Jamba 1.5 Mini and Large utilized their full context length, while many competing models utilized half or less.&nbsp;</li><li>Across 11 popular benchmarks, Jamba 1.5 Mini performed similarly to LLaMA 3.1 8B and Gemma 2 9B. However, Jamba 1.5 Large achieved lower performance than LLaMA 3.1 70B and Mistral Large 2 123B on nearly every benchmark.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;The mamba architecture, which is designed to enable processing to scale linearly with longer input lengths, has been a subject of much research since its release in late 2023. Notably,&nbsp;<a href="https://arxiv.org/abs/2405.21060?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Mamba-2</a>,&nbsp;<a href="https://arxiv.org/abs/2406.07887?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Mamba-2-Hybrid</a>, and&nbsp;<a href="https://arxiv.org/abs/2405.16712/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Zamba</a>&nbsp;combined mamba layers with attention layers with varying degrees of success.<br><br><strong>Why it matters:&nbsp;</strong>The original&nbsp;<a href="https://arxiv.org/abs/2312.00752?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Mamba</a>&nbsp;model was much faster and equally accurate compared to transformers up to 2.8 billion parameters. But how the mamba architecture compared to transformers at larger scales was an open question. Jamba 1.5 shows that the combination of mamba and transformer layers can yield higher speed in larger models — although the results don’t yet exceed those of comparably sized transformers.<br><br><strong>We’re thinking:</strong>&nbsp;While hardware companies like Groq and SambaNova are accelerating LLMs, software innovations like Jamba may enable further speed-ups.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--3-.gif" class="kg-image" alt="Short, Medium and Long Context RAG" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/09/unnamed--3-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/09/unnamed--3-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--3-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="models-ranked-for-hallucinations">Models Ranked for Hallucinations</h1><p>How often do large language models make up information when they generate text based on a retrieved document? A study evaluated the tendency of popular models to hallucinate while performing retrieval-augmented generation (RAG).&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Galileo, which offers a platform for evaluating AI models,&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_X-3qgyTW7lCdLW6lZ3kHVjRKLW8dZ8LNW89jxTJ6rN9_7W1bZ0x-1gbTZqVzr5v05RJb05W5G1zs95HSw3-W6B7cf12VlGRPN8jblyw5SFNyN8DhQdtPDjr7N96YXktJh2Z5VN4zt55xx36YW2q1S8m8M66-SW5_KFG05lhlx8W7LHpc43DR4jJW5w13F51VbMbbN4Qxr7Lp4mgjW8-tbCw5_bV3DW2_Nhc315DykjN1jf7VvyFq9_W3QN7hY7fc_tFW8FNhZR3CvMLYW5kjCl65GXxKRVCPJvB2mK3cRVFCLNW1PC5qlW18MPRm6bqhz5f2GlGNg04?ref=dl-staging-website.ghost.io" rel="noopener">tested</a>&nbsp;22 models to see whether they hallucinated after retrieving information from documents of various lengths. Claude 3.5 Sonnet was the overall winner, and most models performed best when retrieving information from medium-length documents.</p><p><strong>How it works:</strong>&nbsp;The researchers tested 10 closed and 12 open models based on their sizes and popularity. They ran each model 20 times using short, medium, and long context lengths (a total of 60 tests) using GPT-4o to evaluate how closely the output text adhered to the context.&nbsp;</p><ul><li>The researchers selected text from four public and two proprietary datasets for short-context tests (less than 5,000 tokens each). They chose longer documents from private companies for medium- and long-context tests. They split these documents into passages of 5,000, 10,000, 15,000, 20,000, and 25,000 tokens for medium-context tests, and 40,000, 60,000, 80,000, and 100,000 tokens for long-context tests.</li><li>For each test, they fed a prompt and a related document to a model. The prompt asked the model to retrieve particular information from the document.</li><li>They fed the prompt and response to Galileo’s&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_YT3qgyTW95jsWP6lZ3l-W2dkmwn8mX4S0Vs6zhD2gWDXxW3jPLSj2YT3NyN7Wxrn0dwlX4W2H72gs3Dl3bXW8_hGWW1cwdWMN29S9XN_p351W37KH-Q3ccvmQN2t3sfvm8VcCW8hkBsk5fh3HhW3MnLxJ7494lYW7QtLml2tcggcW3cwbG21RZlqpN923rhJHG26SW1w0s9w3hRD67W6VzWQc5Q3h-VW13x6W-83BPPFN2mX6G1HCDy_W4l7y8q7qbDZ-W6k1SFb1D5SLkW5MJysF7x_zz-Vh7JcJ8S3nQJW8FL0bP960LfgW6ytSR11l-PwHW7CR8vn3wJdtbW5PrVDw94FCnBW2WD61z44krp1W7r-ZbQ9byw7wW2K9pCK2hf3SzW1FtWkk1MPycff6WryFs04?ref=dl-staging-website.ghost.io" rel="noopener">ChainPoll</a>&nbsp;hallucination detection tool. ChainPoll queries a model (in this case, GPT-4o) multiple times using&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_XH3qgyTW6N1vHY6lZ3nyW2tVsG-7PzMF-W6SjJ9y1LNqtdW4fpz__37BS1JW3VqkmN50QXSPW8fqww07sc6jfW9gjGyq4WdZqTW1cvwlP2FdLqKW425lf_3sh_H7W64kZXQ5R33-pW4d__9h4_NlwZW7Rnpr03m64q5W3qQ8nJ42Hd7SW542FpH3dG2XHN8jyCPhxQyY5W321bld5yq9x3W1GHBqT8sqT2PVVFQRD7scLD0MRWDgHttm4zW1kdvqX9dVr9mVrdG-Z64-4_-W5TfyFW1V9qSLW7Y3lJx7gs9vSf1rXWJb04?ref=dl-staging-website.ghost.io" rel="noopener">chain-of-thought prompting</a>&nbsp;to return a score of either 1 (the response is directly supported by the context document) or 0 (the response is not supported by the context document). They tallied each model’s average scores for each context length and averaged those to produce a final score.</li></ul><p><strong>Results:</strong>&nbsp;Anthropic’s Claude 3.5 Sonnet ranked highest overall, achieving 0.97 in short context lengths and 1.0 in medium and long context lengths.</p><ul><li>Among models with open weights, Qwen2-72b Instruct scored highest for short (0.95) and medium (1.0) context lengths. The researchers singled out Gemini 1.5 Flash for high performance (0.94, 1.0, and 0.92 for short, medium, and long context lengths respectively) at low cost.</li><li>Most models performed best in medium context lengths, which the report calls the “sweet spot for most LLMs.”</li></ul><p><strong>Behind the news:</strong>&nbsp;Galileo performed similar&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_X-3qgyTW7lCdLW6lZ3pMW2hxz0T1G81JQVdHHnW9gH8ZkW3BfhnQ4z3DkPW65363_8h1MmlVcjSqt8w4F2qW6CJ9Xs2fVZYrV2Jclk6L_DwyW8gdXgL46mdyzW58sMYC45mC2fW5yjTf_6zSBVYW7sSsgL8pbnrfW3-q6G21VhvQtW34Kqbf2BS92PW7r6tgQ9hZDdNW3KQVFH3mXD76W1cbN6h7NLb_YW4HL1L572053RW58FLd37Qqr2MVSKLKJ2vTrhPW2cXXC_7G-GtBW1DYlGB7Rs0lSW6JcKlF928B6bW4F7hW14jjfC3V3CJMg49KJLZf7L8dcT04?ref=dl-staging-website.ghost.io" rel="noopener">tests</a>&nbsp;last year, when it compared performance in both RAG and non-RAG settings (without differentiating among context lengths). GPT-4 and GPT-3.5 held the top three spots in both settings despite strong showings by Llama 2 and Zephyr 7B. However, the top scores were lower (between 0.70 and 0.77).</p><p><strong>Why it matters:</strong>&nbsp;Model builders have reduced hallucinations, but the difference between rare falsehoods and none at all may be critical in some applications.</p><p><strong>We’re thinking:</strong>&nbsp;It’s curious that medium-length RAG contexts generally yielded fewer hallucinations than short or long. Maybe we should give models more context than we think they need.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--7-.jpg" class="kg-image" alt="Argentina-NeuralNetwork" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/09/unnamed--7-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/09/unnamed--7-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--7-.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="ai-powered-policing-goes-national">AI-Powered Policing Goes National</h1><p>Argentina created a national law-enforcement department that will use AI to detect crimes as they’re committed, investigate them afterward, and predict them before they occur.</p><p><strong>What’s new:</strong>&nbsp;President Javier Milei of Argentina established the&nbsp;Artificial Intelligence Unit Applied to Security (UIAAS),&nbsp;<em>The Register</em>&nbsp;<a href="https://www.theregister.com/2024/08/01/argentina_crime_prediction/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">reported</a>. The unit aims to detect, investigate, and predict criminal activity by using machine learning algorithms to monitor the internet, wireless communications, security cameras, drone surveillance, financial transactions, and other data in real time.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Milei&nbsp;established the UIAAS in a late-July&nbsp;<a href="https://www.boletinoficial.gob.ar/detalleAviso/primera/311381/20240729?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">resolution</a>. Milei created it under the Ministry of Security shortly after he&nbsp;<a href="https://buenosairesherald.com/politics/presidency-transforms-spy-agency-afi-into-secretariat-to-grant-it-more-power?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">reorganized</a>&nbsp;the national intelligence agency to give himself more direct control. In December, his security minister&nbsp;<a href="https://www.theguardian.com/world/2023/dec/17/argentina-president-javier-milei-security-guidelines-protests-currency-devaluation?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">quashed</a>&nbsp;public protests against his austerity policies; he promised to identify protesters via “video, digital, or manual means” and bill them for the cost of policing the demonstrations.</p><ul><li>The UIAAS is empowered to “use machine learning algorithms to analyze historical crime data to predict future crimes and help prevent them.” This approach “will significantly improve the efficiency of the different areas of the ministry and of the federal police and security forces, allowing for faster and more precise responses to threats and emergencies,” the resolution states.&nbsp;</li><li>The resolution notes that Argentina is not alone among nations in using AI for law enforcement. It cites China, France, India, Israel, Singapore, the United Kingdom, and the United States as “pioneers in the use of Artificial Intelligence in their areas of government and Security Forces.”</li><li>The new unit is part of a broader cost-cutting effort that aims to replace government workers and organizations with AI systems,&nbsp;<a href="https://english.elpais.com/international/2024-07-30/javier-mileis-government-will-monitor-social-media-with-ai-to-predict-future-crimes.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">according to</a>&nbsp;<em>El Pais</em>, a news outlet based in Madrid.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;Argentina’s government is a presidential representative democratic republic. The country was ruled by a military dictatorship between 1976 and 1983.&nbsp;</p><ul><li>A&nbsp;<a href="https://pulitzercenter.org/stories/twisted-eye-sky-over-buenos-aires?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">report</a>&nbsp;by the Pulitzer Center, which sponsors independent reporting on global issues, found that, between 2019 and 2020, a face recognition network in the Argentine capital city of Buenos Aires overreached its mission to track only fugitives and led to at least 140 errors that culminated in mistaken arrests or police checks. In 2022, a judge ruled the system unconstitutional and shut it down. City officials are trying to overturn the decision.</li><li>However, Buenos Aires has used AI successfully in its criminal justice system. A rule-based system designed to prepare court opinions&nbsp;<a href="https://publications.iadb.org/es/prometea-transformando-la-administracion-de-justicia-con-herramientas-de-inteligencia-artificial?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">shortened</a>&nbsp;the process of presenting evidence for consideration in a trial from 90 minutes to 1 minute and the time to process injunctions from 190 days to 42 days, according to the Inter-American Development Bank.</li></ul><p><strong>Why it matters:</strong>&nbsp;AI has valuable uses in law enforcement and security. At the same time, it needs to be applied responsibly and implemented in a way that’s fair and respectful of legal rights such as presumption of innocence.</p><p><strong>We’re thinking:</strong>&nbsp;Surveillance is easy to abuse, and the notion of predictive policing warrants extreme caution to avoid bias against certain groups, violating civil rights, and other pitfalls. Ensuring that it’s used well requires robust technology, rigid controls, clear oversight, and public transparency. We hope that Argentina — no less than the countries that inspired it establish a national AI police agency — will put strong safeguards in place.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--4-.gif" class="kg-image" alt="Gemma Scope 2" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--4-.gif 600w"></figure><h1 id="making-llms-explainable">Making LLMs Explainable</h1><p>Researchers have probed the inner workings of individual layers of large language models. A new tool applies this approach to all layers.</p><p><strong>What’s new:</strong>&nbsp;Tom Lieberum and colleagues at Google released&nbsp;<a href="https://storage.googleapis.com/gemma-scope/gemma-scope-report.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Gemma Scope</a>, a system designed to illuminate how each layer in Gemma 2-family large language models responds to a given input token. Gemma Scope is available for the 9 billion-parameter and newly released 2 billion-parameter versions of Gemma 2. You can play with an&nbsp;<a href="https://www.neuronpedia.org/gemma-scope?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23#microscope" rel="noopener">interactive demo</a>&nbsp;or download the&nbsp;<a href="https://huggingface.co/google/gemma-scope?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">weights</a>.</p><p><strong>Key insight:</strong>&nbsp;A sparse autoencoder (SAE) is a sparse neural network that learns to reconstruct its input. The authors drew on earlier research into using SAEs to interpret neural networks.&nbsp;</p><ul><li>To see what a neural network layer knows about a given input token, you can feed it the token and study the embedding it generates. The difficulty with this approach is that the value at each index of the embedding may represent a tangle of concepts that are associated with many other values — too many other values to track.&nbsp;</li><li>Instead, an SAE can transform the embedding into one in which each index corresponds to a distinct concept. The SAE can learn to represent the embedding by the weighted sum of a much larger number of vectors than the number of values in the embedding. However, each weighted sum has only a small number of non-zero weights — in other words, each embedding is expressed as only a small-number, or sparse, subset of the SAE vectors. Since the number of learned SAE vectors is far greater than the number of values in the original embedding, any given vector is more likely to represent a distinct concept than any value in the original embedding.&nbsp;</li><li>The weights of this sum are interpretable: Each weight represents how strongly the corresponding concept is represented in the input. Given a token, the SAE’s first layer produces these weights.</li></ul><p><strong>How it works:</strong>&nbsp;The authors built over 400 SAEs, one for each layer of Gemma 2 2B and Gemma 2 9B. They fed Gemma 2 examples from its pretraining set and extracted the resulting embeddings at each layer. Given the resulting embeddings from a specific layer, an SAE learned to reconstruct each of them. An additional loss term minimized the number of non-zero outputs from the SAE’s first layer to help ensure that the SAE used only concepts related to the embedding. To interpret an embedding produced by the first layer of the SAE, the team labeled the embedding’s indices with their corresponding concepts. They used two main methods: manual and automatic.&nbsp;</p><ul><li>Manual labeling: (1)&nbsp;<a href="https://github.com/google-deepmind/mishax?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">Insert the SAE</a>&nbsp;in the appropriate location in Gemma 2. (2) Prompt Gemma 2. (3) Select an index in the embedding from the SAE’s first layer. (4) Note which token(s) cause the value at that index to be high. (5) Label the index manually based on commonalities between the noted tokens.</li><li>Automatic labeling: This was similar to manual labeling, but GPT4o-mini labeled the indices based on commonalities between the noted tokens.&nbsp;</li><li>In addition to testing how Gemma 2 responds to particular input tokens, Gemma Scope can be used to steer the model; that is, to see how the model responds when it’s forced to generate text related (or unrelated) to a particular concept: (1) Search the index labels to determine which index corresponds to the concept in question. (2) Insert the corresponding SAE into Gemma 2 at the appropriate layer. (3) Prompt the modified Gemma 2 to generate text, adjusting the output of the SAE’s first layer at the index. Gemma 2’s text should reflect the changed value.</li></ul><p><strong>Behind the news:</strong>&nbsp;Earlier research into using SAEs to interpret neural networks was limited to&nbsp;<a href="https://arxiv.org/abs/2405.14860?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">interpreting a single layer</a>&nbsp;or a&nbsp;<a href="https://arxiv.org/abs/2309.08600?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">small network</a>. Earlier this year, Anthropic used an SAE to&nbsp;<a href="https://transformer-circuits.pub/2024/scaling-monosemanticity/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23#scaling-to-sonnet" rel="noopener">interpret Claude 3 Sonnet’s middle layer</a>, building on an earlier report in which they interpreted a&nbsp;<a href="https://transformer-circuits.pub/2023/monosemantic-features/index.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">single-layer transformer</a>.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Many questions about how LLMs work have yet to be answered: How does fine-tuning change the way a model represents an input? What happens inside a model during chain-of-thought prompting versus unstructured prompting? Training an SAE for each layer is a step toward developing ways to answer these questions.</p><p><strong>We’re thinking:</strong>&nbsp;In 2017, researchers&nbsp;<a href="https://distill.pub/2017/feature-visualization/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23" rel="noopener">visualized</a>&nbsp;the layers of a convolutional neural network to show that the deeper the layer, the more complex the concepts it learned. We’re excited by the prospect that SAEs can deliver similar insights with respect to transformers.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://bit.ly/3YX9G3n"><div class="absolute inset-0" data-gtm-event-title="AI Python for Beginners"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-265/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-265/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-265/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm74" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-265","id":"66d8efb898bf2a0001c49677","uuid":"bb798686-bfbd-46af-940e-2abab4aeea74","title":"Hallucination Index, AI-Powered Policing Goes National, Explainable LLMs, Faster Processing for Longer Inputs","html":"\u003cp\u003eDear friends,\u003c/p\u003e\u003cp\u003eRecently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw there in government, business, and academia, the nation is well positioned to become a strong AI hub. When he asked me if I would advise South Korea as a member of the Global AI Strategy Steering Group of the country’s National AI Committee, I agreed on the spot. I was delighted to learn this week that Yann LeCun has also joined.\u0026nbsp;I’ve been consistently impressed by the thoughtful approach the Korean government has taken toward AI, with an emphasis on investment and innovation and a realistic understanding of risks without being distracted by science-fiction scenarios of harm.\u003c/p\u003e\u003cp\u003eI’ve advised many countries to build AI for the sectors where they’re strong. For example, I felt that by investing in sectors like tourism and certain industries,\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/thailands-ai-push/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74\" rel=\"noopener\"\u003eThailand\u003c/a\u003e\u0026nbsp;can do projects more efficiently than I can in Silicon Valley. South Korea’s tech ecosystem gives it a foundation to move even faster across multiple sectors. This emphasizes the long-term value for countries to become good at tech, because tech is now pervasive and affects all industries.\u003c/p\u003e\u003cp\u003eKorea has a very strong local software ecosystem. For example, the dominant search engine is not Google or Bing, but Naver (a Korean company). The dominant messaging system is not WhatsApp or WeChat, but KakaoTalk. With local tech giants Naver and Kakao offering email, mobile payment, cloud computing, ride sharing, and other services, the country has many sophisticated tech businesses. Additionally, SK hynix and Samsung are advanced semiconductor manufacturers. It also has a thriving entrepreneurship ecosystem, including Upstage, a language modeling startup, which taught a course with us on “\u003ca href=\"https://www.deeplearning.ai/short-courses/pretraining-llms/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74\" rel=\"noopener\"\u003ePretraining LLMs\u003c/a\u003e.” Finally, the Korean institutions Seoul National University, which I visited last year, and KAIST have global reputations.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5--1.png\" class=\"kg-image\" alt=\"NG YEOL\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/09/unnamed--5--1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/09/unnamed--5--1.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5--1.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eKorea has a highly educated population, highly skilled software engineers, and a thriving set of software products. This gives it a fantastic foundation to embrace the next generation of AI. After meeting with businesses in retail, construction, insurance, cosmetics, telecoms, and other industries, I was delighted by the wide variety of opportunities many companies are pursuing across different industry sectors.\u003c/p\u003e\u003cp\u003eLastly, Korea is known globally for its K-pop. Meeting\u0026nbsp;\u003ca href=\"https://n.news.naver.com/article/011/0004386078?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74\" rel=\"noopener\"\u003eBang Si-Hyuk\u003c/a\u003e, the chairman of HYBE, which manages the superstar singing group BTS, and learning how the company operates was a real treat! (Another treat was eating at a Korean eel house, where the seafood was unforgettable.)\u003c/p\u003e\u003cp\u003eThat’s why I’ve traveled to South Korea four times since last year. My venture studio AI Fund, which collaborates with many Korean companies, has benefited tremendously from the advice of many South Koreans, including Taizo Son, Changmook Kang, Hyungjun Kim, Sung Kim, JP Lee, Ian Park, and Alice Oh. I look forward to doing more in, and with, South Korea!\u003c/p\u003e\u003cp\u003e화이팅 (Let’s go)!\u003c/p\u003e\u003cp\u003eAndrew\u003c/p\u003e\u003cp\u003eP.S. We just released the final two courses of\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74\" rel=\"noopener\"\u003e\u003cem\u003eAI Python for Beginners\u003c/em\u003e\u003c/a\u003e! The complete set of four courses is now available and remains free for a limited time. If you know someone who is considering learning to code, please recommend these courses! They teach how to (a) write code using AI-assistance, which is where the field is going, and (b) take advantage of generative AI, which allows you to do valuable things quickly.\u0026nbsp;Since releasing the first two courses, I’ve been inspired by many learner stories like\u0026nbsp;\u003ca href=\"https://www.linkedin.com/pulse/my-first-python-programs-ai-beginners-course-julia-kryuchkova-2ft9e/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74\" rel=\"noopener\"\u003ethis one\u003c/a\u003e. Julia K. started with\u0026nbsp;\u003cem\u003eAI Python for Beginners\u003c/em\u003e\u0026nbsp;and shortly afterward wrote useful program after useful program. (She accomplished this before we had even finished releasing all four courses!)\u0026nbsp;I hope many others will have similar stories to tell.\u003c/p\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--QLV3stB3bwLzjBohF2UaWVwcaKjIvq6n7N_uFXp2PBA7QZzM5nYL7WtqHadARKcVGYo74\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--6-.png\" class=\"kg-image\" alt=\"AI Python for Beginners.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/09/unnamed--6-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/09/unnamed--6-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--6-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eThe final courses of Andrew Ng’s\u0026nbsp;\u003cem\u003eAI Python for Beginners\u003c/em\u003e\u0026nbsp;are live! Work on hands-on projects to analyze data, automate tasks, create reusable functions, and extend Python with third-party tools.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/ai-python-for-beginners/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eJoin for free today!\u003c/a\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed.gif\" class=\"kg-image\" alt=\"Throughput and latency at different context lengths\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"long-context-gets-up-to-speed\"\u003eLong Context Gets Up to Speed\u003c/h1\u003e\u003cp\u003eA new open weights model generates tokens faster than current transformers, especially when processing long inputs.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u0026nbsp;\u003c/strong\u003eAI21 Labs released\u0026nbsp;\u003ca href=\"https://arxiv.org/pdf/2408.12570?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eJamba 1.5\u003c/a\u003e, an update of its earlier\u0026nbsp;\u003ca href=\"https://arxiv.org/pdf/2403.19887?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eJamba\u003c/a\u003e. It comes in\u0026nbsp;\u003ca href=\"https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eMini\u003c/a\u003e\u0026nbsp;and\u0026nbsp;\u003ca href=\"https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eLarge\u003c/a\u003e\u0026nbsp;versions and boasts a relatively large (and validated) input context length of 256,000 tokens. The model weights are\u0026nbsp;\u003ca href=\"https://www.ai21.com/licenses/jamba-open-model-license?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003efree\u003c/a\u003e\u0026nbsp;to users who have annual recurring revenue under $50 million and available on several cloud platforms including Google Cloud Vertex AI, Hugging Face, and Microsoft Azure.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Jamba 1.5 is a hybrid architecture made up of transformer,\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/mamba-a-new-approach-that-may-outperform-transformers/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003emamba\u003c/a\u003e, and\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/1701.06538?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003emixture of experts\u003c/a\u003e\u0026nbsp;(MoE) layers. Unlike transformer layers, in which processing power scales quadratically as input length increases, the mamba layers enable the required processing power to scale linearly as input length increases without requiring workarounds like sparse attention and sliding windows. The MoE layers are composed of many fully connected sublayers, of which only a small number are used to process a given input. Jamba 1.5 Mini has roughly 50 billion parameters but uses only 12 billion at a time, while Jamba 1.5 Large has around 400 billion parameters but uses only 94 billion at a time.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe authors pretrained Jamba 1.5 on a proprietary dataset of web documents, code, books, and scientific articles. They further pretrained it on a higher proportion of longer documents to increase its ability to process long-text inputs.\u003c/li\u003e\u003cli\u003eThey fine-tuned Jamba 1.5 on generated data to handle specific types of input such as instructions, conversations, longer documents, question-answer pairs, and calls to external tools.\u0026nbsp;\u003c/li\u003e\u003cli\u003eUnlike transformer-based models, Jamba 1.5 showed no benefit from positional embeddings of input tokens, so it doesn’t use them.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;Both versions of Jamba 1.5 produced output tokens faster than other models (running on identical hardware), especially given longer inputs. However, the larger version achieved lower performance on popular benchmarks than other open models.\u003c/p\u003e\u003cul\u003e\u003cli\u003eWith 262,144 tokens as input, Jamba 1.5 Mini generated about 62 tokens per second, LLaMA 3.1 8B generated about 41, and Mixtral generated about 39. The difference became narrower as input length decreased.\u0026nbsp;With 4,096 tokens as input, Jamba 1.5 Mini generated around 78 tokens per second, LLaMA 3.1 8B generated about 79, and Mixtral 8x7B generated about 60.\u0026nbsp;\u003c/li\u003e\u003cli\u003eBoth models performed extraordinarily well on\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2404.06654?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eRULER\u003c/a\u003e, a suite of 13 tasks that assess the ability of large language models to take advantage of input context at various lengths. Jamba 1.5 Mini and Large utilized their full context length, while many competing models utilized half or less.\u0026nbsp;\u003c/li\u003e\u003cli\u003eAcross 11 popular benchmarks, Jamba 1.5 Mini performed similarly to LLaMA 3.1 8B and Gemma 2 9B. However, Jamba 1.5 Large achieved lower performance than LLaMA 3.1 70B and Mistral Large 2 123B on nearly every benchmark.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;The mamba architecture, which is designed to enable processing to scale linearly with longer input lengths, has been a subject of much research since its release in late 2023. Notably,\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2405.21060?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eMamba-2\u003c/a\u003e,\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2406.07887?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eMamba-2-Hybrid\u003c/a\u003e, and\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2405.16712/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eZamba\u003c/a\u003e\u0026nbsp;combined mamba layers with attention layers with varying degrees of success.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u0026nbsp;\u003c/strong\u003eThe original\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2312.00752?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eMamba\u003c/a\u003e\u0026nbsp;model was much faster and equally accurate compared to transformers up to 2.8 billion parameters. But how the mamba architecture compared to transformers at larger scales was an open question. Jamba 1.5 shows that the combination of mamba and transformer layers can yield higher speed in larger models — although the results don’t yet exceed those of comparably sized transformers.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;While hardware companies like Groq and SambaNova are accelerating LLMs, software innovations like Jamba may enable further speed-ups.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--3-.gif\" class=\"kg-image\" alt=\"Short, Medium and Long Context RAG\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/09/unnamed--3-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/09/unnamed--3-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--3-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"models-ranked-for-hallucinations\"\u003eModels Ranked for Hallucinations\u003c/h1\u003e\u003cp\u003eHow often do large language models make up information when they generate text based on a retrieved document? A study evaluated the tendency of popular models to hallucinate while performing retrieval-augmented generation (RAG).\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Galileo, which offers a platform for evaluating AI models,\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_X-3qgyTW7lCdLW6lZ3kHVjRKLW8dZ8LNW89jxTJ6rN9_7W1bZ0x-1gbTZqVzr5v05RJb05W5G1zs95HSw3-W6B7cf12VlGRPN8jblyw5SFNyN8DhQdtPDjr7N96YXktJh2Z5VN4zt55xx36YW2q1S8m8M66-SW5_KFG05lhlx8W7LHpc43DR4jJW5w13F51VbMbbN4Qxr7Lp4mgjW8-tbCw5_bV3DW2_Nhc315DykjN1jf7VvyFq9_W3QN7hY7fc_tFW8FNhZR3CvMLYW5kjCl65GXxKRVCPJvB2mK3cRVFCLNW1PC5qlW18MPRm6bqhz5f2GlGNg04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003etested\u003c/a\u003e\u0026nbsp;22 models to see whether they hallucinated after retrieving information from documents of various lengths. Claude 3.5 Sonnet was the overall winner, and most models performed best when retrieving information from medium-length documents.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The researchers tested 10 closed and 12 open models based on their sizes and popularity. They ran each model 20 times using short, medium, and long context lengths (a total of 60 tests) using GPT-4o to evaluate how closely the output text adhered to the context.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe researchers selected text from four public and two proprietary datasets for short-context tests (less than 5,000 tokens each). They chose longer documents from private companies for medium- and long-context tests. They split these documents into passages of 5,000, 10,000, 15,000, 20,000, and 25,000 tokens for medium-context tests, and 40,000, 60,000, 80,000, and 100,000 tokens for long-context tests.\u003c/li\u003e\u003cli\u003eFor each test, they fed a prompt and a related document to a model. The prompt asked the model to retrieve particular information from the document.\u003c/li\u003e\u003cli\u003eThey fed the prompt and response to Galileo’s\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_YT3qgyTW95jsWP6lZ3l-W2dkmwn8mX4S0Vs6zhD2gWDXxW3jPLSj2YT3NyN7Wxrn0dwlX4W2H72gs3Dl3bXW8_hGWW1cwdWMN29S9XN_p351W37KH-Q3ccvmQN2t3sfvm8VcCW8hkBsk5fh3HhW3MnLxJ7494lYW7QtLml2tcggcW3cwbG21RZlqpN923rhJHG26SW1w0s9w3hRD67W6VzWQc5Q3h-VW13x6W-83BPPFN2mX6G1HCDy_W4l7y8q7qbDZ-W6k1SFb1D5SLkW5MJysF7x_zz-Vh7JcJ8S3nQJW8FL0bP960LfgW6ytSR11l-PwHW7CR8vn3wJdtbW5PrVDw94FCnBW2WD61z44krp1W7r-ZbQ9byw7wW2K9pCK2hf3SzW1FtWkk1MPycff6WryFs04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eChainPoll\u003c/a\u003e\u0026nbsp;hallucination detection tool. ChainPoll queries a model (in this case, GPT-4o) multiple times using\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_XH3qgyTW6N1vHY6lZ3nyW2tVsG-7PzMF-W6SjJ9y1LNqtdW4fpz__37BS1JW3VqkmN50QXSPW8fqww07sc6jfW9gjGyq4WdZqTW1cvwlP2FdLqKW425lf_3sh_H7W64kZXQ5R33-pW4d__9h4_NlwZW7Rnpr03m64q5W3qQ8nJ42Hd7SW542FpH3dG2XHN8jyCPhxQyY5W321bld5yq9x3W1GHBqT8sqT2PVVFQRD7scLD0MRWDgHttm4zW1kdvqX9dVr9mVrdG-Z64-4_-W5TfyFW1V9qSLW7Y3lJx7gs9vSf1rXWJb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003echain-of-thought prompting\u003c/a\u003e\u0026nbsp;to return a score of either 1 (the response is directly supported by the context document) or 0 (the response is not supported by the context document). They tallied each model’s average scores for each context length and averaged those to produce a final score.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;Anthropic’s Claude 3.5 Sonnet ranked highest overall, achieving 0.97 in short context lengths and 1.0 in medium and long context lengths.\u003c/p\u003e\u003cul\u003e\u003cli\u003eAmong models with open weights, Qwen2-72b Instruct scored highest for short (0.95) and medium (1.0) context lengths. The researchers singled out Gemini 1.5 Flash for high performance (0.94, 1.0, and 0.92 for short, medium, and long context lengths respectively) at low cost.\u003c/li\u003e\u003cli\u003eMost models performed best in medium context lengths, which the report calls the “sweet spot for most LLMs.”\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Galileo performed similar\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVc07qnyPYW460KV092-pn-W44_bnN5kzqG6N1f4_X-3qgyTW7lCdLW6lZ3pMW2hxz0T1G81JQVdHHnW9gH8ZkW3BfhnQ4z3DkPW65363_8h1MmlVcjSqt8w4F2qW6CJ9Xs2fVZYrV2Jclk6L_DwyW8gdXgL46mdyzW58sMYC45mC2fW5yjTf_6zSBVYW7sSsgL8pbnrfW3-q6G21VhvQtW34Kqbf2BS92PW7r6tgQ9hZDdNW3KQVFH3mXD76W1cbN6h7NLb_YW4HL1L572053RW58FLd37Qqr2MVSKLKJ2vTrhPW2cXXC_7G-GtBW1DYlGB7Rs0lSW6JcKlF928B6bW4F7hW14jjfC3V3CJMg49KJLZf7L8dcT04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003etests\u003c/a\u003e\u0026nbsp;last year, when it compared performance in both RAG and non-RAG settings (without differentiating among context lengths). GPT-4 and GPT-3.5 held the top three spots in both settings despite strong showings by Llama 2 and Zephyr 7B. However, the top scores were lower (between 0.70 and 0.77).\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Model builders have reduced hallucinations, but the difference between rare falsehoods and none at all may be critical in some applications.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;It’s curious that medium-length RAG contexts generally yielded fewer hallucinations than short or long. Maybe we should give models more context than we think they need.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--7-.jpg\" class=\"kg-image\" alt=\"Argentina-NeuralNetwork\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/09/unnamed--7-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/09/unnamed--7-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--7-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"ai-powered-policing-goes-national\"\u003eAI-Powered Policing Goes National\u003c/h1\u003e\u003cp\u003eArgentina created a national law-enforcement department that will use AI to detect crimes as they’re committed, investigate them afterward, and predict them before they occur.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;President Javier Milei of Argentina established the\u0026nbsp;Artificial Intelligence Unit Applied to Security (UIAAS),\u0026nbsp;\u003cem\u003eThe Register\u003c/em\u003e\u0026nbsp;\u003ca href=\"https://www.theregister.com/2024/08/01/argentina_crime_prediction/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003ereported\u003c/a\u003e. The unit aims to detect, investigate, and predict criminal activity by using machine learning algorithms to monitor the internet, wireless communications, security cameras, drone surveillance, financial transactions, and other data in real time.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Milei\u0026nbsp;established the UIAAS in a late-July\u0026nbsp;\u003ca href=\"https://www.boletinoficial.gob.ar/detalleAviso/primera/311381/20240729?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eresolution\u003c/a\u003e. Milei created it under the Ministry of Security shortly after he\u0026nbsp;\u003ca href=\"https://buenosairesherald.com/politics/presidency-transforms-spy-agency-afi-into-secretariat-to-grant-it-more-power?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003ereorganized\u003c/a\u003e\u0026nbsp;the national intelligence agency to give himself more direct control. In December, his security minister\u0026nbsp;\u003ca href=\"https://www.theguardian.com/world/2023/dec/17/argentina-president-javier-milei-security-guidelines-protests-currency-devaluation?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003equashed\u003c/a\u003e\u0026nbsp;public protests against his austerity policies; he promised to identify protesters via “video, digital, or manual means” and bill them for the cost of policing the demonstrations.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe UIAAS is empowered to “use machine learning algorithms to analyze historical crime data to predict future crimes and help prevent them.” This approach “will significantly improve the efficiency of the different areas of the ministry and of the federal police and security forces, allowing for faster and more precise responses to threats and emergencies,” the resolution states.\u0026nbsp;\u003c/li\u003e\u003cli\u003eThe resolution notes that Argentina is not alone among nations in using AI for law enforcement. It cites China, France, India, Israel, Singapore, the United Kingdom, and the United States as “pioneers in the use of Artificial Intelligence in their areas of government and Security Forces.”\u003c/li\u003e\u003cli\u003eThe new unit is part of a broader cost-cutting effort that aims to replace government workers and organizations with AI systems,\u0026nbsp;\u003ca href=\"https://english.elpais.com/international/2024-07-30/javier-mileis-government-will-monitor-social-media-with-ai-to-predict-future-crimes.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eaccording to\u003c/a\u003e\u0026nbsp;\u003cem\u003eEl Pais\u003c/em\u003e, a news outlet based in Madrid.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Argentina’s government is a presidential representative democratic republic. The country was ruled by a military dictatorship between 1976 and 1983.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eA\u0026nbsp;\u003ca href=\"https://pulitzercenter.org/stories/twisted-eye-sky-over-buenos-aires?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003ereport\u003c/a\u003e\u0026nbsp;by the Pulitzer Center, which sponsors independent reporting on global issues, found that, between 2019 and 2020, a face recognition network in the Argentine capital city of Buenos Aires overreached its mission to track only fugitives and led to at least 140 errors that culminated in mistaken arrests or police checks. In 2022, a judge ruled the system unconstitutional and shut it down. City officials are trying to overturn the decision.\u003c/li\u003e\u003cli\u003eHowever, Buenos Aires has used AI successfully in its criminal justice system. A rule-based system designed to prepare court opinions\u0026nbsp;\u003ca href=\"https://publications.iadb.org/es/prometea-transformando-la-administracion-de-justicia-con-herramientas-de-inteligencia-artificial?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eshortened\u003c/a\u003e\u0026nbsp;the process of presenting evidence for consideration in a trial from 90 minutes to 1 minute and the time to process injunctions from 190 days to 42 days, according to the Inter-American Development Bank.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;AI has valuable uses in law enforcement and security. At the same time, it needs to be applied responsibly and implemented in a way that’s fair and respectful of legal rights such as presumption of innocence.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Surveillance is easy to abuse, and the notion of predictive policing warrants extreme caution to avoid bias against certain groups, violating civil rights, and other pitfalls. Ensuring that it’s used well requires robust technology, rigid controls, clear oversight, and public transparency. We hope that Argentina — no less than the countries that inspired it establish a national AI police agency — will put strong safeguards in place.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--4-.gif\" class=\"kg-image\" alt=\"Gemma Scope 2\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--4-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"making-llms-explainable\"\u003eMaking LLMs Explainable\u003c/h1\u003e\u003cp\u003eResearchers have probed the inner workings of individual layers of large language models. A new tool applies this approach to all layers.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Tom Lieberum and colleagues at Google released\u0026nbsp;\u003ca href=\"https://storage.googleapis.com/gemma-scope/gemma-scope-report.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eGemma Scope\u003c/a\u003e, a system designed to illuminate how each layer in Gemma 2-family large language models responds to a given input token. Gemma Scope is available for the 9 billion-parameter and newly released 2 billion-parameter versions of Gemma 2. You can play with an\u0026nbsp;\u003ca href=\"https://www.neuronpedia.org/gemma-scope?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23#microscope\" rel=\"noopener\"\u003einteractive demo\u003c/a\u003e\u0026nbsp;or download the\u0026nbsp;\u003ca href=\"https://huggingface.co/google/gemma-scope?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eweights\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;A sparse autoencoder (SAE) is a sparse neural network that learns to reconstruct its input. The authors drew on earlier research into using SAEs to interpret neural networks.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eTo see what a neural network layer knows about a given input token, you can feed it the token and study the embedding it generates. The difficulty with this approach is that the value at each index of the embedding may represent a tangle of concepts that are associated with many other values — too many other values to track.\u0026nbsp;\u003c/li\u003e\u003cli\u003eInstead, an SAE can transform the embedding into one in which each index corresponds to a distinct concept. The SAE can learn to represent the embedding by the weighted sum of a much larger number of vectors than the number of values in the embedding. However, each weighted sum has only a small number of non-zero weights — in other words, each embedding is expressed as only a small-number, or sparse, subset of the SAE vectors. Since the number of learned SAE vectors is far greater than the number of values in the original embedding, any given vector is more likely to represent a distinct concept than any value in the original embedding.\u0026nbsp;\u003c/li\u003e\u003cli\u003eThe weights of this sum are interpretable: Each weight represents how strongly the corresponding concept is represented in the input. Given a token, the SAE’s first layer produces these weights.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The authors built over 400 SAEs, one for each layer of Gemma 2 2B and Gemma 2 9B. They fed Gemma 2 examples from its pretraining set and extracted the resulting embeddings at each layer. Given the resulting embeddings from a specific layer, an SAE learned to reconstruct each of them. An additional loss term minimized the number of non-zero outputs from the SAE’s first layer to help ensure that the SAE used only concepts related to the embedding. To interpret an embedding produced by the first layer of the SAE, the team labeled the embedding’s indices with their corresponding concepts. They used two main methods: manual and automatic.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eManual labeling: (1)\u0026nbsp;\u003ca href=\"https://github.com/google-deepmind/mishax?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003eInsert the SAE\u003c/a\u003e\u0026nbsp;in the appropriate location in Gemma 2. (2) Prompt Gemma 2. (3) Select an index in the embedding from the SAE’s first layer. (4) Note which token(s) cause the value at that index to be high. (5) Label the index manually based on commonalities between the noted tokens.\u003c/li\u003e\u003cli\u003eAutomatic labeling: This was similar to manual labeling, but GPT4o-mini labeled the indices based on commonalities between the noted tokens.\u0026nbsp;\u003c/li\u003e\u003cli\u003eIn addition to testing how Gemma 2 responds to particular input tokens, Gemma Scope can be used to steer the model; that is, to see how the model responds when it’s forced to generate text related (or unrelated) to a particular concept: (1) Search the index labels to determine which index corresponds to the concept in question. (2) Insert the corresponding SAE into Gemma 2 at the appropriate layer. (3) Prompt the modified Gemma 2 to generate text, adjusting the output of the SAE’s first layer at the index. Gemma 2’s text should reflect the changed value.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Earlier research into using SAEs to interpret neural networks was limited to\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2405.14860?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003einterpreting a single layer\u003c/a\u003e\u0026nbsp;or a\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2309.08600?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003esmall network\u003c/a\u003e. Earlier this year, Anthropic used an SAE to\u0026nbsp;\u003ca href=\"https://transformer-circuits.pub/2024/scaling-monosemanticity/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23#scaling-to-sonnet\" rel=\"noopener\"\u003einterpret Claude 3 Sonnet’s middle layer\u003c/a\u003e, building on an earlier report in which they interpreted a\u0026nbsp;\u003ca href=\"https://transformer-circuits.pub/2023/monosemantic-features/index.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003esingle-layer transformer\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Many questions about how LLMs work have yet to be answered: How does fine-tuning change the way a model represents an input? What happens inside a model during chain-of-thought prompting versus unstructured prompting? Training an SAE for each layer is a step toward developing ways to answer these questions.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;In 2017, researchers\u0026nbsp;\u003ca href=\"https://distill.pub/2017/feature-visualization/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-8XjpMmSJNO9rhgAxXfOudBKD3Z2vm_VkDozlaIPeE3UCCo0iAaAlnKfIYjvfd5lxh_Yh23\" rel=\"noopener\"\u003evisualized\u003c/a\u003e\u0026nbsp;the layers of a convolutional neural network to show that the deeper the layer, the more complex the concepts it learned. We’re excited by the prospect that SAEs can deliver similar insights with respect to transformers.\u003c/p\u003e","comment_id":"66d8efb898bf2a0001c49677","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5-.png","featured":false,"visibility":"public","created_at":"2024-09-04T16:39:36.000-07:00","updated_at":"2024-09-05T15:40:51.000-07:00","published_at":"2024-09-04T17:02:00.000-07:00","custom_excerpt":"The Batch AI News and Insights: Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw there in government, business, and academia, the nation is well positioned to become a strong AI hub.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"66d8f5b898bf2a0001c496bb","name":"issue-265","slug":"issue-265","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-265/"},{"id":"66da132a98bf2a0001c49962","name":"Sep 04, 2024","slug":"sep-04-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/sep-04-2024/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-265/","excerpt":"The Batch AI News and Insights: Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw there in government, business, and academia, the nation is well positioned to become a strong AI hub.","reading_time":13,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Hallucination Index, AI-Powered Policing Goes National, Explainable LLMs, and more...","meta_description":"The Batch AI News and Insights: Recently I visited South Korea, where I spoke at length about AI with President Yoon Suk Yeol. Based on what I saw...","email_subject":null,"frontmatter":null,"feature_image_alt":"NG YEOL","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/09/unnamed--5-.png","dimensions":{"width":1200,"height":675}},"banner":{"title":"AI Python for Beginners","databaseId":35163,"id":"cG9zdDozNTE2Mw==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/08/1-9.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3YX9G3n","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-265"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>