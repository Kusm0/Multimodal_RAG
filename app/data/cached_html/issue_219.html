<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>AI for Brain Surgery, Microsoft&#x27;s ChatGPT Bill, Google&#x27;s Generative Phones, and more</title><meta name="description" content="The Batch - AI News &amp; Insights: I wrote earlier about how my team at AI Fund saw that GPT-3 set a new direction for building language applications..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-219/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="AI for Brain Surgery, Microsoft&#x27;s ChatGPT Bill, Google&#x27;s Generative Phones, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: I wrote earlier about how my team at AI Fund saw that GPT-3 set a new direction for building language applications..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="AI for Brain Surgery, Microsoft&#x27;s ChatGPT Bill, Google&#x27;s Generative Phones, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-219/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2023-10-18T11:40:04.000-07:00"/><meta property="article:modified_time" content="2023-10-18T11:40:04.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-219"/><meta property="article:tag" content="Oct 18, 2023"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="AI for Brain Surgery, Microsoft&#x27;s ChatGPT Bill, Google&#x27;s Generative Phones, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: I wrote earlier about how my team at AI Fund saw that GPT-3 set a new direction for building language applications..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-219/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--20-.jpg"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--20-.jpg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="675"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2023-10-18T11:40:04.000-07:00","dateModified":"2023-10-18T11:40:04.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"AI for Brain Surgery, Microsoft's ChatGPT Bill, Google's Generative Phones, and more","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--20-.jpg","width":1200,"height":675},"publisher":{"@type":"Organization","name":"AI for Brain Surgery, Microsoft's ChatGPT Bill, Google's Generative Phones, and more","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: I wrote earlier about how my team at AI Fund saw that GPT-3 set a new direction for building language applications..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-219/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 219</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Oct 18, 2023</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">13<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/oct-18-2023/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Oct 18, 2023</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">13<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-219/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-219/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-219/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,</em></p><p><em>I&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-to-spot-high-impact-technologies/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener"><em>wrote</em></a>&nbsp;earlier about how my team at AI Fund saw that GPT-3 set a new direction for building language applications, two years before ChatGPT was released. I’ll go out on a limb to make another prediction: I think we’ll see significant growth in AI, including Generative AI, applications running at the edge of the network (PC, laptop, mobile, and so on).&nbsp;</em></p><p><em>I realize this flies in the face of conventional wisdom. Most AI runs in data centers, not on edge devices. There are good reasons for this:</em></p><ul><li><em>The most powerful large language models require 100B+ parameters and massive amounts of memory even for inference (100B parameters, stored using 8- bit quantization, requires 100GB of memory).</em></li><li><em>Many businesses prefer to operate cloud-based, software-as-a-service (SaaS) products (which allows them to charge a recurring subscription fee) rather than software running at the edge (where customers tend to prefer paying a one-time fee). SaaS also gives the company access to data to improve the product and makes the product easier to upgrade.</em></li><li><em>Many developers today have been trained to build SaaS applications, and want to build cloud-hosted applications rather than desktop or other edge applications.</em></li></ul><p><em>Here’s why I think those factors won’t stop AI’s growth at the edge.&nbsp;</em></p><ul><li><em>AI applications are starting to run quite well on modern edge devices. For example, I regularly run models with around 1B to 10B parameters on my laptop. If I’m working on an airplane without WiFi access, I will occasionally run a small model to help me with my work.</em></li><li><em>For many applications, a model of modest size works fine, especially if it’s fine-tuned to the task at hand. To help me find grammatical errors in my writing, do I really need a 175B parameter model that has broad knowledge of philosophy, history, astronomy, and every other topic under the sun?</em></li><li><em>Many users, especially those from Gen Z (born around 1996 to 2010), whose behavior tends to be a leading indicator of future consumer trends, are increasingly sensitive to privacy. This has been a boon to Apple’s product sales, given the company’s reputation for privacy. Surely, to check my grammar, I don’t need to share my data with a big tech company?&nbsp;</em></li><li><em>Similarly, for corporations worried about their own data privacy, edge computing (as well as on-premises and virtual private cloud options) could be appealing.</em></li></ul><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--20--1.jpg" class="kg-image" alt="Left: Datacenter Right: Human hands holding and manipulating a mobile phone" loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/ezgif.com-webp-to-jpg--20--1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/ezgif.com-webp-to-jpg--20--1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--20--1.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><p><em>Further, strong commercial interests are propelling AI to the edge. Chip makers like Nvidia, AMD, and Intel sell chips to data centers (where sales have grown rapidly) and for use in PCs and laptops (where sales have plummeted since the pandemic). Thus, semiconductor manufacturers as well as PC/laptop makers (and Microsoft, whose sales of the Windows operating system depend on sales of new PC/laptops) are highly motivated to encourage adoption of edge AI, since this would likely require consumers to upgrade their devices to have the more modern AI accelerators.&nbsp;So many companies stand to benefit from the rise of edge AI and will have an incentive to promote it.&nbsp;</em></p><p><em>AI Fund has been exploring a variety of edge AI applications, and I think the opportunities will be rich and varied. Interesting semiconductor technology will support them. For example, AMD’s&nbsp;<a href="https://www.amd.com/en/solutions/ai.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener"><em>xDNA</em></a>&nbsp;architecture, drawing on&nbsp;<a href="https://www.xilinx.com/products/technology/ai-engine.html]?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener"><em>configurable cores</em></a>&nbsp;designed by Xilinx (now an AMD company), is making it easier to run multiple AI models simultaneously. This enables a future in which one AI model adjusts image quality on our video call, another checks our grammar in real time, and a third pulls up relevant articles. &nbsp;</em></p><p><em>While it’s still early days for edge AI — in both consumer and industrial markets (for example, running in factories or on heavy machinery) — I think it’s worth investigating, in addition to the numerous opportunities in cloud-hosted AI applications. &nbsp;<br><br>Keep learning!</em></p><p><em>Andrew</em></p><p>&nbsp;<em>P.S. My team at Landing AI will present a livestream, “Building Computer Vision Applications,” on Monday, November 6, 2023, at 10 a.m. Pacific Time. We’ll discuss the practical aspects of building vision applications including how to identify and scope vision projects, choose a project type and model, apply data-centric AI, and develop an MLOps pipeline. Register&nbsp;<a href="https://landing.ai/building-computer-vision-applications/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener"><em>here</em></a>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/10/PIXEL_600px--1--1.gif" class="kg-image" alt="Excerpt from Google Pixel 8 promotional video" loading="lazy" width="600" height="337" srcset="https://dl-staging-website.ghost.io/content/images/2023/10/PIXEL_600px--1--1.gif 600w"></figure><h1 id="generative-ai-calling">Generative AI Calling</h1><p>Google’s new mobile phones put advanced computer vision and audio research into consumers’ hands.<br><br><strong>What’s new:</strong>&nbsp;The Alphabet division&nbsp;<a href="https://blog.google/products/pixel/google-pixel-8-pro/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">introduced</a>&nbsp;its flagship Pixel 8 and Pixel 8 Pro smartphones at its annual hardware-launch event. Both units feature AI-powered tools for editing photos and videos.</p><p><strong>How it works:</strong>&nbsp;Google’s new phones process images in distinctive ways driven by algorithms on the device itself. They raise the bar for Apple, the smartphone leader, to turn its&nbsp;<a href="https://www.deeplearning.ai/the-batch/apple-is-proceeding-on-the-sly-to-capitalize-on-the-generative-ai-trend/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">internal projects</a>&nbsp;into market opportunities.</p><ul><li>The feature called Best Take enables users to select elements from multiple photos and stitches them into a single image. In a group photo, users might replace faces with closed eyes or grimaces with alternatives from other shots that show open eyes and wide smiles.</li><li>Magic Editor uses image-generation technology to edit or alter images. Users can move and resize individual elements and swap in preset backgrounds. They can also generate out-of-frame parts of an element — or an entire photo — on the fly.</li><li>Audio Magic Eraser splits a video’s audio into distinct sounds, enabling users to adjust their relative volume. This capability can be useful to reduce distracting noises or boost dialogue.</li><li>Video Boost, which will arrive later this year on the Pixel 8 Pro only, will improve the image quality of videos by automatically stabilizing motion and adjusting color, lighting, and grain.</li></ul><p><strong>Behind the news:</strong>&nbsp;Google researchers actively pursued AI systems that alter or enhance images, video, and audio.</p><ul><li>Best Take and Magic Editor resemble a&nbsp;<a href="https://arxiv.org/abs/2308.12469?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">system</a>&nbsp;Google and Georgia Tech researchers described in an August 2023 paper, which uses diffusion models to segment and merge multiple images.</li><li>Magic Editor echoes&nbsp;<a href="https://arxiv.org/pdf/2205.11487.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">Imagen</a>, Google’s diffusion text-to-image generator.&nbsp;</li><li>Audio Magic Eraser resembles capabilities described in a recent&nbsp;<a href="https://av4d.org/papers/eccv22/p11.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">paper</a>&nbsp;that proposes AudioScopeV2 to separate and recombine various audio and video tracks.</li></ul><p><strong>Why it matters:</strong>&nbsp;Smartphones produce most of the world’s photos and videos. Yet generative tools for editing them have been confined to the desktop, social-network photo filters notwithstanding. Google’s new phones bring the world closer to parity between the capabilities of desktop image editors and hand-held devices. And the audio-editing capabilities raise the bar all around.</p><p><strong>We’re thinking:</strong>&nbsp;Earlier this year, Google&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-firms-agree-to-voluntary-guidelines/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">agreed</a>&nbsp;to uphold voluntary commitments on AI, including developing robust mechanisms, such as watermarks, that would identify generated media. Will Google apply such a mark to images edited by Pixel users?&nbsp;</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--21-.jpg" class="kg-image" alt="Surgeons performing brain surgery " loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/ezgif.com-webp-to-jpg--21-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/ezgif.com-webp-to-jpg--21-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--21-.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="guiding-the-scalpel">Guiding the Scalpel</h1><p>A neural network helped brain surgeons decide how much healthy tissue to cut out when removing tumors — while the patients were on the operating table.</p><p><strong>What’s new:</strong>&nbsp;Researchers from Amsterdam University Medical Centers and Princess Máxima Center for Pediatric Oncology in the Netherlands&nbsp;<a href="https://www.nature.com/articles/s41586-023-06615-2?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">built</a>&nbsp;a system to assess how aggressively surgeons should treat tumors. It worked accurately and quickly enough to enable doctors to adjust their approach in the operating room.<br><br><strong>Key insight:</strong>&nbsp;Brain surgeons don’t know the type of tumor they will remove until an operation is underway. When they have a sample — about the size of a kernel of corn — they can classify it by looking at it under a microscope. Alternatively, they can send it out for DNA sequencing, which can take weeks, requiring a second surgery. However, faster, less precise DNA sequencing can be performed on-site, and a neural network can classify such preliminary DNA sequences quickly and accurately. This way, a doctor can proceed with the operation with confidence in the tumor’s classification.</p><p><strong>How it works:</strong>&nbsp;The authors trained a system of four vanilla neural networks to classify brain tumors.</p><ul><li>The authors made a labeled dataset of nearly 17 million artificial DNA sequences of around 90 tumor types, each constructed by assembling random parts from one of 2,800&nbsp;<a href="https://www.nature.com/articles/nature26000?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">sequences</a>&nbsp;of tumor and non-tumor DNA. This approach simulated the messy nature of the fast DNA sequencing process.</li><li>For each neural network, they randomly selected half the sequences for training and used the other half for testing and validation. They trained the networks to classify the tumor types.</li><li>At inference, all four models classified each DNA sample. The system selected the classification from the model that had the highest confidence above a certain threshold. Samples that didn’t clear the confidence threshold received no classification.</li></ul><p><strong>Results:</strong>&nbsp;The authors’ system performed well on tumor DNA samples in an existing collection as well as those gathered in an operating room. Tested on samples from 415 tumors, it classified 60.7 percent of them accurately, misclassified 1.9 percent, and was unable to classify 37.3 percent. Tested on samples collected during 25 real surgeries, it correctly classified 18 tumors and was unable to classify 7. In all cases, it returned results within 90 minutes (45 minutes to collect the DNA and 45 minutes to analyze it).</p><p><strong>Why it matters:</strong>&nbsp;90 minutes is fast enough to inform brain surgeons what kind of tumor they’re dealing with in the early phase of an operation. If this technique can be rolled out widely, it may help save many lives.<br><br><strong>We’re thinking:</strong>&nbsp;Inferencing presumably takes seconds. The authors say the quick sequencing method processes DNA in 20 to 40 minutes. Speeding up that step offers great potential to accelerate the process.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/courses/generative-ai-for-everyone?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2023/10/The-Batch-ads-and-exclusive-banners--70-.png" class="kg-image" alt="Generative AI for Everyone course promotional banner" loading="lazy" width="1680" height="945" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/The-Batch-ads-and-exclusive-banners--70-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/The-Batch-ads-and-exclusive-banners--70-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/10/The-Batch-ads-and-exclusive-banners--70-.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/10/The-Batch-ads-and-exclusive-banners--70-.png 1680w" sizes="(min-width: 720px) 720px"></a></figure><p>“Generative AI for Everyone,” taught by Andrew Ng, is coming soon! This course demystifies generative AI and assumes no prior experience in coding or machine learning. Learn how generative AI works, how to use it, and how it will affect jobs, businesses, and society.&nbsp;<a href="https://www.deeplearning.ai/courses/generative-ai-for-everyone?ref=dl-staging-website.ghost.io" rel="noreferrer">Join the waitlist</a></p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/10/POSTGPT_withDollarSign_1200px.gif" class="kg-image" alt="Car made out of Microsoft and OpenAI's logos getting its gas tank filled" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/POSTGPT_withDollarSign_1200px.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/POSTGPT_withDollarSign_1200px.gif 1000w, https://dl-staging-website.ghost.io/content/images/2023/10/POSTGPT_withDollarSign_1200px.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="cost-containment-for-generative-ai">Cost Containment for Generative AI</h1><p>Microsoft is looking to control the expense of its reliance on OpenAI’s models.</p><p><strong>What’s new:</strong>&nbsp;Microsoft seeks to build leaner language models that perform nearly as well as ChatGPT but cost less to run,&nbsp;The Information&nbsp;<a href="https://www.theinformation.com/articles/how-microsoft-is-trying-to-lessen-its-addiction-to-openai-as-ai-costs-soar?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;Microsoft offers a line of&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-extends-copilot-365-windows/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">AI-powered tools</a>&nbsp;that complement the company’s flagship products including Windows, Microsoft 365, and GitHub. Known as Copilot, the line is based on OpenAI models. Serving those models to&nbsp;<a href="https://financialpost.com/personal-finance/business-essentials/over-1-billion-people-worldwide-use-a-ms-office-product-or-service?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">1 billion-plus users</a>&nbsp;could amount to an enormous expense, and it occupies processing power that would be useful elsewhere. To manage the cost, Microsoft’s developers are using knowledge distillation, in which a smaller model is trained to mimic the output of a larger one, as well as other techniques.</p><ul><li>Microsoft’s agreement with OpenAI gives it unique access to outputs from OpenAI models. Distilling Open AI models has become the AI team’s top priority. Such models are already running in Bing Chat.</li><li>Microsoft AI research chief Peter Lee dedicated around 2,000 GPUs to training and validating distilled models, a fraction of the number used to train and validate GPT-4.&nbsp;</li><li><a href="https://arxiv.org/abs/2306.02707?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">Orca</a>, a 13-billion-parameter LLaMA 2 model that was fine-tuned on GPT-4 outputs, matched ChatGPT on the challenging&nbsp;<a href="https://www.deeplearning.ai/the-batch/toward-next-gen-language-models/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">BIG-Bench Hard</a>&nbsp;benchmark. Nonetheless, it trailed GPT-4 on other benchmarks. (Microsoft reportedly considered releasing Orca on Azure as a competitor to GPT-4 and LLaMA 2, but LLaMA 2’s license restricts its ability to do so.)</li><li>The company is also developing smaller models from scratch. For instance,&nbsp;<a href="https://arxiv.org/abs/2306.11644?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">Phi-1</a>&nbsp;surpassed most open source models on benchmarks for generating Python code, such as&nbsp;<a href="https://github.com/openai/human-eval?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">HumanEval</a>, despite being smaller by a factor of 10 and trained on less data by a factor of 100.</li></ul><p><strong>Behind the news:</strong>&nbsp;Microsoft has&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-boosts-its-investment-in-openai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">invested</a>&nbsp;$10 billion in OpenAI. The deal&nbsp;<a href="https://www.theinformation.com/articles/microsoft-openai-inside-techs-hottest-romance?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">promises</a>&nbsp;the tech giant 75 percent of OpenAI’s operating profit until its investment is repaid, then 49 percent of further profits until reaching an unspecified cap. Meanwhile, Microsoft does have access to high-performing models from other sources. Its Azure cloud platform&nbsp;<a href="https://about.fb.com/news/2023/07/llama-2/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">serves</a>&nbsp;Meta’s LLaMA 2.</p><p><strong>Why it matters:</strong>&nbsp;Serving large neural networks at scale is a challenge even for Microsoft, which has immense hardware resources and a favorable agreement with OpenAI. Running distilled and fine-tuned models can cut the cost for both tech giants and tiny startups.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;If users like Copilot so much they're running up a large bill in model inferences, that sounds like a positive sign!&nbsp;</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--22-.jpg" class="kg-image" alt="Illustrations of a proposed iterative bootstrapping approach" loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/ezgif.com-webp-to-jpg--22-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/ezgif.com-webp-to-jpg--22-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--22-.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="better-reasoning-from-chatgpt">Better Reasoning from ChatGPT</h1><p>You can get a large language model to solve math problems more accurately if your prompts include a&nbsp;<a href="https://arxiv.org/abs/2201.11903?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">chain of thought</a>: an example that solves a similar problem through a series of intermediate reasoning steps. A new approach to this sort of prompting improved ChatGPT’s accuracy on a variety of reasoning problems.</p><p><strong>What's new:&nbsp;</strong>Jiashuo Sun and colleagues at Xiamen University, Microsoft, and IDEA Research, introduced&nbsp;<a href="https://arxiv.org/abs/2304.11657?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">iterative bootstrapping in chain-of-thought-prompting</a>, a method that prompts a large language model to generate correct chains of thought for difficult problems, so it can use them as guides to solving other problems.</p><p><strong>Key insight:</strong>&nbsp;Researchers have developed a few ways to prompt a large language model to apply a chain of thought (CoT). The typical method is for a human to write an example CoT for inclusion in a prompt. A faster way is to skip the hand-crafted example and simply instruct the model to “think step by step,” prompting it to generate not only a solution but its own CoT (this is called&nbsp;<a href="https://arxiv.org/abs/2205.11916?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">zero-shot CoT)</a>. To improve zero-shot CoT, other work both (i) asked a model to “think step by step” and (ii) provided generated CoTs (<a href="https://arxiv.org/abs/2210.03493?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">auto-CoT</a>). The weakness of this approach is that the model can generate fallacious CoTs and rely on them when responding to the prompt at hand, which can lead to incorrect responses. To solve this problem, we can draw example prompts from a dataset that includes correct responses, and the model can check its responses against the dataset labels. If it’s wrong, it can try repeatedly until it answers correctly. In this way, it generates correct CoT examples to use in solving other problems.</p><p><strong>How it works:</strong>&nbsp;To prompt ChatGPT to reason effectively, the authors built a database of example problems, chains of thought, and solutions. They drew problems from 11 datasets: six arithmetic reasoning datasets (such as&nbsp;<a href="https://arxiv.org/abs/2110.14168?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">grade-school math word problems</a>), four common-sense reasoning datasets (for example,&nbsp;<a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00370/100680/Did-Aristotle-Use-a-Laptop-A-Question-Answering?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">questions like “Did Aristotle use a laptop?”</a>), and a&nbsp;<a href="https://arxiv.org/abs/2201.11903?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">symbolic reasoning dataset</a>&nbsp;consisting of tasks that involved manipulating letters in words (for instance, “Take the last letters of the words in ‘Steve Sweeney’ and concatenate them”).</p><ul><li>The authors prompted the model with a problem and instructed it to “think step by step” as it generated a solution, and they recorded the input and output.&nbsp;</li><li>When the model’s solution did not match the solution in the dataset, the authors instructed the model to try again using prompts such as, “The answer is not right, can you think more carefully and give me the final answer?” They repeated this step until the model delivered the correct solution.</li><li>Once the model had solved a problem correctly, they prompted it to present the answer again along with the steps that led to it. This output generally rendered the chain of thought more concisely than the model’s initial correct responses. They stored the problem, chain of thought, and solution in a database.</li><li>At inference, when prompting the model to solve a problem, the authors included in the prompt four to eight database entries selected at random.</li></ul><p><strong>Results:</strong>&nbsp;The authors evaluated their method versus hand-crafting and auto-CoT. Of the 11 datasets, their method achieved the best results on 8. For example, on grade-school math word problems, ChatGPT prompted using their method achieved 73.6 percent accuracy; using hand-crafted prompts, it achieved 69.3 percent accuracy, and using auto-CoT, it achieved 71.4 percent accuracy. Their method underperformed hand-crafted prompts on two common-sense reasoning datasets (76.8 percent versus 77.1 percent and 69.3 percent versus 71.1 percent). It underperformed auto-CoT on one arithmetic dataset (91.9 percent versus 92.5 percent.)</p><p><strong>Why it matters:&nbsp;</strong>Large language models have powerful latent capabilities that can be activated by clever prompting. ChatGPT was able to solve the problems in the authors’ database, but only after multiple tries. Prompting it with examples of its own correct solutions to these problems apparently enabled it to solve other, similarly difficult problems without needing multiple tries.</p><p><strong>We're thinking:</strong>&nbsp;It may be possible to modify this method to make human input unnecessary by asking the model to&nbsp;<a href="https://arxiv.org/abs/2212.08073?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">fix the problems in its previous generations</a>&nbsp;or&nbsp;<a href="https://arxiv.org/abs/2305.11738?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe" rel="noopener">use external tools to validate its outputs</a>.</p><hr><h1 id="data-points">Data Points</h1><p><strong>Baidu announces Ernie 4.0</strong><br>The Chinese tech giant demonstrated a new version of its generative AI model at an event on Tuesday. Baidu claims that the new version of Ernie is on par with Open AI’s GPT-4 model. Ernie will also be incorporated into many of Baidu’s products, including Drive and Maps. It is not yet available to the general public. (<a href="https://www.reuters.com/technology/chinas-baidu-unveils-latest-version-its-ernie-ai-model-2023-10-17/?ref=dl-staging-website.ghost.io"><em>Reuters</em></a>)</p><p><strong>Adobe releases Firefly 2.0</strong><br>The creative software giant’s new image generation model features new text to image and text to vector graphic tools. It automatically generates content credentials for AI-generated material and Adobe promises to defend users against copyright infringement claims. But controversies remain about how Adobe secured its users’ permission to train its models on their images. (<a href="https://blog.adobe.com/en/publish/2023/10/10/future-is-firefly-adobe-max?ref=dl-staging-website.ghost.io"><em>Adobe</em></a>)</p><p><strong>Southeast Asia takes business-friendly stance on AI regulation</strong><br>A confidential draft of the Association of Southeast Asian Nations' (ASEAN) "guide to AI ethics and governance" reveals its emphasis on guiding domestic regulations rather than imposing stringent requirements. This aligns closely with the U.S. NIST AI Risk Management Framework and sets it apart from the European Union's AI Act. (<a href="https://www.reuters.com/technology/southeast-asia-eyes-hands-off-ai-rules-defying-eu-ambitions-2023-10-11/?ref=dl-staging-website.ghost.io"><em>Reuters</em></a>)</p><p><strong>Google commits to protect Generative AI users from copyright claims</strong><br>The new policy extends to software that generates text and images in Google Workspace and Cloud applications, including Google Cloud’s Vertex AI development platform and Duet AI system. It does not cover instances where users intentionally infringe on the rights of others. This move aligns Google with companies like Microsoft and Adobe that have made similar pledges. (<a href="https://www.reuters.com/technology/google-defend-generative-ai-users-copyright-claims-2023-10-12/?ref=dl-staging-website.ghost.io"><em>Reuters</em></a>)</p><p><a href="https://arxiv.org/abs/2310.05688?ref=dl-staging-website.ghost.io">Research</a>:<strong> Machine translation dataset bridges gap for ancient Etruscan language</strong><br>Etruscan, an ancient European language with no native speakers today, only has around 12,000 known inscriptions, most of them still untranslated. A dataset for machine translation from Etruscan to English has been introduced, featuring 2,891 translated examples from academic sources. This release opens doors for future research on Etruscan and other languages with limited data. (<a href="https://huggingface.co/papers/2310.05688?ref=dl-staging-website.ghost.io"><em>Hugging Face</em></a>)</p><p><strong>Indigenous communities are using AI to revitalize their languages</strong><br>Researchers are developing AI models to aid native language learning and cultural preservation. While AI offers promise, there are concerns about corporate interests profiting from indigenous languages. Many indigenous-run organizations are pursuing new kinds of partnerships with developers, focusing on ethical and community-focused development. (<a href="https://www.newscientist.com/article/0-how-artificial-intelligence-is-helping-keep-indigenous-languages-alive/?_ptid=%7Bkpdx%7DAAAAsnH1q_DzdQoKcmJhNGYxWmNwZRIQbG51ejducTlxY2VuZmJnbhoMRVg0T1lJVExZRUU2IiUxODIyYm0wMDg0LTAwMDAzMnEwMWRnOW10anNqcjBvc2ttNmxnKhtzaG93VGVtcGxhdGU2MjRIQkkxSUVSUkExMTkwAToMT1RDTzJDNlc2NEhGUhJ2LXYA8BhoYnM2OTB6NHdaDTE5MS4xMTEuMjIuNTJiA2R3Y2iJ3sGpBnASeAQ&ref=dl-staging-website.ghost.io"><em>New Scientist</em></a>)</p><p><strong>Software development startup Replit launches its own AI pair programmer</strong><br>Replit AI contains a comprehensive suite of tools, including Complete Code, Generate Code, Edit Code, and Explain Code. The flagship feature, Complete Code, delivers autocomplete-style suggestions to enhance the coding experience. (<a href="https://blog.replit.com/ai4all?ref=dl-staging-website.ghost.io"><em>Replit</em></a>)</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2F1-9.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://bit.ly/3YX9G3n"><div class="absolute inset-0" data-gtm-event-title="AI Python for Beginners"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-219/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-219/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-219/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm43" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-219","id":"6530221ccb9ee80001b26507","uuid":"20791b75-0802-4a79-ae5f-44fa2b149dbe","title":"AI for Brain Surgery, Microsoft's ChatGPT Bill, Google's Generative Phones, Better Prompts","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eI\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/how-to-spot-high-impact-technologies/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003e\u003cem\u003ewrote\u003c/em\u003e\u003c/a\u003e\u0026nbsp;earlier about how my team at AI Fund saw that GPT-3 set a new direction for building language applications, two years before ChatGPT was released. I’ll go out on a limb to make another prediction: I think we’ll see significant growth in AI, including Generative AI, applications running at the edge of the network (PC, laptop, mobile, and so on).\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eI realize this flies in the face of conventional wisdom. Most AI runs in data centers, not on edge devices. There are good reasons for this:\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003eThe most powerful large language models require 100B+ parameters and massive amounts of memory even for inference (100B parameters, stored using 8- bit quantization, requires 100GB of memory).\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eMany businesses prefer to operate cloud-based, software-as-a-service (SaaS) products (which allows them to charge a recurring subscription fee) rather than software running at the edge (where customers tend to prefer paying a one-time fee). SaaS also gives the company access to data to improve the product and makes the product easier to upgrade.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eMany developers today have been trained to build SaaS applications, and want to build cloud-hosted applications rather than desktop or other edge applications.\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cem\u003eHere’s why I think those factors won’t stop AI’s growth at the edge.\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003eAI applications are starting to run quite well on modern edge devices. For example, I regularly run models with around 1B to 10B parameters on my laptop. If I’m working on an airplane without WiFi access, I will occasionally run a small model to help me with my work.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eFor many applications, a model of modest size works fine, especially if it’s fine-tuned to the task at hand. To help me find grammatical errors in my writing, do I really need a 175B parameter model that has broad knowledge of philosophy, history, astronomy, and every other topic under the sun?\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eMany users, especially those from Gen Z (born around 1996 to 2010), whose behavior tends to be a leading indicator of future consumer trends, are increasingly sensitive to privacy. This has been a boon to Apple’s product sales, given the company’s reputation for privacy. Surely, to check my grammar, I don’t need to share my data with a big tech company?\u0026nbsp;\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eSimilarly, for corporations worried about their own data privacy, edge computing (as well as on-premises and virtual private cloud options) could be appealing.\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--20--1.jpg\" class=\"kg-image\" alt=\"Left: Datacenter Right: Human hands holding and manipulating a mobile phone\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/ezgif.com-webp-to-jpg--20--1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/ezgif.com-webp-to-jpg--20--1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--20--1.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eFurther, strong commercial interests are propelling AI to the edge. Chip makers like Nvidia, AMD, and Intel sell chips to data centers (where sales have grown rapidly) and for use in PCs and laptops (where sales have plummeted since the pandemic). Thus, semiconductor manufacturers as well as PC/laptop makers (and Microsoft, whose sales of the Windows operating system depend on sales of new PC/laptops) are highly motivated to encourage adoption of edge AI, since this would likely require consumers to upgrade their devices to have the more modern AI accelerators.\u0026nbsp;So many companies stand to benefit from the rise of edge AI and will have an incentive to promote it.\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAI Fund has been exploring a variety of edge AI applications, and I think the opportunities will be rich and varied. Interesting semiconductor technology will support them. For example, AMD’s\u0026nbsp;\u003ca href=\"https://www.amd.com/en/solutions/ai.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003e\u003cem\u003exDNA\u003c/em\u003e\u003c/a\u003e\u0026nbsp;architecture, drawing on\u0026nbsp;\u003ca href=\"https://www.xilinx.com/products/technology/ai-engine.html]?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003e\u003cem\u003econfigurable cores\u003c/em\u003e\u003c/a\u003e\u0026nbsp;designed by Xilinx (now an AMD company), is making it easier to run multiple AI models simultaneously. This enables a future in which one AI model adjusts image quality on our video call, another checks our grammar in real time, and a third pulls up relevant articles. \u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWhile it’s still early days for edge AI — in both consumer and industrial markets (for example, running in factories or on heavy machinery) — I think it’s worth investigating, in addition to the numerous opportunities in cloud-hosted AI applications. \u0026nbsp;\u003cbr\u003e\u003cbr\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u0026nbsp;\u003cem\u003eP.S. My team at Landing AI will present a livestream, “Building Computer Vision Applications,” on Monday, November 6, 2023, at 10 a.m. Pacific Time. We’ll discuss the practical aspects of building vision applications including how to identify and scope vision projects, choose a project type and model, apply data-centric AI, and develop an MLOps pipeline. Register\u0026nbsp;\u003ca href=\"https://landing.ai/building-computer-vision-applications/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003e\u003cem\u003ehere\u003c/em\u003e\u003c/a\u003e!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/10/PIXEL_600px--1--1.gif\" class=\"kg-image\" alt=\"Excerpt from Google Pixel 8 promotional video\" loading=\"lazy\" width=\"600\" height=\"337\" srcset=\"https://dl-staging-website.ghost.io/content/images/2023/10/PIXEL_600px--1--1.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"generative-ai-calling\"\u003eGenerative AI Calling\u003c/h1\u003e\u003cp\u003eGoogle’s new mobile phones put advanced computer vision and audio research into consumers’ hands.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;The Alphabet division\u0026nbsp;\u003ca href=\"https://blog.google/products/pixel/google-pixel-8-pro/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eintroduced\u003c/a\u003e\u0026nbsp;its flagship Pixel 8 and Pixel 8 Pro smartphones at its annual hardware-launch event. Both units feature AI-powered tools for editing photos and videos.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Google’s new phones process images in distinctive ways driven by algorithms on the device itself. They raise the bar for Apple, the smartphone leader, to turn its\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/apple-is-proceeding-on-the-sly-to-capitalize-on-the-generative-ai-trend/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003einternal projects\u003c/a\u003e\u0026nbsp;into market opportunities.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe feature called Best Take enables users to select elements from multiple photos and stitches them into a single image. In a group photo, users might replace faces with closed eyes or grimaces with alternatives from other shots that show open eyes and wide smiles.\u003c/li\u003e\u003cli\u003eMagic Editor uses image-generation technology to edit or alter images. Users can move and resize individual elements and swap in preset backgrounds. They can also generate out-of-frame parts of an element — or an entire photo — on the fly.\u003c/li\u003e\u003cli\u003eAudio Magic Eraser splits a video’s audio into distinct sounds, enabling users to adjust their relative volume. This capability can be useful to reduce distracting noises or boost dialogue.\u003c/li\u003e\u003cli\u003eVideo Boost, which will arrive later this year on the Pixel 8 Pro only, will improve the image quality of videos by automatically stabilizing motion and adjusting color, lighting, and grain.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Google researchers actively pursued AI systems that alter or enhance images, video, and audio.\u003c/p\u003e\u003cul\u003e\u003cli\u003eBest Take and Magic Editor resemble a\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2308.12469?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003esystem\u003c/a\u003e\u0026nbsp;Google and Georgia Tech researchers described in an August 2023 paper, which uses diffusion models to segment and merge multiple images.\u003c/li\u003e\u003cli\u003eMagic Editor echoes\u0026nbsp;\u003ca href=\"https://arxiv.org/pdf/2205.11487.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eImagen\u003c/a\u003e, Google’s diffusion text-to-image generator.\u0026nbsp;\u003c/li\u003e\u003cli\u003eAudio Magic Eraser resembles capabilities described in a recent\u0026nbsp;\u003ca href=\"https://av4d.org/papers/eccv22/p11.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003epaper\u003c/a\u003e\u0026nbsp;that proposes AudioScopeV2 to separate and recombine various audio and video tracks.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Smartphones produce most of the world’s photos and videos. Yet generative tools for editing them have been confined to the desktop, social-network photo filters notwithstanding. Google’s new phones bring the world closer to parity between the capabilities of desktop image editors and hand-held devices. And the audio-editing capabilities raise the bar all around.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Earlier this year, Google\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/ai-firms-agree-to-voluntary-guidelines/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eagreed\u003c/a\u003e\u0026nbsp;to uphold voluntary commitments on AI, including developing robust mechanisms, such as watermarks, that would identify generated media. Will Google apply such a mark to images edited by Pixel users?\u0026nbsp;\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--21-.jpg\" class=\"kg-image\" alt=\"Surgeons performing brain surgery \" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/ezgif.com-webp-to-jpg--21-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/ezgif.com-webp-to-jpg--21-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--21-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"guiding-the-scalpel\"\u003eGuiding the Scalpel\u003c/h1\u003e\u003cp\u003eA neural network helped brain surgeons decide how much healthy tissue to cut out when removing tumors — while the patients were on the operating table.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Researchers from Amsterdam University Medical Centers and Princess Máxima Center for Pediatric Oncology in the Netherlands\u0026nbsp;\u003ca href=\"https://www.nature.com/articles/s41586-023-06615-2?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003ebuilt\u003c/a\u003e\u0026nbsp;a system to assess how aggressively surgeons should treat tumors. It worked accurately and quickly enough to enable doctors to adjust their approach in the operating room.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;Brain surgeons don’t know the type of tumor they will remove until an operation is underway. When they have a sample — about the size of a kernel of corn — they can classify it by looking at it under a microscope. Alternatively, they can send it out for DNA sequencing, which can take weeks, requiring a second surgery. However, faster, less precise DNA sequencing can be performed on-site, and a neural network can classify such preliminary DNA sequences quickly and accurately. This way, a doctor can proceed with the operation with confidence in the tumor’s classification.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The authors trained a system of four vanilla neural networks to classify brain tumors.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe authors made a labeled dataset of nearly 17 million artificial DNA sequences of around 90 tumor types, each constructed by assembling random parts from one of 2,800\u0026nbsp;\u003ca href=\"https://www.nature.com/articles/nature26000?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003esequences\u003c/a\u003e\u0026nbsp;of tumor and non-tumor DNA. This approach simulated the messy nature of the fast DNA sequencing process.\u003c/li\u003e\u003cli\u003eFor each neural network, they randomly selected half the sequences for training and used the other half for testing and validation. They trained the networks to classify the tumor types.\u003c/li\u003e\u003cli\u003eAt inference, all four models classified each DNA sample. The system selected the classification from the model that had the highest confidence above a certain threshold. Samples that didn’t clear the confidence threshold received no classification.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The authors’ system performed well on tumor DNA samples in an existing collection as well as those gathered in an operating room. Tested on samples from 415 tumors, it classified 60.7 percent of them accurately, misclassified 1.9 percent, and was unable to classify 37.3 percent. Tested on samples collected during 25 real surgeries, it correctly classified 18 tumors and was unable to classify 7. In all cases, it returned results within 90 minutes (45 minutes to collect the DNA and 45 minutes to analyze it).\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;90 minutes is fast enough to inform brain surgeons what kind of tumor they’re dealing with in the early phase of an operation. If this technique can be rolled out widely, it may help save many lives.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Inferencing presumably takes seconds. The authors say the quick sequencing method processes DNA in 20 to 40 minutes. Speeding up that step offers great potential to accelerate the process.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/courses/generative-ai-for-everyone?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/10/The-Batch-ads-and-exclusive-banners--70-.png\" class=\"kg-image\" alt=\"Generative AI for Everyone course promotional banner\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/The-Batch-ads-and-exclusive-banners--70-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/The-Batch-ads-and-exclusive-banners--70-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/10/The-Batch-ads-and-exclusive-banners--70-.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/10/The-Batch-ads-and-exclusive-banners--70-.png 1680w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003e“Generative AI for Everyone,” taught by Andrew Ng, is coming soon! This course demystifies generative AI and assumes no prior experience in coding or machine learning. Learn how generative AI works, how to use it, and how it will affect jobs, businesses, and society.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/courses/generative-ai-for-everyone?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eJoin the waitlist\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/10/POSTGPT_withDollarSign_1200px.gif\" class=\"kg-image\" alt=\"Car made out of Microsoft and OpenAI's logos getting its gas tank filled\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/POSTGPT_withDollarSign_1200px.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/POSTGPT_withDollarSign_1200px.gif 1000w, https://dl-staging-website.ghost.io/content/images/2023/10/POSTGPT_withDollarSign_1200px.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"cost-containment-for-generative-ai\"\u003eCost Containment for Generative AI\u003c/h1\u003e\u003cp\u003eMicrosoft is looking to control the expense of its reliance on OpenAI’s models.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Microsoft seeks to build leaner language models that perform nearly as well as ChatGPT but cost less to run,\u0026nbsp;The Information\u0026nbsp;\u003ca href=\"https://www.theinformation.com/articles/how-microsoft-is-trying-to-lessen-its-addiction-to-openai-as-ai-costs-soar?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003ereported\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Microsoft offers a line of\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/microsoft-extends-copilot-365-windows/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eAI-powered tools\u003c/a\u003e\u0026nbsp;that complement the company’s flagship products including Windows, Microsoft 365, and GitHub. Known as Copilot, the line is based on OpenAI models. Serving those models to\u0026nbsp;\u003ca href=\"https://financialpost.com/personal-finance/business-essentials/over-1-billion-people-worldwide-use-a-ms-office-product-or-service?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003e1 billion-plus users\u003c/a\u003e\u0026nbsp;could amount to an enormous expense, and it occupies processing power that would be useful elsewhere. To manage the cost, Microsoft’s developers are using knowledge distillation, in which a smaller model is trained to mimic the output of a larger one, as well as other techniques.\u003c/p\u003e\u003cul\u003e\u003cli\u003eMicrosoft’s agreement with OpenAI gives it unique access to outputs from OpenAI models. Distilling Open AI models has become the AI team’s top priority. Such models are already running in Bing Chat.\u003c/li\u003e\u003cli\u003eMicrosoft AI research chief Peter Lee dedicated around 2,000 GPUs to training and validating distilled models, a fraction of the number used to train and validate GPT-4.\u0026nbsp;\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2306.02707?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eOrca\u003c/a\u003e, a 13-billion-parameter LLaMA 2 model that was fine-tuned on GPT-4 outputs, matched ChatGPT on the challenging\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/toward-next-gen-language-models/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eBIG-Bench Hard\u003c/a\u003e\u0026nbsp;benchmark. Nonetheless, it trailed GPT-4 on other benchmarks. (Microsoft reportedly considered releasing Orca on Azure as a competitor to GPT-4 and LLaMA 2, but LLaMA 2’s license restricts its ability to do so.)\u003c/li\u003e\u003cli\u003eThe company is also developing smaller models from scratch. For instance,\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2306.11644?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003ePhi-1\u003c/a\u003e\u0026nbsp;surpassed most open source models on benchmarks for generating Python code, such as\u0026nbsp;\u003ca href=\"https://github.com/openai/human-eval?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eHumanEval\u003c/a\u003e, despite being smaller by a factor of 10 and trained on less data by a factor of 100.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Microsoft has\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/microsoft-boosts-its-investment-in-openai/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003einvested\u003c/a\u003e\u0026nbsp;$10 billion in OpenAI. The deal\u0026nbsp;\u003ca href=\"https://www.theinformation.com/articles/microsoft-openai-inside-techs-hottest-romance?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003epromises\u003c/a\u003e\u0026nbsp;the tech giant 75 percent of OpenAI’s operating profit until its investment is repaid, then 49 percent of further profits until reaching an unspecified cap. Meanwhile, Microsoft does have access to high-performing models from other sources. Its Azure cloud platform\u0026nbsp;\u003ca href=\"https://about.fb.com/news/2023/07/llama-2/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eserves\u003c/a\u003e\u0026nbsp;Meta’s LLaMA 2.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Serving large neural networks at scale is a challenge even for Microsoft, which has immense hardware resources and a favorable agreement with OpenAI. Running distilled and fine-tuned models can cut the cost for both tech giants and tiny startups.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;If users like Copilot so much they're running up a large bill in model inferences, that sounds like a positive sign!\u0026nbsp;\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--22-.jpg\" class=\"kg-image\" alt=\"Illustrations of a proposed iterative bootstrapping approach\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/10/ezgif.com-webp-to-jpg--22-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/10/ezgif.com-webp-to-jpg--22-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--22-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"better-reasoning-from-chatgpt\"\u003eBetter Reasoning from ChatGPT\u003c/h1\u003e\u003cp\u003eYou can get a large language model to solve math problems more accurately if your prompts include a\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2201.11903?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003echain of thought\u003c/a\u003e: an example that solves a similar problem through a series of intermediate reasoning steps. A new approach to this sort of prompting improved ChatGPT’s accuracy on a variety of reasoning problems.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat's new:\u0026nbsp;\u003c/strong\u003eJiashuo Sun and colleagues at Xiamen University, Microsoft, and IDEA Research, introduced\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2304.11657?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eiterative bootstrapping in chain-of-thought-prompting\u003c/a\u003e, a method that prompts a large language model to generate correct chains of thought for difficult problems, so it can use them as guides to solving other problems.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;Researchers have developed a few ways to prompt a large language model to apply a chain of thought (CoT). The typical method is for a human to write an example CoT for inclusion in a prompt. A faster way is to skip the hand-crafted example and simply instruct the model to “think step by step,” prompting it to generate not only a solution but its own CoT (this is called\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2205.11916?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003ezero-shot CoT)\u003c/a\u003e. To improve zero-shot CoT, other work both (i) asked a model to “think step by step” and (ii) provided generated CoTs (\u003ca href=\"https://arxiv.org/abs/2210.03493?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003eauto-CoT\u003c/a\u003e). The weakness of this approach is that the model can generate fallacious CoTs and rely on them when responding to the prompt at hand, which can lead to incorrect responses. To solve this problem, we can draw example prompts from a dataset that includes correct responses, and the model can check its responses against the dataset labels. If it’s wrong, it can try repeatedly until it answers correctly. In this way, it generates correct CoT examples to use in solving other problems.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;To prompt ChatGPT to reason effectively, the authors built a database of example problems, chains of thought, and solutions. They drew problems from 11 datasets: six arithmetic reasoning datasets (such as\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2110.14168?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003egrade-school math word problems\u003c/a\u003e), four common-sense reasoning datasets (for example,\u0026nbsp;\u003ca href=\"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00370/100680/Did-Aristotle-Use-a-Laptop-A-Question-Answering?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003equestions like “Did Aristotle use a laptop?”\u003c/a\u003e), and a\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2201.11903?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003esymbolic reasoning dataset\u003c/a\u003e\u0026nbsp;consisting of tasks that involved manipulating letters in words (for instance, “Take the last letters of the words in ‘Steve Sweeney’ and concatenate them”).\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe authors prompted the model with a problem and instructed it to “think step by step” as it generated a solution, and they recorded the input and output.\u0026nbsp;\u003c/li\u003e\u003cli\u003eWhen the model’s solution did not match the solution in the dataset, the authors instructed the model to try again using prompts such as, “The answer is not right, can you think more carefully and give me the final answer?” They repeated this step until the model delivered the correct solution.\u003c/li\u003e\u003cli\u003eOnce the model had solved a problem correctly, they prompted it to present the answer again along with the steps that led to it. This output generally rendered the chain of thought more concisely than the model’s initial correct responses. They stored the problem, chain of thought, and solution in a database.\u003c/li\u003e\u003cli\u003eAt inference, when prompting the model to solve a problem, the authors included in the prompt four to eight database entries selected at random.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The authors evaluated their method versus hand-crafting and auto-CoT. Of the 11 datasets, their method achieved the best results on 8. For example, on grade-school math word problems, ChatGPT prompted using their method achieved 73.6 percent accuracy; using hand-crafted prompts, it achieved 69.3 percent accuracy, and using auto-CoT, it achieved 71.4 percent accuracy. Their method underperformed hand-crafted prompts on two common-sense reasoning datasets (76.8 percent versus 77.1 percent and 69.3 percent versus 71.1 percent). It underperformed auto-CoT on one arithmetic dataset (91.9 percent versus 92.5 percent.)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u0026nbsp;\u003c/strong\u003eLarge language models have powerful latent capabilities that can be activated by clever prompting. ChatGPT was able to solve the problems in the authors’ database, but only after multiple tries. Prompting it with examples of its own correct solutions to these problems apparently enabled it to solve other, similarly difficult problems without needing multiple tries.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe're thinking:\u003c/strong\u003e\u0026nbsp;It may be possible to modify this method to make human input unnecessary by asking the model to\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2212.08073?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003efix the problems in its previous generations\u003c/a\u003e\u0026nbsp;or\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2305.11738?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-90rGB3yM9BNW-WXLvbhGGf8NIouu7ehIo-z12ju_TCVJNYfoOMO-RzCDtJYHxJnbdlQ-qe\" rel=\"noopener\"\u003euse external tools to validate its outputs\u003c/a\u003e.\u003c/p\u003e\u003chr\u003e\u003ch1 id=\"data-points\"\u003eData Points\u003c/h1\u003e\u003cp\u003e\u003cstrong\u003eBaidu announces Ernie 4.0\u003c/strong\u003e\u003cbr\u003eThe Chinese tech giant demonstrated a new version of its generative AI model at an event on Tuesday. Baidu claims that the new version of Ernie is on par with Open AI’s GPT-4 model. Ernie will also be incorporated into many of Baidu’s products, including Drive and Maps. It is not yet available to the general public. (\u003ca href=\"https://www.reuters.com/technology/chinas-baidu-unveils-latest-version-its-ernie-ai-model-2023-10-17/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eReuters\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAdobe releases Firefly 2.0\u003c/strong\u003e\u003cbr\u003eThe creative software giant’s new image generation model features new text to image and text to vector graphic tools. It automatically generates content credentials for AI-generated material and Adobe promises to defend users against copyright infringement claims. But controversies remain about how Adobe secured its users’ permission to train its models on their images. (\u003ca href=\"https://blog.adobe.com/en/publish/2023/10/10/future-is-firefly-adobe-max?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eAdobe\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSoutheast Asia takes business-friendly stance on AI regulation\u003c/strong\u003e\u003cbr\u003eA confidential draft of the Association of Southeast Asian Nations' (ASEAN) \"guide to AI ethics and governance\" reveals its emphasis on guiding domestic regulations rather than imposing stringent requirements. This aligns closely with the U.S. NIST AI Risk Management Framework and sets it apart from the European Union's AI Act. (\u003ca href=\"https://www.reuters.com/technology/southeast-asia-eyes-hands-off-ai-rules-defying-eu-ambitions-2023-10-11/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eReuters\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eGoogle commits to protect Generative AI users from copyright claims\u003c/strong\u003e\u003cbr\u003eThe new policy extends to software that generates text and images in Google Workspace and Cloud applications, including Google Cloud’s Vertex AI development platform and Duet AI system. It does not cover instances where users intentionally infringe on the rights of others. This move aligns Google with companies like Microsoft and Adobe that have made similar pledges. (\u003ca href=\"https://www.reuters.com/technology/google-defend-generative-ai-users-copyright-claims-2023-10-12/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eReuters\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2310.05688?ref=dl-staging-website.ghost.io\"\u003eResearch\u003c/a\u003e:\u003cstrong\u003e Machine translation dataset bridges gap for ancient Etruscan language\u003c/strong\u003e\u003cbr\u003eEtruscan, an ancient European language with no native speakers today, only has around 12,000 known inscriptions, most of them still untranslated. A dataset for machine translation from Etruscan to English has been introduced, featuring 2,891 translated examples from academic sources. This release opens doors for future research on Etruscan and other languages with limited data. (\u003ca href=\"https://huggingface.co/papers/2310.05688?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eHugging Face\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eIndigenous communities are using AI to revitalize their languages\u003c/strong\u003e\u003cbr\u003eResearchers are developing AI models to aid native language learning and cultural preservation. While AI offers promise, there are concerns about corporate interests profiting from indigenous languages. Many indigenous-run organizations are pursuing new kinds of partnerships with developers, focusing on ethical and community-focused development. (\u003ca href=\"https://www.newscientist.com/article/0-how-artificial-intelligence-is-helping-keep-indigenous-languages-alive/?_ptid=%7Bkpdx%7DAAAAsnH1q_DzdQoKcmJhNGYxWmNwZRIQbG51ejducTlxY2VuZmJnbhoMRVg0T1lJVExZRUU2IiUxODIyYm0wMDg0LTAwMDAzMnEwMWRnOW10anNqcjBvc2ttNmxnKhtzaG93VGVtcGxhdGU2MjRIQkkxSUVSUkExMTkwAToMT1RDTzJDNlc2NEhGUhJ2LXYA8BhoYnM2OTB6NHdaDTE5MS4xMTEuMjIuNTJiA2R3Y2iJ3sGpBnASeAQ\u0026ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eNew Scientist\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSoftware development startup Replit launches its own AI pair programmer\u003c/strong\u003e\u003cbr\u003eReplit AI contains a comprehensive suite of tools, including Complete Code, Generate Code, Edit Code, and Explain Code. The flagship feature, Complete Code, delivers autocomplete-style suggestions to enhance the coding experience. (\u003ca href=\"https://blog.replit.com/ai4all?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eReplit\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e","comment_id":"6530221ccb9ee80001b26507","feature_image":"https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--20-.jpg","featured":false,"visibility":"public","created_at":"2023-10-18T11:21:16.000-07:00","updated_at":"2023-10-18T11:40:04.000-07:00","published_at":"2023-10-18T11:40:04.000-07:00","custom_excerpt":"The Batch - AI News \u0026 Insights: I wrote earlier about how my team at AI Fund saw that GPT-3 set a new direction for building language applications, two years before ChatGPT was released.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"65302515cb9ee80001b2655f","name":"issue-219","slug":"issue-219","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-219/"},{"id":"65302515cb9ee80001b26560","name":"Oct 18, 2023","slug":"oct-18-2023","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/oct-18-2023/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-219/","excerpt":"The Batch - AI News \u0026 Insights: I wrote earlier about how my team at AI Fund saw that GPT-3 set a new direction for building language applications, two years before ChatGPT was released.","reading_time":13,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"AI for Brain Surgery, Microsoft's ChatGPT Bill, Google's Generative Phones, and more","meta_description":"The Batch - AI News \u0026 Insights: I wrote earlier about how my team at AI Fund saw that GPT-3 set a new direction for building language applications...","email_subject":null,"frontmatter":null,"feature_image_alt":"Left: Datacenter Right: Human hands holding and manipulating a mobile phone","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2023/10/ezgif.com-webp-to-jpg--20-.jpg","dimensions":{"width":1200,"height":675}},"banner":{"title":"AI Python for Beginners","databaseId":35163,"id":"cG9zdDozNTE2Mw==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/08/1-9.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3YX9G3n","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-219"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>