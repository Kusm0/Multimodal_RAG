<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Face Datasets Under Fire, Baking With AI, Human Disabilities</title><meta name="description" content="The Batch - AI News &amp; Insights: Cutting Corners to Recognize Faces | AI may help revolutionize the human diet – or dessert, at least | Human Disabilities Baffle Algorithms" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-80/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Face Datasets Under Fire, Baking With AI, Human Disabilities" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: Cutting Corners to Recognize Faces | AI may help revolutionize the human diet – or dessert, at least | Human Disabilities Baffle Algorithms" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Face Datasets Under Fire, Baking With AI, Human Disabilities" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-80/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2021-02-24T12:00:00.000-08:00"/><meta property="article:modified_time" content="2022-10-06T09:37:13.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-80"/><meta property="article:tag" content="Feb 24, 2021"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Face Datasets Under Fire, Baking With AI, Human Disabilities" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: Cutting Corners to Recognize Faces | AI may help revolutionize the human diet – or dessert, at least | Human Disabilities Baffle Algorithms" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-80/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/unnamed-1-1.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/unnamed-1-1.png"/><meta property="og:image:width" content="576"/><meta property="og:image:height" content="324"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2021-02-24T12:00:00.000-08:00","dateModified":"2022-10-06T09:37:13.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Face Datasets Under Fire, Baking With AI, Human Disabilities","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/06/unnamed-1-1.png","width":576,"height":324},"publisher":{"@type":"Organization","name":"Face Datasets Under Fire, Baking With AI, Human Disabilities","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: Cutting Corners to Recognize Faces | AI may help revolutionize the human diet – or dessert, at least | Human Disabilities Baffle Algorithms"}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-80/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 80</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Feb 24, 2021</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">11<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/feb-24-2021/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Feb 24, 2021</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">11<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-80/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-80/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-80/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,</em></p><p><em>AI-enabled automation is often portrayed as a binary on-or-off: A process is either automated or not. But in practice, automation is a spectrum, and AI teams have to choose where on this spectrum to operate. It’s important to weigh the social impact of our work, and we must ameliorate automation’s impact on jobs. In addition to this important consideration, the best choice often depends on the application and what AI can and cannot do.</em><br><br><em>Take the problem of diagnosing medical patients from X-rays. The deployment options include:</em></p><ul><li><em><strong>Human only:</strong> No AI involved.</em></li><li><em><strong>Shadow mode:</strong> A human doctor reads an X-ray and decides on a diagnosis, but an AI system shadows the doctor with its own attempt. The system’s output doesn’t create value for doctors or patients directly, but it is saved for analysis to help a machine learning team evaluate the AI’s performance before dialing it up to the next level of automation.</em></li><li><em><strong>AI assistance:</strong> A human doctor is responsible for the diagnosis, but the AI system may supply suggestions. For example, it can highlight areas of an X-ray for the doctor to focus on.</em></li><li><em><strong>Partial automation:</strong> An AI system looks at an X-ray image and, if it has high confidence in its decision, renders a diagnosis. In cases where it’s not confident, it asks a human to make the decision.</em></li><li><em><strong>Full automation:</strong> AI makes the diagnosis.</em></li></ul><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/02/unnamed-1-1.png" class="kg-image" alt="Process of diagnosing a medical patient slide" loading="lazy"></figure><p><em>These options can apply to medical diagnosis, visual inspection, autonomous navigation, media content moderation, and many other tasks. In many cases, I’ve found that picking the right one is critical for a successful deployment, and that using either too much or too little automation can have a significant negative impact.</em><br><br><em>When you’re choosing a point along the automation spectrum, it’s worth considering what degree of automation is possible given the AI system’s accuracy, availability of humans to assist with the task, and desired rate of decision making (for example, human-in-the-loop options won’t work if you need to select an ad to place on a webpage within 100 milliseconds). Today’s algorithms are good enough only for certain points on the spectrum in a given application. As an AI team gains experience and collects data, it might gradually move to higher levels of automation within ethical and legal boundaries.</em><br><br><em>Some people say that we should focus on IA (intelligence augmentation) rather than AI — that AI should be used to help humans perform tasks rather than automate those tasks. I believe we should try to create value for society overall. Automation can transform and create jobs (as when taxi cabs created new opportunities for cab drivers) as well as destroy them. Even as we pick a point on this spectrum, let’s take others’ livelihoods into account and create value that is widely and fairly shared.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h2 id="news">News</h2><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/02/unnamed-1.gif" class="kg-image" alt="Dozens of different faces shown in a series of images" loading="lazy"></figure><h2 id="cutting-corners-to-recognize-faces">Cutting Corners to Recognize Faces</h2><p>Datasets for training face recognition models have ballooned in size — while slipping in quality and respect for privacy.</p><p><strong>What’s new:</strong> In a <a href="https://arxiv.org/pdf/2102.00813.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">survey</a> of 130 datasets compiled over the last four decades, Mozilla fellow Inioluwa Deborah Raji and AI consultant Genevieve Fried traced how the need for increasing quantities of data led researchers to relax their standards. The result: datasets riddled with blurred photos, biased labels, and images of minors, collected and used without permission, the authors told <em><a href="https://www.technologyreview.com/2021/02/05/1017388/ai-deep-learning-facial-recognition-data-history/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">MIT Technology Review</a></em>.</p><p><strong>What they found:</strong> The study divides the history of face datasets into four periods.</p><ul><li>Starting in 1964, face images were captured in photo shoots using paid models and controlled lighting. Gathering these datasets was expensive and time-consuming; the biggest comprised 7,900 images.</li><li>The U.S. Department of Defense kicked off the second period in 1996 by spending $6.5 million to develop <a href="https://www.nist.gov/programs-projects/face-recognition-technology-feret?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">FERET</a>, which contained 14,126 images of 1,200 individuals. Like most other datasets of this era, it was compiled from photo shoots with consenting subjects. Models trained on these datasets faltered in the real world partly due to their relatively homogenous lighting and poses.</li><li>Released in 2007, <a href="http://vis-www.cs.umass.edu/lfw/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Labeled Faces in the Wild</a> was the first face dataset scraped from the web. LFW’s 13,000 images included varied lighting conditions, poses, and facial expressions. Other large datasets were gathered from Google, Flickr, and Yahoo as well as mugshots and surveillance footage.</li><li>In 2014, Facebook introduced <a href="https://research.fb.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">DeepFace</a>, the first face recognition model that used deep learning, which identified people with unprecedented accuracy. Researchers collected tens of millions of images to take advantage of this data-intensive approach. Obtaining consent for every example became impossible, as did ensuring that each one’s label was accurate and unbiased.</li></ul><p><strong>Why it matters:</strong> People deserve to be treated fairly and respectfully by algorithms as well as other people. Moreover, datasets assembled without due attention to permission and data quality erode the public’s trust in machine learning. Companies like <a href="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Clearview.ai</a> and <a href="https://nakedsecurity.sophos.com/2019/05/31/facial-recognition-used-to-strip-adult-industry-workers-of-anonymity/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">FindFace</a> stand accused of harvesting online images without consent and using them in ways that violate individuals’ privacy, while shaky algorithms have contributed to <a href="https://www.technologyreview.com/2020/12/29/1015563/why-2020-was-a-pivotal-contradictory-year-for-facial-recognition/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">biased policing</a>. In the <a href="https://www.theguardian.com/technology/2020/jun/23/uks-facial-recognition-technology-breaches-privacy-rights?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">U.K.</a>, <a href="https://www.cbc.ca/news/politics/technology-clearview-facial-recognition-1.5899008?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Canada</a>, and <a href="https://techcrunch.com/2020/07/15/facial-recognition-lawsuit-vance-janecyk-bipa/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">certain U.S. jurisdictions</a>, lawmakers and lawsuits are calling for restrictions on the use of face images without consent.</p><p><strong>We’re thinking:</strong> Andrew and his teams have worked on many face recognition systems over the years. Our practices have evolved — and continue to do so — as both society and AI practitioners have come to recognize the importance of privacy. As we gather data, we must also work toward fairer and more respectful standards governing its collection, documentation, and use.</p><p><strong>Fun fact:</strong> Andrew’s face appears (with permission!) in a Carnegie Mellon University face <a href="https://www.cs.cmu.edu/~tom/faces.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">dataset</a> collected by Tom Mitchell in 1996. Here’s <a href="https://twitter.com/i/status/1105594325344251904?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">what Andrew looked like</a> in those days. </p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/02/unnamed-1-1.gif" class="kg-image" alt="Different graphs showing switch transformer data " loading="lazy"></figure><h2 id="bigger-faster-transformers">Bigger, Faster Transformers</h2><p>Performance in language tasks <a href="https://arxiv.org/abs/2001.0836?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">rises with the size of the model</a> — yet, as a model’s parameter count rises, so does the time it takes to render output. New work pumps up the number of parameters without slowing down the network.<br><br><strong>What’s new:</strong> William Fedus, Barret Zoph, and Noam Shazeer at Google Brain developed the <a href="https://arxiv.org/abs/2101.03961?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Switch Transformer</a>, a large-scale architecture (the authors built a version comprising 1.6 <em>trillion</em> parameters) that’s nearly as fast as a much smaller model.<br><br><strong>Key insight:</strong> The approach known as <a href="https://arxiv.org/abs/1701.06538?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">mixture-of-experts</a> uses only a subset of a model’s parameters per input example. Like mixture-of-experts, Switch Transformer chooses which of many layers would best process a given input.<br><br><strong>How it works:</strong> The authors trained Switch Transformer to predict words that had been removed at random from a <a href="https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">large text dataset</a> scraped from the web. The dataset was preprocessed to remove offensive language, placeholder text, and other issues.</p><ul><li>A typical transformer extracts a representation from each input token, such as a word, and then uses self-attention to compare the representations before passing them to a fully connected layer. Switch Transformer replaces the fully connected layer with one of a number (determined by a hyperparameter) of fully connected layers.</li><li>A softmax layer calculates the probability that any particular fully connected layer is best for processing a given token. Then it uses the chosen layer in the usual manner.</li><li>The fully connected layers process tokens in parallel. The authors added a loss to encourage them to be equally active. On a hardware chip, a separate processor core handles each layer, so this loss encourages equal distribution of the load on each core.</li></ul><p><strong>Results:</strong> The authors compared Switch Transformer (7.4 billion parameters) to <a href="https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">T5</a> (223 million parameters), a variant similar to the original transformer that was trained on the same dataset, using negative log perplexity, a measure of the model’s uncertainty (higher is better). The new model achieved -1.561 negative log perplexity compared to T5’s -1.731. Switch Transformer ran at two-thirds the speed of T5 — it executed 1,000 predictions per second compared to T5’s 1,600 — with 33 times the number of parameters. It beat a mixture-of-experts transformer, presumably of roughly the same size, on both counts.<br><br><strong>Why it matters:</strong> In deep learning, bigger is better — but so is a manageable computation budget.<br><br><strong>We’re thinking:</strong> Transformers come in an increasing variety of flavors. We hope this summary helps you remember which is switch. </p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/02/unnamed-2.gif" class="kg-image" alt="Person in wheelchair, person in side profile, person wearing a hoodie" loading="lazy"></figure><h2 id="human-disabilities-baffle-algorithms">Human Disabilities Baffle Algorithms</h2><p>Facebook’s content moderation algorithms block many advertisements aimed at disabled people.</p><p><strong>What’s new:</strong> The social media platform’s automated systems regularly reject ads for clothing designed for people with physical disabilities. The algorithms have misread such messages as pornography or sales pitches for medical devices, <em><a href="https://www.nytimes.com/2021/02/11/style/disabled-fashion-facebook-discrimination.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">The New York Times</a></em> reported.</p><p><strong>How it works:</strong> Automated systems at Facebook and Instagram examines the images and words in ads that users try to place on the sites. They turn down ads they deem to violate their terms of service. The system tells would-be ad buyers when it rejects their messages, but not why, making it difficult for advertisers to bring rejected materials into compliance. Companies can appeal rejections, but appeals often are reviewed by another AI system, creating a frustrating loop.</p><ul><li>Facebook disallowed an ad for a sweatshirt from <a href="https://mighty-well.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Mighty Well</a> bearing the words “I am immunocompromised — please give me space.” The social network’s algorithm had flagged it as a medical product. Mighty Well successfully appealed the decision.</li><li>Facebook and Instagram rejected ads from <a href="https://slickchicksonline.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Slick Chicks</a>, which makes underwear that clasps on the side as a convenience for wheelchair users, saying the ads contained “adult content.” Slick Chicks’ founder appealed the decision in dozens of emails and launched an online petition before Facebook lifted the ban.</li><li>The social-networking giant routinely rejects ads from <a href="https://juniperunltd.com/blogs/style/yarrow?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Yarrow</a>, which sells pants specially fitted for people in wheelchairs. Facebook doesn’t allow ads for medical equipment, and apparently the algorithm concluded that the ads were for wheelchairs. Yarrow has successfully appealed the rejections, which takes an average of 10 days each.</li><li><a href="https://www.pattiandricky.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Patty + Ricky</a>, a marketplace that sells clothing for people with disabilities, has appealed Facebook’s rejection of 200 adaptive fashion products.</li></ul><p><strong>Behind the news:</strong> Other social media platforms have been tripped up by well-intentioned efforts to control harmful speech.</p><ul><li><a href="https://www.news18.com/news/buzz/youtube-ai-blocked-chess-channel-after-confusing-black-and-white-for-racist-slurs-3454316.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">YouTube</a> blocked a popular chess channel for promoting harmful and dangerous content. Apparently, its algorithm objected to words like “black,” “white,” “attack,” and “threat” in descriptions of chess matches.</li><li>In 2019, TikTok admitted to <a href="https://www.theverge.com/2019/12/2/20991843/tiktok-bytedance-platform-disabled-autism-lgbt-fat-user-algorithm-reach-limit?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">suppressing</a> videos made by users who were disabled, queer, or overweight, purportedly an effort to discourage bullying.</li></ul><p><strong>Why it matters:</strong> Millions of <a href="https://www.facebook.com/business/news/3-million-advertisers?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">small businesses</a> advertise on Facebook and Instagram, many of which serve niche communities. For such companies, being barred from promoting their wares on these platforms is a major blow.</p><p><strong>We’re thinking:</strong> Moderating content on platforms as big as Facebook would be impossible without AI. But these cases illustrate how far automated systems are from being able to handle the job by themselves. Humans in the loop are still required to mediate between online platforms and their users.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM <a href="https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io">DEEPLEARNING.AI</a></h2><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/02/unnamed-2-1024x576.png" class="kg-image" alt loading="lazy"></figure><p>Last day to register for “Optimizing BizOps with AI,” an Expert Panel presented in collaboration with FourthBrain. Technical leaders at Amazon, Samsung, and Uber will explain how they’re deploying AI to improve business efficiency. Join us on Feb. 25, 2021, at 4 p.m. Pacific Standard Time! <a href="https://aibusiness.eventbrite.com/?aff=batch&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">RSVP</a></p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/02/unnamed-3.gif" class="kg-image" alt="Model predicting ingredients in a recipe and woman cooking" loading="lazy"></figure><h2 id="cake-cookie-cakie">Cake + Cookie = Cakie</h2><p>AI may help revolutionize the human diet – or dessert, at least.</p><p><strong>What’s new:</strong> Google applied AI engineer Dale Markowitz and developer advocate Sara Robinson <a href="https://cloud.google.com/blog/topics/developers-practitioners/baking-recipes-made-ai?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">trained</a> a model to predict whether a recipe is a bread, cake, or cookie. They brightened the recent holiday season by using it to develop novel hybrid recipes.</p><p><strong>How it works:</strong> The engineers conceived their project to demonstrate Google’s AutoML, a software suite for easy-bake machine learning.</p><ul><li>They compiled and labeled roughly 600 recipes for breads, cakes, or cookies and limited ingredient lists to 16 essentials, like eggs, flour, and milk.</li><li>They trained a model to classify recipes as bread, cake, or cookies with high accuracy.</li><li>For each recipe, AutoML’s explainability feature assigned the ingredients a percentage that described their importance to the classification. Butter, sugar, and yeast were most important overall.</li><li>The authors adjusted ingredient ratios until they developed a recipe that the model classified as equal parts cookie and cake, and another that was equal parts bread and cookie. They baked and tasted these creations: a cakie (“nasty”) and a breakie (“pretty good”).</li></ul><p><strong>Behind the news:</strong> Machine learning’s culinary education is coming along, though some of its creations are tastier than others.</p><ul><li>Sony AI’s <a href="https://venturebeat.com/2020/12/14/sony-ai-launches-the-gastronomy-flagship-project-to-apply-ai-to-cooking/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Flagship Gastronomy Project</a> recently launched an app to help professional chefs develop new recipes, food pairings, and menus.</li><li>In 2019, <a href="https://ai.facebook.com/blog/inverse-cooking/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Facebook</a> trained a vision model to recognize different types of food and generate recipes to produce them.</li><li>In 2016, IBM debuted <a href="https://www.newyorker.com/magazine/2016/11/28/cooking-with-chef-watson-ibms-artificial-intelligence-app?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Chef Watson</a>, an app trained partly on <em>Bon</em> <em>Appétit’s</em> recipe archive, which generates recipes based on ingredients specified by users.</li><li>Blogger Janelle Shane <a href="https://aiweirdness.com/post/190569291992/ai-recipes-are-bad-and-a-proposal-for-making-them?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">prompted</a> GPT-2 to generate recipes for dish names that were themselves generated by AI, producing gustatory horrors like Chocolate Chicken Chicken Cake.</li></ul><p><strong>Why it matters:</strong> Experimenting with new recipes isn’t just fun for home cooks. Commercial test kitchens are on the lookout for novel flavors, textures, and dishes. AI could help chefs invent smorgasbords of culinary delights.</p><p><strong>We’re thinking:</strong> These AI-powered recipes may seem half-baked, but suddenly we have a craving for Chocolate Chicken Chicken Cake.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/02/unnamed-4.gif" class="kg-image" alt="System Oscar+ working" loading="lazy"></figure><h2 id="sharper-eyes-for-visionlanguage">Sharper Eyes For Vision+Language</h2><p>Models that interpret the interplay of words and images tend to be trained on richer bodies of text than images. Recent research worked toward giving such models a more balanced knowledge of the two domains.<br><br><strong>What’s new:</strong> Pengchuan Zhang and Xiujun Li led a team at Microsoft and University of Washington raised the bar in several vision-and-language tasks. They call their system <a href="https://www.microsoft.com/en-us/research/publication/vinvl-making-visual-representations-matter-in-vision-language-models/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Oscar+</a>, building on earlier <a href="https://arxiv.org/abs/2004.06165?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">work </a>that used class names of objects in an image to improve matching of image and text representations.<br><br><strong>Key insight:</strong> Recent progress in vision-and-language models has come mostly by combining learned image and text representations more effectively rather than improving the representations themselves, the authors observed. Honing these representations through additional pretraining ought to boost their performance.<br><br><strong>How it works:</strong> The authors started with pretrained representations for images and text generated by separate models for vision (<a href="https://arxiv.org/abs/1611.05431?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">ResNeXt-152 C4</a>  pretrained on <a href="http://image-net.org/index?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">ImageNet-5k</a>) and language (pretrained <a href="https://arxiv.org/abs/1810.04805?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">BERT</a>). They honed the image representations by further pretraining the vision model on new data. Then they generated image-and-text representations as they pretrained Oscar+ as a whole. Finally, they fine-tuned the system on specific vision-and-language tasks.</p><ul><li>In the additional pretraining step, the authors pretrained the ResNeXt-152 C4 to detect 1,848 objects or attributes (such as labels describing colors or textures) in 2.49 million images in <a href="https://cocodataset.org/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">four </a><a href="https://github.com/openimages/dataset?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">object</a> <a href="https://www.objects365.org/overview.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">detection</a> <a href="http://visualgenome.org/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">datasets</a>.</li><li>A transformer fused image and text representations as the authors pretrained Oscar+ on 8.85 million examples from <a href="https://www.kaggle.com/hsankesara/flickr-image-dataset?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">four</a> <a href="https://cocodataset.org/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">image</a> <a href="https://ai.google.com/research/ConceptualCaptions/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">caption</a> <a href="https://www.cs.virginia.edu/~vicente/sbucaptions/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">datasets</a> with generated image tags, <a href="https://github.com/openimages/dataset?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">image tag datasets</a> with generated captions, and <a href="https://visualqa.org/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">visual question-and-answer</a> <a href="https://cs.stanford.edu/people/dorarad/gqa/about.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">datasets</a>. At this stage, the system optimized two loss terms. One term encouraged the system to predict randomly hidden words in a caption or an image’s tags. The other term encouraged the system to match an image and its tags, or an answer with its question and its image.</li><li>They fine-tuned the system to perform seven specific tasks.</li></ul><p><strong>Results:</strong> Oscar+ achieved state-of-the-art results in all seven tasks, from <a href="https://cocodataset.org/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">matching images with captions</a> (and vice-versa) to <a href="http://lil.nlp.cornell.edu/nlvr/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">determining the truth of a statement about two images</a>. The system boosted <a href="https://nocaps.org/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">NoCaps</a> accuracy (captioning images that contain objects not seen in training) to 92.5 percent from 86.6 percent — its biggest gain. To show that performance was substantially improved by separately pretraining the object detector on additional data, the authors compared performance with and without that step. That step boosted visual question-answering accuracy, for instance, to 74.90 percent from 71.34 percent.<br><br><strong>Why it matters:</strong> Performance in multimodal tasks can improve with additional learning in just one of the modes involved.<br><br><strong>We’re thinking:</strong> If <a href="https://www.youtube.com/watch?v=7JRoo4o9fF8&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=2&_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ" rel="noreferrer noopener">Oscar is a grouch</a>, is Oscar+ nicer — or even more grumpy?</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F08%2FVertical-side-banner-ads-5.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://bit.ly/3YTVMir"><div class="absolute inset-0" data-gtm-event-title="Generative AI for Software Development"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-80/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-80/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-80/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm42" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-80","id":"60bfddae274d5b003b1062fc","uuid":"196ce8c5-9f67-4c0b-a45e-fba5a8074eec","title":"The Batch: Face Datasets Under Fire, Baking With AI, Human Disabilities Baffle Algorithms, Ginormous Transformers","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAI-enabled automation is often portrayed as a binary on-or-off: A process is either automated or not. But in practice, automation is a spectrum, and AI teams have to choose where on this spectrum to operate. It’s important to weigh the social impact of our work, and we must ameliorate automation’s impact on jobs. In addition to this important consideration, the best choice often depends on the application and what AI can and cannot do.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eTake the problem of diagnosing medical patients from X-rays. The deployment options include:\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003eHuman only:\u003c/strong\u003e No AI involved.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003eShadow mode:\u003c/strong\u003e A human doctor reads an X-ray and decides on a diagnosis, but an AI system shadows the doctor with its own attempt. The system’s output doesn’t create value for doctors or patients directly, but it is saved for analysis to help a machine learning team evaluate the AI’s performance before dialing it up to the next level of automation.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003eAI assistance:\u003c/strong\u003e A human doctor is responsible for the diagnosis, but the AI system may supply suggestions. For example, it can highlight areas of an X-ray for the doctor to focus on.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003ePartial automation:\u003c/strong\u003e An AI system looks at an X-ray image and, if it has high confidence in its decision, renders a diagnosis. In cases where it’s not confident, it asks a human to make the decision.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003eFull automation:\u003c/strong\u003e AI makes the diagnosis.\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/unnamed-1-1.png\" class=\"kg-image\" alt=\"Process of diagnosing a medical patient slide\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eThese options can apply to medical diagnosis, visual inspection, autonomous navigation, media content moderation, and many other tasks. In many cases, I’ve found that picking the right one is critical for a successful deployment, and that using either too much or too little automation can have a significant negative impact.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eWhen you’re choosing a point along the automation spectrum, it’s worth considering what degree of automation is possible given the AI system’s accuracy, availability of humans to assist with the task, and desired rate of decision making (for example, human-in-the-loop options won’t work if you need to select an ad to place on a webpage within 100 milliseconds). Today’s algorithms are good enough only for certain points on the spectrum in a given application. As an AI team gains experience and collects data, it might gradually move to higher levels of automation within ethical and legal boundaries.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eSome people say that we should focus on IA (intelligence augmentation) rather than AI — that AI should be used to help humans perform tasks rather than automate those tasks. I believe we should try to create value for society overall. Automation can transform and create jobs (as when taxi cabs created new opportunities for cab drivers) as well as destroy them. Even as we pick a point on this spectrum, let’s take others’ livelihoods into account and create value that is widely and fairly shared.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"news\"\u003eNews\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/unnamed-1.gif\" class=\"kg-image\" alt=\"Dozens of different faces shown in a series of images\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch2 id=\"cutting-corners-to-recognize-faces\"\u003eCutting Corners to Recognize Faces\u003c/h2\u003e\u003cp\u003eDatasets for training face recognition models have ballooned in size — while slipping in quality and respect for privacy.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e In a \u003ca href=\"https://arxiv.org/pdf/2102.00813.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003esurvey\u003c/a\u003e of 130 datasets compiled over the last four decades, Mozilla fellow Inioluwa Deborah Raji and AI consultant Genevieve Fried traced how the need for increasing quantities of data led researchers to relax their standards. The result: datasets riddled with blurred photos, biased labels, and images of minors, collected and used without permission, the authors told \u003cem\u003e\u003ca href=\"https://www.technologyreview.com/2021/02/05/1017388/ai-deep-learning-facial-recognition-data-history/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eMIT Technology Review\u003c/a\u003e\u003c/em\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat they found:\u003c/strong\u003e The study divides the history of face datasets into four periods.\u003c/p\u003e\u003cul\u003e\u003cli\u003eStarting in 1964, face images were captured in photo shoots using paid models and controlled lighting. Gathering these datasets was expensive and time-consuming; the biggest comprised 7,900 images.\u003c/li\u003e\u003cli\u003eThe U.S. Department of Defense kicked off the second period in 1996 by spending $6.5 million to develop \u003ca href=\"https://www.nist.gov/programs-projects/face-recognition-technology-feret?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eFERET\u003c/a\u003e, which contained 14,126 images of 1,200 individuals. Like most other datasets of this era, it was compiled from photo shoots with consenting subjects. Models trained on these datasets faltered in the real world partly due to their relatively homogenous lighting and poses.\u003c/li\u003e\u003cli\u003eReleased in 2007, \u003ca href=\"http://vis-www.cs.umass.edu/lfw/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eLabeled Faces in the Wild\u003c/a\u003e was the first face dataset scraped from the web. LFW’s 13,000 images included varied lighting conditions, poses, and facial expressions. Other large datasets were gathered from Google, Flickr, and Yahoo as well as mugshots and surveillance footage.\u003c/li\u003e\u003cli\u003eIn 2014, Facebook introduced \u003ca href=\"https://research.fb.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eDeepFace\u003c/a\u003e, the first face recognition model that used deep learning, which identified people with unprecedented accuracy. Researchers collected tens of millions of images to take advantage of this data-intensive approach. Obtaining consent for every example became impossible, as did ensuring that each one’s label was accurate and unbiased.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e People deserve to be treated fairly and respectfully by algorithms as well as other people. Moreover, datasets assembled without due attention to permission and data quality erode the public’s trust in machine learning. Companies like \u003ca href=\"https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eClearview.ai\u003c/a\u003e and \u003ca href=\"https://nakedsecurity.sophos.com/2019/05/31/facial-recognition-used-to-strip-adult-industry-workers-of-anonymity/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eFindFace\u003c/a\u003e stand accused of harvesting online images without consent and using them in ways that violate individuals’ privacy, while shaky algorithms have contributed to \u003ca href=\"https://www.technologyreview.com/2020/12/29/1015563/why-2020-was-a-pivotal-contradictory-year-for-facial-recognition/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003ebiased policing\u003c/a\u003e. In the \u003ca href=\"https://www.theguardian.com/technology/2020/jun/23/uks-facial-recognition-technology-breaches-privacy-rights?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eU.K.\u003c/a\u003e, \u003ca href=\"https://www.cbc.ca/news/politics/technology-clearview-facial-recognition-1.5899008?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eCanada\u003c/a\u003e, and \u003ca href=\"https://techcrunch.com/2020/07/15/facial-recognition-lawsuit-vance-janecyk-bipa/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003ecertain U.S. jurisdictions\u003c/a\u003e, lawmakers and lawsuits are calling for restrictions on the use of face images without consent.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Andrew and his teams have worked on many face recognition systems over the years. Our practices have evolved — and continue to do so — as both society and AI practitioners have come to recognize the importance of privacy. As we gather data, we must also work toward fairer and more respectful standards governing its collection, documentation, and use.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eFun fact:\u003c/strong\u003e Andrew’s face appears (with permission!) in a Carnegie Mellon University face \u003ca href=\"https://www.cs.cmu.edu/~tom/faces.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003edataset\u003c/a\u003e collected by Tom Mitchell in 1996. Here’s \u003ca href=\"https://twitter.com/i/status/1105594325344251904?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003ewhat Andrew looked like\u003c/a\u003e in those days. \u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/unnamed-1-1.gif\" class=\"kg-image\" alt=\"Different graphs showing switch transformer data \" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch2 id=\"bigger-faster-transformers\"\u003eBigger, Faster Transformers\u003c/h2\u003e\u003cp\u003ePerformance in language tasks \u003ca href=\"https://arxiv.org/abs/2001.0836?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003erises with the size of the model\u003c/a\u003e — yet, as a model’s parameter count rises, so does the time it takes to render output. New work pumps up the number of parameters without slowing down the network.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e William Fedus, Barret Zoph, and Noam Shazeer at Google Brain developed the \u003ca href=\"https://arxiv.org/abs/2101.03961?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eSwitch Transformer\u003c/a\u003e, a large-scale architecture (the authors built a version comprising 1.6 \u003cem\u003etrillion\u003c/em\u003e parameters) that’s nearly as fast as a much smaller model.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e The approach known as \u003ca href=\"https://arxiv.org/abs/1701.06538?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003emixture-of-experts\u003c/a\u003e uses only a subset of a model’s parameters per input example. Like mixture-of-experts, Switch Transformer chooses which of many layers would best process a given input.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The authors trained Switch Transformer to predict words that had been removed at random from a \u003ca href=\"https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003elarge text dataset\u003c/a\u003e scraped from the web. The dataset was preprocessed to remove offensive language, placeholder text, and other issues.\u003c/p\u003e\u003cul\u003e\u003cli\u003eA typical transformer extracts a representation from each input token, such as a word, and then uses self-attention to compare the representations before passing them to a fully connected layer. Switch Transformer replaces the fully connected layer with one of a number (determined by a hyperparameter) of fully connected layers.\u003c/li\u003e\u003cli\u003eA softmax layer calculates the probability that any particular fully connected layer is best for processing a given token. Then it uses the chosen layer in the usual manner.\u003c/li\u003e\u003cli\u003eThe fully connected layers process tokens in parallel. The authors added a loss to encourage them to be equally active. On a hardware chip, a separate processor core handles each layer, so this loss encourages equal distribution of the load on each core.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The authors compared Switch Transformer (7.4 billion parameters) to \u003ca href=\"https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eT5\u003c/a\u003e (223 million parameters), a variant similar to the original transformer that was trained on the same dataset, using negative log perplexity, a measure of the model’s uncertainty (higher is better). The new model achieved -1.561 negative log perplexity compared to T5’s -1.731. Switch Transformer ran at two-thirds the speed of T5 — it executed 1,000 predictions per second compared to T5’s 1,600 — with 33 times the number of parameters. It beat a mixture-of-experts transformer, presumably of roughly the same size, on both counts.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e In deep learning, bigger is better — but so is a manageable computation budget.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Transformers come in an increasing variety of flavors. We hope this summary helps you remember which is switch. \u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/unnamed-2.gif\" class=\"kg-image\" alt=\"Person in wheelchair, person in side profile, person wearing a hoodie\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch2 id=\"human-disabilities-baffle-algorithms\"\u003eHuman Disabilities Baffle Algorithms\u003c/h2\u003e\u003cp\u003eFacebook’s content moderation algorithms block many advertisements aimed at disabled people.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e The social media platform’s automated systems regularly reject ads for clothing designed for people with physical disabilities. The algorithms have misread such messages as pornography or sales pitches for medical devices, \u003cem\u003e\u003ca href=\"https://www.nytimes.com/2021/02/11/style/disabled-fashion-facebook-discrimination.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eThe New York Times\u003c/a\u003e\u003c/em\u003e reported.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e Automated systems at Facebook and Instagram examines the images and words in ads that users try to place on the sites. They turn down ads they deem to violate their terms of service. The system tells would-be ad buyers when it rejects their messages, but not why, making it difficult for advertisers to bring rejected materials into compliance. Companies can appeal rejections, but appeals often are reviewed by another AI system, creating a frustrating loop.\u003c/p\u003e\u003cul\u003e\u003cli\u003eFacebook disallowed an ad for a sweatshirt from \u003ca href=\"https://mighty-well.com/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eMighty Well\u003c/a\u003e bearing the words “I am immunocompromised — please give me space.” The social network’s algorithm had flagged it as a medical product. Mighty Well successfully appealed the decision.\u003c/li\u003e\u003cli\u003eFacebook and Instagram rejected ads from \u003ca href=\"https://slickchicksonline.com/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eSlick Chicks\u003c/a\u003e, which makes underwear that clasps on the side as a convenience for wheelchair users, saying the ads contained “adult content.” Slick Chicks’ founder appealed the decision in dozens of emails and launched an online petition before Facebook lifted the ban.\u003c/li\u003e\u003cli\u003eThe social-networking giant routinely rejects ads from \u003ca href=\"https://juniperunltd.com/blogs/style/yarrow?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eYarrow\u003c/a\u003e, which sells pants specially fitted for people in wheelchairs. Facebook doesn’t allow ads for medical equipment, and apparently the algorithm concluded that the ads were for wheelchairs. Yarrow has successfully appealed the rejections, which takes an average of 10 days each.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.pattiandricky.com/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003ePatty + Ricky\u003c/a\u003e, a marketplace that sells clothing for people with disabilities, has appealed Facebook’s rejection of 200 adaptive fashion products.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Other social media platforms have been tripped up by well-intentioned efforts to control harmful speech.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://www.news18.com/news/buzz/youtube-ai-blocked-chess-channel-after-confusing-black-and-white-for-racist-slurs-3454316.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eYouTube\u003c/a\u003e blocked a popular chess channel for promoting harmful and dangerous content. Apparently, its algorithm objected to words like “black,” “white,” “attack,” and “threat” in descriptions of chess matches.\u003c/li\u003e\u003cli\u003eIn 2019, TikTok admitted to \u003ca href=\"https://www.theverge.com/2019/12/2/20991843/tiktok-bytedance-platform-disabled-autism-lgbt-fat-user-algorithm-reach-limit?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003esuppressing\u003c/a\u003e videos made by users who were disabled, queer, or overweight, purportedly an effort to discourage bullying.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Millions of \u003ca href=\"https://www.facebook.com/business/news/3-million-advertisers?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003esmall businesses\u003c/a\u003e advertise on Facebook and Instagram, many of which serve niche communities. For such companies, being barred from promoting their wares on these platforms is a major blow.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Moderating content on platforms as big as Facebook would be impossible without AI. But these cases illustrate how far automated systems are from being able to handle the job by themselves. Humans in the loop are still required to mediate between online platforms and their users.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM \u003ca href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\"\u003eDEEPLEARNING.AI\u003c/a\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/unnamed-2-1024x576.png\" class=\"kg-image\" alt loading=\"lazy\"\u003e\u003c/figure\u003e\u003cp\u003eLast day to register for “Optimizing BizOps with AI,” an Expert Panel presented in collaboration with FourthBrain. Technical leaders at Amazon, Samsung, and Uber will explain how they’re deploying AI to improve business efficiency. Join us on Feb. 25, 2021, at 4 p.m. Pacific Standard Time! \u003ca href=\"https://aibusiness.eventbrite.com/?aff=batch\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eRSVP\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/unnamed-3.gif\" class=\"kg-image\" alt=\"Model predicting ingredients in a recipe and woman cooking\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch2 id=\"cake-cookie-cakie\"\u003eCake + Cookie = Cakie\u003c/h2\u003e\u003cp\u003eAI may help revolutionize the human diet – or dessert, at least.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Google applied AI engineer Dale Markowitz and developer advocate Sara Robinson \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/baking-recipes-made-ai?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003etrained\u003c/a\u003e a model to predict whether a recipe is a bread, cake, or cookie. They brightened the recent holiday season by using it to develop novel hybrid recipes.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The engineers conceived their project to demonstrate Google’s AutoML, a software suite for easy-bake machine learning.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThey compiled and labeled roughly 600 recipes for breads, cakes, or cookies and limited ingredient lists to 16 essentials, like eggs, flour, and milk.\u003c/li\u003e\u003cli\u003eThey trained a model to classify recipes as bread, cake, or cookies with high accuracy.\u003c/li\u003e\u003cli\u003eFor each recipe, AutoML’s explainability feature assigned the ingredients a percentage that described their importance to the classification. Butter, sugar, and yeast were most important overall.\u003c/li\u003e\u003cli\u003eThe authors adjusted ingredient ratios until they developed a recipe that the model classified as equal parts cookie and cake, and another that was equal parts bread and cookie. They baked and tasted these creations: a cakie (“nasty”) and a breakie (“pretty good”).\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Machine learning’s culinary education is coming along, though some of its creations are tastier than others.\u003c/p\u003e\u003cul\u003e\u003cli\u003eSony AI’s \u003ca href=\"https://venturebeat.com/2020/12/14/sony-ai-launches-the-gastronomy-flagship-project-to-apply-ai-to-cooking/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eFlagship Gastronomy Project\u003c/a\u003e recently launched an app to help professional chefs develop new recipes, food pairings, and menus.\u003c/li\u003e\u003cli\u003eIn 2019, \u003ca href=\"https://ai.facebook.com/blog/inverse-cooking/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eFacebook\u003c/a\u003e trained a vision model to recognize different types of food and generate recipes to produce them.\u003c/li\u003e\u003cli\u003eIn 2016, IBM debuted \u003ca href=\"https://www.newyorker.com/magazine/2016/11/28/cooking-with-chef-watson-ibms-artificial-intelligence-app?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eChef Watson\u003c/a\u003e, an app trained partly on \u003cem\u003eBon\u003c/em\u003e \u003cem\u003eAppétit’s\u003c/em\u003e recipe archive, which generates recipes based on ingredients specified by users.\u003c/li\u003e\u003cli\u003eBlogger Janelle Shane \u003ca href=\"https://aiweirdness.com/post/190569291992/ai-recipes-are-bad-and-a-proposal-for-making-them?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eprompted\u003c/a\u003e GPT-2 to generate recipes for dish names that were themselves generated by AI, producing gustatory horrors like Chocolate Chicken Chicken Cake.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Experimenting with new recipes isn’t just fun for home cooks. Commercial test kitchens are on the lookout for novel flavors, textures, and dishes. AI could help chefs invent smorgasbords of culinary delights.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e These AI-powered recipes may seem half-baked, but suddenly we have a craving for Chocolate Chicken Chicken Cake.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/02/unnamed-4.gif\" class=\"kg-image\" alt=\"System Oscar+ working\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch2 id=\"sharper-eyes-for-visionlanguage\"\u003eSharper Eyes For Vision+Language\u003c/h2\u003e\u003cp\u003eModels that interpret the interplay of words and images tend to be trained on richer bodies of text than images. Recent research worked toward giving such models a more balanced knowledge of the two domains.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Pengchuan Zhang and Xiujun Li led a team at Microsoft and University of Washington raised the bar in several vision-and-language tasks. They call their system \u003ca href=\"https://www.microsoft.com/en-us/research/publication/vinvl-making-visual-representations-matter-in-vision-language-models/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eOscar+\u003c/a\u003e, building on earlier \u003ca href=\"https://arxiv.org/abs/2004.06165?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003ework \u003c/a\u003ethat used class names of objects in an image to improve matching of image and text representations.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e Recent progress in vision-and-language models has come mostly by combining learned image and text representations more effectively rather than improving the representations themselves, the authors observed. Honing these representations through additional pretraining ought to boost their performance.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The authors started with pretrained representations for images and text generated by separate models for vision (\u003ca href=\"https://arxiv.org/abs/1611.05431?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eResNeXt-152 C4\u003c/a\u003e  pretrained on \u003ca href=\"http://image-net.org/index?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eImageNet-5k\u003c/a\u003e) and language (pretrained \u003ca href=\"https://arxiv.org/abs/1810.04805?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eBERT\u003c/a\u003e). They honed the image representations by further pretraining the vision model on new data. Then they generated image-and-text representations as they pretrained Oscar+ as a whole. Finally, they fine-tuned the system on specific vision-and-language tasks.\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn the additional pretraining step, the authors pretrained the ResNeXt-152 C4 to detect 1,848 objects or attributes (such as labels describing colors or textures) in 2.49 million images in \u003ca href=\"https://cocodataset.org/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003efour \u003c/a\u003e\u003ca href=\"https://github.com/openimages/dataset?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eobject\u003c/a\u003e \u003ca href=\"https://www.objects365.org/overview.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003edetection\u003c/a\u003e \u003ca href=\"http://visualgenome.org/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003edatasets\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eA transformer fused image and text representations as the authors pretrained Oscar+ on 8.85 million examples from \u003ca href=\"https://www.kaggle.com/hsankesara/flickr-image-dataset?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003efour\u003c/a\u003e \u003ca href=\"https://cocodataset.org/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eimage\u003c/a\u003e \u003ca href=\"https://ai.google.com/research/ConceptualCaptions/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003ecaption\u003c/a\u003e \u003ca href=\"https://www.cs.virginia.edu/~vicente/sbucaptions/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003edatasets\u003c/a\u003e with generated image tags, \u003ca href=\"https://github.com/openimages/dataset?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eimage tag datasets\u003c/a\u003e with generated captions, and \u003ca href=\"https://visualqa.org/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003evisual question-and-answer\u003c/a\u003e \u003ca href=\"https://cs.stanford.edu/people/dorarad/gqa/about.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003edatasets\u003c/a\u003e. At this stage, the system optimized two loss terms. One term encouraged the system to predict randomly hidden words in a caption or an image’s tags. The other term encouraged the system to match an image and its tags, or an answer with its question and its image.\u003c/li\u003e\u003cli\u003eThey fine-tuned the system to perform seven specific tasks.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e Oscar+ achieved state-of-the-art results in all seven tasks, from \u003ca href=\"https://cocodataset.org/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003ematching images with captions\u003c/a\u003e (and vice-versa) to \u003ca href=\"http://lil.nlp.cornell.edu/nlvr/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003edetermining the truth of a statement about two images\u003c/a\u003e. The system boosted \u003ca href=\"https://nocaps.org/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eNoCaps\u003c/a\u003e accuracy (captioning images that contain objects not seen in training) to 92.5 percent from 86.6 percent — its biggest gain. To show that performance was substantially improved by separately pretraining the object detector on additional data, the authors compared performance with and without that step. That step boosted visual question-answering accuracy, for instance, to 74.90 percent from 71.34 percent.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Performance in multimodal tasks can improve with additional learning in just one of the modes involved.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e If \u003ca href=\"https://www.youtube.com/watch?v=7JRoo4o9fF8\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026utm_content=2\u0026_hsenc=p2ANqtz--XRa7vIW8UYuvGD4sU9D8-a0ryBxFZA2N0M4bzWpMf8nD_LeeUPpkCl_TMXUSpylC7TuAKoSbzJOmNyBwPoTtYsNQRJQ\" rel=\"noreferrer noopener\"\u003eOscar is a grouch\u003c/a\u003e, is Oscar+ nicer — or even more grumpy?\u003c/p\u003e","comment_id":"60bfc9a1274d5b003b1060c3","feature_image":"https://dl-staging-website.ghost.io/content/images/2021/06/unnamed-1-1.png","featured":false,"visibility":"public","created_at":"2021-06-08T12:48:49.000-07:00","updated_at":"2022-10-06T09:37:13.000-07:00","published_at":"2021-02-24T12:00:00.000-08:00","custom_excerpt":"AI-enabled automation is often portrayed as a binary on-or-off: A process is either automated or not. But in practice, automation is a spectrum, and AI teams have to choose where on this spectrum to operate. It’s important to...","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"60bfddad274d5b003b1062be","name":"issue-80","slug":"issue-80","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-80/"},{"id":"60cc1d2a70a082003e13dd0e","name":"Feb 24, 2021","slug":"feb-24-2021","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/feb-24-2021/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-80/","excerpt":"AI-enabled automation is often portrayed as a binary on-or-off: A process is either automated or not. But in practice, automation is a spectrum, and AI teams have to choose where on this spectrum to operate. It’s important to...","reading_time":11,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Face Datasets Under Fire, Baking With AI, Human Disabilities","meta_description":"The Batch - AI News \u0026 Insights: Cutting Corners to Recognize Faces | AI may help revolutionize the human diet – or dessert, at least | Human Disabilities Baffle Algorithms","email_subject":null,"frontmatter":null,"feature_image_alt":"Process of diagnosing a medical patient slide","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/06/unnamed-1-1.png","dimensions":{"width":576,"height":324}},"banner":{"title":"Generative AI for Software Development","databaseId":35156,"id":"cG9zdDozNTE1Ng==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/08/Vertical-side-banner-ads-5.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3YTVMir","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-80"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>