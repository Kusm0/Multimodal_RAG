<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, and more...</title><meta name="description" content="The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-270/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-270/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2024-10-09T14:59:00.000-07:00"/><meta property="article:modified_time" content="2024-10-09T16:44:38.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue 270"/><meta property="article:tag" content="Oct 09, 2024"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, and more..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-270/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY.jpg"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY.jpg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="675"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2024-10-09T14:59:00.000-07:00","dateModified":"2024-10-09T16:44:38.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, and more...","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY.jpg","width":1200,"height":675},"publisher":{"@type":"Organization","name":"How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, and more...","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!"}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">‚ú® New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-270/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 270</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Oct 9, 2024</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">14<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/oct-09-2024/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Oct 09, 2024</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">14<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-270/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-270/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-270/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p>Dear friends,</p><p>Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize! It‚Äôs wonderful to see pioneering work in AI recognized, and this will be good for our whole field. Years ago, I was the first to call Geoff the ‚ÄúGodfather of Deep Learning,‚Äù which later became ‚ÄúGodfather of AI.‚Äù I‚Äôm thrilled at the recognition he‚Äôs receiving via this most prestigious of awards.</p><p>As Geoff relayed in the ‚ÄúHeroes of Deep Learning‚Äù&nbsp;<a href="https://www.youtube.com/watch?v=-eyhCTvrEtE&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">interview</a>&nbsp;I did with him years ago, his early work developing the foundations of neural networks has been instrumental to the rise of deep learning and AI. It has been years since I implemented a&nbsp;<a href="https://en.wikipedia.org/wiki/Hopfield_network?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">Hopfield network</a>, but John‚Äôs work, too, has been influential. Their recognition is well deserved!</p><p>But the Nobel committee wasn‚Äôt done yet. One day after the physics prize was announced, Demis Hassabis, John Jumper, and David Baker won the Chemistry Nobel Prize for their work on AlphaFold and protein design. AlphaFold and AlphaFold 2, as well as the work of Baker‚Äôs lab, are compelling applications of AI that made significant steps forward in chemistry and biology, and this award, too, is well deserved!</p><p>It‚Äôs remarkable that the Nobel committees for physics and chemistry, which are made up of scientists in those fields, chose to honor AI researchers with this year‚Äôs awards. This is a sign of our field‚Äôs growing impact on society.</p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY-1.jpg" class="kg-image" alt="Three people, Jeff Dean, Andrew Ng, and Geoff Hinton, stand together at Hinton‚Äôs retirement party, with Hinton holding a microphone." loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/HINTON-PARTY-1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/HINTON-PARTY-1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY-1.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><p>While it‚Äôs good that people from outside AI are recognizing AI researchers, I wonder if there‚Äôs room for the AI community to pick more award recipients ourselves. Best-known in computer science is the Turing Award, which is selected by a broad group of computer scientists, many of whom have deep AI knowledge. Many AI conferences give out best-paper awards. And applications of AI to other fields doubtless will continue to receive much-deserved recognition by leaders in those fields. I‚Äôm optimistic this will allow AI researchers to win more Nobel Prizes ‚Äî someday also in economics, literature, medicine, and peace, too.&nbsp;Nonetheless, this seems like a good time to see how all of us in AI can do more to recognize the work of innovators in our field.</p><p>Geoff once thanked me for my role in getting him anointed ‚ÄúGodfather of AI,‚Äù which he said was good for his career. I didn‚Äôt realize before that I had the power to give out such titles üòâ but I would love for there to be numerous godfathers and godmothers ‚Äî and many other awards ‚Äî in AI!</p><p>At Geoff's retirement party last October (pictured in the photo above), I spoke with affection and gratitude for all the work he has done to grow AI. Even as we cheer the new Nobel wins for AI, let‚Äôs continue to think about how we in AI can do more to celebrate the next generation of innovators.</p><p>Keep learning!</p><p>Andrew</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/introducing-multimodal-llama-3-2/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3"><img src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--15-.png" class="kg-image" alt="Promo banner for &quot;Introducing Multimodal Llama 3.2&quot;" loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/unnamed--15-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/unnamed--15-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--15-.png 1200w" sizes="(min-width: 720px) 720px"></a></figure><p>Try the new capabilities of Llama 3.2 in our latest course with Meta. Learn how to compose multimodal prompts, call custom tools, and use the Llama Stack API to build applications with Meta‚Äôs family of open weights models.&nbsp;<a href="https://www.deeplearning.ai/short-courses/introducing-multimodal-llama-3-2/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">Enroll for free!</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.gif" class="kg-image" alt="A demonstration of video editing through text input, altering a runner‚Äôs background and costume." loading="lazy" width="600" height="336" srcset="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.gif 600w"></figure><h1 id="familiar-faces-synthetic-soundtracks">Familiar Faces, Synthetic Soundtracks</h1><p>Meta upped the ante for text-to-video generation with new systems that produce consistent characters and matching soundtracks.</p><p><strong>What‚Äôs new:&nbsp;</strong>Meta presented&nbsp;<a href="https://ai.meta.com/research/movie-gen/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">Movie Gen</a>, a series of four systems that generate videos, include consistent characters, alter generated imagery, and add matching sound effects and music. Movie Gen will be&nbsp;<a href="https://www.instagram.com/zuck/reel/DAs_J17Pw0G/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">available</a>&nbsp;on Instagram in 2025. Meanwhile, you can view and listen to examples&nbsp;<a href="https://ai.meta.com/research/movie-gen/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">here</a>. The team&nbsp;<a href="https://ai.meta.com/static-resource/movie-gen-research-paper?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">explains</a>&nbsp;how the model was built an extensive 92-page paper.</p><p><strong>Generated videos:</strong>&nbsp;Movie Gen Video can output 256 frames (up to 16 seconds at 16 frames per second) at 1920x1080-pixel resolution. It includes a convolutional neural network autoencoder, transformer, and multiple embedding models.</p><ul><li>Movie Gen Video produces imagery by flow matching, a technique related to diffusion. It learned to remove noise from noisy versions of images and videos given matching text descriptions from 1 billion image-text pairs and 100 million video-text pairs. At inference, it starts with pure noise and generates detailed imagery according to a text prompt.</li><li>The system concatenates multiple text embeddings to combine the strengths of different embedding models.&nbsp;<a href="https://arxiv.org/abs/2205.05131?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">UL2</a>&nbsp;was trained on text-only data, so its embeddings may provide ‚Äúreasoning abilities,‚Äù according to the authors.&nbsp;<a href="https://arxiv.org/abs/2309.16671?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">Long-prompt MetaCLIP</a>&nbsp;was trained to produce similar text and image representations, so its embeddings might be useful for ‚Äúcross-modal generation.‚Äù&nbsp;<a href="https://arxiv.org/abs/2105.13626?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">ByT5</a>&nbsp;produces embeddings of individual text elements such as letters, numbers, and symbols; the system uses it when a prompt requests text within a clip.&nbsp;</li></ul><p><strong>Consistent characters:</strong>&nbsp;Given an image of a face, a fine-tuned version of Movie Gen Video generates a video that depicts a person with that face.&nbsp;</p><ul><li>To gather a training dataset for this capability, the team filtered Movie Gen Video‚Äôs pretraining dataset for clips that show a single face and consecutive frames are similar to one another. They built video-face examples by pairing each clip with a frame selected from the clip at random. To train the system, the team fed it text, the clip with added noise, and the single-frame face. It learned to remove the noise.</li><li>Trained on this data alone, the system generated videos in which the person always faces the camera. To expand the variety of poses, they further trained it on examples that substituted the faces in the previous step with&nbsp;<a href="https://arxiv.org/abs/2409.13346?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">generated versions</a>&nbsp;with alternate poses and facial expressions.</li></ul><p><strong>Altered clips:</strong>&nbsp;The team modified Movie Gen Video‚Äôs autoencoder to accept an embedding of an alteration ‚Äî say, changing the background or adding an object. They trained the system to alter videos in three stages:</p><ul><li>First, they trained the system, given a starting image and an instruction to alter it, to produce an altered image.</li><li>They further trained the system to produce altered clips. They generated two datasets of before-and-after clips based on instructions. (i) For instance, given a random frame and an instruction to, say, replace a person with a cat, the system altered the frame accordingly. Then the team subjected both frames to a series of augmentations selected at random, creating matching clips, one featuring a person, the other featuring a cat. Given the initial clip and the instruction, the system learned to generate the altered clip. (ii) The team used&nbsp;<a href="https://arxiv.org/abs/2303.05499?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">DINO</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2408.00714?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">SAM 2</a>&nbsp;to segment clips. Given an unsegmented clip and an instruction such as ‚Äúmark &lt;object&gt; with &lt;color&gt;,‚Äù the system learned to generate the segmented clip.&nbsp;</li><li>Finally, they trained the system to restore altered clips to their original content. They built a dataset by taking a ground-truth clip and using their system to generate an altered version according to an instruction. Then Llama 3 rewrote the instruction to modify the altered clip to match the original. Given the altered clip and the instruction, the system learned to generate the original clip.</li></ul><p><strong>Synthetic soundtracks:</strong>&nbsp;Given a text description, a system called Movie Gen Audio generates sound effects and instrumental music for video clips up to 30 seconds long. It includes a&nbsp;<a href="https://arxiv.org/abs/2306.06546?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">DACVAE</a>&nbsp;audio encoder (which encodes sounds that comes before and/or after the target audio), Long-prompt MetaCLIP video encoder,&nbsp;<a href="https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">T5</a>&nbsp;text encoder, vanilla neural network that encodes the current time step, and transformer.</p><ul><li>Movie Gen Audio learned to remove noise from noisy versions of audio associated with 1 million videos with text captions.&nbsp; At inference, it starts with pure noise and generates up to 30 seconds of audio at once.</li><li>At inference, it can extend audio. Given the last n seconds of audio, the associated portion of a video, and a text description, it can generate the next 30 - n seconds.</li></ul><p><strong>Results:</strong>&nbsp;Overall, Movie Gen achieved performance roughly equal to or better than competitors in qualitative evaluations of overall quality and a number of specific qualities (such as ‚Äúrealness‚Äù). Human evaluators rated their preferences for Movie Gen or a competitor. The team reported the results in terms of net win rate (win percentage minus loss percentage) between -100 percent and 100 percent, where a score above zero means that a system won more than it lost.</p><ul><li>For overall video quality, Movie Gen achieved a net win rate of 35.02 percent versus Runway Gen3, 8.23 percent versus Sora (based on the prompts and generated clips available on OpenAI‚Äôs website), and 3.87 percent versus Kling 1.5.</li><li>Generating clips of specific characters, Movie Gen achieved a net win rate of 64.74 percent versus ID-Animator, the state of the art for this capability.</li><li>Generating soundtracks for videos from the SReal SFX dataset, Movie Gen Audio achieved a net win rate between 32 percent and 85 percent compared to various video-to-audio models.</li><li>Altering videos in the&nbsp;<a href="https://arxiv.org/abs/2403.09334?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">TGVE+</a>&nbsp;dataset, Movie Gen beat all competitors more than 70 percent of the time.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;With Movie Gen, table stakes for video generation rises to include consistent characters, soundtracks, and various video-to-video alterations. The 92-page paper is a valuable resource for builders of video generation systems, explaining in detail how the team filtered data, structured models, and trained them to achieve good results.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;Meta has a great track record of publishing both model weights and papers that describe how the models were built. Kudos to the Movie Gen team for publishing the details of this work!</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--18-.gif" class="kg-image" alt="A smartphone on a table showing an incoming call with voice waveform displayed on screen." loading="lazy" width="600" height="337" srcset="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--18-.gif 600w"></figure><h1 id="voice-to-voice-and-more-for-gpt-4o-api">Voice-to-Voice and More for GPT-4o API</h1><p>OpenAI launched a suite of new and updated tools to help AI developers build applications and reduce costs.</p><p><strong>What‚Äôs new:&nbsp;</strong>At its annual DevDay conference, OpenAI&nbsp;introduced an&nbsp;<a href="https://openai.com/index/introducing-the-realtime-api/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">API<u>&nbsp;</u></a>for speech processing using GPT-4o,&nbsp;<a href="https://openai.com/index/api-model-distillation/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">distillation tools</a>,&nbsp;<a href="https://openai.com/index/introducing-vision-to-the-fine-tuning-api/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">vision fine-tuning capabilities</a>, and the ability to&nbsp;<a href="https://openai.com/index/api-prompt-caching/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">cache prompts</a>&nbsp;for later re-use. These tools are designed to make it easier to build fast applications using audio inputs and outputs, customize models, and cut costs for common tasks.</p><p><strong>Development simplified:</strong>&nbsp;The new offerings aim to make it easier to build applications using OpenAI models, with an emphasis on voice input/output and image input, customizing models, and resolving common pain points.</p><ul><li>The Realtime API enables speech-to-speech interactions with GPT-4o using six preset voices, like ChatGPT's Advanced Voice Mode but with lower latency. The API&nbsp;<a href="https://openai.com/api/pricing/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">costs</a>&nbsp;$100/$200 per 1 million input/output tokens (about $0.06/$0.24 per minute of input/output). (The API processes text at $5/$20 per million input/output tokens.</li><li>The Chat Completions API now accepts voice input and generates voice outputs for GPT-4o‚Äôs usual price ($3.75/$15 per million input/output tokens). However, it generates outputs less quickly than the Realtime API. (OpenAI didn‚Äôt disclose specific latency measurements.)</li><li>The distillation tools simplify the process of using larger models like o1-preview as teachers whose output is used to fine-tune smaller, more cost-efficient students like GPT-4o mini. Developers can generate datasets, fine-tune models, and evaluate performance within OpenAI's platform. For example, you can use GPT-4o to create responses to customer-service questions, then use the resulting dataset to fine-tune GPT-4o mini.</li><li>Vision fine-tuning allows developers to enhance GPT-4o's image understanding by fine-tuning the model on a custom image dataset. For instance, developers can improve visual search, object detection, or image analysis for a particular application by fine-tuning the model on domain-specific images. Vision fine-tuning costs $25 per million training tokens for GPT-4o, but OpenAI will give developers 1 million free training tokens per day through October 31.</li><li>Prompt caching automatically reuses input tokens that were entered in recent interactions with GPT-4o, GPT-4o mini, and their fine-tuned variants. Repeated prompts cost half as much and get processed faster. The discount and speed especially benefit applications like chatbots and code editors, which frequently reuse input context.</li></ul><p><strong>Behind the news:</strong>&nbsp;OpenAI is undertaking a major corporate transformation. A recent funding round&nbsp;<a href="https://www.nytimes.com/2024/10/02/technology/openai-valuation-150-billion.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">values</a>&nbsp;OpenAI at $157 billion, making it among the world‚Äôs most valuable private companies, and the company is&nbsp;<a href="https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">transferring</a>&nbsp;more control from its nonprofit board to its for-profit subsidiary. Meanwhile, it has seen an&nbsp;<a href="https://techcrunch.com/2024/10/03/a-co-lead-on-sora-openais-video-generator-has-left-for-google/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">exodus</a>&nbsp;of executives that include CTO Mira Murati, Sora co-lead Tim Brooks, chief research officer Bob McGrew, research VP Barret Zoph, and&nbsp;<a href="https://www.businessinsider.com/openai-talent-exodus-joke-tech-world-mira-murati-sam-altman-2024-9?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">other key researchers</a>.</p><p><strong>Why it matters:&nbsp;</strong>The Realtime API enables speech input and output without converting speech to text, allowing for more natural voice interactions. Such interactions open a wide range of applications, and they‚Äôre crucial for real-time systems like customer service bots and virtual assistants. Although&nbsp;<a href="https://aws.amazon.com/blogs/machine-learning/use-llama-3-1-405b-to-generate-synthetic-data-for-fine-tuning-tasks/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">Amazon Web Service</a>&nbsp;and&nbsp;<a href="https://labelbox.com/guides/end-to-end-workflow-for-knowledge-distillation-with-nlp/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">Labelbox</a>&nbsp;provide services to distill knowledge from OpenAI models into open architectures, OpenAI‚Äôs tools ease the process of distilling from OpenAI models into other OpenAI models. Image fine-tuning and prompt caching, like similar capabilities for Anthropic Claude and Google Gemini, are welcome additions.&nbsp;</p><p><strong>We‚Äôre thinking:</strong>&nbsp;OpenAI‚Äôs offerings have come a long way since&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-the-new-models-and-products-announced-by-openai-during-devday/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">DevDay 2023</a>, when speech recognition was ‚Äúcoming soon.‚Äù We‚Äôre eager to see what developers do with voice-driven applications!</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--16-.png" class="kg-image" alt="Collage of various images featuring a baseball player, movie scenes, portraits, landscapes, and diverse wildlife." loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/unnamed--16-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/unnamed--16-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--16-.png 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="german-court-laion-didn%E2%80%99t-violate-copyrights">German Court: LAION Didn‚Äôt Violate Copyrights</h1><p>A German court dismissed a copyright lawsuit against LAION, the nonprofit responsible for large-scale image datasets used to train Midjourney, Stable Diffusion, and other image generators.</p><p><strong>What‚Äôs new:</strong>&nbsp;The court&nbsp;<a href="https://www.technollama.co.uk/laion-wins-copyright-infringement-lawsuit-in-german-court?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">rejected</a>&nbsp;a lawsuit claiming that cataloging images on the web to train machine learning models violates the image owners‚Äô copyrights. It ruled that LAION‚Äôs activities fall under protections for scientific research.</p><p><strong>How it works:</strong>&nbsp;LAION doesn‚Äôt distribute images. Instead, it compiles links to images and related text that are published on publicly available websites. Model builders who wish to use the images and/or text must download them from those sources. In 2023, photographer Robert Kneschke&nbsp;<a href="https://www.technollama.co.uk/photographer-sues-laion-for-copyright-infringement?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">sued</a>&nbsp;LAION for including his photos. The court‚Äôs&nbsp;<a href="https://drive.google.com/file/d/1A_vnSJUwlrVovhIqA4rKIFaOktR4TvBt/view?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">decision</a>&nbsp;emphasized several key points.</p><ul><li>LAION, while compiling links to images, had indeed made unauthorized copies of images protected by copyright, as defined by German law. However, Germany‚Äôs Copyright Act allows unauthorized use of copyrighted works for scientific research. The court ruled that LAION had collected the material for this purpose, so it did not violate copyrights.</li><li>Moreover, the court found that downloading images and text in order to correlate them likely fell under a further exemption to copyright for data mining. This finding wasn‚Äôt definitive because the exemption for research made it irrelevant, but the court mentioned it to help guide future rulings.</li><li>The dataset‚Äôs noncommercial status was a key factor in the ruling. LAION distributed the dataset for free, and no commercial entity controlled its operations. Although a LAION dataset may be used to train a machine learning model that‚Äôs intended to be sold commercially, this is not sufficient to classify creating such datasets as commercial activity. The plaintiff contended that, because some LAION members have paid roles in commercial companies, LAION could be considered a commercial entity. However, the court rejected that argument.</li></ul><p><strong>Behind the news:</strong>&nbsp;Several other artists have sued&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-story-of-laion-the-dataset-behind-stable-diffusion/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">LAION</a>, which stands for Large-scale AI Open Network, claiming that the organization used their works without their consent. They have also sued AI companies, including a&nbsp;<a href="https://www.deeplearning.ai/the-batch/artists-file-a-lawsuit-against-stability-ai-and-midjourney/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">class action suit</a>&nbsp;against Stability AI, Midjourney, and DeviantArt for using materials under copyright, including images in LAION‚Äôs datasets, to train their models. Similar cases have been brought against makers of&nbsp;<a href="https://www.deeplearning.ai/the-batch/sony-umg-and-warner-music-sue-suno-and-udio-over-alleged-copyright-violations/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">music generators</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/judge-dismisses-key-arguments-in-ai-copyright-lawsuit-against-github-microsoft-and-openai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">coding assistants</a>. All these lawsuits, which are in progress, rest on the plaintiff‚Äôs claim that assembling a training dataset of copyrighted works infringes copyrights.</p><p><strong>Why it matters:</strong>&nbsp;The German ruling is the first AI-related decision in Europe since the adoption of the AI Act, and the court took that law‚Äôs intent into account when making its decision. It affirms that creating text-image pairs of publicly available material for the purpose of training machine learning models does not violate copyrights, even if commercial organizations later use the data. However, the court did not address whether training AI models on such datasets, or using the trained models in a commercial setting, violates copyrights.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;This decision is encouraging news for AI researchers. We hope jurisdictions worldwide establish that training models on media that‚Äôs available on the open web is fair and legal.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.png" class="kg-image" alt="Diagram illustrating the process of developing, deploying, and promoting a malicious LLM application for phishing and malicious services." loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/unnamed--17-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/unnamed--17-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.png 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="ai%E2%80%99s-criminal-underground-revealed">AI‚Äôs Criminal Underground Revealed</h1><p>Researchers probed the black market for AI services that are designed to facilitate cybercrime.</p><p><strong>What‚Äôs new</strong>: Zilong Lin and colleagues at Indiana University Bloomington&nbsp;<a href="https://arxiv.org/abs/2401.03315?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">studied</a>&nbsp;how large language models (LLMs) are used to provide harmful services, specifically generating malicious code, phishing emails, and phishing websites. They weren‚Äôt very effective, by and large (though a high success rate may not be necessary to support a thriving market in automated criminal activity).</p><p><strong>Risky business:</strong>&nbsp;Providers base such services on either uncensored LLMs ‚Äî that is, those that weren‚Äôt fine-tuned to reflect human preferences or don‚Äôt employ input/output filters ‚Äî or publicly available models that they prompt using jailbreak techniques that circumvent built-in guardrails. They sell their services in hacker‚Äôs marketplaces and forums, charging far less than typical traditional malware vendors, but services based on models that have been fine-tuned to deliver malicious output command a premium. The authors found that one&nbsp;service generated revenue of more than $28,000 in two months.</p><p><strong>Sprawling market:&nbsp;</strong>The authors identified 212 harmful services. Of those, 125 were hosted on the Poe AI platform, 73 were on FlowGPT, and the remaining 14 resided on unique servers. Of those, the authors were unable to access five because either the provider blocked them, or the service was fraudulent. They identified 11 LLMs used by these services including Claude-2-100k, GPT-4, and Pygmalion-13B (a variant of LLaMA-13B).</p><p><strong>Testing output quality:&nbsp;</strong>The authors prompted more than 200 services using over 30 prompts to generate malicious code, phishing emails, or phishing websites. They evaluated the responses according to:</p><ul><li>Format: How often they followed the expected format (as defined by regular expressions)</li><li>Compilability: How often generated Python, C, or C++ code was able to compile</li><li>Validity: How often generated HTML and CSS ran successfully in both Chrome and Firefox</li><li>Readability: How often generated phishing emails were fluent and coherent according to the&nbsp;<a href="https://en.wikipedia.org/wiki/Gunning_fog_index?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">Gunning fog Index</a>&nbsp;of reading difficulty</li><li>Evasiveness, or how often generated text both succeeded in all previous checks and evaded detection by&nbsp;<a href="https://www.virustotal.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">VirusTotal</a>&nbsp;(for malicious code and phishing sites) or&nbsp;<a href="https://www.oopspam.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">OOPSpam</a>&nbsp;(for phishing emails).</li></ul><p>In all three tasks, at least one service achieved evasiveness of 67 percent or higher, while the majority of services achieved an evasiveness of less than 30 percent.</p><p><strong>Testing real-world effectiveness:&nbsp;</strong>In addition, the authors ran practical tests to see how well the output worked in real-world situations. They prompted nine services to generate code that would target three specific vulnerabilities that relate to buffer overflow and SQL injection. In these tests, the models were markedly less successful.</p><ul><li>The authors tested generated code for two vulnerabilities on&nbsp;<a href="https://www.vicidial.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">VICIdial</a>, a call-center system known to be vulnerable to such issues. Of 22 generated programs that were able to compile, none changed VICIdial‚Äôs databases or disclosed system data.</li><li>They tested generated code further on&nbsp;<a href="https://owasp.org/www-project-webgoat/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">OWASP WebGoat 7.1</a>, a website that provides code with known security flaws. Of 39 generated programs that were able to compile, seven launched successful attacks. However, these attacks did not target the specific vulnerabilities requested by the authors.</li></ul><p><strong>Why it matters</strong>: Previous work showed that LLMs-based services could generate&nbsp;<a href="https://dl.acm.org/doi/10.1145/3544548.3581318?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3" rel="noopener">misinformation</a>&nbsp;and other malicious output, but little research has probed their actual use in cybercrime. This work evaluates their quality and effectiveness. In addition, the authors released the prompts they used to circumvent guardrails and generate malicious output ‚Äî a resource for further research that aims to fix such issues in future models.</p><p><strong>We‚Äôre thinking:</strong>&nbsp;It‚Äôs encouraging to see that harmful services didn‚Äôt get far in real-world tests, and the authors' findings should put a damper on alarmist scenarios of AI-enabled cybercrime. That doesn‚Äôt mean we don‚Äôt need to worry about harmful applications of AI technology. The AI community has a responsibility to design its products to be beneficial and evaluate them thoroughly for safety.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="Become an AI professional with one of the world&#x27;s most popular Machine Learning courses. #BreakIntoAI with Machine Learning Specialization" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="Become an AI professional with one of the world&#x27;s most popular Machine Learning courses. #BreakIntoAI with Machine Learning Specialization" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/courses/machine-learning-specialization/"><div class="absolute inset-0" data-gtm-event-title="BreakIntoAI with Machine Learning Specialization"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-270/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-270/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-270/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm166" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-270","id":"6706fa8a504fea00012eb1a4","uuid":"f01d475b-16c7-4d7f-abe0-79d5679fbba1","title":"How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, OpenAI‚Äôs New Voice API","html":"\u003cp\u003eDear friends,\u003c/p\u003e\u003cp\u003eCongratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize! It‚Äôs wonderful to see pioneering work in AI recognized, and this will be good for our whole field. Years ago, I was the first to call Geoff the ‚ÄúGodfather of Deep Learning,‚Äù which later became ‚ÄúGodfather of AI.‚Äù I‚Äôm thrilled at the recognition he‚Äôs receiving via this most prestigious of awards.\u003c/p\u003e\u003cp\u003eAs Geoff relayed in the ‚ÄúHeroes of Deep Learning‚Äù\u0026nbsp;\u003ca href=\"https://www.youtube.com/watch?v=-eyhCTvrEtE\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003einterview\u003c/a\u003e\u0026nbsp;I did with him years ago, his early work developing the foundations of neural networks has been instrumental to the rise of deep learning and AI. It has been years since I implemented a\u0026nbsp;\u003ca href=\"https://en.wikipedia.org/wiki/Hopfield_network?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eHopfield network\u003c/a\u003e, but John‚Äôs work, too, has been influential. Their recognition is well deserved!\u003c/p\u003e\u003cp\u003eBut the Nobel committee wasn‚Äôt done yet. One day after the physics prize was announced, Demis Hassabis, John Jumper, and David Baker won the Chemistry Nobel Prize for their work on AlphaFold and protein design. AlphaFold and AlphaFold 2, as well as the work of Baker‚Äôs lab, are compelling applications of AI that made significant steps forward in chemistry and biology, and this award, too, is well deserved!\u003c/p\u003e\u003cp\u003eIt‚Äôs remarkable that the Nobel committees for physics and chemistry, which are made up of scientists in those fields, chose to honor AI researchers with this year‚Äôs awards. This is a sign of our field‚Äôs growing impact on society.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY-1.jpg\" class=\"kg-image\" alt=\"Three people, Jeff Dean, Andrew Ng, and Geoff Hinton, stand together at Hinton‚Äôs retirement party, with Hinton holding a microphone.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/HINTON-PARTY-1.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/HINTON-PARTY-1.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY-1.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eWhile it‚Äôs good that people from outside AI are recognizing AI researchers, I wonder if there‚Äôs room for the AI community to pick more award recipients ourselves. Best-known in computer science is the Turing Award, which is selected by a broad group of computer scientists, many of whom have deep AI knowledge. Many AI conferences give out best-paper awards. And applications of AI to other fields doubtless will continue to receive much-deserved recognition by leaders in those fields. I‚Äôm optimistic this will allow AI researchers to win more Nobel Prizes ‚Äî someday also in economics, literature, medicine, and peace, too.\u0026nbsp;Nonetheless, this seems like a good time to see how all of us in AI can do more to recognize the work of innovators in our field.\u003c/p\u003e\u003cp\u003eGeoff once thanked me for my role in getting him anointed ‚ÄúGodfather of AI,‚Äù which he said was good for his career. I didn‚Äôt realize before that I had the power to give out such titles üòâ but I would love for there to be numerous godfathers and godmothers ‚Äî and many other awards ‚Äî in AI!\u003c/p\u003e\u003cp\u003eAt Geoff's retirement party last October (pictured in the photo above), I spoke with affection and gratitude for all the work he has done to grow AI. Even as we cheer the new Nobel wins for AI, let‚Äôs continue to think about how we in AI can do more to celebrate the next generation of innovators.\u003c/p\u003e\u003cp\u003eKeep learning!\u003c/p\u003e\u003cp\u003eAndrew\u003c/p\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/introducing-multimodal-llama-3-2/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--15-.png\" class=\"kg-image\" alt=\"Promo banner for \u0026quot;Introducing Multimodal Llama 3.2\u0026quot;\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/unnamed--15-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/unnamed--15-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--15-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eTry the new capabilities of Llama 3.2 in our latest course with Meta. Learn how to compose multimodal prompts, call custom tools, and use the Llama Stack API to build applications with Meta‚Äôs family of open weights models.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/introducing-multimodal-llama-3-2/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eEnroll for free!\u003c/a\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.gif\" class=\"kg-image\" alt=\"A demonstration of video editing through text input, altering a runner‚Äôs background and costume.\" loading=\"lazy\" width=\"600\" height=\"336\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"familiar-faces-synthetic-soundtracks\"\u003eFamiliar Faces, Synthetic Soundtracks\u003c/h1\u003e\u003cp\u003eMeta upped the ante for text-to-video generation with new systems that produce consistent characters and matching soundtracks.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u0026nbsp;\u003c/strong\u003eMeta presented\u0026nbsp;\u003ca href=\"https://ai.meta.com/research/movie-gen/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eMovie Gen\u003c/a\u003e, a series of four systems that generate videos, include consistent characters, alter generated imagery, and add matching sound effects and music. Movie Gen will be\u0026nbsp;\u003ca href=\"https://www.instagram.com/zuck/reel/DAs_J17Pw0G/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eavailable\u003c/a\u003e\u0026nbsp;on Instagram in 2025. Meanwhile, you can view and listen to examples\u0026nbsp;\u003ca href=\"https://ai.meta.com/research/movie-gen/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003ehere\u003c/a\u003e. The team\u0026nbsp;\u003ca href=\"https://ai.meta.com/static-resource/movie-gen-research-paper?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eexplains\u003c/a\u003e\u0026nbsp;how the model was built an extensive 92-page paper.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eGenerated videos:\u003c/strong\u003e\u0026nbsp;Movie Gen Video can output 256 frames (up to 16 seconds at 16 frames per second) at 1920x1080-pixel resolution. It includes a convolutional neural network autoencoder, transformer, and multiple embedding models.\u003c/p\u003e\u003cul\u003e\u003cli\u003eMovie Gen Video produces imagery by flow matching, a technique related to diffusion. It learned to remove noise from noisy versions of images and videos given matching text descriptions from 1 billion image-text pairs and 100 million video-text pairs. At inference, it starts with pure noise and generates detailed imagery according to a text prompt.\u003c/li\u003e\u003cli\u003eThe system concatenates multiple text embeddings to combine the strengths of different embedding models.\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2205.05131?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eUL2\u003c/a\u003e\u0026nbsp;was trained on text-only data, so its embeddings may provide ‚Äúreasoning abilities,‚Äù according to the authors.\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2309.16671?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eLong-prompt MetaCLIP\u003c/a\u003e\u0026nbsp;was trained to produce similar text and image representations, so its embeddings might be useful for ‚Äúcross-modal generation.‚Äù\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2105.13626?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eByT5\u003c/a\u003e\u0026nbsp;produces embeddings of individual text elements such as letters, numbers, and symbols; the system uses it when a prompt requests text within a clip.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eConsistent characters:\u003c/strong\u003e\u0026nbsp;Given an image of a face, a fine-tuned version of Movie Gen Video generates a video that depicts a person with that face.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eTo gather a training dataset for this capability, the team filtered Movie Gen Video‚Äôs pretraining dataset for clips that show a single face and consecutive frames are similar to one another. They built video-face examples by pairing each clip with a frame selected from the clip at random. To train the system, the team fed it text, the clip with added noise, and the single-frame face. It learned to remove the noise.\u003c/li\u003e\u003cli\u003eTrained on this data alone, the system generated videos in which the person always faces the camera. To expand the variety of poses, they further trained it on examples that substituted the faces in the previous step with\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2409.13346?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003egenerated versions\u003c/a\u003e\u0026nbsp;with alternate poses and facial expressions.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eAltered clips:\u003c/strong\u003e\u0026nbsp;The team modified Movie Gen Video‚Äôs autoencoder to accept an embedding of an alteration ‚Äî say, changing the background or adding an object. They trained the system to alter videos in three stages:\u003c/p\u003e\u003cul\u003e\u003cli\u003eFirst, they trained the system, given a starting image and an instruction to alter it, to produce an altered image.\u003c/li\u003e\u003cli\u003eThey further trained the system to produce altered clips. They generated two datasets of before-and-after clips based on instructions. (i) For instance, given a random frame and an instruction to, say, replace a person with a cat, the system altered the frame accordingly. Then the team subjected both frames to a series of augmentations selected at random, creating matching clips, one featuring a person, the other featuring a cat. Given the initial clip and the instruction, the system learned to generate the altered clip. (ii) The team used\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2303.05499?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eDINO\u003c/a\u003e\u0026nbsp;and\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2408.00714?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eSAM 2\u003c/a\u003e\u0026nbsp;to segment clips. Given an unsegmented clip and an instruction such as ‚Äúmark \u0026lt;object\u0026gt; with \u0026lt;color\u0026gt;,‚Äù the system learned to generate the segmented clip.\u0026nbsp;\u003c/li\u003e\u003cli\u003eFinally, they trained the system to restore altered clips to their original content. They built a dataset by taking a ground-truth clip and using their system to generate an altered version according to an instruction. Then Llama 3 rewrote the instruction to modify the altered clip to match the original. Given the altered clip and the instruction, the system learned to generate the original clip.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eSynthetic soundtracks:\u003c/strong\u003e\u0026nbsp;Given a text description, a system called Movie Gen Audio generates sound effects and instrumental music for video clips up to 30 seconds long. It includes a\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2306.06546?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eDACVAE\u003c/a\u003e\u0026nbsp;audio encoder (which encodes sounds that comes before and/or after the target audio), Long-prompt MetaCLIP video encoder,\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eT5\u003c/a\u003e\u0026nbsp;text encoder, vanilla neural network that encodes the current time step, and transformer.\u003c/p\u003e\u003cul\u003e\u003cli\u003eMovie Gen Audio learned to remove noise from noisy versions of audio associated with 1 million videos with text captions.\u0026nbsp; At inference, it starts with pure noise and generates up to 30 seconds of audio at once.\u003c/li\u003e\u003cli\u003eAt inference, it can extend audio. Given the last n seconds of audio, the associated portion of a video, and a text description, it can generate the next 30 - n seconds.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;Overall, Movie Gen achieved performance roughly equal to or better than competitors in qualitative evaluations of overall quality and a number of specific qualities (such as ‚Äúrealness‚Äù). Human evaluators rated their preferences for Movie Gen or a competitor. The team reported the results in terms of net win rate (win percentage minus loss percentage) between -100 percent and 100 percent, where a score above zero means that a system won more than it lost.\u003c/p\u003e\u003cul\u003e\u003cli\u003eFor overall video quality, Movie Gen achieved a net win rate of 35.02 percent versus Runway Gen3, 8.23 percent versus Sora (based on the prompts and generated clips available on OpenAI‚Äôs website), and 3.87 percent versus Kling 1.5.\u003c/li\u003e\u003cli\u003eGenerating clips of specific characters, Movie Gen achieved a net win rate of 64.74 percent versus ID-Animator, the state of the art for this capability.\u003c/li\u003e\u003cli\u003eGenerating soundtracks for videos from the SReal SFX dataset, Movie Gen Audio achieved a net win rate between 32 percent and 85 percent compared to various video-to-audio models.\u003c/li\u003e\u003cli\u003eAltering videos in the\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2403.09334?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eTGVE+\u003c/a\u003e\u0026nbsp;dataset, Movie Gen beat all competitors more than 70 percent of the time.\u0026nbsp;\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;With Movie Gen, table stakes for video generation rises to include consistent characters, soundtracks, and various video-to-video alterations. The 92-page paper is a valuable resource for builders of video generation systems, explaining in detail how the team filtered data, structured models, and trained them to achieve good results.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;Meta has a great track record of publishing both model weights and papers that describe how the models were built. Kudos to the Movie Gen team for publishing the details of this work!\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--18-.gif\" class=\"kg-image\" alt=\"A smartphone on a table showing an incoming call with voice waveform displayed on screen.\" loading=\"lazy\" width=\"600\" height=\"337\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--18-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"voice-to-voice-and-more-for-gpt-4o-api\"\u003eVoice-to-Voice and More for GPT-4o API\u003c/h1\u003e\u003cp\u003eOpenAI launched a suite of new and updated tools to help AI developers build applications and reduce costs.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u0026nbsp;\u003c/strong\u003eAt its annual DevDay conference, OpenAI\u0026nbsp;introduced an\u0026nbsp;\u003ca href=\"https://openai.com/index/introducing-the-realtime-api/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eAPI\u003cu\u003e\u0026nbsp;\u003c/u\u003e\u003c/a\u003efor speech processing using GPT-4o,\u0026nbsp;\u003ca href=\"https://openai.com/index/api-model-distillation/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003edistillation tools\u003c/a\u003e,\u0026nbsp;\u003ca href=\"https://openai.com/index/introducing-vision-to-the-fine-tuning-api/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003evision fine-tuning capabilities\u003c/a\u003e, and the ability to\u0026nbsp;\u003ca href=\"https://openai.com/index/api-prompt-caching/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003ecache prompts\u003c/a\u003e\u0026nbsp;for later re-use. These tools are designed to make it easier to build fast applications using audio inputs and outputs, customize models, and cut costs for common tasks.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eDevelopment simplified:\u003c/strong\u003e\u0026nbsp;The new offerings aim to make it easier to build applications using OpenAI models, with an emphasis on voice input/output and image input, customizing models, and resolving common pain points.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe Realtime API enables speech-to-speech interactions with GPT-4o using six preset voices, like ChatGPT's Advanced Voice Mode but with lower latency. The API\u0026nbsp;\u003ca href=\"https://openai.com/api/pricing/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003ecosts\u003c/a\u003e\u0026nbsp;$100/$200 per 1 million input/output tokens (about $0.06/$0.24 per minute of input/output). (The API processes text at $5/$20 per million input/output tokens.\u003c/li\u003e\u003cli\u003eThe Chat Completions API now accepts voice input and generates voice outputs for GPT-4o‚Äôs usual price ($3.75/$15 per million input/output tokens). However, it generates outputs less quickly than the Realtime API. (OpenAI didn‚Äôt disclose specific latency measurements.)\u003c/li\u003e\u003cli\u003eThe distillation tools simplify the process of using larger models like o1-preview as teachers whose output is used to fine-tune smaller, more cost-efficient students like GPT-4o mini. Developers can generate datasets, fine-tune models, and evaluate performance within OpenAI's platform. For example, you can use GPT-4o to create responses to customer-service questions, then use the resulting dataset to fine-tune GPT-4o mini.\u003c/li\u003e\u003cli\u003eVision fine-tuning allows developers to enhance GPT-4o's image understanding by fine-tuning the model on a custom image dataset. For instance, developers can improve visual search, object detection, or image analysis for a particular application by fine-tuning the model on domain-specific images. Vision fine-tuning costs $25 per million training tokens for GPT-4o, but OpenAI will give developers 1 million free training tokens per day through October 31.\u003c/li\u003e\u003cli\u003ePrompt caching automatically reuses input tokens that were entered in recent interactions with GPT-4o, GPT-4o mini, and their fine-tuned variants. Repeated prompts cost half as much and get processed faster. The discount and speed especially benefit applications like chatbots and code editors, which frequently reuse input context.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;OpenAI is undertaking a major corporate transformation. A recent funding round\u0026nbsp;\u003ca href=\"https://www.nytimes.com/2024/10/02/technology/openai-valuation-150-billion.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003evalues\u003c/a\u003e\u0026nbsp;OpenAI at $157 billion, making it among the world‚Äôs most valuable private companies, and the company is\u0026nbsp;\u003ca href=\"https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003etransferring\u003c/a\u003e\u0026nbsp;more control from its nonprofit board to its for-profit subsidiary. Meanwhile, it has seen an\u0026nbsp;\u003ca href=\"https://techcrunch.com/2024/10/03/a-co-lead-on-sora-openais-video-generator-has-left-for-google/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eexodus\u003c/a\u003e\u0026nbsp;of executives that include CTO Mira Murati, Sora co-lead Tim Brooks, chief research officer Bob McGrew, research VP Barret Zoph, and\u0026nbsp;\u003ca href=\"https://www.businessinsider.com/openai-talent-exodus-joke-tech-world-mira-murati-sam-altman-2024-9?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eother key researchers\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u0026nbsp;\u003c/strong\u003eThe Realtime API enables speech input and output without converting speech to text, allowing for more natural voice interactions. Such interactions open a wide range of applications, and they‚Äôre crucial for real-time systems like customer service bots and virtual assistants. Although\u0026nbsp;\u003ca href=\"https://aws.amazon.com/blogs/machine-learning/use-llama-3-1-405b-to-generate-synthetic-data-for-fine-tuning-tasks/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eAmazon Web Service\u003c/a\u003e\u0026nbsp;and\u0026nbsp;\u003ca href=\"https://labelbox.com/guides/end-to-end-workflow-for-knowledge-distillation-with-nlp/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eLabelbox\u003c/a\u003e\u0026nbsp;provide services to distill knowledge from OpenAI models into open architectures, OpenAI‚Äôs tools ease the process of distilling from OpenAI models into other OpenAI models. Image fine-tuning and prompt caching, like similar capabilities for Anthropic Claude and Google Gemini, are welcome additions.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;OpenAI‚Äôs offerings have come a long way since\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/all-the-new-models-and-products-announced-by-openai-during-devday/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eDevDay 2023\u003c/a\u003e, when speech recognition was ‚Äúcoming soon.‚Äù We‚Äôre eager to see what developers do with voice-driven applications!\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--16-.png\" class=\"kg-image\" alt=\"Collage of various images featuring a baseball player, movie scenes, portraits, landscapes, and diverse wildlife.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/unnamed--16-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/unnamed--16-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--16-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"german-court-laion-didn%E2%80%99t-violate-copyrights\"\u003eGerman Court: LAION Didn‚Äôt Violate Copyrights\u003c/h1\u003e\u003cp\u003eA German court dismissed a copyright lawsuit against LAION, the nonprofit responsible for large-scale image datasets used to train Midjourney, Stable Diffusion, and other image generators.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new:\u003c/strong\u003e\u0026nbsp;The court\u0026nbsp;\u003ca href=\"https://www.technollama.co.uk/laion-wins-copyright-infringement-lawsuit-in-german-court?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003erejected\u003c/a\u003e\u0026nbsp;a lawsuit claiming that cataloging images on the web to train machine learning models violates the image owners‚Äô copyrights. It ruled that LAION‚Äôs activities fall under protections for scientific research.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;LAION doesn‚Äôt distribute images. Instead, it compiles links to images and related text that are published on publicly available websites. Model builders who wish to use the images and/or text must download them from those sources. In 2023, photographer Robert Kneschke\u0026nbsp;\u003ca href=\"https://www.technollama.co.uk/photographer-sues-laion-for-copyright-infringement?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003esued\u003c/a\u003e\u0026nbsp;LAION for including his photos. The court‚Äôs\u0026nbsp;\u003ca href=\"https://drive.google.com/file/d/1A_vnSJUwlrVovhIqA4rKIFaOktR4TvBt/view?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003edecision\u003c/a\u003e\u0026nbsp;emphasized several key points.\u003c/p\u003e\u003cul\u003e\u003cli\u003eLAION, while compiling links to images, had indeed made unauthorized copies of images protected by copyright, as defined by German law. However, Germany‚Äôs Copyright Act allows unauthorized use of copyrighted works for scientific research. The court ruled that LAION had collected the material for this purpose, so it did not violate copyrights.\u003c/li\u003e\u003cli\u003eMoreover, the court found that downloading images and text in order to correlate them likely fell under a further exemption to copyright for data mining. This finding wasn‚Äôt definitive because the exemption for research made it irrelevant, but the court mentioned it to help guide future rulings.\u003c/li\u003e\u003cli\u003eThe dataset‚Äôs noncommercial status was a key factor in the ruling. LAION distributed the dataset for free, and no commercial entity controlled its operations. Although a LAION dataset may be used to train a machine learning model that‚Äôs intended to be sold commercially, this is not sufficient to classify creating such datasets as commercial activity. The plaintiff contended that, because some LAION members have paid roles in commercial companies, LAION could be considered a commercial entity. However, the court rejected that argument.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Several other artists have sued\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/the-story-of-laion-the-dataset-behind-stable-diffusion/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eLAION\u003c/a\u003e, which stands for Large-scale AI Open Network, claiming that the organization used their works without their consent. They have also sued AI companies, including a\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/artists-file-a-lawsuit-against-stability-ai-and-midjourney/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eclass action suit\u003c/a\u003e\u0026nbsp;against Stability AI, Midjourney, and DeviantArt for using materials under copyright, including images in LAION‚Äôs datasets, to train their models. Similar cases have been brought against makers of\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/sony-umg-and-warner-music-sue-suno-and-udio-over-alleged-copyright-violations/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003emusic generators\u003c/a\u003e\u0026nbsp;and\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/judge-dismisses-key-arguments-in-ai-copyright-lawsuit-against-github-microsoft-and-openai/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003ecoding assistants\u003c/a\u003e. All these lawsuits, which are in progress, rest on the plaintiff‚Äôs claim that assembling a training dataset of copyrighted works infringes copyrights.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;The German ruling is the first AI-related decision in Europe since the adoption of the AI Act, and the court took that law‚Äôs intent into account when making its decision. It affirms that creating text-image pairs of publicly available material for the purpose of training machine learning models does not violate copyrights, even if commercial organizations later use the data. However, the court did not address whether training AI models on such datasets, or using the trained models in a commercial setting, violates copyrights.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;This decision is encouraging news for AI researchers. We hope jurisdictions worldwide establish that training models on media that‚Äôs available on the open web is fair and legal.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.png\" class=\"kg-image\" alt=\"Diagram illustrating the process of developing, deploying, and promoting a malicious LLM application for phishing and malicious services.\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/10/unnamed--17-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/10/unnamed--17-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/10/unnamed--17-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"ai%E2%80%99s-criminal-underground-revealed\"\u003eAI‚Äôs Criminal Underground Revealed\u003c/h1\u003e\u003cp\u003eResearchers probed the black market for AI services that are designed to facilitate cybercrime.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat‚Äôs new\u003c/strong\u003e: Zilong Lin and colleagues at Indiana University Bloomington\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2401.03315?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003estudied\u003c/a\u003e\u0026nbsp;how large language models (LLMs) are used to provide harmful services, specifically generating malicious code, phishing emails, and phishing websites. They weren‚Äôt very effective, by and large (though a high success rate may not be necessary to support a thriving market in automated criminal activity).\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRisky business:\u003c/strong\u003e\u0026nbsp;Providers base such services on either uncensored LLMs ‚Äî that is, those that weren‚Äôt fine-tuned to reflect human preferences or don‚Äôt employ input/output filters ‚Äî or publicly available models that they prompt using jailbreak techniques that circumvent built-in guardrails. They sell their services in hacker‚Äôs marketplaces and forums, charging far less than typical traditional malware vendors, but services based on models that have been fine-tuned to deliver malicious output command a premium. The authors found that one\u0026nbsp;service generated revenue of more than $28,000 in two months.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSprawling market:\u0026nbsp;\u003c/strong\u003eThe authors identified 212 harmful services. Of those, 125 were hosted on the Poe AI platform, 73 were on FlowGPT, and the remaining 14 resided on unique servers. Of those, the authors were unable to access five because either the provider blocked them, or the service was fraudulent. They identified 11 LLMs used by these services including Claude-2-100k, GPT-4, and Pygmalion-13B (a variant of LLaMA-13B).\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eTesting output quality:\u0026nbsp;\u003c/strong\u003eThe authors prompted more than 200 services using over 30 prompts to generate malicious code, phishing emails, or phishing websites. They evaluated the responses according to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eFormat: How often they followed the expected format (as defined by regular expressions)\u003c/li\u003e\u003cli\u003eCompilability: How often generated Python, C, or C++ code was able to compile\u003c/li\u003e\u003cli\u003eValidity: How often generated HTML and CSS ran successfully in both Chrome and Firefox\u003c/li\u003e\u003cli\u003eReadability: How often generated phishing emails were fluent and coherent according to the\u0026nbsp;\u003ca href=\"https://en.wikipedia.org/wiki/Gunning_fog_index?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eGunning fog Index\u003c/a\u003e\u0026nbsp;of reading difficulty\u003c/li\u003e\u003cli\u003eEvasiveness, or how often generated text both succeeded in all previous checks and evaded detection by\u0026nbsp;\u003ca href=\"https://www.virustotal.com/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eVirusTotal\u003c/a\u003e\u0026nbsp;(for malicious code and phishing sites) or\u0026nbsp;\u003ca href=\"https://www.oopspam.com/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eOOPSpam\u003c/a\u003e\u0026nbsp;(for phishing emails).\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIn all three tasks, at least one service achieved evasiveness of 67 percent or higher, while the majority of services achieved an evasiveness of less than 30 percent.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eTesting real-world effectiveness:\u0026nbsp;\u003c/strong\u003eIn addition, the authors ran practical tests to see how well the output worked in real-world situations. They prompted nine services to generate code that would target three specific vulnerabilities that relate to buffer overflow and SQL injection. In these tests, the models were markedly less successful.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe authors tested generated code for two vulnerabilities on\u0026nbsp;\u003ca href=\"https://www.vicidial.com/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eVICIdial\u003c/a\u003e, a call-center system known to be vulnerable to such issues. Of 22 generated programs that were able to compile, none changed VICIdial‚Äôs databases or disclosed system data.\u003c/li\u003e\u003cli\u003eThey tested generated code further on\u0026nbsp;\u003ca href=\"https://owasp.org/www-project-webgoat/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003eOWASP WebGoat 7.1\u003c/a\u003e, a website that provides code with known security flaws. Of 39 generated programs that were able to compile, seven launched successful attacks. However, these attacks did not target the specific vulnerabilities requested by the authors.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters\u003c/strong\u003e: Previous work showed that LLMs-based services could generate\u0026nbsp;\u003ca href=\"https://dl.acm.org/doi/10.1145/3544548.3581318?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9RYyXQaS2k5qy2Simn_iOnVPeZeRZG3fSYthoZAju8OmBlyP_shhCuEt2cOimiV0iRvCn3\" rel=\"noopener\"\u003emisinformation\u003c/a\u003e\u0026nbsp;and other malicious output, but little research has probed their actual use in cybercrime. This work evaluates their quality and effectiveness. In addition, the authors released the prompts they used to circumvent guardrails and generate malicious output ‚Äî a resource for further research that aims to fix such issues in future models.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe‚Äôre thinking:\u003c/strong\u003e\u0026nbsp;It‚Äôs encouraging to see that harmful services didn‚Äôt get far in real-world tests, and the authors' findings should put a damper on alarmist scenarios of AI-enabled cybercrime. That doesn‚Äôt mean we don‚Äôt need to worry about harmful applications of AI technology. The AI community has a responsibility to design its products to be beneficial and evaluate them thoroughly for safety.\u003c/p\u003e","comment_id":"6706fa8a504fea00012eb1a4","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY.jpg","featured":false,"visibility":"public","created_at":"2024-10-09T14:50:02.000-07:00","updated_at":"2024-10-09T16:44:38.000-07:00","published_at":"2024-10-09T14:59:00.000-07:00","custom_excerpt":"The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"6706fd5f504fea00012eb1ac","name":"issue 270","slug":"issue-270","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-270/"},{"id":"6706fd5f504fea00012eb1ad","name":"Oct 09, 2024","slug":"oct-09-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/oct-09-2024/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-270/","excerpt":"The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"How Meta‚Äôs Movie Gen Does It, AI‚Äôs Criminal Underground, Court Says LAION is Legal, and more...","meta_description":"The Batch AI News and Insights: Congratulations to Geoff Hinton and John Hopfield for winning the 2024 Physics Nobel Prize!","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/10/HINTON-PARTY.jpg","dimensions":{"width":1200,"height":675}},"banner":{"title":"BreakIntoAI with Machine Learning Specialization","databaseId":28989,"id":"cG9zdDoyODk4OQ==","featuredImage":{"node":{"altText":"Become an AI professional with one of the world's most popular Machine Learning courses. #BreakIntoAI with Machine Learning Specialization","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/4.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/courses/machine-learning-specialization/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"‚ú® New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"‚ú® Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-270"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>