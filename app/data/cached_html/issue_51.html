<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Faster AI Chips, Smarter Prosthetic Legs, Transformers for Image</title><meta name="description" content="The Batch - AI News &amp; Insights: Chips specially designed for AI are becoming much faster at training neural networks | Prosthetic leg that learns from the user’s motion" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-51/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Faster AI Chips, Smarter Prosthetic Legs, Transformers for Image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: Chips specially designed for AI are becoming much faster at training neural networks | Prosthetic leg that learns from the user’s motion" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Faster AI Chips, Smarter Prosthetic Legs, Transformers for Image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-51/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2020-08-05T12:00:00.000-07:00"/><meta property="article:modified_time" content="2022-10-06T16:24:58.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-51"/><meta property="article:tag" content="Aug 05, 2020"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Faster AI Chips, Smarter Prosthetic Legs, Transformers for Image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: Chips specially designed for AI are becoming much faster at training neural networks | Prosthetic leg that learns from the user’s motion" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-51/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter-1.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter-1.png"/><meta property="og:image:width" content="576"/><meta property="og:image:height" content="324"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2020-08-05T12:00:00.000-07:00","dateModified":"2022-10-06T16:24:58.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Faster AI Chips, Smarter Prosthetic Legs, Transformers for Image","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter-1.png","width":576,"height":324},"publisher":{"@type":"Organization","name":"Faster AI Chips, Smarter Prosthetic Legs, Transformers for Image","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: Chips specially designed for AI are becoming much faster at training neural networks | Prosthetic leg that learns from the user’s motion"}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-51/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 51</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Aug 5, 2020</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">10<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/aug-05-2020/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Aug 05, 2020</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">10<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-51/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-51/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-51/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,</em></p><p><em>I spoke last week at the <a href="https://auditforum.org/niaf/?ref=dl-staging-website.ghost.io" rel=" noopener">National Intergovernmental Audit Forum</a>, a meeting attended by U.S. federal, state, and local government auditors. (Apparently some of the organizers had taken <a href="https://www.deeplearning.ai/ai-for-everyone/?ref=dl-staging-website.ghost.io" rel=" noopener">AI for Everyone</a>.) Many attendees wanted to know how AI systems can be rolled out in a responsible and accountable way.</em></p><p><em>Consider the banking industry. Many regional banks are under tremendous competitive pressure. How well they assess risk directly affects their bottom line, so they turn to credit scoring systems from AI vendors. But if they don’t have the technical expertise to evaluate such models, a hasty rollout can lead to unintended consequences like unfairly charging higher interest rates on loans to minority groups.</em></p><p><em>For AI systems to enjoy smooth rollouts, we need to (a) make sure our systems perform well and pose minimal risk of unintended consequences and (b) build trust with customers, users, regulators, and the general public that these systems work as intended. These are hard problems. They require not just solving technical issues but also aligning technology with society’s values, and expectations.</em></p><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/Andrews20Letter-1.png" class="kg-image" alt="Andrew Ng speaking at the National Intergovernmental Audit Forum about auditing AI systems" loading="lazy"></figure><p><em>An important part of the solution is transparency. The open source software movement has taught us that transparency makes software better. And if making source code publicly available means that someone finds an embarrassing security bug, so be it! At least it gets fixed.</em></p><p><em>With the rise of AI, we should similarly welcome third-party assistance, such as allowing independent parties to perform audits according to a well established procedure. That way, we can identify problems and fix them quickly and efficiently.</em></p><p><em>After my presentation, the moderator asked me how auditors can avoid getting into adversarial relationships with AI vendors. Instead, we need to build collaborative relationships. By collaborating, we can help make sure the criteria used to judge our systems is reasonable and well specified. For instance, what are the protected groups we need to make sure our systems aren’t biased against? We can also better avoid “gotcha” situations in which our systems are assessed according to arbitrary, after-the-fact criteria.</em></p><p><em>The AI community has a lot of work to do to ensure that our systems are fair, accountable, and reliable. For example, Credo AI (disclosure: a portfolio company of AI Fund, a sister organization to deeplearning.ai) is building tools that help audit and govern AI systems. Efforts like this can make a difference in designing and deploying AI systems that benefit all people.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h2 id="news"><strong>News</strong></h2><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-optimize2015.gif" class="kg-image" alt="Man with prosthetic leg walking" loading="lazy"></figure><h3 id="ai-steps-up">AI Steps Up</h3><p>A prosthetic leg that learns from the user’s motion could help amputees walk more naturally.<br><br><strong>What’s new:</strong> Researchers from the University of Utah <a href="https://robotics.sciencemag.org/content/5/44/eaba6635?__cf_chl_jschl_tk__=ae7f485139d8b5ed0983aa3c9a294fa3ebfd558e-1595808620-0-AToEO56027Xyn-8QW2_FtJd1lzeugSlF_B0uYj6dXgiQ1zGlfjF8eM2aJpB7xqDxU5FLgKzu81pquDJMNs1N31vjU25KItJSKjcF5a33WcSuA6gBKaBL331QNgiVNtPglUhkgBOCKMgGN59SogmD7KKVG27s7e1oG5VE4RL7DXZkK_1l9E_Jt7RzkjnD_2SsRBnfNlz69PJRZoT5EwSWewUA5__1Cn08qxsq276L7fex9WMxhToWq9ZbNPWIpq6wgsObikU1C7yZ6PX8IT0FNlXLGnCEo-VFvoCYo9sLogQ1&ref=dl-staging-website.ghost.io" rel=" noopener">designed</a> a robotic leg that uses machine learning to generate a human-like stride. It also helps wearers step over obstacles in a natural way.<br><br><strong>How it works:</strong> Rather than trying to recognize obstacles in the user’s path, the prosthesis relies on cues from the user’s body to tell it when something is in the way. Sensors in the user’s hip feed data a thousand times per second into a processing unit located in the unit’s calf. For instance, the way a user rotates their hip might tell the leg to tuck its knee to avoid tripping over an obstacle.</p><ul><li>A finite state machine (a logic-based controller) determines when and how to flex the knee based on angles of the ankle and thigh and the weight on the prosthetic foot.</li><li>A second model called the minimum-jerk planner kicks in when the angle and speed of the artificial limb reach a certain point. It works to minimize sharp, sudden actions.</li><li>The prosthesis applies reinforcement learning to adjust its motion as the user walks, using smoothness as the cost function.</li></ul><p><strong>Behind the news:</strong> A new generation of AI-powered prosthetics could give amputees more control over robotic limbs.</p><ul><li>Researchers from the <a href="https://news.umich.edu/open-source-bionic-leg-first-of-its-kind-platform-aims-to-rapidly-advance-prosthetics/?ref=dl-staging-website.ghost.io" rel=" noopener">University of Michigan</a> developed an open-source bionic leg that extrapolates knee and ankle movements by analyzing the wearer’s hip muscles, similar to the University of Utah’s method.</li><li>A pair of Canadian students won <a href="https://blogs.microsoft.com/blog/2018/07/25/meet-your-2018-imagine-cup-champions-smartarm-of-canada/?ref=dl-staging-website.ghost.io" rel=" noopener">Microsoft’s 2018 Imagine Cup</a> with a camera-equipped prosthetic hand that uses computer vision to detect objects it is about to grasp and adjusts its grip accordingly.</li><li>A mechanical arm from <a href="https://techcrunch.com/2019/09/13/this-prosthetic-arm-combines-manual-control-with-machine-learning/?ref=dl-staging-website.ghost.io" rel=" noopener">École polytechnique fédérale de Lausanne</a> learns to associate common movements with cues from the user’s muscles.</li></ul><p><strong>Why it matters:</strong> Battery-powered prostheses allow amputees to walk more easily, but they tend to stumble on unfamiliar terrain. This smart leg could provide them with smooth, hazard-free perambulation.<br><br><strong>We’re thinking:</strong> AI is helping people with the most basic human functions as well as the most abstract scientific problems.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/iGPT.gif" class="kg-image" alt="Graphs and data related to language models and image processing" loading="lazy"></figure><h3 id="transforming-pixels">Transforming Pixels</h3><p>Language models like Bert, Ernie, and Elmo have achieved spectacular results based on clever pre-training approaches. New research applies some of those <a href="https://www.theverge.com/2019/12/11/20993407/ai-language-models-muppets-sesame-street-muppetware-elmo-bert-ernie?ref=dl-staging-website.ghost.io" rel=" noopener">Sesame Street</a> lessons into image processing.<br><br><strong>What’s new:</strong> OpenAI researchers led by Mark Chen adapted to pixels techniques developed for processing words in <a href="https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf?ref=dl-staging-website.ghost.io" rel=" noopener">Image Generative Pre-Training</a> (iGPT).<br><br><strong>Key insight:</strong> Language models based on the transformer architecture learn to predict the next word, or missing words, in text by unsupervised pre-training on an enormous corpus followed by supervised fine-tuning. The same approach can train models to predict the next pixel in an image.<br><br><strong>How it works:</strong> iGPT uses the <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf?ref=dl-staging-website.ghost.io" rel=" noopener">GPT-2</a> architecture that made waves in natural language processing. However, it learns from sequences of pixels instead of sequences of words.</p><ul><li>The researchers preprocessed images by flattening them into one-dimensional vectors.</li><li>The researchers trained iGPT to either predict the next pixel in a sequence (an autoregressive task) or predict a group of pixels missing from a sequence (which they call Bert).</li><li>Pre-trained NLP models often are fine-tuned on a supervised task such as question answering. Similarly, the researchers fine-tuned iGPT on image classification. They found that hiding pixels from the model during fine-tuning improved performance.</li><li>The researchers provided all intermediate-layer features and labels to a new output layer, but trained only that layer’s parameters.</li></ul><p><strong>Results:</strong> Using features extracted by the intermediate layers in the autoregressive task, iGPT achieved 72 percent accuracy on <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf?ref=dl-staging-website.ghost.io" rel=" noopener">ImageNet</a>, just behind the state-of-the-art 76.5 percent achieved by <a href="https://arxiv.org/abs/2002.05709?ref=dl-staging-website.ghost.io" rel=" noopener">SimCLR</a>, a popular unsupervised approach. iGPT outperformed SimCLR when fine-tuned and evaluated on the <a href="https://www.cs.toronto.edu/~kriz/cifar.html?ref=dl-staging-website.ghost.io" rel=" noopener">CIFAR</a> datasets.<br><strong>Yes, but:</strong> The researchers had to downsample ImageNet examples to about 7 percent of their original size to accommodate GPT-2. They suspect that iGPT would stack up better against SimCLR if it could accept larger images.<br><br><strong>Why it matters:</strong> iGPT isn’t a convolutional neural network. It doesn’t even use the convolutional filter that’s fundamental to current image processing methods. This work shows the value of applying architectures proven in one domain to others.<br><br><strong>We’re thinking:</strong> We’ve been encouraged by the progress in self-supervised learning using methods like <a href="https://arxiv.org/abs/1807.03748?ref=dl-staging-website.ghost.io" rel=" noopener">Contrastive Predictive Coding</a> and variations thereof, in which a neural network is trained on a supervised learning task that is created from unlabeled data. iGPT appears to be a new line of attack on this problem.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/MLPerf202.gif" class="kg-image" alt="Graphs and data related to AI chips" loading="lazy"></figure><h3 id="built-for-speed">Built for Speed</h3><p>Chips specially designed for AI are becoming much faster at training neural networks, judging from recent trials.<br><br><strong>What’s new:</strong> <a href="https://mlperf.org/press?ref=dl-staging-website.ghost.io#mlperf-training-v0.7-results" rel=" noopener">MLPerf</a>, an organization that’s developing standards for hardware performance in machine learning tasks, released <a href="https://mlperf.org/training-results-0-7?ref=dl-staging-website.ghost.io" rel=" noopener">results</a> from its third benchmark competition. Nvidia’s latest products led the pack, but Google’s forthcoming hardware surpassed Nvidia’s scores.<br><br><strong>Start your engines:</strong> MLPerf measures how long it takes various hardware configurations to train particular machine learning <a href="https://mlperf.org/training-overview?ref=dl-staging-website.ghost.io" rel=" noopener">models</a>. Tasks include object detection, image classification, language translation, recommendation, and reinforcement learning goals.</p><ul><li>Systems from nine organizations trained models 2.7 times faster, on average, than they did in tests conducted last November, demonstrating the rapid evolution of AI hardware (and enabling software such as compilers).</li><li>Nvidia submitted 40 different configurations. Those based on its A100 graphics processing unit (GPU) scored highest among commercially available systems.</li><li>Showing off capabilities that aren’t yet on the market, <a href="https://cloud.google.com/blog/products/ai-machine-learning/google-breaks-ai-performance-records-in-mlperf-with-worlds-fastest-training-supercomputer?ref=dl-staging-website.ghost.io" rel=" noopener">Google</a> dominated six of the eight tasks with its fourth-generation tensor processing unit (TPU). Earlier versions are available via the Google Cloud platform.</li><li>Alibaba, Fujitsu, Intel, Inspur, Shenzhen Institute, and Tencent also joined the competition. Conspicuously absent: AI hardware upstarts Cerebras and Graphcore (see “New Horsepower for Neural Nets” below).</li></ul><p><strong>Behind the news:</strong> Nvidia’s GPUs have long been the premier machine learning chips, thanks to their ability to process large volumes of floating point integers per second. But startups including Cerebras, Graphcore, and Habana (acquired by Intel in December) are vying for that position, and Google Cloud is making a strong play for AI workloads.<br><br><strong>Why it matters:</strong> It’s good to be past the era of <a href="https://www.youtube.com/watch?v=-P28LKWTzrI&ref=dl-staging-website.ghost.io" rel=" noopener">Mythbusters videos</a> as a way to compare AI hardware. Machine learning engineers benefit from faster, more energy-efficient hardware systems, but we need clear, consistent metrics like MLPerf to evaluate hardware performance with particular models. <br><br><strong>We’re thinking:</strong> Since MLPerf’s first tests two years ago, the time required to train some models has plummeted from hours to seconds. Clearly semiconductor companies have been chipping away at the problem.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM <a href="https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io" rel="noopener">DEEPLEARNING.AI</a></h2><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/GIF205.gif" class="kg-image" alt="GIF 5" loading="lazy"></figure><p>Course 3 of our Natural Language Processing Specialization is now live on Coursera. <a href="https://www.coursera.org/learn/sequence-models-in-nlp?ref=dl-staging-website.ghost.io">Enroll today</a> to gain in-demand technical skills! Course 4 is scheduled for release in September.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/PNCA.gif" class="kg-image" alt="Data related to Covid-19 symptoms prediction" loading="lazy"></figure><h3 id="cats-cured-of-covid">Cats Cured of Covid</h3><p>Neural networks are famously bad at interpreting input that falls outside the training set’s distribution, so it’s not surprising that some models are certain that cat pictures show symptoms of Covid-19. A new approach won’t mistakenly condemn your feline to a quarantine.<br><br><strong>What’s new:</strong> Led by Ankur Mallick, researchers at Carnegie Mellon and Lawrence Livermore National Lab developed <a href="https://api.deepai.org/publication-download-pdf/can-your-ai-differentiate-cats-from-covid-19-sample-efficient-uncertainty-estimation-for-deep-learning-safety?ref=dl-staging-website.ghost.io" rel=" noopener">Probabilistic Neighborhood Components Analysis</a> (PNCA) to help models estimate the confidence of their predictions.<br><br><strong>Key insight:</strong> Neural networks often show high confidence in predictions that are clearly incorrect — a major issue in areas like healthcare and criminal justice. The problem can fade with enough training data, but it’s pervasive where training data is scarce. Overfitting limited data contributes to overconfidence, so combining deep learning with probabilistic methods, which are less prone to overfitting, might alleviate overconfidence.<br><br><strong>How it works:</strong> PNCA is a probabilistic version of <a href="https://www.cs.toronto.edu/~hinton/absps/nca.pdf?ref=dl-staging-website.ghost.io" rel=" noopener">Neighborhood Component Analysis</a>. NCA is a supervised learning method that trains neural nets to extract features that cluster examples of the same class. NCA determines the class of novel input by computing the distance between training data features and input features. It takes the softmax of the distances to obtain the probability that each training example belongs to the same class of the novel input. Practically speaking, NCA is a classification network with fixed output layer weights, but not size, given by the distance function.</p><ul><li>PNCA borrows ideas from deep Bayesian networks, which interpret inputs, weights, extracted features, neighborhoods, and class predictions as samples of probability distributions. The use of probability distributions allows PNCA to sharpen its confidence by computing the probability that a particular classification would occur with the provided input.</li><li>The technique estimates the distribution of predicted classes by sampling weights from the weight distribution. Every pair of sampled weights and training examples determines a distinct extracted feature, so running the usual NCA on every pair yields a classification that depends on the weight distribution.</li><li>PNCA determines the entire weight distribution by maintaining a sample of weights. Then it trains the sample of weights to generate a sample of predictions to match the training data, updating the weights to minimize the NCA loss.</li></ul><p><strong>Results:</strong> The researchers trained PNCA on a <a href="https://www.kaggle.com/bachrr/covid-chest-xray?ref=dl-staging-website.ghost.io" rel=" noopener">Kaggle dataset</a> of chest x-rays showing Covid-19, and tested it on <a href="https://github.com/agchung/Actualmed-COVID-chestxray-dataset?ref=dl-staging-website.ghost.io" rel=" noopener">Covid-V2</a> and a <a href="https://www.kaggle.com/c/dogs-vs-cats?ref=dl-staging-website.ghost.io" rel=" noopener">Cats and Dogs dataset</a>. PNCA performed with similar accuracy to other deep learning approaches on Covid-V2, while incorrectly classifying 1,000 cats and dogs out of 25,000 as Covid-19 with high confidence. This may seem like poor performance, but the same architecture with a standard supervised learning objective mistook around 2500 cats and dogs as Covid-19 chest x-rays.<br><br><strong>Why it matters:</strong> Deep learning’s overconfidence and data hunger are limitations to their practical deployment. PNCA combines deep learning’s powerful feature extraction with a probabilistic ability to quantify uncertainty.<br><br><strong>We’re thinking:</strong> We’re waiting for a model that can tell us the condition of Schroedinger’s cat.</p><hr><figure class="kg-card kg-image-card"><img src="https://home-wordpress.deeplearning.ai/wp-content/uploads/2021/01/GraphcoreGif.gif" class="kg-image" alt="Colossus Mk2, processor by Graphcore" loading="lazy"></figure><h3 id="new-horsepower-for-neural-nets">New Horsepower for Neural Nets</h3><p>A high-profile semiconductor startup made a bid for the future of AI computation.<br><br><strong>What’s new:</strong> UK startup Graphcore released the <a href="https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale?ref=dl-staging-website.ghost.io" rel=" noopener">Colossus Mk2</a>, a processor intended to perform the matrix math calculations at the heart of deep learning more efficiently than other specialized processors or general-purpose chips from Intel and AMD. The company expects to be shipping at full volume in the fourth quarter.<br><br><strong>How it works:</strong> The Mk2 comprises nearly 60 billion transistors. (Nvidia’s flagship A100 has 54 billion, while Cerebras’ gargantuan Wafer-Scale Engine boasts 1.2 trillion. Google doesn’t advertise its TPU transistor counts.) Girded by 900 megabytes of random access memory, the Mk2’s transistors are organized into 1,500 independent cores capable of running nearly 9,000 parallel threads.</p><ul><li>Graphcore is selling the new chips as part of a platform called IPU-Machine M200. Each M200 will hold four Mk2 chips to deliver a combined computational punch of 1 petaflop, or 1015 floating point operations per second.</li><li>Each M200 can connect to up to 64,000 others for 16 exaflops of compute. (An exaflop is 1,000 petaflops.) That’s a hefty claim, given that competing systems have yet to reach 1 exaflop.</li><li>The package includes software designed to manage a variety of machine learning frameworks. Developers can code directly using Python and C++.</li><li>J.P. Morgan, Lawrence Berkeley National Laboratory, and the University of Oxford are among the first users of the new chip.</li></ul><p><strong>Why it matters:</strong> AI’s demand for computational resources is insatiable. A recent <a href="https://arxiv.org/abs/2007.05558?ref=dl-staging-website.ghost.io" rel=" noopener">study</a> from researchers at MIT, the University of Brasilia, and Yonsei University suggests that progress in deep learning could stall for lack of processing power. Innovations in chip technology may make a difference.<br><br><strong>We’re thinking:</strong> The fact that software evolves faster than hardware is a major challenge to building chips. Graphcore’s design is geared to accelerate large, sparse recurrent neural networks at a moment when transformer networks are beginning to supplant RNNs in some applications. Will some bold chip maker tune its next generation for transformers?</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2025%2F03%2FVertical-side-banner-ads-7.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2025%2F03%2FVertical-side-banner-ads-7.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2025%2F03%2FVertical-side-banner-ads-7.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2025%2F03%2FVertical-side-banner-ads-7.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2025%2F03%2FVertical-side-banner-ads-7.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2025%2F03%2FVertical-side-banner-ads-7.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2025%2F03%2FVertical-side-banner-ads-7.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2025%2F03%2FVertical-side-banner-ads-7.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2025%2F03%2FVertical-side-banner-ads-7.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://bit.ly/3XWMC3m"><div class="absolute inset-0" data-gtm-event-title="Data Analytics Professional Certificate"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-51/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-51/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-51/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm365" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-51","id":"60c0372a274d5b003b1065b6","uuid":"23bb23c7-067a-4e15-93bf-802990ea58cf","title":"The Batch: Faster AI Chips, Smarter Prosthetic Legs, Transformers for Image Processing, Humbling Overconfident Models","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eI spoke last week at the \u003ca href=\"https://auditforum.org/niaf/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eNational Intergovernmental Audit Forum\u003c/a\u003e, a meeting attended by U.S. federal, state, and local government auditors. (Apparently some of the organizers had taken \u003ca href=\"https://www.deeplearning.ai/ai-for-everyone/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eAI for Everyone\u003c/a\u003e.) Many attendees wanted to know how AI systems can be rolled out in a responsible and accountable way.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eConsider the banking industry. Many regional banks are under tremendous competitive pressure. How well they assess risk directly affects their bottom line, so they turn to credit scoring systems from AI vendors. But if they don’t have the technical expertise to evaluate such models, a hasty rollout can lead to unintended consequences like unfairly charging higher interest rates on loans to minority groups.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eFor AI systems to enjoy smooth rollouts, we need to (a) make sure our systems perform well and pose minimal risk of unintended consequences and (b) build trust with customers, users, regulators, and the general public that these systems work as intended. These are hard problems. They require not just solving technical issues but also aligning technology with society’s values, and expectations.\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/Andrews20Letter-1.png\" class=\"kg-image\" alt=\"Andrew Ng speaking at the National Intergovernmental Audit Forum about auditing AI systems\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eAn important part of the solution is transparency. The open source software movement has taught us that transparency makes software better. And if making source code publicly available means that someone finds an embarrassing security bug, so be it! At least it gets fixed.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWith the rise of AI, we should similarly welcome third-party assistance, such as allowing independent parties to perform audits according to a well established procedure. That way, we can identify problems and fix them quickly and efficiently.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAfter my presentation, the moderator asked me how auditors can avoid getting into adversarial relationships with AI vendors. Instead, we need to build collaborative relationships. By collaborating, we can help make sure the criteria used to judge our systems is reasonable and well specified. For instance, what are the protected groups we need to make sure our systems aren’t biased against? We can also better avoid “gotcha” situations in which our systems are assessed according to arbitrary, after-the-fact criteria.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eThe AI community has a lot of work to do to ensure that our systems are fair, accountable, and reliable. For example, Credo AI (disclosure: a portfolio company of AI Fund, a sister organization to deeplearning.ai) is building tools that help audit and govern AI systems. Efforts like this can make a difference in designing and deploying AI systems that benefit all people.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch2 id=\"news\"\u003e\u003cstrong\u003eNews\u003c/strong\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/ezgif.com-optimize2015.gif\" class=\"kg-image\" alt=\"Man with prosthetic leg walking\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"ai-steps-up\"\u003eAI Steps Up\u003c/h3\u003e\u003cp\u003eA prosthetic leg that learns from the user’s motion could help amputees walk more naturally.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Researchers from the University of Utah \u003ca href=\"https://robotics.sciencemag.org/content/5/44/eaba6635?__cf_chl_jschl_tk__=ae7f485139d8b5ed0983aa3c9a294fa3ebfd558e-1595808620-0-AToEO56027Xyn-8QW2_FtJd1lzeugSlF_B0uYj6dXgiQ1zGlfjF8eM2aJpB7xqDxU5FLgKzu81pquDJMNs1N31vjU25KItJSKjcF5a33WcSuA6gBKaBL331QNgiVNtPglUhkgBOCKMgGN59SogmD7KKVG27s7e1oG5VE4RL7DXZkK_1l9E_Jt7RzkjnD_2SsRBnfNlz69PJRZoT5EwSWewUA5__1Cn08qxsq276L7fex9WMxhToWq9ZbNPWIpq6wgsObikU1C7yZ6PX8IT0FNlXLGnCEo-VFvoCYo9sLogQ1\u0026ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003edesigned\u003c/a\u003e a robotic leg that uses machine learning to generate a human-like stride. It also helps wearers step over obstacles in a natural way.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e Rather than trying to recognize obstacles in the user’s path, the prosthesis relies on cues from the user’s body to tell it when something is in the way. Sensors in the user’s hip feed data a thousand times per second into a processing unit located in the unit’s calf. For instance, the way a user rotates their hip might tell the leg to tuck its knee to avoid tripping over an obstacle.\u003c/p\u003e\u003cul\u003e\u003cli\u003eA finite state machine (a logic-based controller) determines when and how to flex the knee based on angles of the ankle and thigh and the weight on the prosthetic foot.\u003c/li\u003e\u003cli\u003eA second model called the minimum-jerk planner kicks in when the angle and speed of the artificial limb reach a certain point. It works to minimize sharp, sudden actions.\u003c/li\u003e\u003cli\u003eThe prosthesis applies reinforcement learning to adjust its motion as the user walks, using smoothness as the cost function.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e A new generation of AI-powered prosthetics could give amputees more control over robotic limbs.\u003c/p\u003e\u003cul\u003e\u003cli\u003eResearchers from the \u003ca href=\"https://news.umich.edu/open-source-bionic-leg-first-of-its-kind-platform-aims-to-rapidly-advance-prosthetics/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eUniversity of Michigan\u003c/a\u003e developed an open-source bionic leg that extrapolates knee and ankle movements by analyzing the wearer’s hip muscles, similar to the University of Utah’s method.\u003c/li\u003e\u003cli\u003eA pair of Canadian students won \u003ca href=\"https://blogs.microsoft.com/blog/2018/07/25/meet-your-2018-imagine-cup-champions-smartarm-of-canada/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eMicrosoft’s 2018 Imagine Cup\u003c/a\u003e with a camera-equipped prosthetic hand that uses computer vision to detect objects it is about to grasp and adjusts its grip accordingly.\u003c/li\u003e\u003cli\u003eA mechanical arm from \u003ca href=\"https://techcrunch.com/2019/09/13/this-prosthetic-arm-combines-manual-control-with-machine-learning/?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eÉcole polytechnique fédérale de Lausanne\u003c/a\u003e learns to associate common movements with cues from the user’s muscles.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Battery-powered prostheses allow amputees to walk more easily, but they tend to stumble on unfamiliar terrain. This smart leg could provide them with smooth, hazard-free perambulation.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e AI is helping people with the most basic human functions as well as the most abstract scientific problems.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/iGPT.gif\" class=\"kg-image\" alt=\"Graphs and data related to language models and image processing\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"transforming-pixels\"\u003eTransforming Pixels\u003c/h3\u003e\u003cp\u003eLanguage models like Bert, Ernie, and Elmo have achieved spectacular results based on clever pre-training approaches. New research applies some of those \u003ca href=\"https://www.theverge.com/2019/12/11/20993407/ai-language-models-muppets-sesame-street-muppetware-elmo-bert-ernie?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eSesame Street\u003c/a\u003e lessons into image processing.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e OpenAI researchers led by Mark Chen adapted to pixels techniques developed for processing words in \u003ca href=\"https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eImage Generative Pre-Training\u003c/a\u003e (iGPT).\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e Language models based on the transformer architecture learn to predict the next word, or missing words, in text by unsupervised pre-training on an enormous corpus followed by supervised fine-tuning. The same approach can train models to predict the next pixel in an image.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e iGPT uses the \u003ca href=\"https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eGPT-2\u003c/a\u003e architecture that made waves in natural language processing. However, it learns from sequences of pixels instead of sequences of words.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe researchers preprocessed images by flattening them into one-dimensional vectors.\u003c/li\u003e\u003cli\u003eThe researchers trained iGPT to either predict the next pixel in a sequence (an autoregressive task) or predict a group of pixels missing from a sequence (which they call Bert).\u003c/li\u003e\u003cli\u003ePre-trained NLP models often are fine-tuned on a supervised task such as question answering. Similarly, the researchers fine-tuned iGPT on image classification. They found that hiding pixels from the model during fine-tuning improved performance.\u003c/li\u003e\u003cli\u003eThe researchers provided all intermediate-layer features and labels to a new output layer, but trained only that layer’s parameters.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e Using features extracted by the intermediate layers in the autoregressive task, iGPT achieved 72 percent accuracy on \u003ca href=\"http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eImageNet\u003c/a\u003e, just behind the state-of-the-art 76.5 percent achieved by \u003ca href=\"https://arxiv.org/abs/2002.05709?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eSimCLR\u003c/a\u003e, a popular unsupervised approach. iGPT outperformed SimCLR when fine-tuned and evaluated on the \u003ca href=\"https://www.cs.toronto.edu/~kriz/cifar.html?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eCIFAR\u003c/a\u003e datasets.\u003cbr\u003e\u003cstrong\u003eYes, but:\u003c/strong\u003e The researchers had to downsample ImageNet examples to about 7 percent of their original size to accommodate GPT-2. They suspect that iGPT would stack up better against SimCLR if it could accept larger images.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e iGPT isn’t a convolutional neural network. It doesn’t even use the convolutional filter that’s fundamental to current image processing methods. This work shows the value of applying architectures proven in one domain to others.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e We’ve been encouraged by the progress in self-supervised learning using methods like \u003ca href=\"https://arxiv.org/abs/1807.03748?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eContrastive Predictive Coding\u003c/a\u003e and variations thereof, in which a neural network is trained on a supervised learning task that is created from unlabeled data. iGPT appears to be a new line of attack on this problem.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/MLPerf202.gif\" class=\"kg-image\" alt=\"Graphs and data related to AI chips\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"built-for-speed\"\u003eBuilt for Speed\u003c/h3\u003e\u003cp\u003eChips specially designed for AI are becoming much faster at training neural networks, judging from recent trials.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e \u003ca href=\"https://mlperf.org/press?ref=dl-staging-website.ghost.io#mlperf-training-v0.7-results\" rel=\" noopener\"\u003eMLPerf\u003c/a\u003e, an organization that’s developing standards for hardware performance in machine learning tasks, released \u003ca href=\"https://mlperf.org/training-results-0-7?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eresults\u003c/a\u003e from its third benchmark competition. Nvidia’s latest products led the pack, but Google’s forthcoming hardware surpassed Nvidia’s scores.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eStart your engines:\u003c/strong\u003e MLPerf measures how long it takes various hardware configurations to train particular machine learning \u003ca href=\"https://mlperf.org/training-overview?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003emodels\u003c/a\u003e. Tasks include object detection, image classification, language translation, recommendation, and reinforcement learning goals.\u003c/p\u003e\u003cul\u003e\u003cli\u003eSystems from nine organizations trained models 2.7 times faster, on average, than they did in tests conducted last November, demonstrating the rapid evolution of AI hardware (and enabling software such as compilers).\u003c/li\u003e\u003cli\u003eNvidia submitted 40 different configurations. Those based on its A100 graphics processing unit (GPU) scored highest among commercially available systems.\u003c/li\u003e\u003cli\u003eShowing off capabilities that aren’t yet on the market, \u003ca href=\"https://cloud.google.com/blog/products/ai-machine-learning/google-breaks-ai-performance-records-in-mlperf-with-worlds-fastest-training-supercomputer?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eGoogle\u003c/a\u003e dominated six of the eight tasks with its fourth-generation tensor processing unit (TPU). Earlier versions are available via the Google Cloud platform.\u003c/li\u003e\u003cli\u003eAlibaba, Fujitsu, Intel, Inspur, Shenzhen Institute, and Tencent also joined the competition. Conspicuously absent: AI hardware upstarts Cerebras and Graphcore (see “New Horsepower for Neural Nets” below).\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Nvidia’s GPUs have long been the premier machine learning chips, thanks to their ability to process large volumes of floating point integers per second. But startups including Cerebras, Graphcore, and Habana (acquired by Intel in December) are vying for that position, and Google Cloud is making a strong play for AI workloads.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e It’s good to be past the era of \u003ca href=\"https://www.youtube.com/watch?v=-P28LKWTzrI\u0026ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eMythbusters videos\u003c/a\u003e as a way to compare AI hardware. Machine learning engineers benefit from faster, more energy-efficient hardware systems, but we need clear, consistent metrics like MLPerf to evaluate hardware performance with particular models. \u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Since MLPerf’s first tests two years ago, the time required to train some models has plummeted from hours to seconds. Clearly semiconductor companies have been chipping away at the problem.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM \u003ca href=\"https://www.deeplearning.ai/?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eDEEPLEARNING.AI\u003c/a\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/GIF205.gif\" class=\"kg-image\" alt=\"GIF 5\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003cp\u003eCourse 3 of our Natural Language Processing Specialization is now live on Coursera. \u003ca href=\"https://www.coursera.org/learn/sequence-models-in-nlp?ref=dl-staging-website.ghost.io\"\u003eEnroll today\u003c/a\u003e to gain in-demand technical skills! Course 4 is scheduled for release in September.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/PNCA.gif\" class=\"kg-image\" alt=\"Data related to Covid-19 symptoms prediction\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"cats-cured-of-covid\"\u003eCats Cured of Covid\u003c/h3\u003e\u003cp\u003eNeural networks are famously bad at interpreting input that falls outside the training set’s distribution, so it’s not surprising that some models are certain that cat pictures show symptoms of Covid-19. A new approach won’t mistakenly condemn your feline to a quarantine.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Led by Ankur Mallick, researchers at Carnegie Mellon and Lawrence Livermore National Lab developed \u003ca href=\"https://api.deepai.org/publication-download-pdf/can-your-ai-differentiate-cats-from-covid-19-sample-efficient-uncertainty-estimation-for-deep-learning-safety?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eProbabilistic Neighborhood Components Analysis\u003c/a\u003e (PNCA) to help models estimate the confidence of their predictions.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e Neural networks often show high confidence in predictions that are clearly incorrect — a major issue in areas like healthcare and criminal justice. The problem can fade with enough training data, but it’s pervasive where training data is scarce. Overfitting limited data contributes to overconfidence, so combining deep learning with probabilistic methods, which are less prone to overfitting, might alleviate overconfidence.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e PNCA is a probabilistic version of \u003ca href=\"https://www.cs.toronto.edu/~hinton/absps/nca.pdf?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eNeighborhood Component Analysis\u003c/a\u003e. NCA is a supervised learning method that trains neural nets to extract features that cluster examples of the same class. NCA determines the class of novel input by computing the distance between training data features and input features. It takes the softmax of the distances to obtain the probability that each training example belongs to the same class of the novel input. Practically speaking, NCA is a classification network with fixed output layer weights, but not size, given by the distance function.\u003c/p\u003e\u003cul\u003e\u003cli\u003ePNCA borrows ideas from deep Bayesian networks, which interpret inputs, weights, extracted features, neighborhoods, and class predictions as samples of probability distributions. The use of probability distributions allows PNCA to sharpen its confidence by computing the probability that a particular classification would occur with the provided input.\u003c/li\u003e\u003cli\u003eThe technique estimates the distribution of predicted classes by sampling weights from the weight distribution. Every pair of sampled weights and training examples determines a distinct extracted feature, so running the usual NCA on every pair yields a classification that depends on the weight distribution.\u003c/li\u003e\u003cli\u003ePNCA determines the entire weight distribution by maintaining a sample of weights. Then it trains the sample of weights to generate a sample of predictions to match the training data, updating the weights to minimize the NCA loss.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The researchers trained PNCA on a \u003ca href=\"https://www.kaggle.com/bachrr/covid-chest-xray?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eKaggle dataset\u003c/a\u003e of chest x-rays showing Covid-19, and tested it on \u003ca href=\"https://github.com/agchung/Actualmed-COVID-chestxray-dataset?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eCovid-V2\u003c/a\u003e and a \u003ca href=\"https://www.kaggle.com/c/dogs-vs-cats?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eCats and Dogs dataset\u003c/a\u003e. PNCA performed with similar accuracy to other deep learning approaches on Covid-V2, while incorrectly classifying 1,000 cats and dogs out of 25,000 as Covid-19 with high confidence. This may seem like poor performance, but the same architecture with a standard supervised learning objective mistook around 2500 cats and dogs as Covid-19 chest x-rays.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Deep learning’s overconfidence and data hunger are limitations to their practical deployment. PNCA combines deep learning’s powerful feature extraction with a probabilistic ability to quantify uncertainty.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e We’re waiting for a model that can tell us the condition of Schroedinger’s cat.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://www.deeplearning.ai/wp-content/uploads/2021/01/GraphcoreGif.gif\" class=\"kg-image\" alt=\"Colossus Mk2, processor by Graphcore\" loading=\"lazy\"\u003e\u003c/figure\u003e\u003ch3 id=\"new-horsepower-for-neural-nets\"\u003eNew Horsepower for Neural Nets\u003c/h3\u003e\u003cp\u003eA high-profile semiconductor startup made a bid for the future of AI computation.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e UK startup Graphcore released the \u003ca href=\"https://www.graphcore.ai/posts/introducing-second-generation-ipu-systems-for-ai-at-scale?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003eColossus Mk2\u003c/a\u003e, a processor intended to perform the matrix math calculations at the heart of deep learning more efficiently than other specialized processors or general-purpose chips from Intel and AMD. The company expects to be shipping at full volume in the fourth quarter.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The Mk2 comprises nearly 60 billion transistors. (Nvidia’s flagship A100 has 54 billion, while Cerebras’ gargantuan Wafer-Scale Engine boasts 1.2 trillion. Google doesn’t advertise its TPU transistor counts.) Girded by 900 megabytes of random access memory, the Mk2’s transistors are organized into 1,500 independent cores capable of running nearly 9,000 parallel threads.\u003c/p\u003e\u003cul\u003e\u003cli\u003eGraphcore is selling the new chips as part of a platform called IPU-Machine M200. Each M200 will hold four Mk2 chips to deliver a combined computational punch of 1 petaflop, or 1015 floating point operations per second.\u003c/li\u003e\u003cli\u003eEach M200 can connect to up to 64,000 others for 16 exaflops of compute. (An exaflop is 1,000 petaflops.) That’s a hefty claim, given that competing systems have yet to reach 1 exaflop.\u003c/li\u003e\u003cli\u003eThe package includes software designed to manage a variety of machine learning frameworks. Developers can code directly using Python and C++.\u003c/li\u003e\u003cli\u003eJ.P. Morgan, Lawrence Berkeley National Laboratory, and the University of Oxford are among the first users of the new chip.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e AI’s demand for computational resources is insatiable. A recent \u003ca href=\"https://arxiv.org/abs/2007.05558?ref=dl-staging-website.ghost.io\" rel=\" noopener\"\u003estudy\u003c/a\u003e from researchers at MIT, the University of Brasilia, and Yonsei University suggests that progress in deep learning could stall for lack of processing power. Innovations in chip technology may make a difference.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e The fact that software evolves faster than hardware is a major challenge to building chips. Graphcore’s design is geared to accelerate large, sparse recurrent neural networks at a moment when transformer networks are beginning to supplant RNNs in some applications. Will some bold chip maker tune its next generation for transformers?\u003c/p\u003e","comment_id":"60c0372a274d5b003b1065b6","feature_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter-1.png","featured":false,"visibility":"public","created_at":"2021-06-08T20:36:10.000-07:00","updated_at":"2022-10-06T16:24:58.000-07:00","published_at":"2020-08-05T12:00:00.000-07:00","custom_excerpt":"I spoke last week at the National Intergovernmental Audit Forum, a meeting attended by U.S. federal, state, and local government auditors. (Apparently some of the organizers had taken AI for Everyone.) ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"60c03750274d5b003b1065bc","name":"issue-51","slug":"issue-51","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-51/"},{"id":"631f3f658e369f003ddfc654","name":"Aug 05, 2020","slug":"aug-05-2020","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/aug-05-2020/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-51/","excerpt":"I spoke last week at the National Intergovernmental Audit Forum, a meeting attended by U.S. federal, state, and local government auditors. (Apparently some of the organizers had taken AI for Everyone.) ","reading_time":10,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Faster AI Chips, Smarter Prosthetic Legs, Transformers for Image","meta_description":"The Batch - AI News \u0026 Insights: Chips specially designed for AI are becoming much faster at training neural networks | Prosthetic leg that learns from the user’s motion","email_subject":null,"frontmatter":null,"feature_image_alt":"Andrew Ng speaking at the National Intergovernmental Audit Forum about auditing AI systems","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/06/Andrews20Letter-1.png","dimensions":{"width":576,"height":324}},"banner":{"title":"Data Analytics Professional Certificate","databaseId":36316,"id":"cG9zdDozNjMxNg==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2025/03/Vertical-side-banner-ads-7.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/3XWMC3m","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-51"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>