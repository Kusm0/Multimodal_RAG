<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>GPU Shortage, Affordable Robodog, Humanizing Large Language Models, and more</title><meta name="description" content="The Batch - AI News &amp; Insights: An increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-210/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="GPU Shortage, Affordable Robodog, Humanizing Large Language Models, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: An increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="GPU Shortage, Affordable Robodog, Humanizing Large Language Models, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-210/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2023-08-17T06:55:43.000-07:00"/><meta property="article:modified_time" content="2024-02-06T10:04:52.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-210"/><meta property="article:tag" content="Aug 16, 2023"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="GPU Shortage, Affordable Robodog, Humanizing Large Language Models, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: An increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-210/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--45-.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--45-.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="675"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2023-08-17T06:55:43.000-07:00","dateModified":"2024-02-06T10:04:52.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"GPU Shortage, Affordable Robodog, Humanizing Large Language Models, and more","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--45-.png","width":1200,"height":675},"publisher":{"@type":"Organization","name":"GPU Shortage, Affordable Robodog, Humanizing Large Language Models, and more","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: An increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-210/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 210</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Aug 17, 2023</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">15<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/aug-16-2023/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Aug 16, 2023</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">15<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-210/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-210/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-210/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,</em></p><p><em>An increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models with relatively permissive licenses gives developers more options for building applications.</em></p><p><em>Here are some different ways to build applications based on LLMs, in increasing order of cost/complexity:</em></p><ul><li><em><strong>Prompting. </strong>Giving a pretrained LLM instructions lets you build a prototype in minutes or hours </em><a href="https://www.deeplearning.ai/the-batch/building-ai-systems-no-longer-requires-much-data/?ref=dl-staging-website.ghost.io"><em>without a training set</em></a><em>. Earlier this year, I saw a lot of people start experimenting with prompting, and that momentum continues unabated. Several of our </em><a href="https://www.deeplearning.ai/short-courses/?ref=dl-staging-website.ghost.io"><em>short courses</em></a><em> teach best practices for this approach.</em></li><li><em><strong>One-shot or few-shot prompting.</strong> In addition to a prompt, giving the LLM a handful of examples of how to carry out a task — the input and the desired output — sometimes yields better results. </em></li><li><em><strong>Fine-tuning.</strong> An LLM that has been pretrained on a lot of text can be fine-tuned to your task by training it further on a small dataset of your own. The tools for fine-tuning are maturing, making it accessible to more developers.</em></li><li><em><strong>Pretraining.</strong> Pretraining your own LLM from scratch takes a lot of resources, so very few teams do it. In addition to general-purpose models pretrained on diverse topics, this approach has led to specialized models like BloombergGPT, which knows about finance, and Med-PaLM 2, which is focused on medicine.</em></li></ul><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--45--1.png" class="kg-image" alt="Two coworkers interacting: - I prompted it to play Mozart. - Try Fine-Tuning!" loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--45--1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--45--1.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--45--1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><em>For most teams, I recommend starting with prompting, since that allows you to get an application working quickly. If you’re unsatisfied with the quality of the output, ease into the more complex techniques gradually. Start one-shot or few-shot prompting with a handful of examples. If that doesn’t work well enough, perhaps use RAG (retrieval augmented generation) to further improve prompts with key information the LLM needs to generate high-quality outputs. If that still doesn’t deliver the performance you want, then try fine-tuning — but this represents a significantly greater level of complexity and may require hundreds or thousands more examples. To gain an in-depth understanding of these options, I highly recommend the course </em><a href="https://www.deeplearning.ai/courses/generative-ai-with-llms/?ref=dl-staging-website.ghost.io">Generative AI with Large Language Models</a><em>, created by AWS and DeepLearning.AI.</em></p><p><em>(Fun fact: A member of the DeepLearning.AI team has been trying to fine-tune Llama-2-7B to sound like me. I wonder if my job is at risk? 😜)</em></p><p><em>Additional complexity arises if you want to move to fine-tuning after prompting a proprietary model, such as GPT-4, that’s not available for fine-tuning. Is fine-tuning a much smaller model likely to yield superior results than prompting a larger, more capable model? The answer often depends on your application. If your goal is to change the style of an LLM’s output, then fine-tuning a smaller model can work well. However, if your application has been prompting GPT-4 to perform complex reasoning — in which GPT-4 surpasses current open models — it can be difficult to fine-tune a smaller model to deliver superior results.</em></p><p><em>Beyond choosing a development approach, it’s also necessary to choose a specific model. Smaller models require less processing power and work well for many applications, but larger models tend to have more knowledge about the world and better reasoning ability. I’ll talk about how to make this choice in a future letter.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. We just released “Large Language Models with Semantic Search,”  a short course built in collaboration with Cohere and taught by Jay Alammar and Luis Serrano. Search is a key part of many applications. Say, you need to retrieve documents or products in response to a user query. How can LLMs help? You’ll learn about (i) embeddings to retrieve a collection of documents loosely related to a query and (ii) LLM-assisted re-ranking to rank them precisely according to a query. You’ll also go through code that shows how to build a search system for retrieving relevant Wikipedia articles. Please </em><a href="https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/?ref=dl-staging-website.ghost.io"><em>check it out</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--82-.gif" class="kg-image" alt="" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--82-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--82-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--82-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="gpu-shortage-intensifies">GPU Shortage Intensifies</h1><p>Nvidia’s top-of-the-line chips are in high demand and short supply.</p><p><strong>What’s new:</strong> There aren’t enough H100 graphics processing units (GPUs) to meet the crush of demand brought on by the vogue for generative AI, <em>VentureBeat</em> <a href="https://venturebeat.com/ai/nvidia-gpu-shortage-is-top-gossip-of-silicon-valley/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">reported</a>.</p><p><strong>Bottleneck:</strong> Cloud providers began having <a href="https://www.deeplearning.ai/the-batch/generative-ai-demand-is-overwhelming-cloud-servers/?ref=dl-staging-website.ghost.io">trouble finding GPUs</a> earlier this year, but the shortfall has spread to AI companies large and small. SemiAnalysis, a semiconductor market research firm, <a href="https://www.semianalysis.com/p/ai-capacity-constraints-cowos-and?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">estimates</a> that the chip will remain sold out into 2024.</p><ul><li>TSMC, which fabricates Nvidia’s designs, can produce only so many H100s. Its high-end <a href="https://3dfabric.tsmc.com/english/dedicatedFoundry/technology/cowos.htm?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">chip packaging technology</a>, which is shared among Nvidia, AMD, and other chip designers, currently has limited capacity. The manufacturer expects to double that capacity by the end of 2024.</li><li>Nvidia executive Charlie Boyle downplayed the notion of a shortage, saying that cloud providers had presold much of their H100 capacity. As a result, startups that need access to thousands of H100s to train large models and serve a sudden swell of users have few options.</li><li>An individual H100 with memory and high-speed interface originally retailed for around <a href="https://www.tomshardware.com/news/nvidia-hopper-h100-80gb-price-revealed?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">$33,000</a>. Second-hand units now cost <a href="https://www.extremetech.com/computing/nvidias-h100-ai-processors-are-selling-for-over-40000-on-ebay?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">between $40,000 and $51,000</a> on eBay.</li></ul><p><strong>Who’s buying: </strong>Demand for H100s is hard to quantify. Large AI companies and cloud providers may need tens of thousands to hundreds of thousands of them, while AI startups may need hundreds to thousands.</p><ul><li>The blog gpus.llm-utils.org <a href="https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">ballparked</a> current demand at around 430,000 H100s, which amounts to roughly $15 billion in sales. The author said the tally is a guess based on projected purchases by major AI companies, AI startups, and cloud providers. It omits Chinese companies and may double-count chips purchased by cloud providers and processing purchased by cloud customers.</li><li>Chinese tech giants Alibaba, Baidu, ByteDance, and Tencent ordered $5 billion worth of Nvidia chips, the bulk of them to be delivered next year, the <a href="https://www.ft.com/content/9dfee156-4870-4ca4-b67d-bb5a285d855c?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener"><em>Financial Times</em></a> reported.</li><li>CoreWeave, a startup cloud computing provider, ordered between 35,000 and 40,000 H100s. It has a close relationship with Nvidia, which <a href="https://techcrunch.com/2023/04/20/coreweave-a-gpu-focused-cloud-compute-provider-lands-221m-investment/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAANitwUGBpYDY_iKAWwaVFcRLBkkM-CZWy0LK_uyDcsCpaw-_gnm23dh2ICt7sysU1_BbBzyJ9Tj05d8NNp8blYiiwY4_rzPGlyvPxf2wZ1qjiM1ScfzOGrbD-QIarcQOPaRwBwt4F0vApIOkvhJmLdFC6XRCUREWW8_efahMiqRc&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">invested</a> in its recent funding round, and it <a href="https://www.reuters.com/technology/coreweave-raises-23-billion-debt-collateralized-by-nvidia-chips-2023-08-03/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">secured</a> a $2.3 billion loan — using H100 chips as collateral — to finance construction of data centers that are outfitted to process AI workloads.</li><li>Machine learning startup Inflection AI <a href="https://inflection.ai/inflection-ai-announces-1-3-billion-of-funding?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">plans</a> to have 22,000 H100s by December.</li></ul><p><strong>Behind the news:</strong> Nvidia <a href="https://www.deeplearning.ai/the-batch/transformer-accelerator/?ref=dl-staging-website.ghost.io">announced</a> the H100 early last year and began full production in September. Compared to its predecessor, the A100, the H100 performs about 2.3 times faster in training and 3.5 times faster at inference.</p><p><strong>Why it matters:</strong> Developers need these top-of-the-line chips to train high-performance models and deploy them in cutting-edge products. At a time when AI is white-hot, a dearth of chips could affect the pace of innovation.<br><br><strong>We’re thinking:</strong> Nvidia’s CUDA software, which undergirds many deep learning software packages, gives the company’s chips a significant advantage. However, AMD’s open source ROCm is making great strides, and its MI250 and upcoming MI300-series chips appear to be promising alternatives. An open software infrastructure that made it easy to choose among GPU providers would benefit the AI community.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--83-.gif" class="kg-image" alt="" loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--83-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--83-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--83-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="china%E2%80%99s-llms-open-up">China’s LLMs Open Up</h1><p>The latest wave of large language models trained in Chinese is open source for some users.</p><p><strong>What’s new:</strong> Internet giant Alibaba released large language models that are freely available to smaller organizations. The internet giant followed Baichuan Intelligent Technology, a startup that contributed its own partly open models, and Beijing Academy of Artificial Intelligence, which announced that its WuDao 3.0 would be open source.<br><br><strong>How it works:</strong> These pretrained models are small compared to, say, Meta’s LLaMa 2 (70 billion parameters) — but that may be a plus in China, where U.S. export restrictions have made chips for processing AI hard to get.</p><ul><li>Alibaba <a href="https://github.com/QwenLM/Qwen-7B?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">offers</a> Qwen-7B and Qwen-7B-Chat. The models are freely available to small-scale users, but organizations with more than 100 million monthly active users require a license.</li><li>Baichuan Intelligent Technology, a firm owned by Wang Xiaochuan, founder of search engine Sogou (now owned by Tencent), <a href="https://github.com/baichuan-inc/Baichuan-13B?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">released</a> Baichuan-13B and Baichuan-13B-Chat. The models are freely available to academic users. Commercial users require a license.</li><li>Beijing Academy of Artificial Intelligence <a href="https://spectrum.ieee.org/china-chatgpt-wu-dao?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">revealed</a> its open source Wu Dao 3.0 model family to <em>IEEE Spectrum</em>. The family includes AquilaChat-7B and AquilaChat-33B (both fine-tuned for conversation), AquilaCode (fine-tuned to generate code from natural-language prompts), and Wu Dao Vision (for computer vision tasks). The new models upgrade and slim down the 1.75-trillion-parameter <a href="https://www.deeplearning.ai/the-batch/trillions-of-parameters/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">WuDao 2.0</a>.</li></ul><p><strong>Behind the news:</strong> Developers in China are <a href="https://www.deeplearning.ai/the-batch/chinese-tech-companies-race-to-cash-in-on-chatgpt-fever/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">racing</a> to cash in on chatbot fever. But they face unique hurdles.</p><ul><li>In September, the United States Commerce Department <a href="https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">restricted</a> the sale of high-performance AI chips including Nvidia A100 and H100 GPUs in China. Some Chinese customers have <a href="https://www.deeplearning.ai/the-batch/loopholes-help-chinese-companies-get-us-chips/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">found</a> loopholes, but demand continues to outstrip supply.</li><li>Language models and their output are restricted by law. Interim rules set to take effect on August 15 <a href="https://www.reuters.com/technology/china-issues-temporary-rules-generative-ai-services-2023-07-13/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">require</a> government approval for generative AI products before they’re released to the public. Developers have <a href="https://www.theatlantic.com/international/archive/2023/04/chatbot-ai-problem-china/673754/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">limited</a> recent chatbots to comply with restrictions on internet content.</li></ul><p><strong>Why it matters:</strong> The March leak of Meta’s <a href="https://www.deeplearning.ai/the-batch/how-metas-llama-nlp-model-leaked/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">LLaMA</a> initiated a groundswell of open models that excel in English and a subsequent explosion of innovation and entrepreneurial activity. Competitive open models trained in Mandarin and other Chinese languages could spark similar developments in one of the world’s biggest countries — as long as developers hew to the law.</p><p><strong>We’re thinking:</strong> High-profile models like ChatGPT and Bard, having been trained on huge amounts of English-language data, tend to know a lot about the histories, geographies, and societies of English-speaking countries but relatively little about places where other languages are spoken. Models trained on Chinese corpora will serve speakers of China’s languages far better, and open source models fine-tuned for Chinese users likely will play an important role.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM <strong>DEEPLEARNING.AI</strong></h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/large-language-models-semantic-search?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--48-.png" class="kg-image" alt="" loading="lazy" width="1680" height="945" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/The-Batch-ads-and-exclusive-banners--48-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/The-Batch-ads-and-exclusive-banners--48-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/08/The-Batch-ads-and-exclusive-banners--48-.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--48-.png 1680w" sizes="(min-width: 720px) 720px"></a></figure><p>Join our new course, “Large Language Models with Semantic Search,” and learn the techniques you need to integrate LLMs with search and how to use your website’s information to generate responses. <a href="https://www.deeplearning.ai/short-courses/large-language-models-semantic-search?ref=dl-staging-website.ghost.io">Enroll for free</a></p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--4-.gif" class="kg-image" alt="" loading="lazy" width="672" height="378" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/The-Batch-ads-and-exclusive-banners--4-.gif 600w, https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--4-.gif 672w"></figure><h1 id="chatgpt%E2%80%99s-best-friend">ChatGPT’s Best Friend</h1><p>The latest robot dog is smarter — and less expensive — than ever.</p><p><strong>What’s new:</strong> Unitree Robotics of Hangzhou, China, <a href="https://www.unitree.com/en/go2/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">unleashed</a> Go2, a quadruped robot that trots alongside its owner, stands on two legs, jumps, talks, takes photos, and retails for less than a high-end MacBook.</p><p><strong>How it works: </strong>Go2 is made of aluminum and plastic, weighs around 15 kilograms, and moves using 12 joints. A robotic arm mounted on the unit’s back is optional. It comes in three versions with a starting price of $1,600.</p><ul><li>All three models include a 360-degree LIDAR sensor and object detection and avoidance capability. They can connect to other devices using either Wi-Fi or Bluetooth and take pictures with a front-facing camera.</li><li>The Go2 Pro, priced at $2,800, contains an eight-core CPU and foot-end force sensors that enable it to navigate autonomously at around 3.5 meters per second. It can communicate via 4G cellular as well as converse and follow plain-language verbal commands using an unspecified “GPT” language model.</li><li>The Go2 Edu, the price of which is not listed, adds an Nvidia <a href="https://www.nvidia.com/en-gb/autonomous-machines/embedded-systems/jetson-orin/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">Jetson Orin</a> computer and a more powerful, faster-charging battery.</li></ul><p><strong>Why it matters:</strong> Boston Dynamics’ industrial-strength robodog Spot is <a href="https://www.therobotreport.com/ontario-power-generation-tests-boston-dynamics-spot-to-save-lives/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">manipulating</a> high-voltage electrical equipment, <a href="https://www.csrwire.com/press_releases/744021-spot-robot-dog-helps-humans-inspect-nuclear-power-plant?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">inspecting</a> nuclear power plants, and <a href="https://www.theverge.com/2023/4/11/23679297/nypd-robot-dog-spot-surveillance-boston-dynamics?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">helping</a> to monitor urban areas. But its price — from <a href="https://spectrum.ieee.org/boston-dynamics-spot-robot-dog-now-available?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">$74,500</a> to <a href="https://www.thestack.technology/how-much-does-boston-dynamics-spot-cost-uk/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">$200,000</a> — puts it out of reach of many potential users. With its dramatically lower price, Go2 suggests that such mechanical beasts may find a wider range of uses.<br><br><strong>We’re thinking:</strong> While wheels are great on flat ground, four legs with backward-facing joints are more <a href="https://transmitter.ieee.org/why-do-so-many-robots-look-like-dogs/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">stable</a> on uneven terrain. Plus, robot dogs are cute!</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--84-.gif" class="kg-image" alt="" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--84-.gif 600w"></figure><h1 id="llms-get-a-life">LLMs Get a Life</h1><p>Large language models increasingly reply to prompts with a believably human response. Can they also mimic human behavior?</p><p><strong>What's new:</strong> Joon Sung Park and colleagues at Stanford and Google extended GPT-3.5 to build <a href="https://arxiv.org/abs/2304.03442?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">generative agents</a> that went about their business in a small town and interacted with one another in human-like ways. The code is newly <a href="https://github.com/joonspk-research/generative_agents?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">available</a> as open source.</p><p><strong>Key insight: </strong>With the right prompts, a text database, and a server to keep track of things, a large language model (LLM) can simulate human activity.</p><ul><li>Just as people observe the world, an LLM can describe its experiences. Observations can be stored and retrieved to function like memories.</li><li>Just as people consolidate memories, an LLM can summarize them as reflections for later use.</li><li>To behave in a coherent way, an LLM can generate a plan and revise it as events unfold.</li></ul><p><strong>How it works:</strong> The authors designed 25 agents (represented by 2D sprites) who lived in a simulated town (a 2D background depicting the layout and the contents of its buildings) and let them run for two days. Each agent used <a href="https://arxiv.org/abs/2005.14165?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">GPT 3.5;</a> a database of actions, memories, reflections, and plans generated by GPT 3.5; and a server that tracked agent and object behaviors, locations (for instance, in the kitchen of Isabella’s apartment), and statuses (whether a stove was on or off), and relayed this information to agents when they came nearby.</p><ul><li>At each time step, the server gave each agent an observation that comprised what it last said it was doing, the objects and people in view, and their statuses.</li><li>Given an observation, an agent retrieved a memory based on recency, relevance, and importance. It measured relevance according to cosine similarity between embeddings of the observation and the memory. It rated importance by asking GPT-3.5 to score memories on a scale from “mundane” (1) to “poignant” (10). Having retrieved the memory, the agent generated text that described its action, upon which the server updated the appropriate locations and statuses.</li><li>The reflection function consolidated the latest 100 memories a couple of times a day. Given 100 recent memories (say, what agent Klaus Mueller looked up at the library), the agent proposed 3 high-level questions that its memories could provide answers to (for instance, “What topic is Klaus Mueller passionate about?”). For each question, the agent retrieved relevant memories and generated five high-level insights (such as, “Klaus Mueller is dedicated to his research on gentrification”). Then it stored these insights in the memory.</li><li>Given general information about its identity and a summary of memories from the previous day, the agent generated a plan for the current day. Then it decomposed the plan into chunks an hour long, and finally into chunks that are minutes long (“4:00 p.m.: grab a light snack, such as a piece of fruit, a granola bar, or some nuts. 4:05 p.m.: …”. The detailed plans went into the memory.</li><li>At each time step, the agent asked itself whether and how it should react to its observation given general information about its identity, its plan, and a summary of relevant memories. If it should react, the agent updated its plan and output a statement that describes its reactions. Otherwise, the agent generated a statement saying it would continue the existing plan. For example, a father might observe another agent and, based on a memory, identify it as his son who is currently working on a project. Then the father might decide to ask the son how the project is going.</li></ul><p><strong>Results:</strong> The complete agents exhibited three types of emergent behavior: They spread information initially known only to themselves, formed relationships, and cooperated (specifically to attend a party). The authors gave 100 human evaluators access to all agent actions and memories. The evaluators asked the agents simple questions about their identities, behaviors, and thoughts. Then they ranked the agents’ responses for believability. They also ranked versions of each agent that were missing one or more functions, as well as humans who stood in for each agent (“to identify whether the architecture passes a basic level of behavioral competency,” the authors write). These rankings were turned into a <a href="https://www.microsoft.com/en-us/research/publication/trueskilltm-a-bayesian-skill-rating-system/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">TrueSkill</a> score (a variation on the Elo system used in chess) for each agent type. The complete agent architecture scored highest, while the versions that lacked particular functions scored lower. Surprisingly, the human stand-ins also underperformed the complete agents.</p><p><strong>Yes, but:</strong> Some complete agents “remembered” details they had not experienced. Others showed erratic behavior, like not recognizing that a one-person bathroom was occupied or that a business was closed. And they used oddly formal language in intimate conversation; one ended exchanges with her husband, “It was good talking to you as always.”</p><p><strong>Why it matters:</strong> Large language models produce surprisingly human-like output. Combined with a database and server, they can begin to simulate human interactions. While the TrueSkill results don’t fully convey how humanly these agents behaved, they do suggest a role for such agents in fields like game development, social media, robotics, and <a href="https://arxiv.org/abs/2307.04986?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">epidemiology</a>.</p><p><strong>We're thinking:</strong> The evaluators found the human stand-ins less believable than the full-fledged agents. Did the agents exceed human-level performance in the task of acting human, or does this result reflect a limitation of the evaluation method?</p><hr><h2 id="a-message-from-deeplearningai-1">A MESSAGE FROM <strong>DEEPLEARNING.AI</strong></h2><figure class="kg-card kg-image-card"><a href="https://www.eventbrite.com/e/efficient-fine-tuning-for-llama-7b-on-a-single-gpu-tickets-696331224437?aff=Batch&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--50-.png" class="kg-image" alt="" loading="lazy" width="1680" height="945" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/The-Batch-ads-and-exclusive-banners--50-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/The-Batch-ads-and-exclusive-banners--50-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/08/The-Batch-ads-and-exclusive-banners--50-.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--50-.png 1680w" sizes="(min-width: 720px) 720px"></a></figure><p>Join our upcoming workshop with Predibase and learn how to use open source tools to overcome challenges like the “host out of memory” error when fine-tuning models like Llama-2. <a href="https://www.eventbrite.com/e/efficient-fine-tuning-for-llama-7b-on-a-single-gpu-tickets-696331224437?aff=Batch&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67" rel="noopener">Register now</a></p><hr><h1 id="data-points">Data Points</h1><p><strong>Publisher surprised to find it published AI-generated art</strong><br>Wizards of the Coast, the publisher of Dungeons &amp; Dragons guidebooks and stories, admitted the use of AI-generated artwork in a digital book. The company, which claimed to have been unaware that it had published generated content prior to the book’s release, said it would update its policies to prevent AI art from being included in future publications. (<a href="https://www.polygon.com/23823516/dnd-dungeons-dragons-wizards-ai-art-controversy-bigby-presents-glory-of-the-giants?ref=dl-staging-website.ghost.io"><em>Polygon</em></a>)<br><br><strong>Brookings shows the uneven geography of AI activity in the U.S.</strong><br>A report from Brookings Institute highlights the concentration of AI activity in tech-focused cities like San Francisco, New York, and Seattle. It proposes policy actions at federal, state, and local levels to promote more widespread AI development. (<a href="https://www.brookings.edu/articles/building-ai-cities-how-to-spread-the-benefits-of-an-emerging-technology-across-more-of-america/?ref=dl-staging-website.ghost.io">Brookings</a>)<br><br><strong>AI and robotics make recycling more efficient</strong><br>Companies such as EverestLabs and AMP Robotics are using AI to streamline the recycling process. Their robotic arms identify recyclable items to boost object recovery rates by up to three times compared to human efforts. (<a href="https://www.cnbc.com/2023/08/08/everestlabs-using-robotic-arms-and-ai-to-make-recycling-more-efficient.html?ref=dl-staging-website.ghost.io"><em>CNBC</em></a>)<br><br><a href="https://arxiv.org/pdf/2308.01074.pdf?ref=dl-staging-website.ghost.io">Research:</a><strong> A deep learning model recognizes laptop keystrokes by sound</strong><br>Researchers trained a model to analyze sound profiles of laptop keystrokes. They achieved 93 percent accuracy when interpreting individual key sounds in Zoom audio recordings. This approach raises security concerns, especially for laptops used in public settings. (<a href="https://arstechnica.com/gadgets/2023/08/type-softly-researchers-can-guess-keystrokes-by-sound-with-93-accuracy/?ref=dl-staging-website.ghost.io"><em>Ars Technica</em></a>)<br><br><strong>Commercialized deepfakes raise questions about control and misuse</strong><br>Synthesia touts its AI avatars, which look like video recordings of people,  to enhance corporate presentations and training sessions. However, the photorealistic avatars have been put to use by scammers and propagandists (<a href="https://www.wired.com/story/synthesia-ai-deepfakes-it-control-riparbelli/?ref=dl-staging-website.ghost.io"><em>Wired</em></a>)<br><br><strong>Tech giants rally behind AI in resurgent quarter</strong><br>AI helped companies like Google, Meta, and Microsoft rebound from a financial slump in the most recent quarter. Now they’re doubling down on AI to revitalize their product lines and fuel innovation. Some are already benefiting from the AI fever. (<a href="https://www.nytimes.com/2023/08/05/technology/tech-nvidia-chips.html?ref=dl-staging-website.ghost.io"><em>The New York Times</em></a>)<br><br><strong>Disney forms AI task force</strong><br>The Walt Disney Company established a dedicated group to explore the applications of AI across its entertainment empire. The initiative aims to develop in-house solutions and forge partnerships that can drive innovation and cut costs. (<a href="https://www.reuters.com/technology/disney-creates-task-force-explore-ai-cut-costs-sources-2023-08-08/?ref=dl-staging-website.ghost.io"><em>Reuters</em></a>)</p><p><strong>Google and Universal Music explore licensing for AI-generated music</strong><br>Alphabet's Google is in early discussions with Universal Music  over licenses to use artists' voices and melodies in AI-generated songs. The companies aim to develop technology that would  enable  fans to make their own sound-alike productions while compensating copyright owners. (<a href="https://www.reuters.com/technology/google-universal-music-talks-deal-ai-deepfakes-ft-2023-08-08/?ref=dl-staging-website.ghost.io"><em>Reuters</em></a>)<br><br><strong>Report highlights AI's role in promoting eating disorders</strong><br>A study conducted by the Center for Countering Digital Hate (CCDH) found that ChatGPT and Stable Diffusion produced harmful output around 41 percent of the time when tested with prompts related to eating disorders. Experts emphasize the need to ensure that AI-generated content doesn't promote unhealthy body-image ideals or provide dangerous advice to users who may suffer from eating disorders. (<a href="https://www.washingtonpost.com/technology/2023/08/07/ai-eating-disorders-thinspo-anorexia-bulimia/?ref=dl-staging-website.ghost.io"><em>The Washington Post</em></a> and <a href="https://counterhate.com/wp-content/uploads/2023/08/230705-AI-and-Eating-Disorders-REPORT.pdf?ref=dl-staging-website.ghost.io">CCDH</a>)<br><br><strong>Zoom promises not totrain its AI systems on customer data</strong><br>The video conferencing platform added a line to its terms of service stating that it will not employ customer audio, video, or chat content for training AI models without consent. The company updated its terms after users discovered language that granted the right to use customer data to build AI systems. In July, Zoom had revised its terms to broaden its access to customer data in developing AI products and services. (<a href="https://www.washingtonpost.com/politics/2023/08/08/zooms-privacy-tweaks-stoke-fears-that-its-calls-will-be-used-train-ai/?ref=dl-staging-website.ghost.io"><em>The Washington Post</em></a>)<br><br><strong>Stack Overflow adapts to survive in the age of LLMs</strong><br>The longstanding community for developers faces a decline in traffic as AI models increasingly answer technical questions. Some language models, partly trained on Stack Overflow's data, compete with Stack Overflow directly. The company plans to develop its own question-answering models and charge AI companies to use its data. (<a href="https://www.businessinsider.com/stack-overflow-crisis-future-of-online-data-ai-world-2023-7?ref=dl-staging-website.ghost.io"><em>Business Insider</em></a>)<br><br><strong>Google's AI seeks to continue training AI on published content</strong><br>Google submitted a proposal to the Australian government suggesting that generative AI systems should be allowed to use publishers' content to train AI systems while providing an opt-out for those that want to keep their content out of training datasets. Google's position sparked discussions about content creators' rights. (<a href="https://www.theguardian.com/technology/2023/aug/09/google-says-ai-systems-should-be-able-to-mine-publishers-work-unless-companies-opt-out?ref=dl-staging-website.ghost.io"><em>The Guardian</em></a>)<br><br><strong>OpenAI allows content providers to opt out of its training datasets</strong><br>GPTBot, a web crawler that collects online data used by OpenAI to train its models, offers website operators the ability to opt out. The crawler will not scrape data from sites that exercise the option.(<a href="https://www.theverge.com/2023/8/7/23823046/openai-data-scrape-block-ai?ref=dl-staging-website.ghost.io"><em>The Verge</em></a>)</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="Become an AI professional with one of the world&#x27;s most popular Machine Learning courses. #BreakIntoAI with Machine Learning Specialization" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="Become an AI professional with one of the world&#x27;s most popular Machine Learning courses. #BreakIntoAI with Machine Learning Specialization" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F4.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/courses/machine-learning-specialization/"><div class="absolute inset-0" data-gtm-event-title="BreakIntoAI with Machine Learning Specialization"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-210/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-210/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-210/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm11" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-210","id":"64dd03ecc0c40400019551b7","uuid":"cd58bd0e-ff5a-42ba-aa92-0d36a594079c","title":"GPU Shortage, Affordable Robodog, Humanizing Large Language Models, China's Open LLMs","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAn increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models with relatively permissive licenses gives developers more options for building applications.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eHere are some different ways to build applications based on LLMs, in increasing order of cost/complexity:\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003ePrompting. \u003c/strong\u003eGiving a pretrained LLM instructions lets you build a prototype in minutes or hours \u003c/em\u003e\u003ca href=\"https://www.deeplearning.ai/the-batch/building-ai-systems-no-longer-requires-much-data/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003ewithout a training set\u003c/em\u003e\u003c/a\u003e\u003cem\u003e. Earlier this year, I saw a lot of people start experimenting with prompting, and that momentum continues unabated. Several of our \u003c/em\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eshort courses\u003c/em\u003e\u003c/a\u003e\u003cem\u003e teach best practices for this approach.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003eOne-shot or few-shot prompting.\u003c/strong\u003e In addition to a prompt, giving the LLM a handful of examples of how to carry out a task — the input and the desired output — sometimes yields better results. \u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003eFine-tuning.\u003c/strong\u003e An LLM that has been pretrained on a lot of text can be fine-tuned to your task by training it further on a small dataset of your own. The tools for fine-tuning are maturing, making it accessible to more developers.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003e\u003cstrong\u003ePretraining.\u003c/strong\u003e Pretraining your own LLM from scratch takes a lot of resources, so very few teams do it. In addition to general-purpose models pretrained on diverse topics, this approach has led to specialized models like BloombergGPT, which knows about finance, and Med-PaLM 2, which is focused on medicine.\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--45--1.png\" class=\"kg-image\" alt=\"Two coworkers interacting: - I prompted it to play Mozart. - Try Fine-Tuning!\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--45--1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--45--1.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--45--1.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eFor most teams, I recommend starting with prompting, since that allows you to get an application working quickly. If you’re unsatisfied with the quality of the output, ease into the more complex techniques gradually. Start one-shot or few-shot prompting with a handful of examples. If that doesn’t work well enough, perhaps use RAG (retrieval augmented generation) to further improve prompts with key information the LLM needs to generate high-quality outputs. If that still doesn’t deliver the performance you want, then try fine-tuning — but this represents a significantly greater level of complexity and may require hundreds or thousands more examples. To gain an in-depth understanding of these options, I highly recommend the course \u003c/em\u003e\u003ca href=\"https://www.deeplearning.ai/courses/generative-ai-with-llms/?ref=dl-staging-website.ghost.io\"\u003eGenerative AI with Large Language Models\u003c/a\u003e\u003cem\u003e, created by AWS and DeepLearning.AI.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003e(Fun fact: A member of the DeepLearning.AI team has been trying to fine-tune Llama-2-7B to sound like me. I wonder if my job is at risk? 😜)\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAdditional complexity arises if you want to move to fine-tuning after prompting a proprietary model, such as GPT-4, that’s not available for fine-tuning. Is fine-tuning a much smaller model likely to yield superior results than prompting a larger, more capable model? The answer often depends on your application. If your goal is to change the style of an LLM’s output, then fine-tuning a smaller model can work well. However, if your application has been prompting GPT-4 to perform complex reasoning — in which GPT-4 surpasses current open models — it can be difficult to fine-tune a smaller model to deliver superior results.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eBeyond choosing a development approach, it’s also necessary to choose a specific model. Smaller models require less processing power and work well for many applications, but larger models tend to have more knowledge about the world and better reasoning ability. I’ll talk about how to make this choice in a future letter.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eP.S. We just released “Large Language Models with Semantic Search,”  a short course built in collaboration with Cohere and taught by Jay Alammar and Luis Serrano. Search is a key part of many applications. Say, you need to retrieve documents or products in response to a user query. How can LLMs help? You’ll learn about (i) embeddings to retrieve a collection of documents loosely related to a query and (ii) LLM-assisted re-ranking to rank them precisely according to a query. You’ll also go through code that shows how to build a search system for retrieving relevant Wikipedia articles. Please \u003c/em\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003echeck it out\u003c/em\u003e\u003c/a\u003e\u003cem\u003e!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--82-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--82-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--82-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--82-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"gpu-shortage-intensifies\"\u003eGPU Shortage Intensifies\u003c/h1\u003e\u003cp\u003eNvidia’s top-of-the-line chips are in high demand and short supply.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e There aren’t enough H100 graphics processing units (GPUs) to meet the crush of demand brought on by the vogue for generative AI, \u003cem\u003eVentureBeat\u003c/em\u003e \u003ca href=\"https://venturebeat.com/ai/nvidia-gpu-shortage-is-top-gossip-of-silicon-valley/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003ereported\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBottleneck:\u003c/strong\u003e Cloud providers began having \u003ca href=\"https://www.deeplearning.ai/the-batch/generative-ai-demand-is-overwhelming-cloud-servers/?ref=dl-staging-website.ghost.io\"\u003etrouble finding GPUs\u003c/a\u003e earlier this year, but the shortfall has spread to AI companies large and small. SemiAnalysis, a semiconductor market research firm, \u003ca href=\"https://www.semianalysis.com/p/ai-capacity-constraints-cowos-and?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eestimates\u003c/a\u003e that the chip will remain sold out into 2024.\u003c/p\u003e\u003cul\u003e\u003cli\u003eTSMC, which fabricates Nvidia’s designs, can produce only so many H100s. Its high-end \u003ca href=\"https://3dfabric.tsmc.com/english/dedicatedFoundry/technology/cowos.htm?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003echip packaging technology\u003c/a\u003e, which is shared among Nvidia, AMD, and other chip designers, currently has limited capacity. The manufacturer expects to double that capacity by the end of 2024.\u003c/li\u003e\u003cli\u003eNvidia executive Charlie Boyle downplayed the notion of a shortage, saying that cloud providers had presold much of their H100 capacity. As a result, startups that need access to thousands of H100s to train large models and serve a sudden swell of users have few options.\u003c/li\u003e\u003cli\u003eAn individual H100 with memory and high-speed interface originally retailed for around \u003ca href=\"https://www.tomshardware.com/news/nvidia-hopper-h100-80gb-price-revealed?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003e$33,000\u003c/a\u003e. Second-hand units now cost \u003ca href=\"https://www.extremetech.com/computing/nvidias-h100-ai-processors-are-selling-for-over-40000-on-ebay?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003ebetween $40,000 and $51,000\u003c/a\u003e on eBay.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWho’s buying: \u003c/strong\u003eDemand for H100s is hard to quantify. Large AI companies and cloud providers may need tens of thousands to hundreds of thousands of them, while AI startups may need hundreds to thousands.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe blog gpus.llm-utils.org \u003ca href=\"https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eballparked\u003c/a\u003e current demand at around 430,000 H100s, which amounts to roughly $15 billion in sales. The author said the tally is a guess based on projected purchases by major AI companies, AI startups, and cloud providers. It omits Chinese companies and may double-count chips purchased by cloud providers and processing purchased by cloud customers.\u003c/li\u003e\u003cli\u003eChinese tech giants Alibaba, Baidu, ByteDance, and Tencent ordered $5 billion worth of Nvidia chips, the bulk of them to be delivered next year, the \u003ca href=\"https://www.ft.com/content/9dfee156-4870-4ca4-b67d-bb5a285d855c?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003e\u003cem\u003eFinancial Times\u003c/em\u003e\u003c/a\u003e reported.\u003c/li\u003e\u003cli\u003eCoreWeave, a startup cloud computing provider, ordered between 35,000 and 40,000 H100s. It has a close relationship with Nvidia, which \u003ca href=\"https://techcrunch.com/2023/04/20/coreweave-a-gpu-focused-cloud-compute-provider-lands-221m-investment/?guccounter=1\u0026guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8\u0026guce_referrer_sig=AQAAANitwUGBpYDY_iKAWwaVFcRLBkkM-CZWy0LK_uyDcsCpaw-_gnm23dh2ICt7sysU1_BbBzyJ9Tj05d8NNp8blYiiwY4_rzPGlyvPxf2wZ1qjiM1ScfzOGrbD-QIarcQOPaRwBwt4F0vApIOkvhJmLdFC6XRCUREWW8_efahMiqRc\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003einvested\u003c/a\u003e in its recent funding round, and it \u003ca href=\"https://www.reuters.com/technology/coreweave-raises-23-billion-debt-collateralized-by-nvidia-chips-2023-08-03/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003esecured\u003c/a\u003e a $2.3 billion loan — using H100 chips as collateral — to finance construction of data centers that are outfitted to process AI workloads.\u003c/li\u003e\u003cli\u003eMachine learning startup Inflection AI \u003ca href=\"https://inflection.ai/inflection-ai-announces-1-3-billion-of-funding?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eplans\u003c/a\u003e to have 22,000 H100s by December.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Nvidia \u003ca href=\"https://www.deeplearning.ai/the-batch/transformer-accelerator/?ref=dl-staging-website.ghost.io\"\u003eannounced\u003c/a\u003e the H100 early last year and began full production in September. Compared to its predecessor, the A100, the H100 performs about 2.3 times faster in training and 3.5 times faster at inference.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Developers need these top-of-the-line chips to train high-performance models and deploy them in cutting-edge products. At a time when AI is white-hot, a dearth of chips could affect the pace of innovation.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Nvidia’s CUDA software, which undergirds many deep learning software packages, gives the company’s chips a significant advantage. However, AMD’s open source ROCm is making great strides, and its MI250 and upcoming MI300-series chips appear to be promising alternatives. An open software infrastructure that made it easy to choose among GPU providers would benefit the AI community.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--83-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--83-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--83-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--83-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"china%E2%80%99s-llms-open-up\"\u003eChina’s LLMs Open Up\u003c/h1\u003e\u003cp\u003eThe latest wave of large language models trained in Chinese is open source for some users.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Internet giant Alibaba released large language models that are freely available to smaller organizations. The internet giant followed Baichuan Intelligent Technology, a startup that contributed its own partly open models, and Beijing Academy of Artificial Intelligence, which announced that its WuDao 3.0 would be open source.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e These pretrained models are small compared to, say, Meta’s LLaMa 2 (70 billion parameters) — but that may be a plus in China, where U.S. export restrictions have made chips for processing AI hard to get.\u003c/p\u003e\u003cul\u003e\u003cli\u003eAlibaba \u003ca href=\"https://github.com/QwenLM/Qwen-7B?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eoffers\u003c/a\u003e Qwen-7B and Qwen-7B-Chat. The models are freely available to small-scale users, but organizations with more than 100 million monthly active users require a license.\u003c/li\u003e\u003cli\u003eBaichuan Intelligent Technology, a firm owned by Wang Xiaochuan, founder of search engine Sogou (now owned by Tencent), \u003ca href=\"https://github.com/baichuan-inc/Baichuan-13B?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003ereleased\u003c/a\u003e Baichuan-13B and Baichuan-13B-Chat. The models are freely available to academic users. Commercial users require a license.\u003c/li\u003e\u003cli\u003eBeijing Academy of Artificial Intelligence \u003ca href=\"https://spectrum.ieee.org/china-chatgpt-wu-dao?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003erevealed\u003c/a\u003e its open source Wu Dao 3.0 model family to \u003cem\u003eIEEE Spectrum\u003c/em\u003e. The family includes AquilaChat-7B and AquilaChat-33B (both fine-tuned for conversation), AquilaCode (fine-tuned to generate code from natural-language prompts), and Wu Dao Vision (for computer vision tasks). The new models upgrade and slim down the 1.75-trillion-parameter \u003ca href=\"https://www.deeplearning.ai/the-batch/trillions-of-parameters/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eWuDao 2.0\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Developers in China are \u003ca href=\"https://www.deeplearning.ai/the-batch/chinese-tech-companies-race-to-cash-in-on-chatgpt-fever/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eracing\u003c/a\u003e to cash in on chatbot fever. But they face unique hurdles.\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn September, the United States Commerce Department \u003ca href=\"https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003erestricted\u003c/a\u003e the sale of high-performance AI chips including Nvidia A100 and H100 GPUs in China. Some Chinese customers have \u003ca href=\"https://www.deeplearning.ai/the-batch/loopholes-help-chinese-companies-get-us-chips/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003efound\u003c/a\u003e loopholes, but demand continues to outstrip supply.\u003c/li\u003e\u003cli\u003eLanguage models and their output are restricted by law. Interim rules set to take effect on August 15 \u003ca href=\"https://www.reuters.com/technology/china-issues-temporary-rules-generative-ai-services-2023-07-13/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003erequire\u003c/a\u003e government approval for generative AI products before they’re released to the public. Developers have \u003ca href=\"https://www.theatlantic.com/international/archive/2023/04/chatbot-ai-problem-china/673754/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003elimited\u003c/a\u003e recent chatbots to comply with restrictions on internet content.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e The March leak of Meta’s \u003ca href=\"https://www.deeplearning.ai/the-batch/how-metas-llama-nlp-model-leaked/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eLLaMA\u003c/a\u003e initiated a groundswell of open models that excel in English and a subsequent explosion of innovation and entrepreneurial activity. Competitive open models trained in Mandarin and other Chinese languages could spark similar developments in one of the world’s biggest countries — as long as developers hew to the law.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e High-profile models like ChatGPT and Bard, having been trained on huge amounts of English-language data, tend to know a lot about the histories, geographies, and societies of English-speaking countries but relatively little about places where other languages are spoken. Models trained on Chinese corpora will serve speakers of China’s languages far better, and open source models fine-tuned for Chinese users likely will play an important role.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM \u003cstrong\u003eDEEPLEARNING.AI\u003c/strong\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/large-language-models-semantic-search?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--48-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/The-Batch-ads-and-exclusive-banners--48-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/The-Batch-ads-and-exclusive-banners--48-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/08/The-Batch-ads-and-exclusive-banners--48-.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--48-.png 1680w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eJoin our new course, “Large Language Models with Semantic Search,” and learn the techniques you need to integrate LLMs with search and how to use your website’s information to generate responses. \u003ca href=\"https://www.deeplearning.ai/short-courses/large-language-models-semantic-search?ref=dl-staging-website.ghost.io\"\u003eEnroll for free\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--4-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"672\" height=\"378\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/The-Batch-ads-and-exclusive-banners--4-.gif 600w, https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--4-.gif 672w\"\u003e\u003c/figure\u003e\u003ch1 id=\"chatgpt%E2%80%99s-best-friend\"\u003eChatGPT’s Best Friend\u003c/h1\u003e\u003cp\u003eThe latest robot dog is smarter — and less expensive — than ever.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Unitree Robotics of Hangzhou, China, \u003ca href=\"https://www.unitree.com/en/go2/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eunleashed\u003c/a\u003e Go2, a quadruped robot that trots alongside its owner, stands on two legs, jumps, talks, takes photos, and retails for less than a high-end MacBook.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works: \u003c/strong\u003eGo2 is made of aluminum and plastic, weighs around 15 kilograms, and moves using 12 joints. A robotic arm mounted on the unit’s back is optional. It comes in three versions with a starting price of $1,600.\u003c/p\u003e\u003cul\u003e\u003cli\u003eAll three models include a 360-degree LIDAR sensor and object detection and avoidance capability. They can connect to other devices using either Wi-Fi or Bluetooth and take pictures with a front-facing camera.\u003c/li\u003e\u003cli\u003eThe Go2 Pro, priced at $2,800, contains an eight-core CPU and foot-end force sensors that enable it to navigate autonomously at around 3.5 meters per second. It can communicate via 4G cellular as well as converse and follow plain-language verbal commands using an unspecified “GPT” language model.\u003c/li\u003e\u003cli\u003eThe Go2 Edu, the price of which is not listed, adds an Nvidia \u003ca href=\"https://www.nvidia.com/en-gb/autonomous-machines/embedded-systems/jetson-orin/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eJetson Orin\u003c/a\u003e computer and a more powerful, faster-charging battery.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Boston Dynamics’ industrial-strength robodog Spot is \u003ca href=\"https://www.therobotreport.com/ontario-power-generation-tests-boston-dynamics-spot-to-save-lives/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003emanipulating\u003c/a\u003e high-voltage electrical equipment, \u003ca href=\"https://www.csrwire.com/press_releases/744021-spot-robot-dog-helps-humans-inspect-nuclear-power-plant?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003einspecting\u003c/a\u003e nuclear power plants, and \u003ca href=\"https://www.theverge.com/2023/4/11/23679297/nypd-robot-dog-spot-surveillance-boston-dynamics?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003ehelping\u003c/a\u003e to monitor urban areas. But its price — from \u003ca href=\"https://spectrum.ieee.org/boston-dynamics-spot-robot-dog-now-available?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003e$74,500\u003c/a\u003e to \u003ca href=\"https://www.thestack.technology/how-much-does-boston-dynamics-spot-cost-uk/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003e$200,000\u003c/a\u003e — puts it out of reach of many potential users. With its dramatically lower price, Go2 suggests that such mechanical beasts may find a wider range of uses.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e While wheels are great on flat ground, four legs with backward-facing joints are more \u003ca href=\"https://transmitter.ieee.org/why-do-so-many-robots-look-like-dogs/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003estable\u003c/a\u003e on uneven terrain. Plus, robot dogs are cute!\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--84-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--84-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"llms-get-a-life\"\u003eLLMs Get a Life\u003c/h1\u003e\u003cp\u003eLarge language models increasingly reply to prompts with a believably human response. Can they also mimic human behavior?\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat's new:\u003c/strong\u003e Joon Sung Park and colleagues at Stanford and Google extended GPT-3.5 to build \u003ca href=\"https://arxiv.org/abs/2304.03442?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003egenerative agents\u003c/a\u003e that went about their business in a small town and interacted with one another in human-like ways. The code is newly \u003ca href=\"https://github.com/joonspk-research/generative_agents?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eavailable\u003c/a\u003e as open source.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight: \u003c/strong\u003eWith the right prompts, a text database, and a server to keep track of things, a large language model (LLM) can simulate human activity.\u003c/p\u003e\u003cul\u003e\u003cli\u003eJust as people observe the world, an LLM can describe its experiences. Observations can be stored and retrieved to function like memories.\u003c/li\u003e\u003cli\u003eJust as people consolidate memories, an LLM can summarize them as reflections for later use.\u003c/li\u003e\u003cli\u003eTo behave in a coherent way, an LLM can generate a plan and revise it as events unfold.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e The authors designed 25 agents (represented by 2D sprites) who lived in a simulated town (a 2D background depicting the layout and the contents of its buildings) and let them run for two days. Each agent used \u003ca href=\"https://arxiv.org/abs/2005.14165?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eGPT 3.5;\u003c/a\u003e a database of actions, memories, reflections, and plans generated by GPT 3.5; and a server that tracked agent and object behaviors, locations (for instance, in the kitchen of Isabella’s apartment), and statuses (whether a stove was on or off), and relayed this information to agents when they came nearby.\u003c/p\u003e\u003cul\u003e\u003cli\u003eAt each time step, the server gave each agent an observation that comprised what it last said it was doing, the objects and people in view, and their statuses.\u003c/li\u003e\u003cli\u003eGiven an observation, an agent retrieved a memory based on recency, relevance, and importance. It measured relevance according to cosine similarity between embeddings of the observation and the memory. It rated importance by asking GPT-3.5 to score memories on a scale from “mundane” (1) to “poignant” (10). Having retrieved the memory, the agent generated text that described its action, upon which the server updated the appropriate locations and statuses.\u003c/li\u003e\u003cli\u003eThe reflection function consolidated the latest 100 memories a couple of times a day. Given 100 recent memories (say, what agent Klaus Mueller looked up at the library), the agent proposed 3 high-level questions that its memories could provide answers to (for instance, “What topic is Klaus Mueller passionate about?”). For each question, the agent retrieved relevant memories and generated five high-level insights (such as, “Klaus Mueller is dedicated to his research on gentrification”). Then it stored these insights in the memory.\u003c/li\u003e\u003cli\u003eGiven general information about its identity and a summary of memories from the previous day, the agent generated a plan for the current day. Then it decomposed the plan into chunks an hour long, and finally into chunks that are minutes long (“4:00 p.m.: grab a light snack, such as a piece of fruit, a granola bar, or some nuts. 4:05 p.m.: …”. The detailed plans went into the memory.\u003c/li\u003e\u003cli\u003eAt each time step, the agent asked itself whether and how it should react to its observation given general information about its identity, its plan, and a summary of relevant memories. If it should react, the agent updated its plan and output a statement that describes its reactions. Otherwise, the agent generated a statement saying it would continue the existing plan. For example, a father might observe another agent and, based on a memory, identify it as his son who is currently working on a project. Then the father might decide to ask the son how the project is going.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e The complete agents exhibited three types of emergent behavior: They spread information initially known only to themselves, formed relationships, and cooperated (specifically to attend a party). The authors gave 100 human evaluators access to all agent actions and memories. The evaluators asked the agents simple questions about their identities, behaviors, and thoughts. Then they ranked the agents’ responses for believability. They also ranked versions of each agent that were missing one or more functions, as well as humans who stood in for each agent (“to identify whether the architecture passes a basic level of behavioral competency,” the authors write). These rankings were turned into a \u003ca href=\"https://www.microsoft.com/en-us/research/publication/trueskilltm-a-bayesian-skill-rating-system/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eTrueSkill\u003c/a\u003e score (a variation on the Elo system used in chess) for each agent type. The complete agent architecture scored highest, while the versions that lacked particular functions scored lower. Surprisingly, the human stand-ins also underperformed the complete agents.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYes, but:\u003c/strong\u003e Some complete agents “remembered” details they had not experienced. Others showed erratic behavior, like not recognizing that a one-person bathroom was occupied or that a business was closed. And they used oddly formal language in intimate conversation; one ended exchanges with her husband, “It was good talking to you as always.”\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Large language models produce surprisingly human-like output. Combined with a database and server, they can begin to simulate human interactions. While the TrueSkill results don’t fully convey how humanly these agents behaved, they do suggest a role for such agents in fields like game development, social media, robotics, and \u003ca href=\"https://arxiv.org/abs/2307.04986?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eepidemiology\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe're thinking:\u003c/strong\u003e The evaluators found the human stand-ins less believable than the full-fledged agents. Did the agents exceed human-level performance in the task of acting human, or does this result reflect a limitation of the evaluation method?\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai-1\"\u003eA MESSAGE FROM \u003cstrong\u003eDEEPLEARNING.AI\u003c/strong\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.eventbrite.com/e/efficient-fine-tuning-for-llama-7b-on-a-single-gpu-tickets-696331224437?aff=Batch\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--50-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/The-Batch-ads-and-exclusive-banners--50-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/The-Batch-ads-and-exclusive-banners--50-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/08/The-Batch-ads-and-exclusive-banners--50-.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/08/The-Batch-ads-and-exclusive-banners--50-.png 1680w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eJoin our upcoming workshop with Predibase and learn how to use open source tools to overcome challenges like the “host out of memory” error when fine-tuning models like Llama-2. \u003ca href=\"https://www.eventbrite.com/e/efficient-fine-tuning-for-llama-7b-on-a-single-gpu-tickets-696331224437?aff=Batch\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-_LukDvWZAbjr5nKga1lbAKisZXwdC2e0z9eseogyJ-byP93S1HrLuzOSUWOQjEes0tXV67\" rel=\"noopener\"\u003eRegister now\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003ch1 id=\"data-points\"\u003eData Points\u003c/h1\u003e\u003cp\u003e\u003cstrong\u003ePublisher surprised to find it published AI-generated art\u003c/strong\u003e\u003cbr\u003eWizards of the Coast, the publisher of Dungeons \u0026amp; Dragons guidebooks and stories, admitted the use of AI-generated artwork in a digital book. The company, which claimed to have been unaware that it had published generated content prior to the book’s release, said it would update its policies to prevent AI art from being included in future publications. (\u003ca href=\"https://www.polygon.com/23823516/dnd-dungeons-dragons-wizards-ai-art-controversy-bigby-presents-glory-of-the-giants?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003ePolygon\u003c/em\u003e\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eBrookings shows the uneven geography of AI activity in the U.S.\u003c/strong\u003e\u003cbr\u003eA report from Brookings Institute highlights the concentration of AI activity in tech-focused cities like San Francisco, New York, and Seattle. It proposes policy actions at federal, state, and local levels to promote more widespread AI development. (\u003ca href=\"https://www.brookings.edu/articles/building-ai-cities-how-to-spread-the-benefits-of-an-emerging-technology-across-more-of-america/?ref=dl-staging-website.ghost.io\"\u003eBrookings\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eAI and robotics make recycling more efficient\u003c/strong\u003e\u003cbr\u003eCompanies such as EverestLabs and AMP Robotics are using AI to streamline the recycling process. Their robotic arms identify recyclable items to boost object recovery rates by up to three times compared to human efforts. (\u003ca href=\"https://www.cnbc.com/2023/08/08/everestlabs-using-robotic-arms-and-ai-to-make-recycling-more-efficient.html?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eCNBC\u003c/em\u003e\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003ca href=\"https://arxiv.org/pdf/2308.01074.pdf?ref=dl-staging-website.ghost.io\"\u003eResearch:\u003c/a\u003e\u003cstrong\u003e A deep learning model recognizes laptop keystrokes by sound\u003c/strong\u003e\u003cbr\u003eResearchers trained a model to analyze sound profiles of laptop keystrokes. They achieved 93 percent accuracy when interpreting individual key sounds in Zoom audio recordings. This approach raises security concerns, especially for laptops used in public settings. (\u003ca href=\"https://arstechnica.com/gadgets/2023/08/type-softly-researchers-can-guess-keystrokes-by-sound-with-93-accuracy/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eArs Technica\u003c/em\u003e\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eCommercialized deepfakes raise questions about control and misuse\u003c/strong\u003e\u003cbr\u003eSynthesia touts its AI avatars, which look like video recordings of people,  to enhance corporate presentations and training sessions. However, the photorealistic avatars have been put to use by scammers and propagandists (\u003ca href=\"https://www.wired.com/story/synthesia-ai-deepfakes-it-control-riparbelli/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eWired\u003c/em\u003e\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eTech giants rally behind AI in resurgent quarter\u003c/strong\u003e\u003cbr\u003eAI helped companies like Google, Meta, and Microsoft rebound from a financial slump in the most recent quarter. Now they’re doubling down on AI to revitalize their product lines and fuel innovation. Some are already benefiting from the AI fever. (\u003ca href=\"https://www.nytimes.com/2023/08/05/technology/tech-nvidia-chips.html?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eThe New York Times\u003c/em\u003e\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eDisney forms AI task force\u003c/strong\u003e\u003cbr\u003eThe Walt Disney Company established a dedicated group to explore the applications of AI across its entertainment empire. The initiative aims to develop in-house solutions and forge partnerships that can drive innovation and cut costs. (\u003ca href=\"https://www.reuters.com/technology/disney-creates-task-force-explore-ai-cut-costs-sources-2023-08-08/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eReuters\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eGoogle and Universal Music explore licensing for AI-generated music\u003c/strong\u003e\u003cbr\u003eAlphabet's Google is in early discussions with Universal Music  over licenses to use artists' voices and melodies in AI-generated songs. The companies aim to develop technology that would  enable  fans to make their own sound-alike productions while compensating copyright owners. (\u003ca href=\"https://www.reuters.com/technology/google-universal-music-talks-deal-ai-deepfakes-ft-2023-08-08/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eReuters\u003c/em\u003e\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eReport highlights AI's role in promoting eating disorders\u003c/strong\u003e\u003cbr\u003eA study conducted by the Center for Countering Digital Hate (CCDH) found that ChatGPT and Stable Diffusion produced harmful output around 41 percent of the time when tested with prompts related to eating disorders. Experts emphasize the need to ensure that AI-generated content doesn't promote unhealthy body-image ideals or provide dangerous advice to users who may suffer from eating disorders. (\u003ca href=\"https://www.washingtonpost.com/technology/2023/08/07/ai-eating-disorders-thinspo-anorexia-bulimia/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eThe Washington Post\u003c/em\u003e\u003c/a\u003e and \u003ca href=\"https://counterhate.com/wp-content/uploads/2023/08/230705-AI-and-Eating-Disorders-REPORT.pdf?ref=dl-staging-website.ghost.io\"\u003eCCDH\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eZoom promises not totrain its AI systems on customer data\u003c/strong\u003e\u003cbr\u003eThe video conferencing platform added a line to its terms of service stating that it will not employ customer audio, video, or chat content for training AI models without consent. The company updated its terms after users discovered language that granted the right to use customer data to build AI systems. In July, Zoom had revised its terms to broaden its access to customer data in developing AI products and services. (\u003ca href=\"https://www.washingtonpost.com/politics/2023/08/08/zooms-privacy-tweaks-stoke-fears-that-its-calls-will-be-used-train-ai/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eThe Washington Post\u003c/em\u003e\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eStack Overflow adapts to survive in the age of LLMs\u003c/strong\u003e\u003cbr\u003eThe longstanding community for developers faces a decline in traffic as AI models increasingly answer technical questions. Some language models, partly trained on Stack Overflow's data, compete with Stack Overflow directly. The company plans to develop its own question-answering models and charge AI companies to use its data. (\u003ca href=\"https://www.businessinsider.com/stack-overflow-crisis-future-of-online-data-ai-world-2023-7?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eBusiness Insider\u003c/em\u003e\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eGoogle's AI seeks to continue training AI on published content\u003c/strong\u003e\u003cbr\u003eGoogle submitted a proposal to the Australian government suggesting that generative AI systems should be allowed to use publishers' content to train AI systems while providing an opt-out for those that want to keep their content out of training datasets. Google's position sparked discussions about content creators' rights. (\u003ca href=\"https://www.theguardian.com/technology/2023/aug/09/google-says-ai-systems-should-be-able-to-mine-publishers-work-unless-companies-opt-out?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eThe Guardian\u003c/em\u003e\u003c/a\u003e)\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eOpenAI allows content providers to opt out of its training datasets\u003c/strong\u003e\u003cbr\u003eGPTBot, a web crawler that collects online data used by OpenAI to train its models, offers website operators the ability to opt out. The crawler will not scrape data from sites that exercise the option.(\u003ca href=\"https://www.theverge.com/2023/8/7/23823046/openai-data-scrape-block-ai?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003eThe Verge\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e","comment_id":"64dd03ecc0c40400019551b7","feature_image":"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--45-.png","featured":false,"visibility":"public","created_at":"2023-08-16T10:14:20.000-07:00","updated_at":"2024-02-06T10:04:52.000-08:00","published_at":"2023-08-17T06:55:43.000-07:00","custom_excerpt":"The Batch - AI News \u0026 Insights: An increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models with relatively permissive licenses gives developers more options for building applications.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"64dd04a5c0c40400019551d4","name":"issue-210","slug":"issue-210","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-210/"},{"id":"64dd04a5c0c40400019551d5","name":"Aug 16, 2023","slug":"aug-16-2023","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/aug-16-2023/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-210/","excerpt":"The Batch - AI News \u0026 Insights: An increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models with relatively permissive licenses gives developers more options for building applications.","reading_time":15,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"GPU Shortage, Affordable Robodog, Humanizing Large Language Models, and more","meta_description":"The Batch - AI News \u0026 Insights: An increasing variety of large language models (LLMs) are open source, or close to it. The proliferation of models...","email_subject":null,"frontmatter":null,"feature_image_alt":"Two coworkers interacting: - I prompted it to play Mozart. - Try Fine-Tuning!","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--45-.png","dimensions":{"width":1200,"height":675}},"banner":{"title":"BreakIntoAI with Machine Learning Specialization","databaseId":28989,"id":"cG9zdDoyODk4OQ==","featuredImage":{"node":{"altText":"Become an AI professional with one of the world's most popular Machine Learning courses. #BreakIntoAI with Machine Learning Specialization","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/4.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/courses/machine-learning-specialization/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-210"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>