<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Text to 3D Animation, China Restricts Face Recognition, and more</title><meta name="description" content="The Batch - AI News &amp; Insights: I’d like to share a part of the origin story of large language models that isn’t widely known. A lot of early work..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-212/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Text to 3D Animation, China Restricts Face Recognition, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: I’d like to share a part of the origin story of large language models that isn’t widely known. A lot of early work..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Text to 3D Animation, China Restricts Face Recognition, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-212/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2023-08-30T12:24:30.000-07:00"/><meta property="article:modified_time" content="2023-08-30T12:24:30.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-212"/><meta property="article:tag" content="Aug 30, 2023"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Text to 3D Animation, China Restricts Face Recognition, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: I’d like to share a part of the origin story of large language models that isn’t widely known. A lot of early work..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-212/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--49-.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--49-.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="675"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2023-08-30T12:24:30.000-07:00","dateModified":"2023-08-30T12:24:30.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Text to 3D Animation, China Restricts Face Recognition, and more","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--49-.png","width":1200,"height":675},"publisher":{"@type":"Organization","name":"Text to 3D Animation, China Restricts Face Recognition, and more","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: I’d like to share a part of the origin story of large language models that isn’t widely known. A lot of early work..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-212/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 212</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Aug 30, 2023</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">11<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/aug-30-2023/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Aug 30, 2023</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">11<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-212/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-212/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-212/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,</em></p><p><em>I’d like to share a part of the origin story of large language models that isn’t widely known. A lot of early work in natural language processing (NLP) was funded by U.S. military intelligence agencies that needed machine translation and speech recognition capabilities. Then, as now, such agencies analyzed large volumes of text and recorded speech in various languages. They poured money into research in machine translation and speech recognition over decades, which motivated researchers to give these applications disproportionate attention relative to other uses of NLP.</em><br><br><em>This explains why many important technical breakthroughs in NLP stem from studying translation — more than you might imagine based on the modest role that translation plays in current applications. For instance, the celebrated transformer paper, “<a href="https://arxiv.org/abs/1706.03762?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">Attention is All You Need</a>” by the Google Brain team, introduced a technique for mapping a sentence in one language to a translation in another. This laid the foundation for large language models (LLMs) like ChatGPT, which map a prompt to a generated response.</em></p><p><em>Or consider the <a href="https://www.coursera.org/lecture/nlp-sequence-models/bleu-score-(optional)-kC2HD?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">BLEU score</a>, which is occasionally still used to evaluate LLMs by comparing their outputs to ground-truth examples. It was developed in 2002 to measure how well a machine-generated translation compares to a ground truth, human-created translation.</em></p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--49--1.png" class="kg-image" alt loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--49--1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--49--1.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--49--1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><em>A key component of LLMs is tokenization, the process of breaking raw input text into sub-word components that become the tokens to be processed. For example, the first part of the previous sentence may be divided into tokens like this:</em></p><p><em>/A /key /component /of /LL/Ms/ is/ token/ization</em></p><p><em>The most widely used tokenization algorithm for text today is Byte Pair Encoding (BPE), which gained popularity in NLP after a 2015 <a href="https://arxiv.org/abs/1508.07909?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">paper</a> by Sennrich et al. BPE starts with individual characters as tokens and repeatedly merges tokens that occur together frequently. Eventually, entire words as well as common sub-words become tokens. How did this technique come about? The authors wanted to build a model that could translate words that weren’t represented in the training data. They found that splitting words into sub-words created an input representation that enabled the model, if it had seen “token” and “ization,” to guess the meaning of a word it might not have seen before, such as “tokenization.”</em></p><p><em>I don’t intend this description of NLP history as advocacy for military-funded research. (I have accepted military funding, too. Some of my early work in deep learning at Stanford University was funded by DARPA, a U.S. defense research agency. This led directly to my starting Google Brain.) War is a horribly ugly business, and I would like there to be much less of it. Still, I find it striking that basic research in one area can lead to broadly beneficial developments in others. In similar ways, research into space travel led to LED lights and solar panels, experiments in particle physics led to magnetic resonance imaging, and studies of bacteria’s defenses against viruses led to the CRISPR gene-editing technology.</em></p><p><em>So it’s especially exciting to see so much basic research going on in so many different areas of AI. Who knows, a few years hence, what today’s experiments will yield?</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. Built in collaboration with Microsoft, our short course “How Business Thinkers Can Start Building AI Plugins With Semantic Kernel” is now available! This is taught by John Maeda, VP of Design and AI (who also co-invented the Scratch programming language!). You’ll join John in building his “AI Kitchen” and learn to cook up a full AI meal from, well, scratch – including all the steps to build full business-thinking AI pipelines. You’ll conclude by creating an AI planner that can automatically select plugins it needs to produce multi-step plans with sophisticated logic.</em> <em><a href="https://www.deeplearning.ai/short-courses/microsoft-semantic-kernel?ref=dl-staging-website.ghost.io">Sign up to learn here</a>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--89-.gif" class="kg-image" alt loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--89-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--89-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--89-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="industrial-strength-llm">Industrial-Strength LLM</h1><p>Anthropic, the startup behind the safety-focused Claude chatbot, teamed up with South Korea’s largest mobile phone provider.</p><p><strong>What’s new: </strong>The independent research lab, which is an offshoot of OpenAI, will receive $100 million from SK Telecom to build a multilingual large language model tailored for the telecommunications industry, <em>VentureBeat</em> <a href="https://venturebeat.com/ai/ai-startup-anthropic-gets-100m-to-build-custom-llm-for-telecom-industry/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">reported</a>.</p><p><strong>How it works:</strong> Anthropic will base the specialized model on the technology that underpins its large language model <a href="https://claude.ai/login?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">Claude</a>. SK Telecom plans to offer it to other telecoms firms, such as members of the <a href="https://www.prnewswire.com/news-releases/sk-telecom-deutsche-telekom-e-and-singtel-form-global-telco-ai-alliance-for-collaboration-and-innovation-in-ai-301887205.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">Global Telco AI Alliance</a>, a consortium devoted to building new lines of business based on AI-driven services.</p><ul><li>The model will be fine-tuned for telecoms applications like customer service, marketing, and sales.</li><li>It will support six languages: Korean, English, German, Japanese, Arabic, and Spanish.</li><li>Claude takes advantage of <a href="https://arxiv.org/pdf/2212.08073.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">constitutional AI</a>, a method designed to align large language models and human values based on a set of principles, or constitution. Initially, the model critiques and refines its own responses according to the constitution. Then it’s fine-tuned on the results via supervised learning. This is followed by a phase that Anthropic calls reinforcement learning from AI feedback, or RLAIF.</li></ul><p><strong>Behind the news:</strong> SK Telecom has a history of building its own machine learning models, particularly Korean-language models. The company emulated GPT-3's architecture to train models like <a href="https://huggingface.co/skt/ko-gpt-trinity-1.2B-v0.5?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">Ko-GPT-Trinity-1.2B</a>. An unidentified model <a href="https://www.koreaherald.com/view.php?ud=20220516000723&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">enables</a> A. (pronounced “a dot”), a virtual assistant for the company’s mobile users.</p><p><strong>Why it matters:</strong> AI models have a bright future in virtually every industry, and specialized AI models have an even brighter outlook. Like <a href="https://arxiv.org/abs/2303.17564?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">BloombergGPT</a>, this partnership represents a step toward adapting foundation models to a vertical industry, along with a new business model for good measure.<br><br><strong>We’re thinking:</strong> Prompting a foundation model can go a long way in tasks for which it’s easy to write instructions that describe clearly what you want done. But many tasks involve specialized knowledge that’s difficult to put into a prompt; for instance, consider explaining how to draft a good legal document. In such cases, fine-tuning or specialized training can be a promising approach.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--47-.png" class="kg-image" alt loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--47-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--47-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--47-.png 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="china-restricts-face-recognition">China Restricts Face Recognition</h1><p>China’s internet watchdog proposed sweeping limitations on face recognition — with significant exceptions.</p><p><strong>What’s new:</strong> The Cyberspace Administration of China <a href="http://www.cac.gov.cn/2023-08/08/c_1693064670537413.htm?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">unveiled</a> draft rules that restrict the use of face recognition systems, with explicit carve-outs when national security or public or personal safety is at stake. The public can submit feedback before September 7.</p><p><strong>Narrow limits, broad exceptions:</strong> The proposal, which will affect mainland China but not Macau or Hong Kong, applies to both public and private users of face recognition. It follows recent restrictions on <a href="https://www.deeplearning.ai/the-batch/chinas-new-law-limits-ai-generated-media/?ref=dl-staging-website.ghost.io">generative AI</a> and <a href="https://techcrunch.com/2021/08/20/china-passes-data-protection-law/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">collecting personal data</a>.</p><ul><li>Face recognition can’t be used to analyze race, ethnicity, religion, health status, or social class except to protect national security or public or personal safety.</li><li>It can’t be used to identify people in public places at a distance except to protect national security or public or personal safety.</li><li>Face recognition is allowed for verifying identity only if other methods aren't available.</li><li>It isn’t allowed in locations where it may infringe on personal privacy, such as hotel rooms or toilets.</li><li>Users can’t coerce or mislead the public into providing face data with excuses such as “improving service quality.”</li><li>Institutions that use face recognition in public locations or store images of more than 10,000 faces must register their use and data-handling procedure with the government.</li><li>Before gathering face data, users must obtain the subject’s permission, or a parent’s or guardian’s if the subject is less than 14 years old.</li></ul><p><strong>Behind the news:</strong> China <a href="https://www.wired.com/story/china-is-the-worlds-biggest-face-recognition-dealer/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">leads</a> the world in developing and deploying face recognition. Authorities use it widely in law enforcement, while businesses use it for authenticating payments, checking the identities of air and rail passengers, and granting access to residential buildings. Nonetheless, many Chinese residents have voiced their unease with the technology.</p><ul><li>In 2021, a Chinese appeals court <a href="https://www.washingtonpost.com/world/facial-recognition-china-tech-data/2021/07/30/404c2e96-f049-11eb-81b2-9b7061a582d8_story.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">ruled</a> in favor of a law professor who sued a Hangzhou zoo. The plaintiff claimed that the zoo’s use of face recognition to verify its visitors’ identities was unnecessary.</li><li>74 percent of Chinese residents surveyed favored alternatives to face recognition for verifying identity, according to a 2019 <a href="https://www.ft.com/content/7c32c7a8-172e-11ea-9ee4-11f260415385?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">survey</a> conducted by Beijing’s Nandu Personal Information Protection Research Centre. 80 percent of respondents were concerned about data security, and 84 percent wanted the option to review face-recognition data that represented them.</li></ul><p><strong>Yes, but:</strong> The exemptions for national security and safety give China’s government authority to continue using the technology for potentially <a href="https://www.theguardian.com/world/2022/jan/06/china-sensetime-facial-recognition-uyghur-surveillance-us-sanctions?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">controversial</a> applications.</p><p><strong>Why it matters:</strong> Face recognition is a double-edged sword. It has legitimate uses for security and law enforcement, but it can also be misused to violate privacy. Such concerns <a href="https://www.politico.eu/article/meps-adopt-ai-act-text-in-committees/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">motivated</a> European Union lawmakers to insert a prohibition on face recognition in public spaces into the current draft of the union’s AI Act, which is in the final stage of revision. China’s new rules bring that country’s face recognition policy closer into line with that standard — the exceptions for national security and public safety notwithstanding.<br><br><strong>We’re thinking:</strong> It’s interesting to see China take the lead in regulating face recognition, where it dominates the technology and market. We support stronger protections for personal privacy.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM <strong>DEEPLEARNING.AI</strong></h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/microsoft-semantic-kernel?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png" class="kg-image" alt loading="lazy" width="2000" height="1043" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png 2070w" sizes="(min-width: 720px) 720px"></a></figure><p>Learn how to utilize Semantic Kernel, Microsoft’s open source SDK, to develop sophisticated business applications using LLMs. <a href="https://www.deeplearning.ai/short-courses/microsoft-semantic-kernel?ref=dl-staging-website.ghost.io">Sign up for free</a></p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--48-.png" class="kg-image" alt loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--48-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--48-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--48-.png 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="crash-tracker">Crash Tracker</h1><p>Event data recorders, also known as black boxes, got an update for the era of self-driving cars.</p><p><strong>What’s new: </strong>The Institute of Electrical and Electronics Engineers <a href="https://standards.ieee.org/ieee/1616.1/10939/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">published</a> guidelines for internal devices that track the performance of autonomous road vehicles.</p><p><strong>How it works:</strong> Like airplanes, cars and trucks carry event data recorders that capture their moment-to-moment behavior for examination in the event of a crash. The new specification calls for vehicles with <a href="https://www.sae.org/blog/sae-j3016-update?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">Level 3</a> autonomous capabilities or higher, which can drive themselves but may require a human driver to take over, to carry a recorder dedicated to automated driving functions. The working group will meet later this year to discuss further revisions that address subjects like cybersecurity and protocols accessing recorded data.</p><ul><li>The autonomous-driving recorder logs when a vehicle’s self-driving function is activated or deactivated, when the driver’s action overrides it (for instance, by manually braking or turning the wheel), or when it overrides a driver’s action.</li><li>The recorder also logs when the vehicle fails to stay in its lane, starts or ends an emergency maneuver, suffers a major malfunction, or collides with another object.</li><li>The minimum log entry includes an event, the event’s cause, and its date and timestamp to the second.</li><li>A tamper-resistant electronic lock restricts access to recorded data.</li></ul><p><strong>Behind the news:</strong> Event data recorders became a fixture in road vehicles decades ago as a way to evaluate the performance of safety airbags. Today, they record parameters such as speed, acceleration, and braking in 99 percent of new vehicles in the United States. They’ll be <a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12989-Vehicle-safety-technical-requirements-%26-test-procedures-for-EU-type-approval-of-event-data-recorders-EDRs-_en?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">mandatory</a> in new cars in the European Union starting next year.</p><p><strong>Why it matters:</strong> As more automated driving systems hit the road, safety concerns are on the rise. Event data recorders help shed light on mishaps, and the resulting data can help authorities, manufacturers, and consumers to understand the role, if any, played by self-driving technology. Although compliance is voluntary, IEEE standards are influential and widely followed.</p><p><strong>We’re thinking:</strong> Self-driving systems have the potential to reduce road and pedestrian fatalities dramatically. A clear picture of what goes wrong and why will enable engineers to improve self-driving technology steadily. Ultimately, we hope, accidents will become rare and relatively inconsequential.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--90-.gif" class="kg-image" alt loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--90-.gif 600w"></figure><h1 id="text-to-3d-animation">Text-To-3D Animation</h1><p>Text-to-video generation is so 2022! A new system takes in text and generates an animated 3D scene that can be viewed or rendered from any angle.</p><p><strong>What’s new:</strong> Uriel Singer and colleagues at Meta AI proposed <a href="https://arxiv.org/abs/2301.11280?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">Make-A-Video3D</a> (MAV3D). Lacking a corpus of matched text and animated 3D scenes, the authors used a pretrained text-to-video diffusion model to guide the training of a neural radiance field (NeRF) model that learned how to represent a 3D scene with moving elements. You can see MAV3D’s output <a href="https://make-a-video3d.github.io/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">here</a>.</p><p><strong>Key insight:</strong> Earlier work known as <a href="https://www.deeplearning.ai/the-batch/how-dreamfusion-generates-3d-images-from-text/?ref=dl-staging-website.ghost.io">DreamFusion</a> learned to produce a 3D scene from text by setting up a feedback loop between a pretrained diffusion text-to-image generator, which creates 2D images according to a text prompt, and a NeRF, which takes embeddings of points in space and learns to produce a 3D scene (mesh, point colors, and point transparencies) to match the 2D images shot from various angles. (NeRF can also generate images of the scene.) Basically, (i) the NeRF generated 2D images of a random 3D scene; (ii) the images — with added noise — were given as input to the diffusion text-to-image generator, which sharpened them according to the text prompt; and (iii) the NeRF used the sharpened images to sharpen the 3D scene, repeating the cycle. MAV3D worked the same way but (a) used a more computationally efficient embedding method called HexPlane, (b) swapped the pretrained text-to-image generator for a pretrained text-to-video generator, and (c) modified the NeRF to generate sequences of video frames. The resulting system takes a text prompt and learns to generate a matching 3D scene that changes over time.</p><p><strong>How it works:</strong> MAV3D is an animated version of the earlier DreamFusion, as described above. It includes the following models: <a href="https://arxiv.org/abs/2301.09632?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">HexPlane</a> (which efficiently represents an animated 3D scene), <a href="https://arxiv.org/abs/2209.14792?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">Make-A-Video</a> (a text-to-video generator pretrained on LAION-5B text/image pairs and fine-tuned on 20 million videos), and a <a href="https://arxiv.org/abs/2003.08934?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">NeRF</a> modified for video/animation.</p><ul><li>HexPlane learned an embedding for each point on each 2D plane in an animated 3D scene (xy, xz, xt, yz, yt, and zt) over 16 video frames. Given a point (three spatial dimensions plus time), the model projected it onto each plane, retrieved the corresponding embeddings, and concatenated them to produce a point embedding.</li><li>Given the embeddings and a random camera position per frame, NeRF produced a video.</li><li>The system added noise to the NeRF video and fed it to Make-A-Video. Given a text prompt, Make-A-Video estimated what the video would look like without the noise.</li><li>The loss function minimized the difference between the NeRF video and Make-A-Video’s denoised version to update HexPlane and NeRF.</li><li>The system cycled through this process 12,000 times using a different random camera trajectory each time, which enabled it to evaluate every point from multiple angles.</li><li>The authors extracted from NeRF a 64-frame animated 3D scene using the <a href="https://dl.acm.org/doi/10.1145/37402.37422?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv">marching cubes</a> algorithm.</li></ul><p><strong>Results:</strong> No other system generates animated 3D scenes from text, so the authors compared MAV3D with systems that solve two sub-tasks, generating 3D static scenes from text and generating videos from text. They used <a href="https://openreview.net/forum?id=bKBhQhPeKaF&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">CLIP R-Precision</a>, a metric that evaluates the similarity between an image and a text description (higher is better), to measure the systems’ performance averaged across a number of images taken from different angles (for 3D scenes) or images over time (for videos). MAV3D outperformed a <a href="https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">Stable Diffusion</a> implementation of DreamFusion (82.4 CLIP R-Precision versus 66.1 CLIP R-Precision). However, it did worse than Make-A-Video (79.2 CLIP R-Precision versus 86.6 CLIP R-Precision).</p><p><strong>Yes, but:</strong> Examples of MAV3D’s output include very short scenes of varying quality. The system allows only one color per point so, for instance, reflective surfaces look the same regardless of viewing angle. It’s also computationally demanding: It took 6.5 hours per scene using eight A100 GPUs.</p><p><strong>Why it matters: </strong>Adapting NeRF for video/animation is exciting, but the larger lesson is that finding an efficient way to learn representations — HexPlane in this case — can make tasks feasible that otherwise would require impractical amounts of computation.</p><p><strong>We’re thinking:</strong> While MAV3D’s rendering would be improved by variable colors to represent reflections, shadows, and dynamic lighting, its strong performance relative to DreamFusion suggests a way to improve text-to-3D: train on videos instead of images. Videos contain moving objects and sometimes changing camera positions, so they can depict more diverse 3D geometry than a set of static images. Learning from videos could avoid generating 3D images that look fine from only <a href="https://twitter.com/_akhaliq/status/1578040812088479744?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv" rel="noopener">one angle at a time</a>.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook." data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook." data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/resources/#ebooks"><div class="absolute inset-0" data-gtm-event-title="AI is the new electricity"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-212/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-212/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-212/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm15" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-212","id":"64ef7dee10a5d2000149ac64","uuid":"44298edf-f6f5-4a66-9a8e-b80a41ac5150","title":"Text to 3D Animation, China Restricts Face Recognition, Self-Driving Cars Get Crash Recorders","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eI’d like to share a part of the origin story of large language models that isn’t widely known. A lot of early work in natural language processing (NLP) was funded by U.S. military intelligence agencies that needed machine translation and speech recognition capabilities. Then, as now, such agencies analyzed large volumes of text and recorded speech in various languages. They poured money into research in machine translation and speech recognition over decades, which motivated researchers to give these applications disproportionate attention relative to other uses of NLP.\u003c/em\u003e\u003cbr\u003e\u003cbr\u003e\u003cem\u003eThis explains why many important technical breakthroughs in NLP stem from studying translation — more than you might imagine based on the modest role that translation plays in current applications. For instance, the celebrated transformer paper, “\u003ca href=\"https://arxiv.org/abs/1706.03762?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eAttention is All You Need\u003c/a\u003e” by the Google Brain team, introduced a technique for mapping a sentence in one language to a translation in another. This laid the foundation for large language models (LLMs) like ChatGPT, which map a prompt to a generated response.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eOr consider the \u003ca href=\"https://www.coursera.org/lecture/nlp-sequence-models/bleu-score-(optional)-kC2HD?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eBLEU score\u003c/a\u003e, which is occasionally still used to evaluate LLMs by comparing their outputs to ground-truth examples. It was developed in 2002 to measure how well a machine-generated translation compares to a ground truth, human-created translation.\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--49--1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--49--1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--49--1.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--49--1.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eA key component of LLMs is tokenization, the process of breaking raw input text into sub-word components that become the tokens to be processed. For example, the first part of the previous sentence may be divided into tokens like this:\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003e/A /key /component /of /LL/Ms/ is/ token/ization\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eThe most widely used tokenization algorithm for text today is Byte Pair Encoding (BPE), which gained popularity in NLP after a 2015 \u003ca href=\"https://arxiv.org/abs/1508.07909?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003epaper\u003c/a\u003e by Sennrich et al. BPE starts with individual characters as tokens and repeatedly merges tokens that occur together frequently. Eventually, entire words as well as common sub-words become tokens. How did this technique come about? The authors wanted to build a model that could translate words that weren’t represented in the training data. They found that splitting words into sub-words created an input representation that enabled the model, if it had seen “token” and “ization,” to guess the meaning of a word it might not have seen before, such as “tokenization.”\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eI don’t intend this description of NLP history as advocacy for military-funded research. (I have accepted military funding, too. Some of my early work in deep learning at Stanford University was funded by DARPA, a U.S. defense research agency. This led directly to my starting Google Brain.) War is a horribly ugly business, and I would like there to be much less of it. Still, I find it striking that basic research in one area can lead to broadly beneficial developments in others. In similar ways, research into space travel led to LED lights and solar panels, experiments in particle physics led to magnetic resonance imaging, and studies of bacteria’s defenses against viruses led to the CRISPR gene-editing technology.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eSo it’s especially exciting to see so much basic research going on in so many different areas of AI. Who knows, a few years hence, what today’s experiments will yield?\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eP.S. Built in collaboration with Microsoft, our short course “How Business Thinkers Can Start Building AI Plugins With Semantic Kernel” is now available! This is taught by John Maeda, VP of Design and AI (who also co-invented the Scratch programming language!). You’ll join John in building his “AI Kitchen” and learn to cook up a full AI meal from, well, scratch – including all the steps to build full business-thinking AI pipelines. You’ll conclude by creating an AI planner that can automatically select plugins it needs to produce multi-step plans with sophisticated logic.\u003c/em\u003e \u003cem\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/microsoft-semantic-kernel?ref=dl-staging-website.ghost.io\"\u003eSign up to learn here\u003c/a\u003e!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--89-.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--89-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--89-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--89-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"industrial-strength-llm\"\u003eIndustrial-Strength LLM\u003c/h1\u003e\u003cp\u003eAnthropic, the startup behind the safety-focused Claude chatbot, teamed up with South Korea’s largest mobile phone provider.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new: \u003c/strong\u003eThe independent research lab, which is an offshoot of OpenAI, will receive $100 million from SK Telecom to build a multilingual large language model tailored for the telecommunications industry, \u003cem\u003eVentureBeat\u003c/em\u003e \u003ca href=\"https://venturebeat.com/ai/ai-startup-anthropic-gets-100m-to-build-custom-llm-for-telecom-industry/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003ereported\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e Anthropic will base the specialized model on the technology that underpins its large language model \u003ca href=\"https://claude.ai/login?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eClaude\u003c/a\u003e. SK Telecom plans to offer it to other telecoms firms, such as members of the \u003ca href=\"https://www.prnewswire.com/news-releases/sk-telecom-deutsche-telekom-e-and-singtel-form-global-telco-ai-alliance-for-collaboration-and-innovation-in-ai-301887205.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eGlobal Telco AI Alliance\u003c/a\u003e, a consortium devoted to building new lines of business based on AI-driven services.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe model will be fine-tuned for telecoms applications like customer service, marketing, and sales.\u003c/li\u003e\u003cli\u003eIt will support six languages: Korean, English, German, Japanese, Arabic, and Spanish.\u003c/li\u003e\u003cli\u003eClaude takes advantage of \u003ca href=\"https://arxiv.org/pdf/2212.08073.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003econstitutional AI\u003c/a\u003e, a method designed to align large language models and human values based on a set of principles, or constitution. Initially, the model critiques and refines its own responses according to the constitution. Then it’s fine-tuned on the results via supervised learning. This is followed by a phase that Anthropic calls reinforcement learning from AI feedback, or RLAIF.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e SK Telecom has a history of building its own machine learning models, particularly Korean-language models. The company emulated GPT-3's architecture to train models like \u003ca href=\"https://huggingface.co/skt/ko-gpt-trinity-1.2B-v0.5?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eKo-GPT-Trinity-1.2B\u003c/a\u003e. An unidentified model \u003ca href=\"https://www.koreaherald.com/view.php?ud=20220516000723\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eenables\u003c/a\u003e A. (pronounced “a dot”), a virtual assistant for the company’s mobile users.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e AI models have a bright future in virtually every industry, and specialized AI models have an even brighter outlook. Like \u003ca href=\"https://arxiv.org/abs/2303.17564?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eBloombergGPT\u003c/a\u003e, this partnership represents a step toward adapting foundation models to a vertical industry, along with a new business model for good measure.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Prompting a foundation model can go a long way in tasks for which it’s easy to write instructions that describe clearly what you want done. But many tasks involve specialized knowledge that’s difficult to put into a prompt; for instance, consider explaining how to draft a good legal document. In such cases, fine-tuning or specialized training can be a promising approach.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--47-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--47-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--47-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--47-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"china-restricts-face-recognition\"\u003eChina Restricts Face Recognition\u003c/h1\u003e\u003cp\u003eChina’s internet watchdog proposed sweeping limitations on face recognition — with significant exceptions.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e The Cyberspace Administration of China \u003ca href=\"http://www.cac.gov.cn/2023-08/08/c_1693064670537413.htm?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eunveiled\u003c/a\u003e draft rules that restrict the use of face recognition systems, with explicit carve-outs when national security or public or personal safety is at stake. The public can submit feedback before September 7.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eNarrow limits, broad exceptions:\u003c/strong\u003e The proposal, which will affect mainland China but not Macau or Hong Kong, applies to both public and private users of face recognition. It follows recent restrictions on \u003ca href=\"https://www.deeplearning.ai/the-batch/chinas-new-law-limits-ai-generated-media/?ref=dl-staging-website.ghost.io\"\u003egenerative AI\u003c/a\u003e and \u003ca href=\"https://techcrunch.com/2021/08/20/china-passes-data-protection-law/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003ecollecting personal data\u003c/a\u003e.\u003c/p\u003e\u003cul\u003e\u003cli\u003eFace recognition can’t be used to analyze race, ethnicity, religion, health status, or social class except to protect national security or public or personal safety.\u003c/li\u003e\u003cli\u003eIt can’t be used to identify people in public places at a distance except to protect national security or public or personal safety.\u003c/li\u003e\u003cli\u003eFace recognition is allowed for verifying identity only if other methods aren't available.\u003c/li\u003e\u003cli\u003eIt isn’t allowed in locations where it may infringe on personal privacy, such as hotel rooms or toilets.\u003c/li\u003e\u003cli\u003eUsers can’t coerce or mislead the public into providing face data with excuses such as “improving service quality.”\u003c/li\u003e\u003cli\u003eInstitutions that use face recognition in public locations or store images of more than 10,000 faces must register their use and data-handling procedure with the government.\u003c/li\u003e\u003cli\u003eBefore gathering face data, users must obtain the subject’s permission, or a parent’s or guardian’s if the subject is less than 14 years old.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e China \u003ca href=\"https://www.wired.com/story/china-is-the-worlds-biggest-face-recognition-dealer/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eleads\u003c/a\u003e the world in developing and deploying face recognition. Authorities use it widely in law enforcement, while businesses use it for authenticating payments, checking the identities of air and rail passengers, and granting access to residential buildings. Nonetheless, many Chinese residents have voiced their unease with the technology.\u003c/p\u003e\u003cul\u003e\u003cli\u003eIn 2021, a Chinese appeals court \u003ca href=\"https://www.washingtonpost.com/world/facial-recognition-china-tech-data/2021/07/30/404c2e96-f049-11eb-81b2-9b7061a582d8_story.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eruled\u003c/a\u003e in favor of a law professor who sued a Hangzhou zoo. The plaintiff claimed that the zoo’s use of face recognition to verify its visitors’ identities was unnecessary.\u003c/li\u003e\u003cli\u003e74 percent of Chinese residents surveyed favored alternatives to face recognition for verifying identity, according to a 2019 \u003ca href=\"https://www.ft.com/content/7c32c7a8-172e-11ea-9ee4-11f260415385?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003esurvey\u003c/a\u003e conducted by Beijing’s Nandu Personal Information Protection Research Centre. 80 percent of respondents were concerned about data security, and 84 percent wanted the option to review face-recognition data that represented them.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eYes, but:\u003c/strong\u003e The exemptions for national security and safety give China’s government authority to continue using the technology for potentially \u003ca href=\"https://www.theguardian.com/world/2022/jan/06/china-sensetime-facial-recognition-uyghur-surveillance-us-sanctions?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003econtroversial\u003c/a\u003e applications.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e Face recognition is a double-edged sword. It has legitimate uses for security and law enforcement, but it can also be misused to violate privacy. Such concerns \u003ca href=\"https://www.politico.eu/article/meps-adopt-ai-act-text-in-committees/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003emotivated\u003c/a\u003e European Union lawmakers to insert a prohibition on face recognition in public spaces into the current draft of the union’s AI Act, which is in the final stage of revision. China’s new rules bring that country’s face recognition policy closer into line with that standard — the exceptions for national security and public safety notwithstanding.\u003cbr\u003e\u003cbr\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e It’s interesting to see China take the lead in regulating face recognition, where it dominates the technology and market. We support stronger protections for personal privacy.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM \u003cstrong\u003eDEEPLEARNING.AI\u003c/strong\u003e\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/microsoft-semantic-kernel?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1043\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/08/DeepLearning_Microsoft_Semantic_Kernel_Banner_2070x1080.png 2070w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eLearn how to utilize Semantic Kernel, Microsoft’s open source SDK, to develop sophisticated business applications using LLMs. \u003ca href=\"https://www.deeplearning.ai/short-courses/microsoft-semantic-kernel?ref=dl-staging-website.ghost.io\"\u003eSign up for free\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--48-.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/08/unnamed--48-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/08/unnamed--48-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--48-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"crash-tracker\"\u003eCrash Tracker\u003c/h1\u003e\u003cp\u003eEvent data recorders, also known as black boxes, got an update for the era of self-driving cars.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new: \u003c/strong\u003eThe Institute of Electrical and Electronics Engineers \u003ca href=\"https://standards.ieee.org/ieee/1616.1/10939/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003epublished\u003c/a\u003e guidelines for internal devices that track the performance of autonomous road vehicles.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e Like airplanes, cars and trucks carry event data recorders that capture their moment-to-moment behavior for examination in the event of a crash. The new specification calls for vehicles with \u003ca href=\"https://www.sae.org/blog/sae-j3016-update?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eLevel 3\u003c/a\u003e autonomous capabilities or higher, which can drive themselves but may require a human driver to take over, to carry a recorder dedicated to automated driving functions. The working group will meet later this year to discuss further revisions that address subjects like cybersecurity and protocols accessing recorded data.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe autonomous-driving recorder logs when a vehicle’s self-driving function is activated or deactivated, when the driver’s action overrides it (for instance, by manually braking or turning the wheel), or when it overrides a driver’s action.\u003c/li\u003e\u003cli\u003eThe recorder also logs when the vehicle fails to stay in its lane, starts or ends an emergency maneuver, suffers a major malfunction, or collides with another object.\u003c/li\u003e\u003cli\u003eThe minimum log entry includes an event, the event’s cause, and its date and timestamp to the second.\u003c/li\u003e\u003cli\u003eA tamper-resistant electronic lock restricts access to recorded data.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e Event data recorders became a fixture in road vehicles decades ago as a way to evaluate the performance of safety airbags. Today, they record parameters such as speed, acceleration, and braking in 99 percent of new vehicles in the United States. They’ll be \u003ca href=\"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12989-Vehicle-safety-technical-requirements-%26-test-procedures-for-EU-type-approval-of-event-data-recorders-EDRs-_en?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003emandatory\u003c/a\u003e in new cars in the European Union starting next year.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e As more automated driving systems hit the road, safety concerns are on the rise. Event data recorders help shed light on mishaps, and the resulting data can help authorities, manufacturers, and consumers to understand the role, if any, played by self-driving technology. Although compliance is voluntary, IEEE standards are influential and widely followed.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e Self-driving systems have the potential to reduce road and pedestrian fatalities dramatically. A clear picture of what goes wrong and why will enable engineers to improve self-driving technology steadily. Ultimately, we hope, accidents will become rare and relatively inconsequential.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--90-.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--90-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"text-to-3d-animation\"\u003eText-To-3D Animation\u003c/h1\u003e\u003cp\u003eText-to-video generation is so 2022! A new system takes in text and generates an animated 3D scene that can be viewed or rendered from any angle.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e Uriel Singer and colleagues at Meta AI proposed \u003ca href=\"https://arxiv.org/abs/2301.11280?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eMake-A-Video3D\u003c/a\u003e (MAV3D). Lacking a corpus of matched text and animated 3D scenes, the authors used a pretrained text-to-video diffusion model to guide the training of a neural radiance field (NeRF) model that learned how to represent a 3D scene with moving elements. You can see MAV3D’s output \u003ca href=\"https://make-a-video3d.github.io/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e Earlier work known as \u003ca href=\"https://www.deeplearning.ai/the-batch/how-dreamfusion-generates-3d-images-from-text/?ref=dl-staging-website.ghost.io\"\u003eDreamFusion\u003c/a\u003e learned to produce a 3D scene from text by setting up a feedback loop between a pretrained diffusion text-to-image generator, which creates 2D images according to a text prompt, and a NeRF, which takes embeddings of points in space and learns to produce a 3D scene (mesh, point colors, and point transparencies) to match the 2D images shot from various angles. (NeRF can also generate images of the scene.) Basically, (i) the NeRF generated 2D images of a random 3D scene; (ii) the images — with added noise — were given as input to the diffusion text-to-image generator, which sharpened them according to the text prompt; and (iii) the NeRF used the sharpened images to sharpen the 3D scene, repeating the cycle. MAV3D worked the same way but (a) used a more computationally efficient embedding method called HexPlane, (b) swapped the pretrained text-to-image generator for a pretrained text-to-video generator, and (c) modified the NeRF to generate sequences of video frames. The resulting system takes a text prompt and learns to generate a matching 3D scene that changes over time.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e MAV3D is an animated version of the earlier DreamFusion, as described above. It includes the following models: \u003ca href=\"https://arxiv.org/abs/2301.09632?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eHexPlane\u003c/a\u003e (which efficiently represents an animated 3D scene), \u003ca href=\"https://arxiv.org/abs/2209.14792?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eMake-A-Video\u003c/a\u003e (a text-to-video generator pretrained on LAION-5B text/image pairs and fine-tuned on 20 million videos), and a \u003ca href=\"https://arxiv.org/abs/2003.08934?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eNeRF\u003c/a\u003e modified for video/animation.\u003c/p\u003e\u003cul\u003e\u003cli\u003eHexPlane learned an embedding for each point on each 2D plane in an animated 3D scene (xy, xz, xt, yz, yt, and zt) over 16 video frames. Given a point (three spatial dimensions plus time), the model projected it onto each plane, retrieved the corresponding embeddings, and concatenated them to produce a point embedding.\u003c/li\u003e\u003cli\u003eGiven the embeddings and a random camera position per frame, NeRF produced a video.\u003c/li\u003e\u003cli\u003eThe system added noise to the NeRF video and fed it to Make-A-Video. Given a text prompt, Make-A-Video estimated what the video would look like without the noise.\u003c/li\u003e\u003cli\u003eThe loss function minimized the difference between the NeRF video and Make-A-Video’s denoised version to update HexPlane and NeRF.\u003c/li\u003e\u003cli\u003eThe system cycled through this process 12,000 times using a different random camera trajectory each time, which enabled it to evaluate every point from multiple angles.\u003c/li\u003e\u003cli\u003eThe authors extracted from NeRF a 64-frame animated 3D scene using the \u003ca href=\"https://dl.acm.org/doi/10.1145/37402.37422?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\"\u003emarching cubes\u003c/a\u003e algorithm.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e No other system generates animated 3D scenes from text, so the authors compared MAV3D with systems that solve two sub-tasks, generating 3D static scenes from text and generating videos from text. They used \u003ca href=\"https://openreview.net/forum?id=bKBhQhPeKaF\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eCLIP R-Precision\u003c/a\u003e, a metric that evaluates the similarity between an image and a text description (higher is better), to measure the systems’ performance averaged across a number of images taken from different angles (for 3D scenes) or images over time (for videos). MAV3D outperformed a \u003ca href=\"https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eStable Diffusion\u003c/a\u003e implementation of DreamFusion (82.4 CLIP R-Precision versus 66.1 CLIP R-Precision). However, it did worse than Make-A-Video (79.2 CLIP R-Precision versus 86.6 CLIP R-Precision).\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYes, but:\u003c/strong\u003e Examples of MAV3D’s output include very short scenes of varying quality. The system allows only one color per point so, for instance, reflective surfaces look the same regardless of viewing angle. It’s also computationally demanding: It took 6.5 hours per scene using eight A100 GPUs.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters: \u003c/strong\u003eAdapting NeRF for video/animation is exciting, but the larger lesson is that finding an efficient way to learn representations — HexPlane in this case — can make tasks feasible that otherwise would require impractical amounts of computation.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e While MAV3D’s rendering would be improved by variable colors to represent reflections, shadows, and dynamic lighting, its strong performance relative to DreamFusion suggests a way to improve text-to-3D: train on videos instead of images. Videos contain moving objects and sometimes changing camera positions, so they can depict more diverse 3D geometry than a set of static images. Learning from videos could avoid generating 3D images that look fine from only \u003ca href=\"https://twitter.com/_akhaliq/status/1578040812088479744?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--d4Gc6q514bW8fwBxNiIMuQo8hwMPODu9gBeKuJ1pNXfxdleVVivXQC1ffMrjG9lTZEabv\" rel=\"noopener\"\u003eone angle at a time\u003c/a\u003e.\u003c/p\u003e","comment_id":"64ef7dee10a5d2000149ac64","feature_image":"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--49-.png","featured":false,"visibility":"public","created_at":"2023-08-30T10:35:42.000-07:00","updated_at":"2023-08-30T12:24:30.000-07:00","published_at":"2023-08-30T12:24:30.000-07:00","custom_excerpt":"The Batch - AI News \u0026 Insights: I’d like to share a part of the origin story of large language models that isn’t widely known. A lot of early work in natural language processing (NLP) was funded by U.S. military intelligence...","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"64ef7eb310a5d2000149ac85","name":"issue-212","slug":"issue-212","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-212/"},{"id":"64ef7eb310a5d2000149ac86","name":"Aug 30, 2023","slug":"aug-30-2023","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/aug-30-2023/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-212/","excerpt":"The Batch - AI News \u0026 Insights: I’d like to share a part of the origin story of large language models that isn’t widely known. A lot of early work in natural language processing (NLP) was funded by U.S. military intelligence...","reading_time":11,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Text to 3D Animation, China Restricts Face Recognition, and more","meta_description":"The Batch - AI News \u0026 Insights: I’d like to share a part of the origin story of large language models that isn’t widely known. A lot of early work...","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2023/08/unnamed--49-.png","dimensions":{"width":1200,"height":675}},"banner":{"title":"AI is the new electricity","databaseId":29050,"id":"cG9zdDoyOTA1MA==","featuredImage":{"node":{"altText":"AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook.","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/resources/#ebooks","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-212"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>