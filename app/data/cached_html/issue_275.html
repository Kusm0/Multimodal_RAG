<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot</title><meta name="description" content="The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-275/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-275/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2024-11-13T11:54:00.000-08:00"/><meta property="article:modified_time" content="2024-11-13T15:58:00.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="Nov 13, 2024"/><meta property="article:tag" content="issue-275"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-275/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33--1.jpg"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33--1.jpg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="676"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2024-11-13T11:54:00.000-08:00","dateModified":"2024-11-13T15:58:00.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33--1.jpg","width":1200,"height":676},"publisher":{"@type":"Organization","name":"Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-275/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 275</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Nov 13, 2024</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">12<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/nov-13-2024/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Nov 13, 2024</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">12<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-275/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-275/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-275/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p>Dear friends,</p><p>Large language models (LLMs) are typically optimized to answer peoples’ questions. But there is a trend toward models also being optimized to fit into agentic workflows. This will give a huge boost to agentic performance!</p><p>Following ChatGPT’s breakaway success at answering questions, a lot of LLM development focused on providing a good consumer experience. So LLMs were tuned to answer questions (“Why did Shakespeare write&nbsp;<em>Macbeth</em>?”) or follow human-provided instructions (“Explain why Shakespeare wrote&nbsp;<em>Macbeth</em>”). A&nbsp;<a href="https://github.com/zhilizju/Awesome-instruction-tuning?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">large</a>&nbsp;<a href="https://github.com/jianzhnie/awesome-instruction-datasets?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">fraction</a>&nbsp;of the datasets for instruction tuning guide models to provide more helpful responses to human-written questions and instructions of the sort one might ask a consumer-facing LLM like those offered by the web interfaces of ChatGPT, Claude, or Gemini.</p><p>But agentic workloads call on different behaviors. Rather than directly generating responses for consumers, AI software may use a model in part of an iterative&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">workflow</a>&nbsp;to reflect on its own output, use tools, write plans, and collaborate in a multi-agent setting. Major model makers are increasingly optimizing models to be used in AI agents as well.</p><p>Take tool use (or&nbsp;<a href="https://learn.deeplearning.ai/courses/functions-tools-agents-langchain/lesson/1/introduction?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">function calling</a>). If an LLM is asked about the current weather, it won’t be able to derive the information needed from its training data. Instead, it might generate a request for an API call to get that information. Even before GPT-4 natively supported function calls, application developers were already using LLMs to generate function calls, but by writing more complex prompts (such as variations of&nbsp;<a href="https://arxiv.org/abs/2210.03629?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">ReAct</a>&nbsp;prompts) that tell the LLM what functions are available and then have the LLM generate a string that a separate software routine parses (perhaps with regular expressions) to figure out if it wants to call a function.</p><p>Generating such calls became much more reliable after GPT-4 and then many other models natively supported function calling. Today, LLMs can decide to call functions to search for information for&nbsp;<a href="https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">retrieval-augmented generation</a>&nbsp;(RAG), execute code, &nbsp;send emails, place orders online, and much more.</p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33-.jpg" class="kg-image" alt="Man with tools says, “I optimized for tool use!” Woman at computer replies, “Should’ve optimized for computer use!”" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--33-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--33-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33-.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><p>Recently, Anthropic released a version of its model that is capable of computer use, using mouse-clicks and keystrokes to operate a computer (usually a virtual machine). I’ve enjoyed playing with the&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3pNW7-sKn92qM7_7N721lZKNKstxW9b1RrK30QMyTW2jkS2f6J5T-mVSq1xy7Lsdb_W2Tvjwt1KCY8hW2RGvyd6t8BQ3N3HwPSHbPLmcW2JjQX58tPLlhW8tLmTW2ND_yqW8X--zy47Hl6LW59xSBN1GLyYmW4WBx8K122pYHW8LvtD97G5354W2R_kRy5dyP49W6P6gMl3J2DJbVFT_jm4ZGHTWW154LP544LQbNW82qGj77G6dfPVDTxqF2y5cglW6FfX631jG8p9W4lpFml1ms3PjW1yxCPb5yp0pxN8kr_M06C5fnW7QYqmn10LcTNW7_8PWp5VGF5gN3vbhDTKNPKRW29Mph5536c53dPStXg04?ref=dl-staging-website.ghost.io" rel="noopener">demo</a>. While other teams have been prompting LLMs to use computers to build a new generation of RPA (robotic process automation) applications, native support for computer use by a major LLM provider is a great step forward. This will help many developers!</p><p>As agentic workflows mature, here is what I am seeing:</p><ul><li>First, many developers are prompting LLMs to carry out the agentic behaviors they want. This allows for quick, rich exploration!</li><li>In a much smaller number of cases, developers who are working on very valuable applications will fine-tune LLMs to carry out particular agentic functions more reliably. For example, even though many LLMs support function calling natively, they do so by taking as input a description of the functions available and then (hopefully) generating output tokens to request the right function call. For mission-critical applications where generating the right function call is important, fine-tuning a model for your application’s specific function calls significantly increases reliability. (But please avoid premature optimization! Today I still see too many teams fine-tuning when they should probably spend more time on prompting before they resort to this.)</li><li>Finally, when a capability such as tool use or computer use appears valuable to many developers, major LLM providers are building these capabilities directly into their models. Even though OpenAI o1-preview’s advanced reasoning helps consumers, I expect that it will be even more useful for agentic reasoning and planning.</li></ul><p>Most LLMs have been optimized for answering questions primarily to deliver a good consumer experience, and we’ve been able to “graft” them into complex agentic workflows to build valuable applications. The trend of LLMs built to support particular operations in agents natively will create a lot of lift for agentic performance. I’m confident that large agentic performance gains in this direction will be realized in the next few years.</p><p>Keep learning!</p><p>Andrew</p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/safe-and-reliable-ai-via-guardrails/?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png" class="kg-image" alt="Promo banner for &quot;Safe and Reliable AI via Guardrails&quot;" loading="lazy" width="1890" height="1063" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png 1890w" sizes="(min-width: 720px) 720px"></a></figure><p>Prevent common issues in applications based on large language models such as hallucinations, data leaks, and off-topic responses. Build guardrails that protect against incorrect or sensitive responses in our new short course, made in collaboration with GuardrailsAI.&nbsp;<a href="https://www.deeplearning.ai/short-courses/safe-and-reliable-ai-via-guardrails/?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up now!</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--27-.gif" class="kg-image" alt="Performance comparison of models across tasks in English, Chinese, Math, and Code, with Hunyuan-Large leading in most metrics." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--27-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--27-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--27-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="mixture-of-experts-pulls-ahead">Mixture of Experts Pulls Ahead</h1><p>A new open source large language model outperforms competitors, including the open-weights Llama 3.1 405B, on a variety of benchmarks.</p><p><strong>What’s new:</strong>&nbsp;Tencent released&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NqK3qgyTW6N1vHY6lZ3nBW1-r3sv8BHJ_MW7KLVTG2cbf3tW6kn06z1HwfVlW2Y-F4g8FXfP5W8dYm2C6CZ5NfW7C-yxl55nsd3W6-xsx54nSD2dN1RSM_0dD104Vg5c5p4-lTsmW5jBXXw3x7nyhW7tHVrq3k47g6W4DHxqp1_vww6W6l3hk17KP_w6W1lVqvG1QpZl-W64CFpt2sjtGMW1CG_Q54mKbWjW3KDFjY8Hn2GLW4x5xJq2MznLPW4tKgRj910rDgW4lS7wM1zXt_TVJjJCv7F6NHjW8q69LN5ZsxMXf1h55bM04?ref=dl-staging-website.ghost.io" rel="noopener">Hunyuan-Large</a>, a mixture-of-experts model with&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nr03qgyTW7lCdLW6lZ3lbW5FKXmK8qtkTRW3jmYs64Pwr52W53cQ4v9cMC8gVd4fj58qNqhtW6tsdxP2NlscfW5llnS31wpcPBW4rJ8Tb8-SGszW5yPld88PXmbTW2DfZm645CNxHW8LjhwC5Hcc7FW5V9T808hXwFTW8K86Mt294qtXW4D91557FQjVFW6Clrbq15DJj-W5v1B8t6V01Q3W71dJTt8lnR7lN6pMcP3K9dk1W4VSHlX4sg_T8Vb24Yh1D33P5W1Fpzyt4_SLGDW1Q_XQ62nbnjhW7cbPMK14NWznW7g-G8732VTy_W5rv_qY8whLjYf3_zDlj04?ref=dl-staging-website.ghost.io" rel="noopener">open code</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nr03qgyTW7lCdLW6lZ3mNVKYjtm3jr2v2W177hkd5_prBdW2v4RxS4_SZz9W5DjKpG5ZszWgW1c2fq27rMnjgW4Cr23C5cVhljW7jk9-h2m__5RW3qHqYk2wvhS5W892w8c7cvc1JN7HZrhyKVMrFW1jZ8Cx1Kxs-QW5Jwr8t4l-B9VW21rZXf5m65t1W3lk7BW1ZMW99W8cP5wV7CNQ0ZW3X16Gm638GPwW3jYjkq1KjPWvW2ZXhKj6KPnXvW8v5QqW8cwFXXW1qG1GQ1bg3W7W2spqxV8D_V6vW4pGYGt3KsvTJW2DmQBp217zRyW1QKqWm94Dcpvf2v7VSz04?ref=dl-staging-website.ghost.io" rel="noopener">open weights</a>. It comes in base and instruction-tuned versions, both of which can process a relatively large input context window of 256,000 tokens. It’s free for developers outside the European Union who have fewer than 100 million monthly users. You can experiment with it&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nr03qgyTW7lCdLW6lZ3mzW4GV1mJ2nZ1XGN55JtJ6gSkVMW1dRKN_9jbMbGW2ScslH7jXCPQW3KHjRD7s2d94Vy_9Vt21mhJhW3Bct352CWJM0W3SNyl53l9cY2W33-dhH2mXC0bW5t85Rq4YYHf8W6dlWsT4LNtN7W7Q_DhL8f0zx6W7jnSjT7DW7y2W7PgTxH1tzt68VhYj0b5lln38F1JlVBzG5XwW7wYmfP6trTr4W97Ftg38jJs-5W7VGM7f44xtvZVbLC-l6jSg0bW5WMn904gMF1HN5wxnNsD0-1DW6RyZ1v47nyvlW55wXVx79tDqKf5NJWX204?ref=dl-staging-website.ghost.io" rel="noopener">here</a>.</p><p><strong>Mixture of experts (MoE) basics:</strong>&nbsp;The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input.</p><p><strong>How it works:</strong>&nbsp;Hunyuan-Large comprises 389 billion parameters but uses 52 billion parameters to process any given input. The team pretrained the model on 7 trillion tokens primarily of English and Chinese text, of which 5.5 trillion tokens came from unspecified sources and 1.5 trillion synthetic tokens were generated by unspecified large language models. The models used to generate training data were “specialized” to provide expert-level responses in various domains. The team fine-tuned Hunyuan-Large on unspecified datasets of instructions and human feedback.</p><ul><li>MoE models typically select which expert(s) to use based on the input. Hunyuan-Large chooses one of 16 experts, but it also uses a shared expert — an expert that processes every input.</li><li>Recent&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NqK3qgyTW6N1vHY6lZ3nhW3FPqlQ48wC4RW8v8bcR3WYzs2W8z8Qmr5v8XXLW1q38-w4DprYvW959C6n2ywsvqVy_lNG8-KVdbW1tSnBv212bfCW5Jhk8R9brXWFW3H2HbT1kxRqlW2Rmyh-3Dy2kVW7SdFBJ70Xk_kN4MhXrhDXcWJW3dYbd48YZvQMW9gRHJx5QK5-SW3YWSLj7RCWkXW2lcRy57qw7XyW1w7bhr3b6XdhW25L-d-7dv__4VDYnD7384ByDW59yjjT5_1X_BW8Jtc9m1j8K_8W4qh_yQ95bqd5f7tKV8-04?ref=dl-staging-website.ghost.io" rel="noopener">research</a>&nbsp;showed that there is a formula for the optimal learning rate based on the batch size (the number of examples a model sees during one training step). The shared expert and the chosen expert see a different amount of data in each training step, so the team modified the learning rate for the chosen expert based on that formula.</li></ul><p><strong>Results:</strong>&nbsp;The team compared the Hunyuan-Large models to four open source models and their instruction-tuned versions: Llama 3.1 70B, Llama 3.1 405B, and the MoE models Mixtral-8x22B and DeepSeek-V2.</p><ul><li>Hunyuan-Large achieved the best performance on 15 of 19 benchmarks that test English, Chinese, math, and coding proficiency. For example, on&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NqK3qgyTW6N1vHY6lZ3mdN1p1s0X85CX9W4q0BTZ4stSbgN8nNRZGN6HKqW18dSDL4b4nvLW87S-k236YCP5W4mfP004Jl-jbW5ZxZV-9fYYbDW52G06p20v27mW78MRSZ6GcdZHW8lWhNc7pZjdyW4mmLZ53xHWFhW3GTYys6plZQTW6CvRFb23zjzFW20f3Y57D-lCqW7xf0M_7TspxsW6QtXVP4WPS-JW3GHFZg6rSTtNW4NydW23fVW9qMnMRz0VFkBtW8k4zHN6BJ20MN4ySCdtggXpKN2NNXz214rq2f2ZXJK004?ref=dl-staging-website.ghost.io" rel="noopener">MMLU</a>&nbsp;(answering multiple choice questions in topics including elementary mathematics, history, computer science, and law), Hunyuan-Large achieved 88.4 percent accuracy. The next-best competitor, Llama 3.1 405B, achieved 85.2 percent.</li><li>The instruction-tuned version achieved the best performance on 10 of 13 benchmarks including measures of instruction-following ability and alignment with certain human preferences. For instance, Hunyuan-Large-Instruct maintained its dominance on MMLU (89.9 percent accuracy to Llama 3.1 405B Instruct’s 87.3 percent accuracy). On AlpacaEval 2, an instruction-following benchmark, Hunyuan-Large-Instruct achieved 51.8 percent, while the next-best competitor, DeepSeek 2.5 Chat, achieved 50.5 percent.</li></ul><p><strong>Why it matters:</strong>&nbsp;Hunyuan-Large generally outperforms Llama 405B, achieving the performance of a 405 billion parameter model while computing only 52 billion parameters. That’s a significantly lower processing requirement, and the model is free for many purposes.</p><p><strong>We’re thinking:</strong>&nbsp;Setting aside&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nrj3qgyTW7Y8-PT6lZ3mbW2f723G6HLKtlW5c3ff99fP1lwW7wFwNb7XrMl1N659MSJL-D-7W50VHxx4B9h7RW5C9-rk3bqJmwW1SBbth5b9ZCsW5FW-lM5FgGp4W4s1dJy5ZDmTxW52QcRZ5PycGZW1hVn1L1JWrh5W8M41Y65123FqW5cxLBL8Z3VQtW65zkpZ8mr4whW2RCQ2m5XkpCKW92MGCS60VFpbW5hZ5Zg4-NxhnW33xM3J7t18thVKHBGc6SwjYFW2kcT1d3wSHhKW72z69Z75dbZNW5bmp4345HJY5W5n_p0t8thF4DW9czfQb5zqFbYN3bfjdDjSjY2VPhrj73dZ6fXf5F37rF04?ref=dl-staging-website.ghost.io" rel="noopener">Switch Transformer</a>&nbsp;— a 1.6 trillion parameter behemoth that was built to test the limits of size rather than performance — Hunyuan-Large is among the largest MoE models we’ve come across. It’s an impressive demonstration of what larger MoE models can accomplish.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--34-.jpg" class="kg-image" alt="Llama wearing a camouflage helmet, looking determined with a light blue background." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--34-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--34-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--34-.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="big-ai-pursues-military-contracts">Big AI Pursues Military Contracts</h1><p>Two top AI companies changed their stances on military and intelligence applications.</p><p><strong>What’s new:</strong>&nbsp;Meta made its Llama family of large language models&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3mvW16zLw45RVbdGW7m7sdM2n9G8xN6kGXmx63s5RW7vX_3s2DPQb8W6GS2m76prYlmW59L4p34CD9XvW3Yc8m36G0PdtN8-PkHhXwfMVV_lVFd92xRMcW8Bs6WN7GmSRqW1T1w3d6-ZhxXW4GYsvH29jzJRW8FhSBs4w-NjzW7HrqFM8ZtmXDW1834lC3GShgkW8PfH_x5DLTFXW690ZW671pJhcVGrbLs7j_Rn9W3LW6tG95Jc0kVLPKS12CNkKDV5s2w_8kcj4sN5-396QyB4fZVDBHJ26w5PRLVGLsvV6lm9MlW6sMdZF1zl6WGW5StJN643CHYZW89yYKq8nBKnDW7VslWn2DvX_Mdj9TsC04?ref=dl-staging-website.ghost.io" rel="noopener">available</a>&nbsp;to the U.S. government for national security purposes — a major change in its policy on military applications. Similarly, Anthropic will&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nr05nR32W7lCGcx6lZ3m4W6Hp_NY2zykBDW30CZ898GhmYzW6NMrM82-Yxj_W4Kyxlh6GjXx3MDQ2Ml1cHBFW2ncD4d1y076vW7YgqsY8m0lmVVb5FnL5d97t8W6z2vrV4F-CKZVCkGDn4hpk2gM-qpzHQDDDBW8dMlxk3g5zh9W5zz4Qn1MZdBwW4cBJcX46PT0-N7j4wnhNBYw-W40dxhx51LD8MW63BJ-g2JvJD8W40QjL-3rcl4VW1f8qr34Lm5g7W4RH1XD27gFFhW6Xyl6P7D39JsW2K04Vs8M7rfJW6VWYXB71sxzKW2-K-h12txwjWVzWWJM48DrMYW4ZCBwh70RgJzW11QDmn6sfcyTW2trX-b7mrXGfW6hT93m53FDxQN8JRmM9xRxQYW4jwFmK5vFKc8W1-l9fG2XPJZnW1jZrBc7PGLT6W1LMqvv1FfnDjW9gG79r4qMJZmW6mbbQB13SLGKW4yWfS12GRZmGW1lcG9p7xPXHrN3Gz8qkv45dKW7CfhKK5ktKnyf6z3-hz04?ref=dl-staging-website.ghost.io" rel="noopener">offer</a>&nbsp;its Claude models to U.S. intelligence and defense agencies.</p><p><strong>How it works:</strong>&nbsp;Meta and Anthropic are relying on partnerships with government contractors to navigate the security and procurement requirements for military and intelligence work.</p><ul><li>Meta’s partners in the defense and intelligence markets include Accenture, Amazon, Anduril, Booz Allen, Databricks, Deloitte, IBM, Leidos, Lockheed Martin, Microsoft, Oracle, Palantir, Scale AI, and Snowflake. These companies will integrate Llama models into U.S. government applications in areas like logistics, cybersecurity, intelligence analysis, and tracking terrorists’ financial activities.</li><li>Some Meta partners have built specialized versions of Llama. For example, Scale AI&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NqK3qgyTW6N1vHY6lZ3mTW5zpP9v4VjBwHN8xGybGW4VjTW4Ggwqm4SKvj3W4FLw4M34NhllN1V7k6230xWZW4_rgjD2LYLGwVbW3HW53MV16N5Pg3JSKKGnDW6hL8Yt5RMgLQN3ZsQPdJmDG0Vqmqb96_Y8vdW8ZVVQ-2zFG5fW56bWYw94LFYMW2_Q_KP6znhnqW8812ZQ7v5827V3DYjX6kRj9bW4wvVR86ycsc8V7Jr4k8-4lksW8rqtj7509qY5W6mBNq72Nj2DPW5rd1435YZNWGW8F6dw46qLxtff7nchQP04?ref=dl-staging-website.ghost.io" rel="noopener">fine-tuned</a>&nbsp;Llama 3 for national security applications. Called Defense Llama, the fine-tuned model can assist with tasks such as planning military operations and analyzing an adversary’s vulnerabilities.</li><li>Anthropic will make its Claude 3 and 3.5 model families available to U.S. defense and intelligence agencies via a platform built by Palantir, which provides big-data analytics to governments, and hosted by Amazon Web Services. The government will use Claude to review documents, find patterns in large amounts of data, and help officials make decisions.</li></ul><p><strong>Behind the news:</strong>&nbsp;In 2018, Google faced&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3kDN1smYL-QXgkpW7ZTQwx40ftB2W8WBV5M3FmjxJW3HS-KT1JzBBTW2gxzQ23jcRkXN6Fy2nNNqxFHW3WzrQT74CBn-N1D7tnX26f67VMYh5n89y1flW2Z1pFQ7WFJrVW7YbR5s9f3G81W2MbB0k8zgMKyW1wFt_j8n5ckSW1NQn0T5W4bmjW6TXZHd4R7rVkW9h8TxX4JfGwcW5R7hC831L08KW5h5Bl59cWh0sW1DTXGj732F49W1RTxxv4gfq3jW5TjRf95s1nDJN43Pcdb-7qB3W2xqBrL52G0lWW39G2Pv51zk32W67DNDM7KjspDW64LQb6435-wZN7t5Pj2gKNGdW6VzLlG25f1jpf6mT8gR04?ref=dl-staging-website.ghost.io" rel="noopener">backlash</a>&nbsp;when it won a contract with the U.S. government to build&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nq65nR32W5BWr2F6lZ3pKVVv5x523vP5RVBTKYS5294FcW2xlSBw7_fN8JW4tC1Qt4gGXfRW2cqPW25h7_zxW4Bf18744sg6hW5ZhTSz8L_90pW2d2yPK33sJ5wW2smJt48M5LYJW2T8gJx1NM-J4W5gQh5F26mLw-W7mlcsN657nLhW2N7tCG8BpLLdW31h-G22dCX2xW4crvgx8sn2-mW3_z14h475DbfW88KWNw4RQMhFW6NXGXP4WGsdXW7PW9gq8Mf4fwW4YmyRQ5bzGP0N6DtPn66bFbKW6lZD_Z4MXPN3W6ZJ9dl70gr-FVHnNq52Xj8dFW3fDGff8LjVJkW1C5H_76WTmhBW7v2zBC6vtqPTW4416341bG4tZW5Kc8cz244p1bW1_K_CS3ctRm0W2DWNSB8dpGFRW2szw553v2nXzW1nY_lP7N-Dy7W40rX6w6TDVMRf6zBlPn04?ref=dl-staging-website.ghost.io" rel="noopener">Project Maven</a>, an AI-assisted intelligence platform. Employees protested, resigned, and called on the company to eschew military AI work. Google&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3kFV_7DLb61GGmlW2l9cWj8w_qr5W1RXCK71ZH8qRW3bcglT83cfm5W1dKQsj46bQdYW6vcSRG6-r3VKW80LxDD5j5nf5W82GQqq6L06GYW19Xxny5x5lj3W7_TLnw6j3N31VQGvw471fjnfVdJMJN10GfTWW3yslvH1GLZ7CW7NnCzG57PsfMW1HYjBK8s7N83W6wZ7857CDH-WW5kkBlz62_zqSW16Qhn954DQ-VW85kDkG6jlg9ZW3FYmwr9hP3GJW9g-VQy3-RxfkW71GzSg5y1ZFWW3jPXhC264F2NW9hMG0N48wDbTN8jZrX54wVf3W7X7Kr41050f9W2zZXGQ5KNMt8W7zbmTC7zFJ8ff5Z7NLb04?ref=dl-staging-website.ghost.io" rel="noopener">withdrew</a>&nbsp;from the project and Palantir took it over. Subsequently, many AI developers, including Meta and Anthropic, have forbidden use of their models for military applications. Llama’s new availability to U.S. military and intelligence agencies is a notable exception. In July, Anthropic, too, began to&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3kRW6TWPkz7y3pP9W8rGbzZ5NHGJCW1fG0Qq5D71GCVhbwWK5gqS6VW3C3WkY2ZYfHzW4n2hfH24pBHcW2yjgBn1sWs2_W8wXsKZ25Gqg1W5q5djG1K9WtSN1HBkXNC6tg3W3XB0Hr83qWk4W6FJX1h9fRjfxW7R8Dt71C36DwW5GMpF82Ty-KtW83zG2d6wbK76W4zlLsq2K7fLjW5Yn43Q314GX-W11Pzwx94dS8wVpwTR931RkjlW1kF0q32MkwgDN1wLZvvDGK3bW4wJL_h2Vx8t6VGWD062TnMxLW15Nmyy92Y6sWW4nd_p-22pqj4W2-cbGS5gR7rjW31KYws6HFhG6W6L_FM71HpdQhf1vtG-404?ref=dl-staging-website.ghost.io" rel="noopener">accommodate</a>&nbsp;use of its models for intelligence work. Anthropic still prohibits using Claude to develop weapons or mount cyberattacks.</p><p><strong>Why it matters:</strong>&nbsp;The shift in Meta’s and Anthropic’s policies toward military uses of AI is momentous. Lately AI has become a battlefield staple in the form of weaponized&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrW3qgyTW95jsWP6lZ3p3W7gFlL349tqgRVMMxNc92YX7BW24RDlS8CYbzdW18cBFc3RZ_DPW6r-Xm36Bdh0sW3rtp0G1HycmgW1Czy7s2TlgFSW20gTv813G83kN8YbM8Glzh3lW5f_jp74w8NGLW5VG_JW8QxcsSW5P4lw364QGzSW4_8f2H6gppMkW98TTYS3J71-ZW5bhJNv38h8yXW5wZ_576kycDbW3y8bKM3_hqP4W2yW1RM2fgmc9W1BzjL88t9nWMW5BR-2h2Wm9FlW5W0r3y4W0VZLW61k3-q7MvZ6VW2FCb7H7y4f_dV2BvGf5KwqTSN75vskMNlQkJW22fH414GCZh9N8vngLNqR08_W2CwjfX3fXY45W1hRGrq51wXNzW42Pgyg32tHJ7f3PTmGF04?ref=dl-staging-website.ghost.io" rel="noopener">drones</a>, and AI companies must take care that their new policies are consistent with upholding human rights. Military uses for AI include not only weapons development and targeting but also potentially life-saving search and rescue, logistics, intelligence, and communications. Moreover, defense contracts represent major opportunities for AI companies that can fund widely beneficial research and applications.</p><p><strong>We’re thinking:</strong>&nbsp;Peace-loving nations face difficult security challenges, and AI can be&nbsp; helpful in meeting them. At the same time, the militarization of AI brings challenges to maintaining peace and stability, upholding human rights, and retaining human control over autonomous systems. We call on developers of military AI to observe the&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrW3qgyTW95jsWP6lZ3m_W22dTxm1b_DD7W2XnpvT3FV_qkW28XPln7JVFb0V45H943lqR88W8ZZkz95pr2gBW6h_-bG7nbJfRW6mQzRK5yTQL5W8Z3W215p04hNW1B1qR71x56ggW6kx1C88XdRSpW5t-8374S42B7W52kQQn3j65LcW4P5Ll67PBGxlW7LqZkJ6hTG-DW5Hzp9y8b4MC5W7mT_lD1CVXk_W6DC-dK32QfVyW6z54K35vxlyhW4WCwnQ256j-LW21NK0J5q4H2PW4xxGb55G6s2PVPbBYC4S8mTBW4bL4Gq8NBsFGW6HcTSv3WQLcLW3C1ZFS30kCx5W6N2fxD3n0jxcW3B4q5b6Ym6_LW6Lz5yf2NxVMJN5WrN8tpHM0TW3tDTbV5t7zWHf3cGpT004?ref=dl-staging-website.ghost.io" rel="noopener">guidelines</a>, proposed by Responsible Artificial Intelligence in the Military, which are endorsed by more than 60 countries and call for robust governance, oversight, accountability, and respect for human rights.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--28-.gif" class="kg-image" alt="User entering ZIP code ‘94103’ in U.S. General Election ballot lookup to view contests and candidates." loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--28-.gif 600w"></figure><h1 id="voter%E2%80%99s-helper">Voter’s Helper</h1><p>Some voters navigated last week’s United States elections with help from a large language model that generated output based on verified, nonpartisan information.</p><p><strong>What’s new:</strong>&nbsp;Perplexity, an AI-powered search engine founded in 2022 by former OpenAI and Meta researchers, launched its&nbsp;<a href="https://www.perplexity.ai/elections/2024-11-05/us/president?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">Election Information Hub</a>, an AI-enhanced website that combines AI-generated analysis with real-time data. The model provided live updates, summaries, and explanations of key issues in the recent national, state, and local elections in the U.S. (The hub remains live, but it no longer displays information about local contests or delivers detailed results for election-related searches.)</p><p><strong>How it works:</strong>&nbsp;Perplexity partnered with Associated Press for election news and&nbsp;<a href="https://www.democracy.works/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">Democracy Works</a>, a nonprofit that develops technology and data related to democracy. Democracy Works provided an&nbsp;<a href="https://data.democracy.works/api-info?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">API</a>&nbsp;for information about elections, issues, and polling locations.</p><ul><li>Users could search by candidate, issue, state, district, or postal code. For example, searching a&nbsp;postal code returned AI-generated summaries of local races, measures, or other ballot issues drawn from vetted sources such as Ballotpedia, a nonpartisan clearinghouse for election information. A chatbot window enabled users to ask questions and drill down on citations of information sources.</li><li>Initial testing by&nbsp;<em>The Verge</em>&nbsp;<a href="https://www.theverge.com/2024/11/3/24287157/perplexity-ai-election-voting-information-tracking-hub-us-presidential-election-2024-trump-harris?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">revealed</a>&nbsp;problems with accuracy in AI-generated summaries. These included outdated information (for example, summaries failed to consistently note Robert F. Kennedy Jr.’s withdrawal from the presidential election), mistakes in candidate profiles, and mishandling of write-in candidates. Perplexity eventually fixed many of the errors.</li></ul><p><strong>Behind the news:&nbsp;</strong>While Perplexity courted demand for AI-generated information about the U.S. elections, other search-engine providers took more cautious approaches. You.com offered an election chatbot that&nbsp;<a href="https://you.com/articles/you.com-and-tollbit-launch-first-ai-election-agent-with-real-time-results?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">focused</a>&nbsp;on vote tallies provided by Decision Desk HQ, an election information broker, rather than information about issues or polling locations. Google and Microsoft Bing emphasized information from vetted sources. Microsoft Copilot and OpenAI (which had launched its SearchGPT service the week before the election) simply declined to answer election-related questions, referring users to other sources of information.</p><p><strong>Why it matters:</strong>&nbsp;Chatbots are maturing to the point where they can provide fairly trustworthy information in high-stakes decisions like elections. The combination of web search and retrieval-augmented generation contributes to decision support systems that are both personalized and accurate.</p><p><strong>We’re thinking:</strong>&nbsp;Perfect information is hard to come by in any election. Traditional media, social media, and your uncle’s strongly held opinions all have limitations. Chatbots aren’t perfect either, but when they’re properly designed to avoid biased output and outfitted with high-quality information sources, they can help strengthen users’ choices and voices.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--29-.gif" class="kg-image" alt="OpenDevin animation illustrating open-source AI model collaboration." loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--29-.gif 600w"></figure><h1 id="free-agents">Free Agents</h1><p>An open source package inspired by the commercial agentic code generator Devin aims to automate computer programming and more.</p><p><strong>What’s new:</strong>&nbsp;<a href="https://arxiv.org/abs/2407.16741?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">OpenHands</a>, previously known as OpenDevin, implements a variety of agents for coding and other tasks. It was built by Xingyao Wang and a team at University of Illinois Urbana-Champaign, Carnegie Mellon, Yale, University of California Berkeley, Contextual AI, King Abdullah University of Science and Technology, Australian National University, Ho Chi Minh City University of Technology, Alibaba, and All Hands AI. The code is free to&nbsp;<a href="https://github.com/All-Hands-AI/OpenHands?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">download</a>, use, and modify.</p><p><strong>How it works:</strong>&nbsp;OpenHands provides a set of agents, or workflows for the user’s choice of large language models. Users can command various agents to generate, edit, and run code; interact with the web; and perform auxiliary tasks related to coding and other work. The agents run in a secure Docker container with access to a server to execute code, a web browser, and tools that, say, copy text from pdfs or transcribe audio files.</p><ul><li>The CodeAct agent follows the&nbsp;<a href="https://arxiv.org/abs/2402.01030?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">CodeAct</a>&nbsp;framework, which specifies an agentic workflow for code generation. Given a prompt or results of a code execution, it can ask for clarification, write code and execute it, and deliver the result. It can also retrieve relevant information from the web.</li><li>The browsing agent controls a web browser. At every time step, it receives the user’s prompt and a text description of each element it sees on the resulting webpage. The description includes a numerical identifier, words like “paragraph” or “button” (and associated text), a list of possible actions (such as scroll, click, wait, drag and drop, and send a message to the user), an example chain of thought for selecting an action, and a list of previous actions taken. It executes actions iteratively until it has sent a message to the user.</li><li>A set of “micro agents” perform auxiliary tasks such as writing commit messages, writing Postgres databases, summarizing codebases, solving math problems, delegating actions to other agents, and the like. Users can write their own prompts to define micro agents.</li></ul><p><strong>Results:</strong>&nbsp;Overall, OpenHands agents achieve similar performance to previous agents on software engineering problems, web browsing, and miscellaneous tasks like answering questions. For example, fixing issues in Github in&nbsp;<a href="https://arxiv.org/abs/2310.06770?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">SWE-Bench</a>, the CodeAct agent using Claude 3.5 Sonnet solved 26 percent while&nbsp;<a href="https://github.com/aorwall/moatless-tools?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">Moatless Tools</a>&nbsp;using the same model solved 26.7 percent. On&nbsp;<a href="https://arxiv.org/pdf/2311.12022?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n" rel="noopener">GPQA Diamond</a>, a set of graduate-level questions about physics, chemistry, and biology, the CodeAct agent using GPT-4-turbo with search wrote code to perform the necessary calculations and found relevant information to answer the questions, achieving 51.8 percent accuracy. GPT-4 with search achieved 38.8 percent accuracy.</p><p><strong>Why it matters:</strong>&nbsp;Agentic workflows are rapidly expanding the scope and capabilities of large language models. As open source software, this system gives developers an extensible toolkit for designing agentic systems. Although it’s oriented toward coding, it accommodates a variety of information-gathering, -processing, and -publishing tasks.</p><p><strong>We’re thinking:</strong>&nbsp;This system lets users tailor custom agents simply by rewriting prompts. We look forward to seeing what non-programmers do with it!</p><hr><h2 id="a-message-from-deeplearningai-1">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/llms-as-operating-systems-agent-memory?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png" class="kg-image" alt="Promo banner for &quot;LLMs as Operating Systems: Agent Memory&quot;" loading="lazy" width="1890" height="1063" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png 1890w" sizes="(min-width: 720px) 720px"></a></figure><p>Build AI applications that have long-term agentic memory! Our short course “LLMs as Operating Systems: Agent Memory” is based on insights from the MemGPT paper and taught by two of its coauthors. Learn how to implement persistent, efficient memory management for applications based on large language models.&nbsp;<a href="https://www.deeplearning.ai/short-courses/llms-as-operating-systems-agent-memory?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free</a></p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F10%2FDE-Vertical-2.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F10%2FDE-Vertical-2.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F10%2FDE-Vertical-2.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F10%2FDE-Vertical-2.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F10%2FDE-Vertical-2.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F10%2FDE-Vertical-2.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F10%2FDE-Vertical-2.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F10%2FDE-Vertical-2.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2024%2F10%2FDE-Vertical-2.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://bit.ly/4eQA3NM"><div class="absolute inset-0" data-gtm-event-title="Data Engineering"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-275/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-275/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-275/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm91" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-275","id":"673501273ea32c00011e21f8","uuid":"2757feef-b84f-453d-9caf-20d3d0e18d6e","title":"Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot","html":"\u003cp\u003eDear friends,\u003c/p\u003e\u003cp\u003eLarge language models (LLMs) are typically optimized to answer peoples’ questions. But there is a trend toward models also being optimized to fit into agentic workflows. This will give a huge boost to agentic performance!\u003c/p\u003e\u003cp\u003eFollowing ChatGPT’s breakaway success at answering questions, a lot of LLM development focused on providing a good consumer experience. So LLMs were tuned to answer questions (“Why did Shakespeare write\u0026nbsp;\u003cem\u003eMacbeth\u003c/em\u003e?”) or follow human-provided instructions (“Explain why Shakespeare wrote\u0026nbsp;\u003cem\u003eMacbeth\u003c/em\u003e”). A\u0026nbsp;\u003ca href=\"https://github.com/zhilizju/Awesome-instruction-tuning?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003elarge\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://github.com/jianzhnie/awesome-instruction-datasets?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003efraction\u003c/a\u003e\u0026nbsp;of the datasets for instruction tuning guide models to provide more helpful responses to human-written questions and instructions of the sort one might ask a consumer-facing LLM like those offered by the web interfaces of ChatGPT, Claude, or Gemini.\u003c/p\u003e\u003cp\u003eBut agentic workloads call on different behaviors. Rather than directly generating responses for consumers, AI software may use a model in part of an iterative\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eworkflow\u003c/a\u003e\u0026nbsp;to reflect on its own output, use tools, write plans, and collaborate in a multi-agent setting. Major model makers are increasingly optimizing models to be used in AI agents as well.\u003c/p\u003e\u003cp\u003eTake tool use (or\u0026nbsp;\u003ca href=\"https://learn.deeplearning.ai/courses/functions-tools-agents-langchain/lesson/1/introduction?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003efunction calling\u003c/a\u003e). If an LLM is asked about the current weather, it won’t be able to derive the information needed from its training data. Instead, it might generate a request for an API call to get that information. Even before GPT-4 natively supported function calls, application developers were already using LLMs to generate function calls, but by writing more complex prompts (such as variations of\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2210.03629?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eReAct\u003c/a\u003e\u0026nbsp;prompts) that tell the LLM what functions are available and then have the LLM generate a string that a separate software routine parses (perhaps with regular expressions) to figure out if it wants to call a function.\u003c/p\u003e\u003cp\u003eGenerating such calls became much more reliable after GPT-4 and then many other models natively supported function calling. Today, LLMs can decide to call functions to search for information for\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eretrieval-augmented generation\u003c/a\u003e\u0026nbsp;(RAG), execute code, \u0026nbsp;send emails, place orders online, and much more.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33-.jpg\" class=\"kg-image\" alt=\"Man with tools says, “I optimized for tool use!” Woman at computer replies, “Should’ve optimized for computer use!”\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--33-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--33-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eRecently, Anthropic released a version of its model that is capable of computer use, using mouse-clicks and keystrokes to operate a computer (usually a virtual machine). I’ve enjoyed playing with the\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3pNW7-sKn92qM7_7N721lZKNKstxW9b1RrK30QMyTW2jkS2f6J5T-mVSq1xy7Lsdb_W2Tvjwt1KCY8hW2RGvyd6t8BQ3N3HwPSHbPLmcW2JjQX58tPLlhW8tLmTW2ND_yqW8X--zy47Hl6LW59xSBN1GLyYmW4WBx8K122pYHW8LvtD97G5354W2R_kRy5dyP49W6P6gMl3J2DJbVFT_jm4ZGHTWW154LP544LQbNW82qGj77G6dfPVDTxqF2y5cglW6FfX631jG8p9W4lpFml1ms3PjW1yxCPb5yp0pxN8kr_M06C5fnW7QYqmn10LcTNW7_8PWp5VGF5gN3vbhDTKNPKRW29Mph5536c53dPStXg04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003edemo\u003c/a\u003e. While other teams have been prompting LLMs to use computers to build a new generation of RPA (robotic process automation) applications, native support for computer use by a major LLM provider is a great step forward. This will help many developers!\u003c/p\u003e\u003cp\u003eAs agentic workflows mature, here is what I am seeing:\u003c/p\u003e\u003cul\u003e\u003cli\u003eFirst, many developers are prompting LLMs to carry out the agentic behaviors they want. This allows for quick, rich exploration!\u003c/li\u003e\u003cli\u003eIn a much smaller number of cases, developers who are working on very valuable applications will fine-tune LLMs to carry out particular agentic functions more reliably. For example, even though many LLMs support function calling natively, they do so by taking as input a description of the functions available and then (hopefully) generating output tokens to request the right function call. For mission-critical applications where generating the right function call is important, fine-tuning a model for your application’s specific function calls significantly increases reliability. (But please avoid premature optimization! Today I still see too many teams fine-tuning when they should probably spend more time on prompting before they resort to this.)\u003c/li\u003e\u003cli\u003eFinally, when a capability such as tool use or computer use appears valuable to many developers, major LLM providers are building these capabilities directly into their models. Even though OpenAI o1-preview’s advanced reasoning helps consumers, I expect that it will be even more useful for agentic reasoning and planning.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eMost LLMs have been optimized for answering questions primarily to deliver a good consumer experience, and we’ve been able to “graft” them into complex agentic workflows to build valuable applications. The trend of LLMs built to support particular operations in agents natively will create a lot of lift for agentic performance. I’m confident that large agentic performance gains in this direction will be realized in the next few years.\u003c/p\u003e\u003cp\u003eKeep learning!\u003c/p\u003e\u003cp\u003eAndrew\u003c/p\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/safe-and-reliable-ai-via-guardrails/?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png\" class=\"kg-image\" alt=\"Promo banner for \u0026quot;Safe and Reliable AI via Guardrails\u0026quot;\" loading=\"lazy\" width=\"1890\" height=\"1063\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092640.086.png 1890w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003ePrevent common issues in applications based on large language models such as hallucinations, data leaks, and off-topic responses. Build guardrails that protect against incorrect or sensitive responses in our new short course, made in collaboration with GuardrailsAI.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/safe-and-reliable-ai-via-guardrails/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eSign up now!\u003c/a\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--27-.gif\" class=\"kg-image\" alt=\"Performance comparison of models across tasks in English, Chinese, Math, and Code, with Hunyuan-Large leading in most metrics.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--27-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--27-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--27-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"mixture-of-experts-pulls-ahead\"\u003eMixture of Experts Pulls Ahead\u003c/h1\u003e\u003cp\u003eA new open source large language model outperforms competitors, including the open-weights Llama 3.1 405B, on a variety of benchmarks.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Tencent released\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NqK3qgyTW6N1vHY6lZ3nBW1-r3sv8BHJ_MW7KLVTG2cbf3tW6kn06z1HwfVlW2Y-F4g8FXfP5W8dYm2C6CZ5NfW7C-yxl55nsd3W6-xsx54nSD2dN1RSM_0dD104Vg5c5p4-lTsmW5jBXXw3x7nyhW7tHVrq3k47g6W4DHxqp1_vww6W6l3hk17KP_w6W1lVqvG1QpZl-W64CFpt2sjtGMW1CG_Q54mKbWjW3KDFjY8Hn2GLW4x5xJq2MznLPW4tKgRj910rDgW4lS7wM1zXt_TVJjJCv7F6NHjW8q69LN5ZsxMXf1h55bM04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eHunyuan-Large\u003c/a\u003e, a mixture-of-experts model with\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nr03qgyTW7lCdLW6lZ3lbW5FKXmK8qtkTRW3jmYs64Pwr52W53cQ4v9cMC8gVd4fj58qNqhtW6tsdxP2NlscfW5llnS31wpcPBW4rJ8Tb8-SGszW5yPld88PXmbTW2DfZm645CNxHW8LjhwC5Hcc7FW5V9T808hXwFTW8K86Mt294qtXW4D91557FQjVFW6Clrbq15DJj-W5v1B8t6V01Q3W71dJTt8lnR7lN6pMcP3K9dk1W4VSHlX4sg_T8Vb24Yh1D33P5W1Fpzyt4_SLGDW1Q_XQ62nbnjhW7cbPMK14NWznW7g-G8732VTy_W5rv_qY8whLjYf3_zDlj04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eopen code\u003c/a\u003e\u0026nbsp;and\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nr03qgyTW7lCdLW6lZ3mNVKYjtm3jr2v2W177hkd5_prBdW2v4RxS4_SZz9W5DjKpG5ZszWgW1c2fq27rMnjgW4Cr23C5cVhljW7jk9-h2m__5RW3qHqYk2wvhS5W892w8c7cvc1JN7HZrhyKVMrFW1jZ8Cx1Kxs-QW5Jwr8t4l-B9VW21rZXf5m65t1W3lk7BW1ZMW99W8cP5wV7CNQ0ZW3X16Gm638GPwW3jYjkq1KjPWvW2ZXhKj6KPnXvW8v5QqW8cwFXXW1qG1GQ1bg3W7W2spqxV8D_V6vW4pGYGt3KsvTJW2DmQBp217zRyW1QKqWm94Dcpvf2v7VSz04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eopen weights\u003c/a\u003e. It comes in base and instruction-tuned versions, both of which can process a relatively large input context window of 256,000 tokens. It’s free for developers outside the European Union who have fewer than 100 million monthly users. You can experiment with it\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nr03qgyTW7lCdLW6lZ3mzW4GV1mJ2nZ1XGN55JtJ6gSkVMW1dRKN_9jbMbGW2ScslH7jXCPQW3KHjRD7s2d94Vy_9Vt21mhJhW3Bct352CWJM0W3SNyl53l9cY2W33-dhH2mXC0bW5t85Rq4YYHf8W6dlWsT4LNtN7W7Q_DhL8f0zx6W7jnSjT7DW7y2W7PgTxH1tzt68VhYj0b5lln38F1JlVBzG5XwW7wYmfP6trTr4W97Ftg38jJs-5W7VGM7f44xtvZVbLC-l6jSg0bW5WMn904gMF1HN5wxnNsD0-1DW6RyZ1v47nyvlW55wXVx79tDqKf5NJWX204?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eMixture of experts (MoE) basics:\u003c/strong\u003e\u0026nbsp;The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Hunyuan-Large comprises 389 billion parameters but uses 52 billion parameters to process any given input. The team pretrained the model on 7 trillion tokens primarily of English and Chinese text, of which 5.5 trillion tokens came from unspecified sources and 1.5 trillion synthetic tokens were generated by unspecified large language models. The models used to generate training data were “specialized” to provide expert-level responses in various domains. The team fine-tuned Hunyuan-Large on unspecified datasets of instructions and human feedback.\u003c/p\u003e\u003cul\u003e\u003cli\u003eMoE models typically select which expert(s) to use based on the input. Hunyuan-Large chooses one of 16 experts, but it also uses a shared expert — an expert that processes every input.\u003c/li\u003e\u003cli\u003eRecent\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NqK3qgyTW6N1vHY6lZ3nhW3FPqlQ48wC4RW8v8bcR3WYzs2W8z8Qmr5v8XXLW1q38-w4DprYvW959C6n2ywsvqVy_lNG8-KVdbW1tSnBv212bfCW5Jhk8R9brXWFW3H2HbT1kxRqlW2Rmyh-3Dy2kVW7SdFBJ70Xk_kN4MhXrhDXcWJW3dYbd48YZvQMW9gRHJx5QK5-SW3YWSLj7RCWkXW2lcRy57qw7XyW1w7bhr3b6XdhW25L-d-7dv__4VDYnD7384ByDW59yjjT5_1X_BW8Jtc9m1j8K_8W4qh_yQ95bqd5f7tKV8-04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eresearch\u003c/a\u003e\u0026nbsp;showed that there is a formula for the optimal learning rate based on the batch size (the number of examples a model sees during one training step). The shared expert and the chosen expert see a different amount of data in each training step, so the team modified the learning rate for the chosen expert based on that formula.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The team compared the Hunyuan-Large models to four open source models and their instruction-tuned versions: Llama 3.1 70B, Llama 3.1 405B, and the MoE models Mixtral-8x22B and DeepSeek-V2.\u003c/p\u003e\u003cul\u003e\u003cli\u003eHunyuan-Large achieved the best performance on 15 of 19 benchmarks that test English, Chinese, math, and coding proficiency. For example, on\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NqK3qgyTW6N1vHY6lZ3mdN1p1s0X85CX9W4q0BTZ4stSbgN8nNRZGN6HKqW18dSDL4b4nvLW87S-k236YCP5W4mfP004Jl-jbW5ZxZV-9fYYbDW52G06p20v27mW78MRSZ6GcdZHW8lWhNc7pZjdyW4mmLZ53xHWFhW3GTYys6plZQTW6CvRFb23zjzFW20f3Y57D-lCqW7xf0M_7TspxsW6QtXVP4WPS-JW3GHFZg6rSTtNW4NydW23fVW9qMnMRz0VFkBtW8k4zHN6BJ20MN4ySCdtggXpKN2NNXz214rq2f2ZXJK004?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMMLU\u003c/a\u003e\u0026nbsp;(answering multiple choice questions in topics including elementary mathematics, history, computer science, and law), Hunyuan-Large achieved 88.4 percent accuracy. The next-best competitor, Llama 3.1 405B, achieved 85.2 percent.\u003c/li\u003e\u003cli\u003eThe instruction-tuned version achieved the best performance on 10 of 13 benchmarks including measures of instruction-following ability and alignment with certain human preferences. For instance, Hunyuan-Large-Instruct maintained its dominance on MMLU (89.9 percent accuracy to Llama 3.1 405B Instruct’s 87.3 percent accuracy). On AlpacaEval 2, an instruction-following benchmark, Hunyuan-Large-Instruct achieved 51.8 percent, while the next-best competitor, DeepSeek 2.5 Chat, achieved 50.5 percent.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Hunyuan-Large generally outperforms Llama 405B, achieving the performance of a 405 billion parameter model while computing only 52 billion parameters. That’s a significantly lower processing requirement, and the model is free for many purposes.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Setting aside\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nrj3qgyTW7Y8-PT6lZ3mbW2f723G6HLKtlW5c3ff99fP1lwW7wFwNb7XrMl1N659MSJL-D-7W50VHxx4B9h7RW5C9-rk3bqJmwW1SBbth5b9ZCsW5FW-lM5FgGp4W4s1dJy5ZDmTxW52QcRZ5PycGZW1hVn1L1JWrh5W8M41Y65123FqW5cxLBL8Z3VQtW65zkpZ8mr4whW2RCQ2m5XkpCKW92MGCS60VFpbW5hZ5Zg4-NxhnW33xM3J7t18thVKHBGc6SwjYFW2kcT1d3wSHhKW72z69Z75dbZNW5bmp4345HJY5W5n_p0t8thF4DW9czfQb5zqFbYN3bfjdDjSjY2VPhrj73dZ6fXf5F37rF04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eSwitch Transformer\u003c/a\u003e\u0026nbsp;— a 1.6 trillion parameter behemoth that was built to test the limits of size rather than performance — Hunyuan-Large is among the largest MoE models we’ve come across. It’s an impressive demonstration of what larger MoE models can accomplish.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--34-.jpg\" class=\"kg-image\" alt=\"Llama wearing a camouflage helmet, looking determined with a light blue background.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/unnamed--34-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/unnamed--34-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--34-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"big-ai-pursues-military-contracts\"\u003eBig AI Pursues Military Contracts\u003c/h1\u003e\u003cp\u003eTwo top AI companies changed their stances on military and intelligence applications.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Meta made its Llama family of large language models\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3mvW16zLw45RVbdGW7m7sdM2n9G8xN6kGXmx63s5RW7vX_3s2DPQb8W6GS2m76prYlmW59L4p34CD9XvW3Yc8m36G0PdtN8-PkHhXwfMVV_lVFd92xRMcW8Bs6WN7GmSRqW1T1w3d6-ZhxXW4GYsvH29jzJRW8FhSBs4w-NjzW7HrqFM8ZtmXDW1834lC3GShgkW8PfH_x5DLTFXW690ZW671pJhcVGrbLs7j_Rn9W3LW6tG95Jc0kVLPKS12CNkKDV5s2w_8kcj4sN5-396QyB4fZVDBHJ26w5PRLVGLsvV6lm9MlW6sMdZF1zl6WGW5StJN643CHYZW89yYKq8nBKnDW7VslWn2DvX_Mdj9TsC04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eavailable\u003c/a\u003e\u0026nbsp;to the U.S. government for national security purposes — a major change in its policy on military applications. Similarly, Anthropic will\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nr05nR32W7lCGcx6lZ3m4W6Hp_NY2zykBDW30CZ898GhmYzW6NMrM82-Yxj_W4Kyxlh6GjXx3MDQ2Ml1cHBFW2ncD4d1y076vW7YgqsY8m0lmVVb5FnL5d97t8W6z2vrV4F-CKZVCkGDn4hpk2gM-qpzHQDDDBW8dMlxk3g5zh9W5zz4Qn1MZdBwW4cBJcX46PT0-N7j4wnhNBYw-W40dxhx51LD8MW63BJ-g2JvJD8W40QjL-3rcl4VW1f8qr34Lm5g7W4RH1XD27gFFhW6Xyl6P7D39JsW2K04Vs8M7rfJW6VWYXB71sxzKW2-K-h12txwjWVzWWJM48DrMYW4ZCBwh70RgJzW11QDmn6sfcyTW2trX-b7mrXGfW6hT93m53FDxQN8JRmM9xRxQYW4jwFmK5vFKc8W1-l9fG2XPJZnW1jZrBc7PGLT6W1LMqvv1FfnDjW9gG79r4qMJZmW6mbbQB13SLGKW4yWfS12GRZmGW1lcG9p7xPXHrN3Gz8qkv45dKW7CfhKK5ktKnyf6z3-hz04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eoffer\u003c/a\u003e\u0026nbsp;its Claude models to U.S. intelligence and defense agencies.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Meta and Anthropic are relying on partnerships with government contractors to navigate the security and procurement requirements for military and intelligence work.\u003c/p\u003e\u003cul\u003e\u003cli\u003eMeta’s partners in the defense and intelligence markets include Accenture, Amazon, Anduril, Booz Allen, Databricks, Deloitte, IBM, Leidos, Lockheed Martin, Microsoft, Oracle, Palantir, Scale AI, and Snowflake. These companies will integrate Llama models into U.S. government applications in areas like logistics, cybersecurity, intelligence analysis, and tracking terrorists’ financial activities.\u003c/li\u003e\u003cli\u003eSome Meta partners have built specialized versions of Llama. For example, Scale AI\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NqK3qgyTW6N1vHY6lZ3mTW5zpP9v4VjBwHN8xGybGW4VjTW4Ggwqm4SKvj3W4FLw4M34NhllN1V7k6230xWZW4_rgjD2LYLGwVbW3HW53MV16N5Pg3JSKKGnDW6hL8Yt5RMgLQN3ZsQPdJmDG0Vqmqb96_Y8vdW8ZVVQ-2zFG5fW56bWYw94LFYMW2_Q_KP6znhnqW8812ZQ7v5827V3DYjX6kRj9bW4wvVR86ycsc8V7Jr4k8-4lksW8rqtj7509qY5W6mBNq72Nj2DPW5rd1435YZNWGW8F6dw46qLxtff7nchQP04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003efine-tuned\u003c/a\u003e\u0026nbsp;Llama 3 for national security applications. Called Defense Llama, the fine-tuned model can assist with tasks such as planning military operations and analyzing an adversary’s vulnerabilities.\u003c/li\u003e\u003cli\u003eAnthropic will make its Claude 3 and 3.5 model families available to U.S. defense and intelligence agencies via a platform built by Palantir, which provides big-data analytics to governments, and hosted by Amazon Web Services. The government will use Claude to review documents, find patterns in large amounts of data, and help officials make decisions.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;In 2018, Google faced\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3kDN1smYL-QXgkpW7ZTQwx40ftB2W8WBV5M3FmjxJW3HS-KT1JzBBTW2gxzQ23jcRkXN6Fy2nNNqxFHW3WzrQT74CBn-N1D7tnX26f67VMYh5n89y1flW2Z1pFQ7WFJrVW7YbR5s9f3G81W2MbB0k8zgMKyW1wFt_j8n5ckSW1NQn0T5W4bmjW6TXZHd4R7rVkW9h8TxX4JfGwcW5R7hC831L08KW5h5Bl59cWh0sW1DTXGj732F49W1RTxxv4gfq3jW5TjRf95s1nDJN43Pcdb-7qB3W2xqBrL52G0lWW39G2Pv51zk32W67DNDM7KjspDW64LQb6435-wZN7t5Pj2gKNGdW6VzLlG25f1jpf6mT8gR04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ebacklash\u003c/a\u003e\u0026nbsp;when it won a contract with the U.S. government to build\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8Nq65nR32W5BWr2F6lZ3pKVVv5x523vP5RVBTKYS5294FcW2xlSBw7_fN8JW4tC1Qt4gGXfRW2cqPW25h7_zxW4Bf18744sg6hW5ZhTSz8L_90pW2d2yPK33sJ5wW2smJt48M5LYJW2T8gJx1NM-J4W5gQh5F26mLw-W7mlcsN657nLhW2N7tCG8BpLLdW31h-G22dCX2xW4crvgx8sn2-mW3_z14h475DbfW88KWNw4RQMhFW6NXGXP4WGsdXW7PW9gq8Mf4fwW4YmyRQ5bzGP0N6DtPn66bFbKW6lZD_Z4MXPN3W6ZJ9dl70gr-FVHnNq52Xj8dFW3fDGff8LjVJkW1C5H_76WTmhBW7v2zBC6vtqPTW4416341bG4tZW5Kc8cz244p1bW1_K_CS3ctRm0W2DWNSB8dpGFRW2szw553v2nXzW1nY_lP7N-Dy7W40rX6w6TDVMRf6zBlPn04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eProject Maven\u003c/a\u003e, an AI-assisted intelligence platform. Employees protested, resigned, and called on the company to eschew military AI work. Google\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3kFV_7DLb61GGmlW2l9cWj8w_qr5W1RXCK71ZH8qRW3bcglT83cfm5W1dKQsj46bQdYW6vcSRG6-r3VKW80LxDD5j5nf5W82GQqq6L06GYW19Xxny5x5lj3W7_TLnw6j3N31VQGvw471fjnfVdJMJN10GfTWW3yslvH1GLZ7CW7NnCzG57PsfMW1HYjBK8s7N83W6wZ7857CDH-WW5kkBlz62_zqSW16Qhn954DQ-VW85kDkG6jlg9ZW3FYmwr9hP3GJW9g-VQy3-RxfkW71GzSg5y1ZFWW3jPXhC264F2NW9hMG0N48wDbTN8jZrX54wVf3W7X7Kr41050f9W2zZXGQ5KNMt8W7zbmTC7zFJ8ff5Z7NLb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ewithdrew\u003c/a\u003e\u0026nbsp;from the project and Palantir took it over. Subsequently, many AI developers, including Meta and Anthropic, have forbidden use of their models for military applications. Llama’s new availability to U.S. military and intelligence agencies is a notable exception. In July, Anthropic, too, began to\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrC3qgyTW8wLKSR6lZ3kRW6TWPkz7y3pP9W8rGbzZ5NHGJCW1fG0Qq5D71GCVhbwWK5gqS6VW3C3WkY2ZYfHzW4n2hfH24pBHcW2yjgBn1sWs2_W8wXsKZ25Gqg1W5q5djG1K9WtSN1HBkXNC6tg3W3XB0Hr83qWk4W6FJX1h9fRjfxW7R8Dt71C36DwW5GMpF82Ty-KtW83zG2d6wbK76W4zlLsq2K7fLjW5Yn43Q314GX-W11Pzwx94dS8wVpwTR931RkjlW1kF0q32MkwgDN1wLZvvDGK3bW4wJL_h2Vx8t6VGWD062TnMxLW15Nmyy92Y6sWW4nd_p-22pqj4W2-cbGS5gR7rjW31KYws6HFhG6W6L_FM71HpdQhf1vtG-404?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eaccommodate\u003c/a\u003e\u0026nbsp;use of its models for intelligence work. Anthropic still prohibits using Claude to develop weapons or mount cyberattacks.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;The shift in Meta’s and Anthropic’s policies toward military uses of AI is momentous. Lately AI has become a battlefield staple in the form of weaponized\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrW3qgyTW95jsWP6lZ3p3W7gFlL349tqgRVMMxNc92YX7BW24RDlS8CYbzdW18cBFc3RZ_DPW6r-Xm36Bdh0sW3rtp0G1HycmgW1Czy7s2TlgFSW20gTv813G83kN8YbM8Glzh3lW5f_jp74w8NGLW5VG_JW8QxcsSW5P4lw364QGzSW4_8f2H6gppMkW98TTYS3J71-ZW5bhJNv38h8yXW5wZ_576kycDbW3y8bKM3_hqP4W2yW1RM2fgmc9W1BzjL88t9nWMW5BR-2h2Wm9FlW5W0r3y4W0VZLW61k3-q7MvZ6VW2FCb7H7y4f_dV2BvGf5KwqTSN75vskMNlQkJW22fH414GCZh9N8vngLNqR08_W2CwjfX3fXY45W1hRGrq51wXNzW42Pgyg32tHJ7f3PTmGF04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003edrones\u003c/a\u003e, and AI companies must take care that their new policies are consistent with upholding human rights. Military uses for AI include not only weapons development and targeting but also potentially life-saving search and rescue, logistics, intelligence, and communications. Moreover, defense contracts represent major opportunities for AI companies that can fund widely beneficial research and applications.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Peace-loving nations face difficult security challenges, and AI can be\u0026nbsp; helpful in meeting them. At the same time, the militarization of AI brings challenges to maintaining peace and stability, upholding human rights, and retaining human control over autonomous systems. We call on developers of military AI to observe the\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/MVp0LvSc0nYW6xhyn28R_q6BW3rtmkr5nlxzXN6B8NrW3qgyTW95jsWP6lZ3m_W22dTxm1b_DD7W2XnpvT3FV_qkW28XPln7JVFb0V45H943lqR88W8ZZkz95pr2gBW6h_-bG7nbJfRW6mQzRK5yTQL5W8Z3W215p04hNW1B1qR71x56ggW6kx1C88XdRSpW5t-8374S42B7W52kQQn3j65LcW4P5Ll67PBGxlW7LqZkJ6hTG-DW5Hzp9y8b4MC5W7mT_lD1CVXk_W6DC-dK32QfVyW6z54K35vxlyhW4WCwnQ256j-LW21NK0J5q4H2PW4xxGb55G6s2PVPbBYC4S8mTBW4bL4Gq8NBsFGW6HcTSv3WQLcLW3C1ZFS30kCx5W6N2fxD3n0jxcW3B4q5b6Ym6_LW6Lz5yf2NxVMJN5WrN8tpHM0TW3tDTbV5t7zWHf3cGpT004?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eguidelines\u003c/a\u003e, proposed by Responsible Artificial Intelligence in the Military, which are endorsed by more than 60 countries and call for robust governance, oversight, accountability, and respect for human rights.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--28-.gif\" class=\"kg-image\" alt=\"User entering ZIP code ‘94103’ in U.S. General Election ballot lookup to view contests and candidates.\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--28-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"voter%E2%80%99s-helper\"\u003eVoter’s Helper\u003c/h1\u003e\u003cp\u003eSome voters navigated last week’s United States elections with help from a large language model that generated output based on verified, nonpartisan information.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Perplexity, an AI-powered search engine founded in 2022 by former OpenAI and Meta researchers, launched its\u0026nbsp;\u003ca href=\"https://www.perplexity.ai/elections/2024-11-05/us/president?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eElection Information Hub\u003c/a\u003e, an AI-enhanced website that combines AI-generated analysis with real-time data. The model provided live updates, summaries, and explanations of key issues in the recent national, state, and local elections in the U.S. (The hub remains live, but it no longer displays information about local contests or delivers detailed results for election-related searches.)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Perplexity partnered with Associated Press for election news and\u0026nbsp;\u003ca href=\"https://www.democracy.works/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eDemocracy Works\u003c/a\u003e, a nonprofit that develops technology and data related to democracy. Democracy Works provided an\u0026nbsp;\u003ca href=\"https://data.democracy.works/api-info?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eAPI\u003c/a\u003e\u0026nbsp;for information about elections, issues, and polling locations.\u003c/p\u003e\u003cul\u003e\u003cli\u003eUsers could search by candidate, issue, state, district, or postal code. For example, searching a\u0026nbsp;postal code returned AI-generated summaries of local races, measures, or other ballot issues drawn from vetted sources such as Ballotpedia, a nonpartisan clearinghouse for election information. A chatbot window enabled users to ask questions and drill down on citations of information sources.\u003c/li\u003e\u003cli\u003eInitial testing by\u0026nbsp;\u003cem\u003eThe Verge\u003c/em\u003e\u0026nbsp;\u003ca href=\"https://www.theverge.com/2024/11/3/24287157/perplexity-ai-election-voting-information-tracking-hub-us-presidential-election-2024-trump-harris?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003erevealed\u003c/a\u003e\u0026nbsp;problems with accuracy in AI-generated summaries. These included outdated information (for example, summaries failed to consistently note Robert F. Kennedy Jr.’s withdrawal from the presidential election), mistakes in candidate profiles, and mishandling of write-in candidates. Perplexity eventually fixed many of the errors.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u0026nbsp;\u003c/strong\u003eWhile Perplexity courted demand for AI-generated information about the U.S. elections, other search-engine providers took more cautious approaches. You.com offered an election chatbot that\u0026nbsp;\u003ca href=\"https://you.com/articles/you.com-and-tollbit-launch-first-ai-election-agent-with-real-time-results?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003efocused\u003c/a\u003e\u0026nbsp;on vote tallies provided by Decision Desk HQ, an election information broker, rather than information about issues or polling locations. Google and Microsoft Bing emphasized information from vetted sources. Microsoft Copilot and OpenAI (which had launched its SearchGPT service the week before the election) simply declined to answer election-related questions, referring users to other sources of information.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Chatbots are maturing to the point where they can provide fairly trustworthy information in high-stakes decisions like elections. The combination of web search and retrieval-augmented generation contributes to decision support systems that are both personalized and accurate.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Perfect information is hard to come by in any election. Traditional media, social media, and your uncle’s strongly held opinions all have limitations. Chatbots aren’t perfect either, but when they’re properly designed to avoid biased output and outfitted with high-quality information sources, they can help strengthen users’ choices and voices.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--29-.gif\" class=\"kg-image\" alt=\"OpenDevin animation illustrating open-source AI model collaboration.\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--29-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"free-agents\"\u003eFree Agents\u003c/h1\u003e\u003cp\u003eAn open source package inspired by the commercial agentic code generator Devin aims to automate computer programming and more.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2407.16741?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eOpenHands\u003c/a\u003e, previously known as OpenDevin, implements a variety of agents for coding and other tasks. It was built by Xingyao Wang and a team at University of Illinois Urbana-Champaign, Carnegie Mellon, Yale, University of California Berkeley, Contextual AI, King Abdullah University of Science and Technology, Australian National University, Ho Chi Minh City University of Technology, Alibaba, and All Hands AI. The code is free to\u0026nbsp;\u003ca href=\"https://github.com/All-Hands-AI/OpenHands?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003edownload\u003c/a\u003e, use, and modify.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;OpenHands provides a set of agents, or workflows for the user’s choice of large language models. Users can command various agents to generate, edit, and run code; interact with the web; and perform auxiliary tasks related to coding and other work. The agents run in a secure Docker container with access to a server to execute code, a web browser, and tools that, say, copy text from pdfs or transcribe audio files.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe CodeAct agent follows the\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2402.01030?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eCodeAct\u003c/a\u003e\u0026nbsp;framework, which specifies an agentic workflow for code generation. Given a prompt or results of a code execution, it can ask for clarification, write code and execute it, and deliver the result. It can also retrieve relevant information from the web.\u003c/li\u003e\u003cli\u003eThe browsing agent controls a web browser. At every time step, it receives the user’s prompt and a text description of each element it sees on the resulting webpage. The description includes a numerical identifier, words like “paragraph” or “button” (and associated text), a list of possible actions (such as scroll, click, wait, drag and drop, and send a message to the user), an example chain of thought for selecting an action, and a list of previous actions taken. It executes actions iteratively until it has sent a message to the user.\u003c/li\u003e\u003cli\u003eA set of “micro agents” perform auxiliary tasks such as writing commit messages, writing Postgres databases, summarizing codebases, solving math problems, delegating actions to other agents, and the like. Users can write their own prompts to define micro agents.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;Overall, OpenHands agents achieve similar performance to previous agents on software engineering problems, web browsing, and miscellaneous tasks like answering questions. For example, fixing issues in Github in\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2310.06770?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eSWE-Bench\u003c/a\u003e, the CodeAct agent using Claude 3.5 Sonnet solved 26 percent while\u0026nbsp;\u003ca href=\"https://github.com/aorwall/moatless-tools?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eMoatless Tools\u003c/a\u003e\u0026nbsp;using the same model solved 26.7 percent. On\u0026nbsp;\u003ca href=\"https://arxiv.org/pdf/2311.12022?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--3_3lBeuiKbim8poHVfF48g7xluhnGimY9mLw2h7Nss4N66sjZfw9dHlS-NoEBnjLgPL-n\" rel=\"noopener\"\u003eGPQA Diamond\u003c/a\u003e, a set of graduate-level questions about physics, chemistry, and biology, the CodeAct agent using GPT-4-turbo with search wrote code to perform the necessary calculations and found relevant information to answer the questions, achieving 51.8 percent accuracy. GPT-4 with search achieved 38.8 percent accuracy.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Agentic workflows are rapidly expanding the scope and capabilities of large language models. As open source software, this system gives developers an extensible toolkit for designing agentic systems. Although it’s oriented toward coding, it accommodates a variety of information-gathering, -processing, and -publishing tasks.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;This system lets users tailor custom agents simply by rewriting prompts. We look forward to seeing what non-programmers do with it!\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai-1\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/llms-as-operating-systems-agent-memory?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png\" class=\"kg-image\" alt=\"Promo banner for \u0026quot;LLMs as Operating Systems: Agent Memory\u0026quot;\" loading=\"lazy\" width=\"1890\" height=\"1063\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/11/The-Batch-ads-and-exclusive-banners---2024-11-12T092833.534.png 1890w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eBuild AI applications that have long-term agentic memory! Our short course “LLMs as Operating Systems: Agent Memory” is based on insights from the MemGPT paper and taught by two of its coauthors. Learn how to implement persistent, efficient memory management for applications based on large language models.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/llms-as-operating-systems-agent-memory?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eEnroll for free\u003c/a\u003e\u003c/p\u003e","comment_id":"673501273ea32c00011e21f8","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33--1.jpg","featured":false,"visibility":"public","created_at":"2024-11-13T11:42:31.000-08:00","updated_at":"2024-11-13T15:58:00.000-08:00","published_at":"2024-11-13T11:54:00.000-08:00","custom_excerpt":"The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"673504713ea32c00011e2243","name":"Nov 13, 2024","slug":"nov-13-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/nov-13-2024/"},{"id":"673504713ea32c00011e2244","name":"issue-275","slug":"issue-275","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-275/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-275/","excerpt":"The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions.","reading_time":12,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Llama On the Battlefield, Mixture of Experts Pulls Ahead, Open Agentic Platform, Voter Support Chatbot","meta_description":"The Batch AI News and Insights: Large language models (LLMs) are typically optimized to answer peoples’ questions.","email_subject":null,"frontmatter":null,"feature_image_alt":"Man with tools says, “I optimized for tool use!” Woman at computer replies, “Should’ve optimized for computer use!”","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/11/unnamed--33--1.jpg","dimensions":{"width":1200,"height":676}},"banner":{"title":"Data Engineering","databaseId":35522,"id":"cG9zdDozNTUyMg==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2024/10/DE-Vertical-2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://bit.ly/4eQA3NM","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-275"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>