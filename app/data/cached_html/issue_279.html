<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs</title><meta name="description" content="The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-279/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-279/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2024-12-11T12:50:00.000-08:00"/><meta property="article:modified_time" content="2024-12-22T12:36:12.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="Dec 11, 2024"/><meta property="article:tag" content="issue-279"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-279/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38--1.jpg"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38--1.jpg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="676"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2024-12-11T12:50:00.000-08:00","dateModified":"2024-12-22T12:36:12.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38--1.jpg","width":1200,"height":676},"publisher":{"@type":"Organization","name":"Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-279/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 279</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Dec 11, 2024</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">14<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/dec-11-2024/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Dec 11, 2024</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">14<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-279/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-279/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-279/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc">
<!--kg-card-begin: html-->
<div id="elevenlabs-audionative-widget" data-height="90" data-width="100%" data-frameborder="no" data-scrolling="no" data-publicuserid="e20b5cfed36900db239c005920538f20ce435963e95a0a4106d34bdd6bf0e46d" data-playerurl="https://elevenlabs.io/player/index.html" >Loading the <a href="https://elevenlabs.io/text-to-speech?ref=dl-staging-website.ghost.io" target="_blank" rel="noopener">Elevenlabs Text to Speech</a> AudioNative Player...</div><script src="https://elevenlabs.io/player/audioNativeHelper.js" type="text/javascript"></script>
<!--kg-card-end: html-->
<p>Dear friends,</p><p>AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications. This is making it possible to build new kinds of things, which in turn is driving shifts in best practices in product management — the discipline of defining what to build to serve users — because what is possible to build has shifted. In this letter, I’ll share some best practices I have noticed.</p><p><strong>Use concrete examples to specify AI products.</strong>&nbsp;Starting with a&nbsp;<a href="https://www.deeplearning.ai/the-batch/concrete-ideas-make-strong-ai-startups/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--Eqm_4XfMsvT6wPKNDMd230B1utOFB2bNF_Fwr6VDghY4piRLWWELt22IvV9osotn89tB_" rel="noopener">concrete idea</a>&nbsp;helps teams gain speed. If a product manager (PM) proposes to build “a chatbot to answer banking inquiries that relate to user accounts,” this is a vague specification that leaves much to the imagination. For instance, should the chatbot answer questions only about account balances or also about interest rates, processes for initiating a wire transfer, and so on? But if the PM writes out a number (say, between 10 and 50) of concrete examples of conversations they’d like a chatbot to execute, the scope of their proposal becomes much clearer. Just as a machine learning algorithm needs training examples to learn from, an AI product development team needs concrete examples of what we want an AI system to do. In other words, the data is your PRD (product requirements document)!</p><p>In a similar vein, if someone requests “a vision system to detect pedestrians outside our store,” it’s hard for a developer to understand the boundary conditions. Is the system expected to work at night? What is the range of permissible camera angles? Is it expected to detect pedestrians who appear in the image even though they’re 100m away? But if the PM collects a handful of pictures and annotates them with the desired output, the meaning of “detect pedestrians” becomes concrete. An engineer can assess if the specification is technically feasible and if so, build toward it. Initially, the data might be obtained via a one-off, scrappy process, such as the PM walking around taking pictures and annotating them. Eventually, the data mix will shift to real-word data collected by a system running in production.</p><p>Using examples (such as inputs and desired outputs) to specify a product has been helpful for many years, but the explosion of possible AI applications is creating a need for more product managers to learn this practice.</p><p><strong>Assess technical feasibility of LLM-based applications by prompting.</strong>&nbsp;When a PM scopes out a potential AI application, whether the application can actually be built — that is, its technical feasibility — is a key criterion in deciding what to do next. For many ideas for LLM-based applications, it’s increasingly possible for a PM, who might not be a software engineer, to try prompting — or write just small amounts of code — to get an initial sense of feasibility.</p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.jpg" class="kg-image" alt="Cartoon showing people stuck in wet concrete, with a person saying ‘You asked for a concrete idea!’" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--38-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--38-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><p>For example, a PM may envision a new internal tool for routing emails from customers to the right department (such as customer service, sales, etc.). They can prompt an LLM to see if they can get it to select the right department based on an input email, and see if they can achieve high accuracy. If so, this gives engineering a great starting point from which to implement the tool. If not, the PM can falsify the idea themselves and perhaps improve the product idea much faster than if they had to rely on an engineer to build a prototype.</p><p>Often, testing feasibility requires a little more than prompting. For example, perhaps the LLM-based email system needs basic RAG capability to help it make decisions. Fortunately, the barrier to writing small amounts of code is now quite low, since AI can help by acting as a coding companion, as I describe in the course, “<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4HzmfH3qgyTW7Y8-PT6lZ3lYW366bW34PBtQRW6Wkd-k7PwcdwW14_2YN81Tn-yW5t7CqF3SNF94VWKqBH5rby5QW64ct3m6yR4VZW18BSTt9jQmJKW6-_6J77-R-2rW5kQBLL8b78lFW2P4_QF4GHgYXW29wFH-7hgGRDW3wyzhL3p6GkzW66bcJP2LjtMYW424vZP4HzRhpW6jP8fY14mB7mW31BVsj6XJqNgW17mrQ510wZC4W1Vk4Vg15WDD0N30kx6Z1zKs0N87bJ3Qyn97MVxkGq44XLlD8N6k64JcgfB0_W2BLkrS2rpvqfW4-Lbdm4KBP-VW6vY4b-5xQSxMW22xtDG1ghL_4f96h33b04?ref=dl-staging-website.ghost.io" rel="noopener">AI Python for Beginners</a>.” This means that PMs can do much more technical feasibility testing, at least at a basic level, than was possible before.</p><p><strong>Prototype and test without engineers.</strong>&nbsp;User feedback to initial prototypes is also instrumental to shaping products. Fortunately, barriers to building prototypes rapidly are falling, and PMs themselves can move prototypes forward without needing software developers.</p><p>In addition to using LLMs to help write code for prototyping, tools like Replit, Vercel’s V0, Bolt, and Anthropic’s Artifacts (I’m a fan of all of these!) are making it easier for people without a coding background to build and experiment with simple prototypes. These tools are increasingly accessible to non-technical users, though I find that those who understand basic coding are able to use them much more effectively, so it’s still important to learn basic coding. (Interestingly, highly technical, experienced developers use them too!) Many members of my teams routinely use such tools to prototype, get user feedback, and iterate quickly.</p><p>AI is enabling a lot of new applications to be built, creating massive growth in demand for AI product managers who know how to scope out and help drive progress in building these products. AI product management existed before the rise of generative AI, but the increasing ease of building applications is creating greater demand for AI applications, and thus a lot of PMs are learning AI and these emerging best practices for building AI products. I find this discipline fascinating, and will keep on sharing best practices as they grow and evolve.</p><p>Keep learning!</p><p>Andrew</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/collaborative-writing-and-coding-with-openai-canvas/?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png" class="kg-image" alt="Promo banner for &quot;Collaborative Writing and Coding with OpenAI Canvas&quot;" loading="lazy" width="1680" height="945" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 1680w" sizes="(min-width: 720px) 720px"></a></figure><p>Write and code more effectively with OpenAI Canvas, a user-friendly workspace for collaborating with AI. In this free course, explore use cases like building game apps and designing SQL databases from screenshots, and gain insights into how GPT-4o powers Canvas’ features.&nbsp;<a href="https://www.deeplearning.ai/short-courses/collaborative-writing-and-coding-with-openai-canvas/?ref=dl-staging-website.ghost.io" rel="noreferrer">Join for free</a></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--36-.gif" class="kg-image" alt="Berkeley Function Calling Leaderboard with metrics like accuracy, latency, and relevance." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--36-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--36-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--36-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="competitive-performance-competitive-prices">Competitive Performance, Competitive Prices</h1><p>Amazon introduced a range of models that confront competitors head-on.</p><p><strong>What’s new:</strong>&nbsp;The&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdv5nR32W5BWr2F6lZ3pHW98tKVM9h8gZfW63HtBL8N30bJW25KwPF6lQ7T4W3jFfzj6wrp79W6Mp8MD5HX5bWVZHrpq8jD1mrN3Rt4CwtC8NgW27cjdP58q1YxW2YW6g03MmPv0W6T3J052zSYtsN3G872BFR4fPN1YfKLDvkcsvW6h9ZqT1Bvs3xN860NNtMdRPhW4cBR4d5sV7l6W6KwXB95pYmNqW4h5h745zT4X5W2PqfgN5zy8JTW45GzZ-2XKrqdW3qg8Z_3MKfCcW2_5FrD2HPYvzW2_ntTR20cwNXW8yNwWF353pVWTMznl8Z9758W6R4vzp1s4pd6W4HmnMG3y33T7VpjHFG79npRpW3H77Kn7pq71CVC3P7Z8gBmGqW6CrXWj5m_q1bW1LgP712qTXjrW64Z_ZB6x9LvFW8gqyb28g-pW3W6kXMcH4dTvS6f6KwPzx04?ref=dl-staging-website.ghost.io" rel="noopener">Nova</a>&nbsp;line from Amazon includes three vision-language models (Nova Premier, Nova Pro, and Nova Lite), one language model (Nova Micro), an image generator (Nova Canvas), and a video generator (Nova Reel). All but Nova Premier are&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lrW3lhZCM3nYVfSMhhFSLNYz8qW2GkrGV1M1pX8W43R0cx6BQC8RW3rN35587H06_W5fmw7C8TZYnfW2n0QXP552JlhN6rwqhhjckQLW94xH2k6FMbNLW8Td11D7T5jYkW1Qxc_t3D9d2HN42dW9RRhyRlN7Czn9hlwtXjW7GRb2825c4-VW38mHDz4rgSsjW4JsPys8dgry3W7jtMrY2nGSZQW12gqgC755sXBW2N-kvF1NwNl6W1D1B742c7mYwW7JgfGx6fLN-sN3RbsMCDh3x4VMHxbP6M9SRtN1SjvbybhpG9f3P8Rtb04?ref=dl-staging-website.ghost.io" rel="noopener">available</a>&nbsp;on Amazon’s Bedrock platform, and Nova Premier, which is the most capable, is expected in early 2025. In addition, Amazon plans to release a speech-to-speech model in early 2025 and a multimodal model that processes text, images, video, and audio by mid-year. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)</p><p><strong>How it works:</strong>&nbsp;Nova models deliver competitive&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdb5nR32W50kH_H6lZ3mbW4fdCNV65QDb8W5HL_y_93s5dgVjHRx355q56yW1Z65TH8cczlpVR9Svw61KqCsW3YXMvT2wyH9sW8CvMp14WzQVmW39p7Qx2cYVssW4DpMRv8ylrn-W8sYkWM6DhPg5VKn88N55w45sW65lBBF6HzlrJW7RbC_V2w_W7qW60B_Pw82xBYQN8W1Mmv3pGr5W3jG25F4KbRJ5W54FKxt7nxK8JW4zv0wb98WwD2W8Rz2DZ2Kw6TvW5b4sRx8vxLbXW7JCft34zsW_WW2ZV83v61qhzkW8NkfyG4NF0BgW2Jh6-C94KH7VW9hf5zg7TH11hN9h8Jm0klZJ4W6YgNjD333K55W5jfb_M2j22sjW8LCn2t4gxNR8W8VBHJF3G4tncW4Dn1r98-3scXVGKPKd6MKdWMf3Qqywv04?ref=dl-staging-website.ghost.io" rel="noopener">performance</a>&nbsp;at relatively low prices. Amazon hasn’t disclosed parameter counts or details about how the models were built except to say that Nova Pro, Lite, and Micro were trained on a combination of proprietary, licensed, public, and open-source text, images, and video in over 200 languages.</p><ul><li><strong>Nova Pro</strong>&nbsp;is roughly comparable to that of Anthropic Claude 3.5 Sonnet, OpenAI GPT-4o, and Google Gemini Pro. It has a 300,000-token input context window, enabling it to process relatively large vision-language inputs. Nova Pro outperforms its primary competitors in tests of following complex instructions (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3pkV-H8v67JsKKSW13QMcP4pTG_lN4K1bd8YGrN5W8t6rDX4YxZVWW7HGMPL287yGvW4Myqvt975HF9N4PVzqL1rKXSW2k0Fjf4dWPRSW7YyZkN7sNylLW4m1KTq6GTNVrW2swtX26ws_KVV26LBl969WdKW4tHthy6nh3ffW5lSsfW1DbGCFW6WLG3M4VNknjW5L_Q168gs_NwW5PnGpq8n1GFnW280ZnV47nQPVVRVD1N61RmYhW56rWC729h81QW72PJDc158Q2LW1njr6h7dtZ2Mf1GD1JK04?ref=dl-staging-website.ghost.io" rel="noopener">IFEval),<u>&nbsp;</u></a>summarizing long texts (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nkW5-072n8Bk1W7W7K0KyX1yRN49V_SZcN5GCHgTW7j7vQ_9gqhpRVJFfzQ2kv03WW8__MPc3Bjm4wW3QVRgb2sWcP6T4qV-8jy46kN6nj4gs1pLR2W4Vxlsj8gPqVBW8hMwj59gRFkqN8Zk4pDZyw_nW3Lm_kK3pTn8KN2Q3ZNvtSjzJW5Dt3rH45P4g_W3dcYW08DMt-TW2Pb_nT35PLzhW6YLJ-x89Ph1jW8rT2K-2ln9HzW126L4c2_CDrFW6j--BX9jX5ZdW2HLktw61t4Jnf4TcljW04?ref=dl-staging-website.ghost.io" rel="noopener">SQuALITY</a>), understanding videos (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3pKVXYbPZ4zrbTXW7jWy_72BlXnNVfrdW53VB2XYMRScsQTGD7vW5Q4Dch5Y5QKyLkSlxLNqkGW1mcxF24vRPrwW2fV0LK86VB9TW5mpnws5xt0cQW2DRL0_2hLFCJW4Zw-d22HC2ScW5c_5Y24LHwvpW4_BQP86YP7v8W2wtF3N7gF2zpW2gnv3H8_L70pW66lw6v7rWLSwW55-K2T8-jpJcN5F66P2mpscjW2vBTDQ4hKFlfW5PWYvh4ByjR9W8QkKXQ4nqvCLW6dhzG16L1Qmwf4_Q_2804?ref=dl-staging-website.ghost.io" rel="noopener">LVBench</a>), and reading and acting on websites (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3lwW345VXL8MyLkRN1g_w89_HJZXW5PsGL05y27KtW5LvgQ_57PRlMW4gp8sg5FYNDcW1wrvJ64Zl4-NW36bvqb21jNyhW5LBK704RN8ylW9bbm1t6qRjr8W6t7wBH6fgFdbW2b6HQg6cqbpwW8B8nBZ3C8z0MW7XjT5p28-nfxW89hLWS5nndsFW8RJ0ZS3KZ290W7NDVXn3SLqGLN6LmrQDzSMzYW6vqlJM7zcWY3W15dx__4kSRb8Vm_nXn4zlLV6W93q0-R3BptmjW6GGvVt2-LHt_f3jKTFR04?ref=dl-staging-website.ghost.io" rel="noopener">MM-Mind2Web</a>). It processes 95 tokens per second. At $0.80/$3.20 per million tokens of input/output, it’s significantly less expensive than GPT-4o ($2.50/$10) and Claude 3.5 Sonnet ($3/$15) but slower than GPT-4o (115 tokens per second).</li><li><strong>Nova Lite</strong>&nbsp;compares favorably with Anthropic Claude Haiku, Google Gemini 1.5 Flash, and OpenAI GPT-4o Mini. Optimized for processing speed and efficiency, it too has a 300,000 token input context window. Nova Lite bests Claude 3.5 Sonnet and GPT-4o on VisualWebBench, which tests visual understanding of web pages. It also beats Claude 3.5 Haiku, GPT-4o Mini, and Gemini 1.5 Flash in multimodal agentic tasks that include MM-Mind2Web and the&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3mMW3dwXYh7BJvWJW8Gv1mv65RNgdW9bBGXc40Bgy9W3bcnPn3lyknbN7Jw3QM_1JtmW257XTK5wWnJ2W2fFdNF6gZszPW8zvTPJ3-LYbxN8d9txFR-M02VkR84C3xQ5VRW1XBGmZ6LjnQPW1DC3061YvPqbW7BWfGf4t205ZVWfhZW3z2jdVW6FRVqW1Hw3DKW7-p-Qx7D8hWrW84jwLV8fl27KW425Mc-3bckJWN1XV80tGRKV0W8cYqbf5pCdt2W5d0D_63LJSNCW4QslLJ8wDN4cW5X-B1Z2XX_7BW6q5Hf23Hy663f59H93b04?ref=dl-staging-website.ghost.io" rel="noopener">Berkeley Function-Calling Leaderboard</a>. It processes 157 tokens per second and costs $0.06/$0.24 per million tokens of input/output, making it less expensive than GPT-4o mini ($0.15/$0.60), Claude 3.5 Haiku ($0.80/$4), or Gemini 1.5 Flash ($0.075/$0.30), but slower than Gemini 1.5 Flash (189 tokens per second).</li><li><strong>Nova Micro</strong>&nbsp;is a text-only model with a 128,000-token context window. It exceeds Llama 3.1 8B and Gemini Flash 8B on all 12 tests reported by Amazon, including generating code (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3ldVflFLk1NPY3XW4mPwdx6NCqkyW74c6qD2mxfkrW5BMyFg1_tpzbW20s7hp6bp3h5W5k66JP963pRrW7MK76V3R-YKpW7FXwQ-2f6BbDN7x58qw1ZcMtW6nd0361Rd0HwN3Lz9tz1K-FjW7xZ8pq9dynhKW8ddtMk2_wRpCN5RC7Jy7KsWsVCPRG817yRPvW4WtXlB7G21L9W4Jn40k7f1N4MW7K7qSM5QS7lqW2gm4MF6d36PjW2xhsmY16-nLFW14Ybt58F8hTCVxVC7S64NYWZf58X8Jv04?ref=dl-staging-website.ghost.io" rel="noopener">HumanEval</a>) and reading financial documents (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3mvW2KVkSl5ymqVYW4nxtFQ6MjXL5W8Czg8S8X8dD2W7HxxkX8ZKk7pW917rt441WVMvW1VmDdM2nwzB7N2XQTZnvcnKNW12Sp5G6ZTpnVN6MRMvShJpZpW6FbhcN3jQhZrW6QQFyq41Dcz_W6dkTrT81kxp7W2Sfpg_9cRCtjW5n2slT3Q5rQxW6VlfXF8r_BVNW3pwqYY8pZ0snW2FvvH228NGB8W29tfJx72wHJnW10BJYg8ctpnpW93THB07kZ37HW4GWBqB4Pvgz-VFDSKY7PBqCzN31Qbv439mTKW4770WS8YzSmmf1SRf7F04?ref=dl-staging-website.ghost.io" rel="noopener">FinQA</a>). It also beats the smaller Claude, Gemini, and Llama models on retrieval-augmented generation tasks (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3mXW4xJ09l3bnxsSW8TnTQZ6RWHRrW22rH-Q8BG-wJW28KM2D1mxv1NW1gT71N8j4GW_W3hxkQH4WVm0VW28G-QQ7F94GjW9dZsJ94hpvCzN6vTPcGdlhcgV5JXqP8fklp9W7DxTqS1_-tn_N64Qt_VFl2TsW6DJ0cK5g4K9xN3Nn5D3N68GnW218SQd1-T2XpW2QFGzW2QxqQ9W76CwLJ2MbpxfW1QXf_p82ftNTW7HZ4jy4M0vYkW6f-xRz2sH2brW7L2h2H2ZKBhmVKKVTG8r5knBf2JB3TM04?ref=dl-staging-website.ghost.io" rel="noopener">CRAG</a>). It processes 210 tokens per second (the lowest latency among Nova models) and costs $0.035/$0.14 per million input/output tokens. That’s cheaper than Gemini Flash 8B ($0.0375/$0.15) and Llama 3.1 8B ($0.10/$0.10), but slower than Gemini Flash 8B (284.2 tokens per second).</li><li><strong>Nova Canvas</strong>&nbsp;accepts English-language text prompts up to 1,024 characters and produces images up to 4.2 megapixels in any aspect ratio. It also performs inpainting, outpainting, and background removal. It excels on&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nGVszv227VyXVWW4pPCjM54hs7tW4X_0tg2xMsbBW1y3Jdk1c8-P2W3MF6PZ8cCb4FW7k7ZRm7n0J_JW8qHQ3N4l19dHW62N7Y563M5wpW8hCS_f77KY1QW5mGNx16CV2pkMRMYRwZ-n7nW1bXC1z8-YlLLW5w4J-N5vGMmlW2MKLhl5W-KDCVjT2PT24NkscW3QBVX97XR_W7W7hBzLl3lBydLW1TY0Jn3h7gcxW2ktfLY6p_lChW58xcJG5p7D5yW5LQTyp3NtzgkV1hhCT67TqJsf7snPMM04?ref=dl-staging-website.ghost.io" rel="noopener">ImageReward</a>, a measure of human preference for generated images, surpassing OpenAI DALL·E 3 and Stability AI Stable Diffusion 3.5. Nova Canvas costs between $0.04 per image up to 1024x1024 pixels and $0.08 per image up to 2,048x2,048 pixels. Prices are hard to compare because many competitors charge by the month or year, but this is less expensive and higher-resolution than DALL·E 3 ($0.04 to $0.12 per image).</li><li><strong>Nova Reel</strong>&nbsp;accepts English-language prompts up to 512 characters and image prompts up to 720x1,280 pixels. It generates video clips of 720x1280 pixels up to six seconds long. It demonstrates superior ability to maintain consistent imagery from frame to frame, winning 67 percent of head-to-head comparisons with the next highest-scoring model, Runway Gen-3 Alpha. Nova Reel costs $0.08 per second of output, which is less expensive than Runway Gen-3 Alpha ($0.096 per second) and Kling 1.5 ($0.12 per second) in their standard monthly plans.</li></ul><p><strong>Behind the news:</strong>&nbsp;The company launched Bedrock in April 2023 with Stability AI’s Stable Diffusion for image generation, Anthropic’s Claude and AI21’s Jurassic-2 for text generation, and its own Titan models for text generation and embeddings. Not long afterward, it added language models from Cohere as well as services for agentic applications and medical applications. It plans to continue to provide models from other companies (including Anthropic), offering a range of choices.</p><p><strong>Why it matters:</strong>&nbsp;While other AI giants raced to outdo one another in models for text and multimodal processing, Amazon was relatively quiet. With Nova, it has staked out a strong position in those areas, as well as the startup-dominated domains of image and video generation. Moreover, it’s strengthening its cloud AI offerings with competitive performance, pricing, and speed. Nova’s pricing continues the rapid&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmgg3qgyTW95jsWP6lZ3pFW3w_PdM2bXK6PW4cD-QZ9lXRMdW3kClgp6xr2Y8VzytDn4fqgPtW8W64QB6pzNmJW8R_HdF6x_6RyW51nLBX4d-BRWW4fzrqj4rHcLNW4M2dv-5XrG_GW83N2DQ5GrZBGTMLbZ1TPpXhW2vZMkl8sMWZyW3MY8bf3slGjJW6GJlXF1hMDFzW5gDzPB9fTlctVY9MSn5jz7h1W2rrvzL7n8NbNW3T_TsK8g93MxN57-lg6JB53BN4Tn-T1NLKlDVVhDXZ5NnX9lW8j5d0R1BZwG4W6W4dgc6MmWR_W5NBHYf3fpn1QW3NvlVc97SWDXN7DHFVB4zsM8W268LPQ8jvjcxW3jNsmm2yYd8dW2hC19c2fgYdBVwyC8x4fsvT5f5fF42H04?ref=dl-staging-website.ghost.io" rel="noopener">drop in AI prices</a>&nbsp;over the last year. Falling per-token prices help make AI agents or applications that process large inputs more practical. For example, Simon Willison, developer of the Django Python framework for web applications,&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3mQW8h-Z_M8klLp6W2Y92m295v2GJW6hKPQP7QmtfbW4wHzPH6W7Z78W237d-F2nrY5gW88F8_v8Lg5wRW8WTcvZ9d1lq0W7bctcV32z483VKj1pY85cKh9W7P5Tf-4vnNZGN4sb4vf4dMy8W53vKM-1PNDkGW4zdsPz7q9QRFW66zZqQ898hh3W8C_FDR2JLTTtW43s80B2j8FXQW2WryXc3zqdg_W48JlL-6bfwFzW8g2fy06CvKsyW7t6NBW6MxY7LW7yFfrT8xBPmbW6V9V0k9hzdjkW2cm5254hG4_YN4Zs2XhkSl10f46fbJY04?ref=dl-staging-website.ghost.io" rel="noopener">found</a>&nbsp;that Nova Lite generated descriptions for his photo library (tens of thousands of images) for less than $10.</p><p><strong>We’re thinking:</strong>&nbsp;The Nova suite is available via APIs as well as two web playgrounds (one in the Bedrock console, the other a new interface for building AI apps called <a href="https://www.linkedin.com/posts/mattgarman_at-reinvent-last-week-we-unveiled-amazon-activity-7272331800822095874-MKlY/?ref=dl-staging-website.ghost.io" rel="noreferrer">PartyRock</a>). This accords with Amazon Web Services’ focus on developers. For consumers, Amazon offers the earlier&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4HzmfH3qgyTW7Y8-PT6lZ3myW2ry85N76RHr7W6jZH0k6KDnwkW4Kfb9z37hKCHW45qSc63Mn9L8W6bYkbT8zTySTV4YQs474j2rQW2zQlKP5jB4PRW6k1N6B8RPcRjVvJzQH8rRrgwW5CVK2X1GPhF5W9hWqFj465hRXW413c938n3CrGW8_ydV47Vgm0bW9d7NQd6MJ8CHW4356pt5SCSWtW4Jsr5999Bl-cW7DMQ0M6nL8M0W8R3n646rtW4dW1v2-YW85tbvYW4yxDbP1srlTyW5TtxjM7dpgLtW20VNQ13pTlHGW6BcQ-y4jRBXLW8x4JMx7mZQPyW1WdCNV1LZtg2W6bkhtd12s4BNf6m3vDP04?ref=dl-staging-website.ghost.io" rel="noopener">Rufus</a>&nbsp;shopping bot; for enterprises, the <a href="https://aws.amazon.com/q/?ref=dl-staging-website.ghost.io" rel="noreferrer">Q</a> assistant. </p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--30-.png" class="kg-image" alt="o1 Family Benchmarks comparing pass rates across AIME, Codeforces, and GPQA." loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--30-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--30-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--30-.png 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="higher-reasoning">Higher Reasoning</h1><p>OpenAI launched not only its highly anticipated o1 model but also an operating mode that enables the model to deliver higher performance — at a hefty price.</p><p><strong>What’s new:</strong>&nbsp;Kicking off a 12-day&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3l_W1Kqhmq2Xxlj6W81Tjc17TL6dJW7d9Z631dRXsXW5T1c7j5LkhgmW4g4VhF944DwTW96k-1Q1FbXhtW28KMXh9gHrQ4W214-Qs28g_YQVThhRR8QBQ7mW9kt_vK8CjFxgW7H5jPH3s_fS7W598Ny33zPSXgW3Zx9qz2nbdGMN4l3YJDQvBT3W78qY5d4s-crQVmrFyN7XZzNfW5j1wXK2SWSB8W5YgvBl5SBZflW5CvXq15VVmDRW8sczpB6brThkW1zcVyb7SS6TfN5xrQFHkS-stf8gXdJb04?ref=dl-staging-website.ghost.io" rel="noopener">holiday blitz</a>, OpenAI launched o1 (previously available in preview and mini versions) and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lLW3CrR588gvJfXW1Nw8t738CW3_VVkdr85TMtmRW8qTphY6MhlwkW1bvm-_6fKnxhW4ydGy25t9Rs7W2j--QT89n5YWW712jj11zK8SHW2NBgGv1npSF9N7QgZYcXQ3YWW92DRrn4ltpVPW4dSQwL8VxrK6W90Fjv76kJYHrVskB4f3G1GfrVkSLJ-8WRYcRW3zhNYh30nQs6W7TfVKg1w84QSW8K6K5k1b_HyhN6Dw655kJRy_VqzKqz17JStcW32Kc5K8CfxZWW1cg5fC39CLZhW3CSkmK4zhFvtW6pbkwn5f3-ZTdCt66d04?ref=dl-staging-website.ghost.io" rel="noopener">introduced</a>&nbsp;o1 pro mode, which processes more tokens at inference to produce more accurate output. Both options accept text and image inputs to generate text outputs. They’re available exclusively through a new ChatGPT Pro subscription for $200 monthly. API access is not yet available.</p><p><strong>How it works:</strong>&nbsp;According to an updated&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lWW5y6cqb8QtG-pV-rlP17gdnxBW53r2hv3dryT0V93Wvr1WSpm-N7Hd9kStHV7BW5gS75M1qJzLjN2hMdVFsC7ZLW4PNwrR5MNQ2CW17J9Xz3wx_pcW6PWqmP8RzV3wW1wh8XX7LnNl9W4p2Tt61j6r6pW1QPNRj3B9-4DW3lRPsv8944Q9W5dn51x7tR4_rW6FCY7F4vzBz9W77MHd673Z1KnN45qMBQtbk8RW1TpG6P1phjB8W3_qGVf5xbSPDW6xW6lg40vnB5W4yL5f43H-LMbW85-8-18B705PW7FWrxb8Lg1smf8Y124M04?ref=dl-staging-website.ghost.io" rel="noopener">system card</a>, o1 models were trained on a mix of public, licensed, and proprietary text, code, and images, with a focus on technical, academic, and structured datasets. They respond to prompts by breaking them down into intermediate steps, each of which consumes a number of hidden “reasoning tokens.” The models don’t reveal these steps, but ChatGPT presents a natural-language summary of the reasoning process. The new o1 and o1 pro mode perform better than o1-preview and o1-mini, but their additional reasoning requires more processing, which translates into higher costs and slower responses.</p><ul><li>o1 consistently outperforms o1-preview in one-shot benchmarks that measure accuracy in advanced math problems (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4HzmfH3qgyTW7Y8-PT6lZ3kZW86S3LY266HgJW5-1s_r7fVCWpF62DkRwd40mW5lXYqq1M69w7W1yNZPL8XpXMjW6xR2ff8MJPw6W33Ybdr4MtjM2W2vXQSh31gGpcW83jqpB7kTRD2W7L1bjZ3YR4zMN5G_GDRdz6GQW52MtSd52045WW12Cvqk601GHfW43rvhd6S19mpW6GhLHG5CMH7YW22lSd41zBGrhW8GBvbV8nK140W5dZyTR12vZ09N99m7W5t84FzW8Vb0Mt8071vzVbfvnV2mByJJW4RVgJM1GYcc1W3nBtYD60DtjHW6VdnSb87LFpHW3gZsKw6JpghNW5jcptf3qGLf9f5yPv1204?ref=dl-staging-website.ghost.io" rel="noopener">AIME 2024</a>), coding challenges (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3mnW1BRNYl7VYKqjVkxCYW3qZFpxW3SZmd67PtBNmN56Hjz0GCylYW2TvZkK1nBhkXW3nd4dq6nFQ7MN3KWVVCP-zbNW3SxLWc4CLs_hW10wsC81Zh1QGW98_wMg1CSzCZW7vP2bC3QG1y1VlwdPD8NJZWwW7Ym59T47qVPVW22R5n94Hq8ylW95CYy36vL5tfW2DwXhW2M0BKvW8HLmpf4wypz4W2yLN3b6kLWX1W6TYM-w6_L2RrW1j2SgB69bTCcW6K5r9c3tSk-YW3ZYSjD5qYCkVf5nNh0R04?ref=dl-staging-website.ghost.io" rel="noopener">Codeforces</a>), and graduate-level science questions (<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nVW80Wt9n67q0mHW6h5Kgf3G3dZtW9jqs8Y60RQ5bW2NZP0G7hKYx-W76ZlPh3vczTVF37q9_y94vjW3FtkwZ6cJKxZW1bTlhm1fBTXvW15h8lT7jZ8gwW3SmRn185thDkW5PW_tv2YZKtsW1LL4lb6rDPSVW3rmGFL8HVRG8W6vp-Zg8FcJXbN8jzp9WjSvqnV5lLv-1TYtt6W19cB-92b3CNfW6xK5pl5nTjcrW6NWw1S4sRCRkW6TCRzb1BScClVWF-_H5ShRSYN5MhmpTsg3frf1m6J6M04?ref=dl-staging-website.ghost.io" rel="noopener">GPQA Diamond</a>).</li><li>o1 pro mode performs only slightly better than o1 on one-shot tests, but its higher accuracy is more evident when it’s asked to respond to the same input four times in a row. For example, given a problem from the American International Mathematics Examination, o1 solves it correctly 78 percent of the time, o1 pro mode 86 percent of the time. Given the same problem four times, o1 solves it correctly in all four tries 67 percent of the time, while o1 pro mode solves it correctly in all four tries 80 percent of the time.</li><li>o1 and o1 pro mode are less prone to generating false or irrelevant information than o1-preview, as measured by OpenAI’s&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nbW62L9hn4L1cB1W5jnRDm4LdNHPVVGHh636KKH1W7951v81QYx5WW1kmLKp52HHMPW4R_LGN467vNdW5n5Gkw6VvZjCW1bVzyZ7zPNW2W8ln2C01FrrKTW9g4Y235FJJVBVrJcQZ7r8rqCW2Pytty5v5Q4dW3kjXgx3sTcD2W7z266R14vB4vVrzt7H4bYMzsW5z_Y3g3cfS2JVBNmG27RnBP6M6sTJYGWNB2W8FFC6P5nfMT5VKZk0W3-MgG0W1W_lpr76txbGW3qzcsb2Ms0ntf3Ncsx004?ref=dl-staging-website.ghost.io" rel="noopener">SimpleQA</a>, which tests the ability to recall facts about science, geography, history, and the like, and PersonQA, which tests the ability to recall facts about people.</li><li>ChatGPT Pro provides chatbot access to o1, o1 pro mode, and other OpenAI models. Subscribers get unlimited use of o1. OpenAI has not clarified whether o1 pro mode is subject to usage limits or other constraints.</li></ul><p><strong>Behind the news:</strong>&nbsp;Since September, when OpenAI introduced o1-preview and o1-mini, other model providers have implemented similar reasoning capabilities.&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmgg3qgyTW95jsWP6lZ3pxW5Wb6fz5HHHmdW5r-kKW2qFtQ4W4mY_DK1sDXMSW6Dk1Zf9cc1yPW5hZw1G3R-16YW5QgPLj8lD5HyW51SDHF8TChrQW5thcTR273LkrW7cr_BN7bNXdVW1s_wK65Vbsj1VnjSwX2F9TVlW3Jnx5Q68kqlpW8wsVp_2FwTnCV1z4tp3pjCH7W83XrdF41QR-pW8DTQYL5XdB9PW4YXRqd1rKjptW4yk87l131f7YW94qzbf36DNN1W3lbT3y3z3zZwW7SJn4z7BTDkKW768yDH7d4kgZW8b7G_N5n3ZcKW6LtYNZ6Zkr6gW4GMTk-2XVyvbW2ZSzMv5tKT0XW6M-h_H69P3G4W7JgY9k3zFNLJW3Fqkqn6whww-N7FF4n827hX4djgBj-04?ref=dl-staging-website.ghost.io" rel="noopener">DeepSeek’s R1</a>&nbsp;displays reasoning steps that o1 models keep hidden. Alibaba’s&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lTW86ncsw46glbdW1_ymNn62GNtkW5dtj6L8Nns5ZW1YrD-t73WWvNVFTTJ95HVK7xW57NTwm5fvgl7W4ZPgPf2hG74fW4fZ0VR18G5-mW31rJ4F8v3t2PVDLGMg6-8LjwVn9zh26XdTCzW8Hnpf-1DCK7SW1q7cFW1Rbp9BW3qfqH23TYstTW3THQk02bDXy4W8wdl-X8x1tPvW3g6_VK64c-VhN2S0ShVVv61xW3XHPVx4j4cYQW4JmW812dFQ80VkmJ5s4M-Y6TN2h8r0Jt7kQDW4DW_5M2DrNC1W2jL6Yw1VCgFHdw4FvR04?ref=dl-staging-website.ghost.io" rel="noopener">QwQ 32B</a>&nbsp;excels at visual reasoning but is slower and has a smaller context window. Amazon’s&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdv5nR32W5BWr2F6lZ3nvVj93qZ2K_mhbW7g-BPf8LvgJQN8SZG8RbjBpNW32qglb6l_8zXW620hxm1d0ks3W257cqw8gq_5QW1xXk8k7H0mDRW6kb1hR6QVPv4W4l-d1c663ntjW4Yn4Sr2Q6RG_W8SJd806YYDgSW3jCqCj4nmqCzW8928xV4R0xZgW81z-sk2zLGKZW46HQrG6hxkCyW4X2JfK1Y5h9NN4hgQDp_l5NmW7hQLwT4YSTDcVywlCt896rHVW81L3Db1tfL3HW15_q684VW-06W6L6nn25ptvVtW3jl2wf64JYQtW2S0mXk3nXQb1W1c6F5g2JY5gVW12v27k2GbvTbW292rz61dD9KXW3vJ9Gr7RJWsrW2HmHBN5fF-6BW2DpcTv3wW9JpW1bFSN1367FZHW5TyRbs6_2bXdW7d5YN37FJ6TFW3XPg407HsJ0Df7VBzJ204?ref=dl-staging-website.ghost.io" rel="noopener">Nova Premier</a>, which is billed as a model for “complex reasoning tasks,” is expected in early 2025, but Amazon has not yet described its performance, architecture, or other details.</p><p><strong>Why it matters:</strong>&nbsp;o1 and o1 pro mode highlight a dramatic shift in model development and pricing. Giving models more processing power at inference enables them to provide more accurate output, and it’s a key part of agentic workflows. It also continues to boost performance even as scaling laws that predict better performance with more training data and compute may be reaching their&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdb5nR32W50kH_H6lZ3pzW4r0mZh7NmkWcW4N-kgQ91WJvzW3GfjjW68ZbnQW6l8pdK5Zzz7HW6VXwLK9bls6gN9fvSrCfx8fGN8FDGN_Mt-_nW64mDVF4_VZQDW2v2-hM881vdHW6X6tmN2HjVlXW2mbSpJ5BK4d4VfnPnG3VjcRjMHsCsvw3LbzV9zXnS5tfXR2W3zHCHz6ZVNvPVWPlXZ51TYn_W6lF_ld352z2gW2WbLgN75GPqPW14zmNH1_0P6bW7yPVp81Rj1DsW2H6JqB5ccD4dW8_WwYz6wPVy-W7rmMpr2Glv1vW178Q7n1rXWs9W5jJ-S739w3qkW6Gbx2-1x34TyW744XH058fTRwW82RXdN841DM-W326N2Z63_Z65W4zRx5m7yMFddW6fYpQV1p6Kd2W5Bdvdz5VfvZQf85Gwlj04?ref=dl-staging-website.ghost.io" rel="noopener">limits</a>. However, it also raises OpenAI’s costs, and at $200 a month, the price of access to o1 and o1 pro is steep. It’s a premium choice for developers who require exceptional accuracy or extensive reasoning.</p><p><strong>We’re thinking:</strong>&nbsp;Discovering scaling laws for using more processing at inference, or&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3n_W3m0vmR6dZJ38W44Wq-L45l4p7W6R2x3P3hGq5YW5l1YfC17qv2QW4YcdPC84jpS5N2t0RpTTBf7yW8JnV8Z4YRynMW5ZJ47t2Z7QxWW5McVhf1-kVZnW8nf9r77MRcJxVdDsFR2MlD_sW736ySV1vwGnrW7s3dx21QsB5BN2CHS-WjRXbJV82lkQ3YNw0rW1x0nbq43CMdvW8rrnM04lx2GBW6DNrh01mVHlPW1R30GC44fjjjW790DX24pJnlWW8rWDxL34pdP1W7J2Fql8Wnd2Yf4sJD3204?ref=dl-staging-website.ghost.io" rel="noopener">test-time compute</a>, is an unsolved problem. Although OpenAI hasn’t disclosed the algorithm behind o1 pro mode, recent&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3lPMhHlRW9v3YPW2KTtBt8yKrv9W25ZCfc6y-3mBW24lylK1_zmyFN2tHT_C2lTbmV9C3FY6yGq90V5wKBJ2q0xCNN8-sFH_6cfDsW66PHHk73LqJvW93dNsJ4LP2MmW37CpKc4G8ws-W1tbYwX1G2rXkW7F_Dl53qW905VQ7_YC93s8qFW7zM5_C5yfSDBW6Vbpn828SlgzN2jNjNT_HrkJW8bn3072fwp6dW656-fS6d79SJW3MvrgH60s3XrW8Fqjzp5Ys_86W3kZ1yw8zw9ZCf2zj8HM04?ref=dl-staging-website.ghost.io" rel="noopener">work</a>&nbsp;at Google allocated tokens dynamically at inference based on a prompt’s difficulty. This approach boosted the compute efficiency by four times and enabled a model that had shown “nontrivial success rates” to outperform one that was 14 times larger.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--37-.gif" class="kg-image" alt="Game character climbing a ladder with visible controls (QWASD) and health bars." loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--37-.gif 600w"></figure><h1 id="game-worlds-on-tap">Game Worlds on Tap</h1><p>A new model improves on recent progress in generating interactive virtual worlds from still images.</p><p><strong>What’s new:</strong>&nbsp;Jack Parker-Holder and colleagues from Google introduced&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf-3qgyTW8wLKSR6lZ3lLW1FWhkP4j57hqW99N8KZ1-pmR-W7rbc1p1Hc3L4W3zPK-_2l7g3HW7TZYNq5xqJv1W64kNqx4BCyZvW7_Hm9v4ng7xsW17YvSs7sNQ79VZrqtv6Lr_-YVtfyTs709vpKW5s4Y442HyWqnW7hgLzQ1YdbgWW57v_ws3m4Nb7W6MQd276J_4vhW1r0TRs3Nx9ZdW7QLr4r50h2rVW4l1b-V1NVn96W3GWv6j1pzhfQN2qVZnt_WcJxW9lws5H14QXMsW8f5GR22C09GKW6G4g1q7r342YW6433nb3tXkGnW8rPCps2bj9RCW7bP5Sr4S2BQcW6YWH0-5rDR_pN1tDd23Xvg8ZW72d5cY980VHQf8G_hxn04?ref=dl-staging-website.ghost.io" rel="noopener">Genie 2</a>, which generates three-dimensional video game worlds that respond to keyboard inputs in real time. The model’s output remains consistent (that is, elements don’t morph or disappear) for up to a minute, and it includes first-person shooters, walking simulators, and driving games from viewpoints that include first person, third person, and isometric. Genie 2 follows up on&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3n3W92Tvw-629NjHW80Pwt37fgR8vW2_BlP-653r63W5YPc8-4nhxXLW8SJ2DX5kPfdFW5hz1H98mKWvWW5nTS296wBRmNW9fJvvt7rNpCjW4713nF2_jZVDVCCZkl195F0RW11NQy41FZ1wtW7xKYNq5qSQClW83Q73S2wQBzvW7j1B6H2LtzvyW4_sZDm7z6zcCW3VYf5W7WXw2LW7PkLfM8D10HlW7txHtZ6LnPldW6Qqg9d4v5XjwW5PkgV17Kw6Q7W2rS91n5jhHsLW1kz29222JR_CW1k2lZp1LTljnW20Vdds83qtKWf2DgyMx04?ref=dl-staging-website.ghost.io" rel="noopener">Genie</a>, which generates two-dimensional games.</p><p><strong>How it works:</strong>&nbsp;Genie 2 is a latent diffusion model that generates video frames made up of an encoder, transformer, and decoder. The developers didn’t reveal how they built it or how they improved on earlier efforts.</p><ul><li>Given video frames, the encoder embeds them. Using those embeddings and keyboard input, the transformer generates the embedding of the next video frame. The decoder takes the new embedding and generates an image.</li><li>At inference, given an image as the starting frame, the encoder embeds it. Given the embedding and keyboard input, the transformer generates the embedding of the next frame, which the decoder uses to generate an image. After the initial frame, the transformer uses embeddings it generated previously plus keyboard input to generate the next embedding.</li></ul><p><strong>Behind the news:</strong>&nbsp;Genie 2 arrives on the heels of&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmgg3qgyTW95jsWP6lZ3nMW8ZQD4y7Q55HnVbZJrM8_7ZBXW77VZyB7Xyq53W7YMkQz3zJSQTW492stg8jyCVmW6552104LXbRnW8stCvg2N9_sBW8pVthw2Mc6jwN7-G-Mwzg2-tW1-T_3p2ncw6CW5CvDSy4xlTWCW1ydPK78dytByW1__y8g3QNzNWW2Hg8jB8BWz62VyjwB09bFvYmN7cNKdypvryMW9gqhB01lTcr-W98t7Y785_hk-W7jDV4X3QsBf9VTV1WJ5vNN9jVtVmS-7_HQFmN2dQsBF5ZxscW5RD_4_2fhyhtN8B0Zf8FBhFxW95wBcJ4VsJ-bW1NbGxG6bGHZjN72ncW2420jQN4smYlfNFRRbN5-PSBNSq3m5VJwy0t4v199Hf3Hwlgx04?ref=dl-staging-website.ghost.io" rel="noopener">Oasis</a>, which generates a Minecraft-like game in real time. Unlike Oasis, Genie 2 worlds are more consistent and not limited to one type of game. It also comes at the same time as another videogame generator,&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3pQW8Ygtml4xrrffW4mkqcb1lXWLyW2nlT7q6xp_5FW84HCG83zVsp3W1YkqcJ8Kv-7rV9Ykwt1dl1yVW942ln07vZ0bnN3GcgqTdzRVGW89CNbw486pnhW1XZB1q1pm75vN4ZGV9dv3ktcW5t5NHs85QZ7NW62nHGX5mJ_nPN6G5G9Fllsw5W2GxKxG96J1DXW7RL3y97W4KvcVv_ybS8TqK3lW3xFB7r1pM74gW64nc4p5PLSS3VLqX0x1LMWwlW6jb4rq7RRdzFN2tbgx5BMlm7f3vb8yl04?ref=dl-staging-website.ghost.io" rel="noopener">World Labs</a>. However, where Genie 2 generates the next frame given previous frames and keyboard input (acting, in terms of game development, as both graphics and physics engines), World Labs generates a 3D mesh of a game world from a single 2D image. This leaves the implementation of physics, graphics rendering, the player’s character, and other game mechanics to external software.</p><p><strong>Why it matters:</strong>&nbsp;Genie 2 extends models that visualize 3D scenes based on 2D images to encompass interactive worlds, a capability that could prove valuable in design, gaming, virtual reality, and other 3D applications. It generates imagery that, the authors suggest, could serve as training data for agents to learn how to navigate and respond to commands in 3D environments.</p><p><strong>We’re thinking:</strong>&nbsp;Generating gameplay directly in the manner of Genie 2 is a quick approach to developing a game, but the current technology comes with caveats. Developers can’t yet control a game’s physics or mechanics and they must manage any flaws in the model (such as a tendency to generate inconsistent worlds). In contrast, generating a 3D mesh, as World Labs does, is a more cumbersome approach, but it gives developers more control.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.gif" class="kg-image" alt="Graph showing how training loss affects token prediction accuracy and hallucination elimination." loading="lazy" width="600" height="336" srcset="https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.gif 600w"></figure><h1 id="getting-the-facts-right">Getting the Facts Right</h1><p>Large language models that remember more hallucinate less.</p><p><strong>What’s new:</strong>&nbsp;Johnny Li and colleagues at Lamini introduced&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3mhM1QZXPd2Wq-MVqxvdCnKRnW10xjq08jntYdW8tvmmP27QqVpVXzvPr1b8dlJW7BYFh77dhCkPW4X0BGH3h86fvW5XtDtm81XzxHN79cj0ksrxZ0W1ZBSGs2ZjtsDW7WrF446DHMCMW88V1gG7n8kfpW3swr2W1YLRdpW8yjL7f1szhRbW3SfpmQ2PxxdfW15GqWq3mCl3sN5NJGjq77R2JW6l-cmj96y75bW3g1MtJ86q_wnW6sZZsl7hRpx6MKMxLTsVvk4W1X6r-54b5yG1f7RPVLv04?ref=dl-staging-website.ghost.io" rel="noopener">Mixture of Memory Experts (MoME)</a>, a method that enables large language models (LLMs) to memorize many facts with relatively modest computational requirements. (Disclosure: Andrew Ng invested in Lamini.)</p><p><strong>Key insight:</strong>&nbsp;The key to getting factual answers from LLMs is to keep training it until it chooses the correct answer every time. In technical terms, train past the point where tokens relevant to the answer have a similar probability distribution, and continue until a single token has 100 percent probability. But this amount of training takes a lot of computation and, since the model may overfit the training set, it also may degrade performance on the test set. Fine-tuning is one solution, and fine-tuning a LoRA adapter to memorize facts reduces the computational burden. But a single LoRA adapter isn’t enough to store all of the knowledge in a large dataset. Training multiple adapters that are selected by cross-attention enables the LLM to memorize a variety of facts.</p><p><strong>How it works:</strong>&nbsp;The authors extended a pretrained&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nNW3WgmD-3-VNfJW6r44tC1MwZ69W5y4-C-83Z1lfW7YzQL31-JmXXW5tz2D46tGxPvM8dXQVhR7x5N618sdWr3BX_W7P_68t7-bP7NW7KJqvK4B8r7QW55PmJf5q3bpzW52KZDp3KF1t0W6bRJcL7NS-ZzW4jCTwl4NxMjMW2ZCK1K5q8x4pVF62v15wX0xrW7RFzBl7c7jN7W1JY1R13L8by8W3G1b8r6Y9XtXW1HyRCS6pWvktW46Ty_z5XB6fyW7QrBZn4QbkgvW3RPShF8XJMlvf408ytK04?ref=dl-staging-website.ghost.io" rel="noopener">Llama-3-8B</a>&nbsp;with a large number (on the order of 1 million) of LoRA adapters and a cross-attention layer. They froze Llama-3-8B and trained the LoRA adapters to predict the next token in a custom dataset of over 1 million questions and answers.</p><ul><li>For any given question, the model learned to select 32 LoRA adapters, each of which was associated with an embedding. The model selected adapters by performing cross-attention between an embedding of the input query and all adapter embeddings.</li><li>The authors trained the LoRA adapters until they memorized all the answers as measured by the loss function (100 epochs).</li><li>At inference, given a query, the model used cross-attention to select a subset of LoRA adapters and responded accordingly.</li></ul><p><strong>Results:</strong>&nbsp;The authors&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3pPW5f_dkq5-WBV-W4PpktS21G4JbW1b7mhD8kLZ64VlQ1KP1YDJnlN6pd9KWXRdl1W1wfFlw89hvnsW71b2jF3n3BJ3W1whM-M4rg0DBW8zpLNS5SZFdsW4X0tbP8-kYHQW5rg3P36z5KpbW6fvxy_11vXb_VNSNwf27L97qW6KWVNb1_0y_8N7SS224h2HZYW4CTzbD2qY7WnW6gN8vT6Ps24mW6HNGgR3sNr80W7LL2B490-TlVW1v2bC81fprkcW4_4cMT5MLztLW95zzTk8Fhz9dW7LkT007Nf1mvW1RySd341g55ff35cWfb04?ref=dl-staging-website.ghost.io" rel="noopener">tested</a>&nbsp;their LoRA-enhanced model’s ability to answer questions about a database via SQL queries. The model, which was outfitted for retrieval-augmented generation (RAG), achieved 94.7 percent accuracy. An unnamed model with RAG achieved 50 percent accuracy.</p><p><strong>Yes, but:</strong>&nbsp;It stands to reason that the authors’ approach saves processing, but it’s unclear how much. The authors didn’t mention the cost of fine-tuning Llama-3-8B in the usual way on their training dataset for the same number of epochs.</p><p><strong>Why it matters:</strong>&nbsp;The authors argue that eliminating hallucinations is possible in typical training, it’s just computationally very expensive (not to mention the risk of overfitting). An architecture designed to store and retrieve facts, via LoRA adapters in this case, makes the process more feasible.</p><p><strong>We’re thinking:</strong>&nbsp;While some researchers want large language models to memorize facts, others want them to&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdb5nR32W50kH_H6lZ3p7N5R_dZxTbT43W4gd7FW4FjyFjW71QYR785qhP7W8mvKrr5m6xXGN4S_r5ddJGVSW1129Q14mpyG0W1zl4tr65cY40W8p1tH-8CWTbdW77g_jt5Dmq9RW6p2nRp5x-WSGW7MYNRc7YKBPKW5dHwn_8lVfXYW7kGq461gWXbWW7FtS4S3gVLyHW1tVJF13xrRHvMHvLF1RjwPxW69ZCN31z-77KW5HHPrC1TKZBJW31hJtr7N39PKW7QDhhT29mLxqW4nW2Gh7D7JBLW3FMf7H3pt9dmW8dXM5Y6FhfVZW14JdBp2qKfh3W4-NwMz2WbCSmW4m3snd9fHsxyW3LkD9L4rk_VXW3XBz--3JlBdYW2k0QqT6HwWDDN1Nj1Lgn3yjmW5x-xTW6gsNhdW6RMRb-86tQjtf8tv_6804?ref=dl-staging-website.ghost.io" rel="noopener">avoid memorizing their training data</a>. These aims address very different problems. Preventing LLMs from memorizing training data would make them less likely to regurgitate it verbatim and thus violate copyrights. On the other hand, this work memorizes facts so the model can deliver consistent, truthful responses that might be stated in a variety of ways.</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="" data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F05%2Fcgpt-2.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/"><div class="absolute inset-0" data-gtm-event-title="ChatGPT Prompt Engineering for Developers"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-279/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-279/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-279/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm71" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-279","id":"6759f81f58d8b10001af9b7b","uuid":"1e5f3304-e695-4b3c-87c2-ee297c2bd353","title":"Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs","html":"\n\u003c!--kg-card-begin: html--\u003e\n\u003cdiv id=\"elevenlabs-audionative-widget\" data-height=\"90\" data-width=\"100%\" data-frameborder=\"no\" data-scrolling=\"no\" data-publicuserid=\"e20b5cfed36900db239c005920538f20ce435963e95a0a4106d34bdd6bf0e46d\" data-playerurl=\"https://elevenlabs.io/player/index.html\" \u003eLoading the \u003ca href=\"https://elevenlabs.io/text-to-speech?ref=dl-staging-website.ghost.io\" target=\"_blank\" rel=\"noopener\"\u003eElevenlabs Text to Speech\u003c/a\u003e AudioNative Player...\u003c/div\u003e\u003cscript src=\"https://elevenlabs.io/player/audioNativeHelper.js\" type=\"text/javascript\"\u003e\u003c/script\u003e\n\u003c!--kg-card-end: html--\u003e\n\u003cp\u003eDear friends,\u003c/p\u003e\u003cp\u003eAI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications. This is making it possible to build new kinds of things, which in turn is driving shifts in best practices in product management — the discipline of defining what to build to serve users — because what is possible to build has shifted. In this letter, I’ll share some best practices I have noticed.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUse concrete examples to specify AI products.\u003c/strong\u003e\u0026nbsp;Starting with a\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/concrete-ideas-make-strong-ai-startups/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--Eqm_4XfMsvT6wPKNDMd230B1utOFB2bNF_Fwr6VDghY4piRLWWELt22IvV9osotn89tB_\" rel=\"noopener\"\u003econcrete idea\u003c/a\u003e\u0026nbsp;helps teams gain speed. If a product manager (PM) proposes to build “a chatbot to answer banking inquiries that relate to user accounts,” this is a vague specification that leaves much to the imagination. For instance, should the chatbot answer questions only about account balances or also about interest rates, processes for initiating a wire transfer, and so on? But if the PM writes out a number (say, between 10 and 50) of concrete examples of conversations they’d like a chatbot to execute, the scope of their proposal becomes much clearer. Just as a machine learning algorithm needs training examples to learn from, an AI product development team needs concrete examples of what we want an AI system to do. In other words, the data is your PRD (product requirements document)!\u003c/p\u003e\u003cp\u003eIn a similar vein, if someone requests “a vision system to detect pedestrians outside our store,” it’s hard for a developer to understand the boundary conditions. Is the system expected to work at night? What is the range of permissible camera angles? Is it expected to detect pedestrians who appear in the image even though they’re 100m away? But if the PM collects a handful of pictures and annotates them with the desired output, the meaning of “detect pedestrians” becomes concrete. An engineer can assess if the specification is technically feasible and if so, build toward it. Initially, the data might be obtained via a one-off, scrappy process, such as the PM walking around taking pictures and annotating them. Eventually, the data mix will shift to real-word data collected by a system running in production.\u003c/p\u003e\u003cp\u003eUsing examples (such as inputs and desired outputs) to specify a product has been helpful for many years, but the explosion of possible AI applications is creating a need for more product managers to learn this practice.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAssess technical feasibility of LLM-based applications by prompting.\u003c/strong\u003e\u0026nbsp;When a PM scopes out a potential AI application, whether the application can actually be built — that is, its technical feasibility — is a key criterion in deciding what to do next. For many ideas for LLM-based applications, it’s increasingly possible for a PM, who might not be a software engineer, to try prompting — or write just small amounts of code — to get an initial sense of feasibility.\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.jpg\" class=\"kg-image\" alt=\"Cartoon showing people stuck in wet concrete, with a person saying ‘You asked for a concrete idea!’\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--38-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--38-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003eFor example, a PM may envision a new internal tool for routing emails from customers to the right department (such as customer service, sales, etc.). They can prompt an LLM to see if they can get it to select the right department based on an input email, and see if they can achieve high accuracy. If so, this gives engineering a great starting point from which to implement the tool. If not, the PM can falsify the idea themselves and perhaps improve the product idea much faster than if they had to rely on an engineer to build a prototype.\u003c/p\u003e\u003cp\u003eOften, testing feasibility requires a little more than prompting. For example, perhaps the LLM-based email system needs basic RAG capability to help it make decisions. Fortunately, the barrier to writing small amounts of code is now quite low, since AI can help by acting as a coding companion, as I describe in the course, “\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4HzmfH3qgyTW7Y8-PT6lZ3lYW366bW34PBtQRW6Wkd-k7PwcdwW14_2YN81Tn-yW5t7CqF3SNF94VWKqBH5rby5QW64ct3m6yR4VZW18BSTt9jQmJKW6-_6J77-R-2rW5kQBLL8b78lFW2P4_QF4GHgYXW29wFH-7hgGRDW3wyzhL3p6GkzW66bcJP2LjtMYW424vZP4HzRhpW6jP8fY14mB7mW31BVsj6XJqNgW17mrQ510wZC4W1Vk4Vg15WDD0N30kx6Z1zKs0N87bJ3Qyn97MVxkGq44XLlD8N6k64JcgfB0_W2BLkrS2rpvqfW4-Lbdm4KBP-VW6vY4b-5xQSxMW22xtDG1ghL_4f96h33b04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eAI Python for Beginners\u003c/a\u003e.” This means that PMs can do much more technical feasibility testing, at least at a basic level, than was possible before.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePrototype and test without engineers.\u003c/strong\u003e\u0026nbsp;User feedback to initial prototypes is also instrumental to shaping products. Fortunately, barriers to building prototypes rapidly are falling, and PMs themselves can move prototypes forward without needing software developers.\u003c/p\u003e\u003cp\u003eIn addition to using LLMs to help write code for prototyping, tools like Replit, Vercel’s V0, Bolt, and Anthropic’s Artifacts (I’m a fan of all of these!) are making it easier for people without a coding background to build and experiment with simple prototypes. These tools are increasingly accessible to non-technical users, though I find that those who understand basic coding are able to use them much more effectively, so it’s still important to learn basic coding. (Interestingly, highly technical, experienced developers use them too!) Many members of my teams routinely use such tools to prototype, get user feedback, and iterate quickly.\u003c/p\u003e\u003cp\u003eAI is enabling a lot of new applications to be built, creating massive growth in demand for AI product managers who know how to scope out and help drive progress in building these products. AI product management existed before the rise of generative AI, but the increasing ease of building applications is creating greater demand for AI applications, and thus a lot of PMs are learning AI and these emerging best practices for building AI products. I find this discipline fascinating, and will keep on sharing best practices as they grow and evolve.\u003c/p\u003e\u003cp\u003eKeep learning!\u003c/p\u003e\u003cp\u003eAndrew\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/collaborative-writing-and-coding-with-openai-canvas/?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png\" class=\"kg-image\" alt=\"Promo banner for \u0026quot;Collaborative Writing and Coding with OpenAI Canvas\u0026quot;\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/12/The-Batch-ads-and-exclusive-banners---2024-11-27T123750.031--1-.png 1680w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eWrite and code more effectively with OpenAI Canvas, a user-friendly workspace for collaborating with AI. In this free course, explore use cases like building game apps and designing SQL databases from screenshots, and gain insights into how GPT-4o powers Canvas’ features.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/collaborative-writing-and-coding-with-openai-canvas/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eJoin for free\u003c/a\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--36-.gif\" class=\"kg-image\" alt=\"Berkeley Function Calling Leaderboard with metrics like accuracy, latency, and relevance.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--36-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--36-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--36-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"competitive-performance-competitive-prices\"\u003eCompetitive Performance, Competitive Prices\u003c/h1\u003e\u003cp\u003eAmazon introduced a range of models that confront competitors head-on.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;The\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdv5nR32W5BWr2F6lZ3pHW98tKVM9h8gZfW63HtBL8N30bJW25KwPF6lQ7T4W3jFfzj6wrp79W6Mp8MD5HX5bWVZHrpq8jD1mrN3Rt4CwtC8NgW27cjdP58q1YxW2YW6g03MmPv0W6T3J052zSYtsN3G872BFR4fPN1YfKLDvkcsvW6h9ZqT1Bvs3xN860NNtMdRPhW4cBR4d5sV7l6W6KwXB95pYmNqW4h5h745zT4X5W2PqfgN5zy8JTW45GzZ-2XKrqdW3qg8Z_3MKfCcW2_5FrD2HPYvzW2_ntTR20cwNXW8yNwWF353pVWTMznl8Z9758W6R4vzp1s4pd6W4HmnMG3y33T7VpjHFG79npRpW3H77Kn7pq71CVC3P7Z8gBmGqW6CrXWj5m_q1bW1LgP712qTXjrW64Z_ZB6x9LvFW8gqyb28g-pW3W6kXMcH4dTvS6f6KwPzx04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eNova\u003c/a\u003e\u0026nbsp;line from Amazon includes three vision-language models (Nova Premier, Nova Pro, and Nova Lite), one language model (Nova Micro), an image generator (Nova Canvas), and a video generator (Nova Reel). All but Nova Premier are\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lrW3lhZCM3nYVfSMhhFSLNYz8qW2GkrGV1M1pX8W43R0cx6BQC8RW3rN35587H06_W5fmw7C8TZYnfW2n0QXP552JlhN6rwqhhjckQLW94xH2k6FMbNLW8Td11D7T5jYkW1Qxc_t3D9d2HN42dW9RRhyRlN7Czn9hlwtXjW7GRb2825c4-VW38mHDz4rgSsjW4JsPys8dgry3W7jtMrY2nGSZQW12gqgC755sXBW2N-kvF1NwNl6W1D1B742c7mYwW7JgfGx6fLN-sN3RbsMCDh3x4VMHxbP6M9SRtN1SjvbybhpG9f3P8Rtb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eavailable\u003c/a\u003e\u0026nbsp;on Amazon’s Bedrock platform, and Nova Premier, which is the most capable, is expected in early 2025. In addition, Amazon plans to release a speech-to-speech model in early 2025 and a multimodal model that processes text, images, video, and audio by mid-year. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Nova models deliver competitive\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdb5nR32W50kH_H6lZ3mbW4fdCNV65QDb8W5HL_y_93s5dgVjHRx355q56yW1Z65TH8cczlpVR9Svw61KqCsW3YXMvT2wyH9sW8CvMp14WzQVmW39p7Qx2cYVssW4DpMRv8ylrn-W8sYkWM6DhPg5VKn88N55w45sW65lBBF6HzlrJW7RbC_V2w_W7qW60B_Pw82xBYQN8W1Mmv3pGr5W3jG25F4KbRJ5W54FKxt7nxK8JW4zv0wb98WwD2W8Rz2DZ2Kw6TvW5b4sRx8vxLbXW7JCft34zsW_WW2ZV83v61qhzkW8NkfyG4NF0BgW2Jh6-C94KH7VW9hf5zg7TH11hN9h8Jm0klZJ4W6YgNjD333K55W5jfb_M2j22sjW8LCn2t4gxNR8W8VBHJF3G4tncW4Dn1r98-3scXVGKPKd6MKdWMf3Qqywv04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eperformance\u003c/a\u003e\u0026nbsp;at relatively low prices. Amazon hasn’t disclosed parameter counts or details about how the models were built except to say that Nova Pro, Lite, and Micro were trained on a combination of proprietary, licensed, public, and open-source text, images, and video in over 200 languages.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eNova Pro\u003c/strong\u003e\u0026nbsp;is roughly comparable to that of Anthropic Claude 3.5 Sonnet, OpenAI GPT-4o, and Google Gemini Pro. It has a 300,000-token input context window, enabling it to process relatively large vision-language inputs. Nova Pro outperforms its primary competitors in tests of following complex instructions (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3pkV-H8v67JsKKSW13QMcP4pTG_lN4K1bd8YGrN5W8t6rDX4YxZVWW7HGMPL287yGvW4Myqvt975HF9N4PVzqL1rKXSW2k0Fjf4dWPRSW7YyZkN7sNylLW4m1KTq6GTNVrW2swtX26ws_KVV26LBl969WdKW4tHthy6nh3ffW5lSsfW1DbGCFW6WLG3M4VNknjW5L_Q168gs_NwW5PnGpq8n1GFnW280ZnV47nQPVVRVD1N61RmYhW56rWC729h81QW72PJDc158Q2LW1njr6h7dtZ2Mf1GD1JK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eIFEval),\u003cu\u003e\u0026nbsp;\u003c/u\u003e\u003c/a\u003esummarizing long texts (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nkW5-072n8Bk1W7W7K0KyX1yRN49V_SZcN5GCHgTW7j7vQ_9gqhpRVJFfzQ2kv03WW8__MPc3Bjm4wW3QVRgb2sWcP6T4qV-8jy46kN6nj4gs1pLR2W4Vxlsj8gPqVBW8hMwj59gRFkqN8Zk4pDZyw_nW3Lm_kK3pTn8KN2Q3ZNvtSjzJW5Dt3rH45P4g_W3dcYW08DMt-TW2Pb_nT35PLzhW6YLJ-x89Ph1jW8rT2K-2ln9HzW126L4c2_CDrFW6j--BX9jX5ZdW2HLktw61t4Jnf4TcljW04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eSQuALITY\u003c/a\u003e), understanding videos (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3pKVXYbPZ4zrbTXW7jWy_72BlXnNVfrdW53VB2XYMRScsQTGD7vW5Q4Dch5Y5QKyLkSlxLNqkGW1mcxF24vRPrwW2fV0LK86VB9TW5mpnws5xt0cQW2DRL0_2hLFCJW4Zw-d22HC2ScW5c_5Y24LHwvpW4_BQP86YP7v8W2wtF3N7gF2zpW2gnv3H8_L70pW66lw6v7rWLSwW55-K2T8-jpJcN5F66P2mpscjW2vBTDQ4hKFlfW5PWYvh4ByjR9W8QkKXQ4nqvCLW6dhzG16L1Qmwf4_Q_2804?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eLVBench\u003c/a\u003e), and reading and acting on websites (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3lwW345VXL8MyLkRN1g_w89_HJZXW5PsGL05y27KtW5LvgQ_57PRlMW4gp8sg5FYNDcW1wrvJ64Zl4-NW36bvqb21jNyhW5LBK704RN8ylW9bbm1t6qRjr8W6t7wBH6fgFdbW2b6HQg6cqbpwW8B8nBZ3C8z0MW7XjT5p28-nfxW89hLWS5nndsFW8RJ0ZS3KZ290W7NDVXn3SLqGLN6LmrQDzSMzYW6vqlJM7zcWY3W15dx__4kSRb8Vm_nXn4zlLV6W93q0-R3BptmjW6GGvVt2-LHt_f3jKTFR04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMM-Mind2Web\u003c/a\u003e). It processes 95 tokens per second. At $0.80/$3.20 per million tokens of input/output, it’s significantly less expensive than GPT-4o ($2.50/$10) and Claude 3.5 Sonnet ($3/$15) but slower than GPT-4o (115 tokens per second).\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eNova Lite\u003c/strong\u003e\u0026nbsp;compares favorably with Anthropic Claude Haiku, Google Gemini 1.5 Flash, and OpenAI GPT-4o Mini. Optimized for processing speed and efficiency, it too has a 300,000 token input context window. Nova Lite bests Claude 3.5 Sonnet and GPT-4o on VisualWebBench, which tests visual understanding of web pages. It also beats Claude 3.5 Haiku, GPT-4o Mini, and Gemini 1.5 Flash in multimodal agentic tasks that include MM-Mind2Web and the\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3mMW3dwXYh7BJvWJW8Gv1mv65RNgdW9bBGXc40Bgy9W3bcnPn3lyknbN7Jw3QM_1JtmW257XTK5wWnJ2W2fFdNF6gZszPW8zvTPJ3-LYbxN8d9txFR-M02VkR84C3xQ5VRW1XBGmZ6LjnQPW1DC3061YvPqbW7BWfGf4t205ZVWfhZW3z2jdVW6FRVqW1Hw3DKW7-p-Qx7D8hWrW84jwLV8fl27KW425Mc-3bckJWN1XV80tGRKV0W8cYqbf5pCdt2W5d0D_63LJSNCW4QslLJ8wDN4cW5X-B1Z2XX_7BW6q5Hf23Hy663f59H93b04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eBerkeley Function-Calling Leaderboard\u003c/a\u003e. It processes 157 tokens per second and costs $0.06/$0.24 per million tokens of input/output, making it less expensive than GPT-4o mini ($0.15/$0.60), Claude 3.5 Haiku ($0.80/$4), or Gemini 1.5 Flash ($0.075/$0.30), but slower than Gemini 1.5 Flash (189 tokens per second).\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eNova Micro\u003c/strong\u003e\u0026nbsp;is a text-only model with a 128,000-token context window. It exceeds Llama 3.1 8B and Gemini Flash 8B on all 12 tests reported by Amazon, including generating code (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3ldVflFLk1NPY3XW4mPwdx6NCqkyW74c6qD2mxfkrW5BMyFg1_tpzbW20s7hp6bp3h5W5k66JP963pRrW7MK76V3R-YKpW7FXwQ-2f6BbDN7x58qw1ZcMtW6nd0361Rd0HwN3Lz9tz1K-FjW7xZ8pq9dynhKW8ddtMk2_wRpCN5RC7Jy7KsWsVCPRG817yRPvW4WtXlB7G21L9W4Jn40k7f1N4MW7K7qSM5QS7lqW2gm4MF6d36PjW2xhsmY16-nLFW14Ybt58F8hTCVxVC7S64NYWZf58X8Jv04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eHumanEval\u003c/a\u003e) and reading financial documents (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3mvW2KVkSl5ymqVYW4nxtFQ6MjXL5W8Czg8S8X8dD2W7HxxkX8ZKk7pW917rt441WVMvW1VmDdM2nwzB7N2XQTZnvcnKNW12Sp5G6ZTpnVN6MRMvShJpZpW6FbhcN3jQhZrW6QQFyq41Dcz_W6dkTrT81kxp7W2Sfpg_9cRCtjW5n2slT3Q5rQxW6VlfXF8r_BVNW3pwqYY8pZ0snW2FvvH228NGB8W29tfJx72wHJnW10BJYg8ctpnpW93THB07kZ37HW4GWBqB4Pvgz-VFDSKY7PBqCzN31Qbv439mTKW4770WS8YzSmmf1SRf7F04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eFinQA\u003c/a\u003e). It also beats the smaller Claude, Gemini, and Llama models on retrieval-augmented generation tasks (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3mXW4xJ09l3bnxsSW8TnTQZ6RWHRrW22rH-Q8BG-wJW28KM2D1mxv1NW1gT71N8j4GW_W3hxkQH4WVm0VW28G-QQ7F94GjW9dZsJ94hpvCzN6vTPcGdlhcgV5JXqP8fklp9W7DxTqS1_-tn_N64Qt_VFl2TsW6DJ0cK5g4K9xN3Nn5D3N68GnW218SQd1-T2XpW2QFGzW2QxqQ9W76CwLJ2MbpxfW1QXf_p82ftNTW7HZ4jy4M0vYkW6f-xRz2sH2brW7L2h2H2ZKBhmVKKVTG8r5knBf2JB3TM04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eCRAG\u003c/a\u003e). It processes 210 tokens per second (the lowest latency among Nova models) and costs $0.035/$0.14 per million input/output tokens. That’s cheaper than Gemini Flash 8B ($0.0375/$0.15) and Llama 3.1 8B ($0.10/$0.10), but slower than Gemini Flash 8B (284.2 tokens per second).\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eNova Canvas\u003c/strong\u003e\u0026nbsp;accepts English-language text prompts up to 1,024 characters and produces images up to 4.2 megapixels in any aspect ratio. It also performs inpainting, outpainting, and background removal. It excels on\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nGVszv227VyXVWW4pPCjM54hs7tW4X_0tg2xMsbBW1y3Jdk1c8-P2W3MF6PZ8cCb4FW7k7ZRm7n0J_JW8qHQ3N4l19dHW62N7Y563M5wpW8hCS_f77KY1QW5mGNx16CV2pkMRMYRwZ-n7nW1bXC1z8-YlLLW5w4J-N5vGMmlW2MKLhl5W-KDCVjT2PT24NkscW3QBVX97XR_W7W7hBzLl3lBydLW1TY0Jn3h7gcxW2ktfLY6p_lChW58xcJG5p7D5yW5LQTyp3NtzgkV1hhCT67TqJsf7snPMM04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eImageReward\u003c/a\u003e, a measure of human preference for generated images, surpassing OpenAI DALL·E 3 and Stability AI Stable Diffusion 3.5. Nova Canvas costs between $0.04 per image up to 1024x1024 pixels and $0.08 per image up to 2,048x2,048 pixels. Prices are hard to compare because many competitors charge by the month or year, but this is less expensive and higher-resolution than DALL·E 3 ($0.04 to $0.12 per image).\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eNova Reel\u003c/strong\u003e\u0026nbsp;accepts English-language prompts up to 512 characters and image prompts up to 720x1,280 pixels. It generates video clips of 720x1280 pixels up to six seconds long. It demonstrates superior ability to maintain consistent imagery from frame to frame, winning 67 percent of head-to-head comparisons with the next highest-scoring model, Runway Gen-3 Alpha. Nova Reel costs $0.08 per second of output, which is less expensive than Runway Gen-3 Alpha ($0.096 per second) and Kling 1.5 ($0.12 per second) in their standard monthly plans.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;The company launched Bedrock in April 2023 with Stability AI’s Stable Diffusion for image generation, Anthropic’s Claude and AI21’s Jurassic-2 for text generation, and its own Titan models for text generation and embeddings. Not long afterward, it added language models from Cohere as well as services for agentic applications and medical applications. It plans to continue to provide models from other companies (including Anthropic), offering a range of choices.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;While other AI giants raced to outdo one another in models for text and multimodal processing, Amazon was relatively quiet. With Nova, it has staked out a strong position in those areas, as well as the startup-dominated domains of image and video generation. Moreover, it’s strengthening its cloud AI offerings with competitive performance, pricing, and speed. Nova’s pricing continues the rapid\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmgg3qgyTW95jsWP6lZ3pFW3w_PdM2bXK6PW4cD-QZ9lXRMdW3kClgp6xr2Y8VzytDn4fqgPtW8W64QB6pzNmJW8R_HdF6x_6RyW51nLBX4d-BRWW4fzrqj4rHcLNW4M2dv-5XrG_GW83N2DQ5GrZBGTMLbZ1TPpXhW2vZMkl8sMWZyW3MY8bf3slGjJW6GJlXF1hMDFzW5gDzPB9fTlctVY9MSn5jz7h1W2rrvzL7n8NbNW3T_TsK8g93MxN57-lg6JB53BN4Tn-T1NLKlDVVhDXZ5NnX9lW8j5d0R1BZwG4W6W4dgc6MmWR_W5NBHYf3fpn1QW3NvlVc97SWDXN7DHFVB4zsM8W268LPQ8jvjcxW3jNsmm2yYd8dW2hC19c2fgYdBVwyC8x4fsvT5f5fF42H04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003edrop in AI prices\u003c/a\u003e\u0026nbsp;over the last year. Falling per-token prices help make AI agents or applications that process large inputs more practical. For example, Simon Willison, developer of the Django Python framework for web applications,\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3mQW8h-Z_M8klLp6W2Y92m295v2GJW6hKPQP7QmtfbW4wHzPH6W7Z78W237d-F2nrY5gW88F8_v8Lg5wRW8WTcvZ9d1lq0W7bctcV32z483VKj1pY85cKh9W7P5Tf-4vnNZGN4sb4vf4dMy8W53vKM-1PNDkGW4zdsPz7q9QRFW66zZqQ898hh3W8C_FDR2JLTTtW43s80B2j8FXQW2WryXc3zqdg_W48JlL-6bfwFzW8g2fy06CvKsyW7t6NBW6MxY7LW7yFfrT8xBPmbW6V9V0k9hzdjkW2cm5254hG4_YN4Zs2XhkSl10f46fbJY04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003efound\u003c/a\u003e\u0026nbsp;that Nova Lite generated descriptions for his photo library (tens of thousands of images) for less than $10.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;The Nova suite is available via APIs as well as two web playgrounds (one in the Bedrock console, the other a new interface for building AI apps called \u003ca href=\"https://www.linkedin.com/posts/mattgarman_at-reinvent-last-week-we-unveiled-amazon-activity-7272331800822095874-MKlY/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003ePartyRock\u003c/a\u003e). This accords with Amazon Web Services’ focus on developers. For consumers, Amazon offers the earlier\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4HzmfH3qgyTW7Y8-PT6lZ3myW2ry85N76RHr7W6jZH0k6KDnwkW4Kfb9z37hKCHW45qSc63Mn9L8W6bYkbT8zTySTV4YQs474j2rQW2zQlKP5jB4PRW6k1N6B8RPcRjVvJzQH8rRrgwW5CVK2X1GPhF5W9hWqFj465hRXW413c938n3CrGW8_ydV47Vgm0bW9d7NQd6MJ8CHW4356pt5SCSWtW4Jsr5999Bl-cW7DMQ0M6nL8M0W8R3n646rtW4dW1v2-YW85tbvYW4yxDbP1srlTyW5TtxjM7dpgLtW20VNQ13pTlHGW6BcQ-y4jRBXLW8x4JMx7mZQPyW1WdCNV1LZtg2W6bkhtd12s4BNf6m3vDP04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eRufus\u003c/a\u003e\u0026nbsp;shopping bot; for enterprises, the \u003ca href=\"https://aws.amazon.com/q/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eQ\u003c/a\u003e assistant. \u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--30-.png\" class=\"kg-image\" alt=\"o1 Family Benchmarks comparing pass rates across AIME, Codeforces, and GPQA.\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/12/unnamed--30-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/12/unnamed--30-.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--30-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"higher-reasoning\"\u003eHigher Reasoning\u003c/h1\u003e\u003cp\u003eOpenAI launched not only its highly anticipated o1 model but also an operating mode that enables the model to deliver higher performance — at a hefty price.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Kicking off a 12-day\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3l_W1Kqhmq2Xxlj6W81Tjc17TL6dJW7d9Z631dRXsXW5T1c7j5LkhgmW4g4VhF944DwTW96k-1Q1FbXhtW28KMXh9gHrQ4W214-Qs28g_YQVThhRR8QBQ7mW9kt_vK8CjFxgW7H5jPH3s_fS7W598Ny33zPSXgW3Zx9qz2nbdGMN4l3YJDQvBT3W78qY5d4s-crQVmrFyN7XZzNfW5j1wXK2SWSB8W5YgvBl5SBZflW5CvXq15VVmDRW8sczpB6brThkW1zcVyb7SS6TfN5xrQFHkS-stf8gXdJb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eholiday blitz\u003c/a\u003e, OpenAI launched o1 (previously available in preview and mini versions) and\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lLW3CrR588gvJfXW1Nw8t738CW3_VVkdr85TMtmRW8qTphY6MhlwkW1bvm-_6fKnxhW4ydGy25t9Rs7W2j--QT89n5YWW712jj11zK8SHW2NBgGv1npSF9N7QgZYcXQ3YWW92DRrn4ltpVPW4dSQwL8VxrK6W90Fjv76kJYHrVskB4f3G1GfrVkSLJ-8WRYcRW3zhNYh30nQs6W7TfVKg1w84QSW8K6K5k1b_HyhN6Dw655kJRy_VqzKqz17JStcW32Kc5K8CfxZWW1cg5fC39CLZhW3CSkmK4zhFvtW6pbkwn5f3-ZTdCt66d04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eintroduced\u003c/a\u003e\u0026nbsp;o1 pro mode, which processes more tokens at inference to produce more accurate output. Both options accept text and image inputs to generate text outputs. They’re available exclusively through a new ChatGPT Pro subscription for $200 monthly. API access is not yet available.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;According to an updated\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lWW5y6cqb8QtG-pV-rlP17gdnxBW53r2hv3dryT0V93Wvr1WSpm-N7Hd9kStHV7BW5gS75M1qJzLjN2hMdVFsC7ZLW4PNwrR5MNQ2CW17J9Xz3wx_pcW6PWqmP8RzV3wW1wh8XX7LnNl9W4p2Tt61j6r6pW1QPNRj3B9-4DW3lRPsv8944Q9W5dn51x7tR4_rW6FCY7F4vzBz9W77MHd673Z1KnN45qMBQtbk8RW1TpG6P1phjB8W3_qGVf5xbSPDW6xW6lg40vnB5W4yL5f43H-LMbW85-8-18B705PW7FWrxb8Lg1smf8Y124M04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003esystem card\u003c/a\u003e, o1 models were trained on a mix of public, licensed, and proprietary text, code, and images, with a focus on technical, academic, and structured datasets. They respond to prompts by breaking them down into intermediate steps, each of which consumes a number of hidden “reasoning tokens.” The models don’t reveal these steps, but ChatGPT presents a natural-language summary of the reasoning process. The new o1 and o1 pro mode perform better than o1-preview and o1-mini, but their additional reasoning requires more processing, which translates into higher costs and slower responses.\u003c/p\u003e\u003cul\u003e\u003cli\u003eo1 consistently outperforms o1-preview in one-shot benchmarks that measure accuracy in advanced math problems (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4HzmfH3qgyTW7Y8-PT6lZ3kZW86S3LY266HgJW5-1s_r7fVCWpF62DkRwd40mW5lXYqq1M69w7W1yNZPL8XpXMjW6xR2ff8MJPw6W33Ybdr4MtjM2W2vXQSh31gGpcW83jqpB7kTRD2W7L1bjZ3YR4zMN5G_GDRdz6GQW52MtSd52045WW12Cvqk601GHfW43rvhd6S19mpW6GhLHG5CMH7YW22lSd41zBGrhW8GBvbV8nK140W5dZyTR12vZ09N99m7W5t84FzW8Vb0Mt8071vzVbfvnV2mByJJW4RVgJM1GYcc1W3nBtYD60DtjHW6VdnSb87LFpHW3gZsKw6JpghNW5jcptf3qGLf9f5yPv1204?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eAIME 2024\u003c/a\u003e), coding challenges (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3mnW1BRNYl7VYKqjVkxCYW3qZFpxW3SZmd67PtBNmN56Hjz0GCylYW2TvZkK1nBhkXW3nd4dq6nFQ7MN3KWVVCP-zbNW3SxLWc4CLs_hW10wsC81Zh1QGW98_wMg1CSzCZW7vP2bC3QG1y1VlwdPD8NJZWwW7Ym59T47qVPVW22R5n94Hq8ylW95CYy36vL5tfW2DwXhW2M0BKvW8HLmpf4wypz4W2yLN3b6kLWX1W6TYM-w6_L2RrW1j2SgB69bTCcW6K5r9c3tSk-YW3ZYSjD5qYCkVf5nNh0R04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eCodeforces\u003c/a\u003e), and graduate-level science questions (\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nVW80Wt9n67q0mHW6h5Kgf3G3dZtW9jqs8Y60RQ5bW2NZP0G7hKYx-W76ZlPh3vczTVF37q9_y94vjW3FtkwZ6cJKxZW1bTlhm1fBTXvW15h8lT7jZ8gwW3SmRn185thDkW5PW_tv2YZKtsW1LL4lb6rDPSVW3rmGFL8HVRG8W6vp-Zg8FcJXbN8jzp9WjSvqnV5lLv-1TYtt6W19cB-92b3CNfW6xK5pl5nTjcrW6NWw1S4sRCRkW6TCRzb1BScClVWF-_H5ShRSYN5MhmpTsg3frf1m6J6M04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eGPQA Diamond\u003c/a\u003e).\u003c/li\u003e\u003cli\u003eo1 pro mode performs only slightly better than o1 on one-shot tests, but its higher accuracy is more evident when it’s asked to respond to the same input four times in a row. For example, given a problem from the American International Mathematics Examination, o1 solves it correctly 78 percent of the time, o1 pro mode 86 percent of the time. Given the same problem four times, o1 solves it correctly in all four tries 67 percent of the time, while o1 pro mode solves it correctly in all four tries 80 percent of the time.\u003c/li\u003e\u003cli\u003eo1 and o1 pro mode are less prone to generating false or irrelevant information than o1-preview, as measured by OpenAI’s\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nbW62L9hn4L1cB1W5jnRDm4LdNHPVVGHh636KKH1W7951v81QYx5WW1kmLKp52HHMPW4R_LGN467vNdW5n5Gkw6VvZjCW1bVzyZ7zPNW2W8ln2C01FrrKTW9g4Y235FJJVBVrJcQZ7r8rqCW2Pytty5v5Q4dW3kjXgx3sTcD2W7z266R14vB4vVrzt7H4bYMzsW5z_Y3g3cfS2JVBNmG27RnBP6M6sTJYGWNB2W8FFC6P5nfMT5VKZk0W3-MgG0W1W_lpr76txbGW3qzcsb2Ms0ntf3Ncsx004?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eSimpleQA\u003c/a\u003e, which tests the ability to recall facts about science, geography, history, and the like, and PersonQA, which tests the ability to recall facts about people.\u003c/li\u003e\u003cli\u003eChatGPT Pro provides chatbot access to o1, o1 pro mode, and other OpenAI models. Subscribers get unlimited use of o1. OpenAI has not clarified whether o1 pro mode is subject to usage limits or other constraints.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Since September, when OpenAI introduced o1-preview and o1-mini, other model providers have implemented similar reasoning capabilities.\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmgg3qgyTW95jsWP6lZ3pxW5Wb6fz5HHHmdW5r-kKW2qFtQ4W4mY_DK1sDXMSW6Dk1Zf9cc1yPW5hZw1G3R-16YW5QgPLj8lD5HyW51SDHF8TChrQW5thcTR273LkrW7cr_BN7bNXdVW1s_wK65Vbsj1VnjSwX2F9TVlW3Jnx5Q68kqlpW8wsVp_2FwTnCV1z4tp3pjCH7W83XrdF41QR-pW8DTQYL5XdB9PW4YXRqd1rKjptW4yk87l131f7YW94qzbf36DNN1W3lbT3y3z3zZwW7SJn4z7BTDkKW768yDH7d4kgZW8b7G_N5n3ZcKW6LtYNZ6Zkr6gW4GMTk-2XVyvbW2ZSzMv5tKT0XW6M-h_H69P3G4W7JgY9k3zFNLJW3Fqkqn6whww-N7FF4n827hX4djgBj-04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eDeepSeek’s R1\u003c/a\u003e\u0026nbsp;displays reasoning steps that o1 models keep hidden. Alibaba’s\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3lTW86ncsw46glbdW1_ymNn62GNtkW5dtj6L8Nns5ZW1YrD-t73WWvNVFTTJ95HVK7xW57NTwm5fvgl7W4ZPgPf2hG74fW4fZ0VR18G5-mW31rJ4F8v3t2PVDLGMg6-8LjwVn9zh26XdTCzW8Hnpf-1DCK7SW1q7cFW1Rbp9BW3qfqH23TYstTW3THQk02bDXy4W8wdl-X8x1tPvW3g6_VK64c-VhN2S0ShVVv61xW3XHPVx4j4cYQW4JmW812dFQ80VkmJ5s4M-Y6TN2h8r0Jt7kQDW4DW_5M2DrNC1W2jL6Yw1VCgFHdw4FvR04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eQwQ 32B\u003c/a\u003e\u0026nbsp;excels at visual reasoning but is slower and has a smaller context window. Amazon’s\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdv5nR32W5BWr2F6lZ3nvVj93qZ2K_mhbW7g-BPf8LvgJQN8SZG8RbjBpNW32qglb6l_8zXW620hxm1d0ks3W257cqw8gq_5QW1xXk8k7H0mDRW6kb1hR6QVPv4W4l-d1c663ntjW4Yn4Sr2Q6RG_W8SJd806YYDgSW3jCqCj4nmqCzW8928xV4R0xZgW81z-sk2zLGKZW46HQrG6hxkCyW4X2JfK1Y5h9NN4hgQDp_l5NmW7hQLwT4YSTDcVywlCt896rHVW81L3Db1tfL3HW15_q684VW-06W6L6nn25ptvVtW3jl2wf64JYQtW2S0mXk3nXQb1W1c6F5g2JY5gVW12v27k2GbvTbW292rz61dD9KXW3vJ9Gr7RJWsrW2HmHBN5fF-6BW2DpcTv3wW9JpW1bFSN1367FZHW5TyRbs6_2bXdW7d5YN37FJ6TFW3XPg407HsJ0Df7VBzJ204?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eNova Premier\u003c/a\u003e, which is billed as a model for “complex reasoning tasks,” is expected in early 2025, but Amazon has not yet described its performance, architecture, or other details.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;o1 and o1 pro mode highlight a dramatic shift in model development and pricing. Giving models more processing power at inference enables them to provide more accurate output, and it’s a key part of agentic workflows. It also continues to boost performance even as scaling laws that predict better performance with more training data and compute may be reaching their\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdb5nR32W50kH_H6lZ3pzW4r0mZh7NmkWcW4N-kgQ91WJvzW3GfjjW68ZbnQW6l8pdK5Zzz7HW6VXwLK9bls6gN9fvSrCfx8fGN8FDGN_Mt-_nW64mDVF4_VZQDW2v2-hM881vdHW6X6tmN2HjVlXW2mbSpJ5BK4d4VfnPnG3VjcRjMHsCsvw3LbzV9zXnS5tfXR2W3zHCHz6ZVNvPVWPlXZ51TYn_W6lF_ld352z2gW2WbLgN75GPqPW14zmNH1_0P6bW7yPVp81Rj1DsW2H6JqB5ccD4dW8_WwYz6wPVy-W7rmMpr2Glv1vW178Q7n1rXWs9W5jJ-S739w3qkW6Gbx2-1x34TyW744XH058fTRwW82RXdN841DM-W326N2Z63_Z65W4zRx5m7yMFddW6fYpQV1p6Kd2W5Bdvdz5VfvZQf85Gwlj04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003elimits\u003c/a\u003e. However, it also raises OpenAI’s costs, and at $200 a month, the price of access to o1 and o1 pro is steep. It’s a premium choice for developers who require exceptional accuracy or extensive reasoning.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Discovering scaling laws for using more processing at inference, or\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3n_W3m0vmR6dZJ38W44Wq-L45l4p7W6R2x3P3hGq5YW5l1YfC17qv2QW4YcdPC84jpS5N2t0RpTTBf7yW8JnV8Z4YRynMW5ZJ47t2Z7QxWW5McVhf1-kVZnW8nf9r77MRcJxVdDsFR2MlD_sW736ySV1vwGnrW7s3dx21QsB5BN2CHS-WjRXbJV82lkQ3YNw0rW1x0nbq43CMdvW8rrnM04lx2GBW6DNrh01mVHlPW1R30GC44fjjjW790DX24pJnlWW8rWDxL34pdP1W7J2Fql8Wnd2Yf4sJD3204?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003etest-time compute\u003c/a\u003e, is an unsolved problem. Although OpenAI hasn’t disclosed the algorithm behind o1 pro mode, recent\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3lPMhHlRW9v3YPW2KTtBt8yKrv9W25ZCfc6y-3mBW24lylK1_zmyFN2tHT_C2lTbmV9C3FY6yGq90V5wKBJ2q0xCNN8-sFH_6cfDsW66PHHk73LqJvW93dNsJ4LP2MmW37CpKc4G8ws-W1tbYwX1G2rXkW7F_Dl53qW905VQ7_YC93s8qFW7zM5_C5yfSDBW6Vbpn828SlgzN2jNjNT_HrkJW8bn3072fwp6dW656-fS6d79SJW3MvrgH60s3XrW8Fqjzp5Ys_86W3kZ1yw8zw9ZCf2zj8HM04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003ework\u003c/a\u003e\u0026nbsp;at Google allocated tokens dynamically at inference based on a prompt’s difficulty. This approach boosted the compute efficiency by four times and enabled a model that had shown “nontrivial success rates” to outperform one that was 14 times larger.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--37-.gif\" class=\"kg-image\" alt=\"Game character climbing a ladder with visible controls (QWASD) and health bars.\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--37-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"game-worlds-on-tap\"\u003eGame Worlds on Tap\u003c/h1\u003e\u003cp\u003eA new model improves on recent progress in generating interactive virtual worlds from still images.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Jack Parker-Holder and colleagues from Google introduced\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf-3qgyTW8wLKSR6lZ3lLW1FWhkP4j57hqW99N8KZ1-pmR-W7rbc1p1Hc3L4W3zPK-_2l7g3HW7TZYNq5xqJv1W64kNqx4BCyZvW7_Hm9v4ng7xsW17YvSs7sNQ79VZrqtv6Lr_-YVtfyTs709vpKW5s4Y442HyWqnW7hgLzQ1YdbgWW57v_ws3m4Nb7W6MQd276J_4vhW1r0TRs3Nx9ZdW7QLr4r50h2rVW4l1b-V1NVn96W3GWv6j1pzhfQN2qVZnt_WcJxW9lws5H14QXMsW8f5GR22C09GKW6G4g1q7r342YW6433nb3tXkGnW8rPCps2bj9RCW7bP5Sr4S2BQcW6YWH0-5rDR_pN1tDd23Xvg8ZW72d5cY980VHQf8G_hxn04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eGenie 2\u003c/a\u003e, which generates three-dimensional video game worlds that respond to keyboard inputs in real time. The model’s output remains consistent (that is, elements don’t morph or disappear) for up to a minute, and it includes first-person shooters, walking simulators, and driving games from viewpoints that include first person, third person, and isometric. Genie 2 follows up on\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3n3W92Tvw-629NjHW80Pwt37fgR8vW2_BlP-653r63W5YPc8-4nhxXLW8SJ2DX5kPfdFW5hz1H98mKWvWW5nTS296wBRmNW9fJvvt7rNpCjW4713nF2_jZVDVCCZkl195F0RW11NQy41FZ1wtW7xKYNq5qSQClW83Q73S2wQBzvW7j1B6H2LtzvyW4_sZDm7z6zcCW3VYf5W7WXw2LW7PkLfM8D10HlW7txHtZ6LnPldW6Qqg9d4v5XjwW5PkgV17Kw6Q7W2rS91n5jhHsLW1kz29222JR_CW1k2lZp1LTljnW20Vdds83qtKWf2DgyMx04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eGenie\u003c/a\u003e, which generates two-dimensional games.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Genie 2 is a latent diffusion model that generates video frames made up of an encoder, transformer, and decoder. The developers didn’t reveal how they built it or how they improved on earlier efforts.\u003c/p\u003e\u003cul\u003e\u003cli\u003eGiven video frames, the encoder embeds them. Using those embeddings and keyboard input, the transformer generates the embedding of the next video frame. The decoder takes the new embedding and generates an image.\u003c/li\u003e\u003cli\u003eAt inference, given an image as the starting frame, the encoder embeds it. Given the embedding and keyboard input, the transformer generates the embedding of the next frame, which the decoder uses to generate an image. After the initial frame, the transformer uses embeddings it generated previously plus keyboard input to generate the next embedding.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Genie 2 arrives on the heels of\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmgg3qgyTW95jsWP6lZ3nMW8ZQD4y7Q55HnVbZJrM8_7ZBXW77VZyB7Xyq53W7YMkQz3zJSQTW492stg8jyCVmW6552104LXbRnW8stCvg2N9_sBW8pVthw2Mc6jwN7-G-Mwzg2-tW1-T_3p2ncw6CW5CvDSy4xlTWCW1ydPK78dytByW1__y8g3QNzNWW2Hg8jB8BWz62VyjwB09bFvYmN7cNKdypvryMW9gqhB01lTcr-W98t7Y785_hk-W7jDV4X3QsBf9VTV1WJ5vNN9jVtVmS-7_HQFmN2dQsBF5ZxscW5RD_4_2fhyhtN8B0Zf8FBhFxW95wBcJ4VsJ-bW1NbGxG6bGHZjN72ncW2420jQN4smYlfNFRRbN5-PSBNSq3m5VJwy0t4v199Hf3Hwlgx04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eOasis\u003c/a\u003e, which generates a Minecraft-like game in real time. Unlike Oasis, Genie 2 worlds are more consistent and not limited to one type of game. It also comes at the same time as another videogame generator,\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3pQW8Ygtml4xrrffW4mkqcb1lXWLyW2nlT7q6xp_5FW84HCG83zVsp3W1YkqcJ8Kv-7rV9Ykwt1dl1yVW942ln07vZ0bnN3GcgqTdzRVGW89CNbw486pnhW1XZB1q1pm75vN4ZGV9dv3ktcW5t5NHs85QZ7NW62nHGX5mJ_nPN6G5G9Fllsw5W2GxKxG96J1DXW7RL3y97W4KvcVv_ybS8TqK3lW3xFB7r1pM74gW64nc4p5PLSS3VLqX0x1LMWwlW6jb4rq7RRdzFN2tbgx5BMlm7f3vb8yl04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eWorld Labs\u003c/a\u003e. However, where Genie 2 generates the next frame given previous frames and keyboard input (acting, in terms of game development, as both graphics and physics engines), World Labs generates a 3D mesh of a game world from a single 2D image. This leaves the implementation of physics, graphics rendering, the player’s character, and other game mechanics to external software.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Genie 2 extends models that visualize 3D scenes based on 2D images to encompass interactive worlds, a capability that could prove valuable in design, gaming, virtual reality, and other 3D applications. It generates imagery that, the authors suggest, could serve as training data for agents to learn how to navigate and respond to commands in 3D environments.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Generating gameplay directly in the manner of Genie 2 is a quick approach to developing a game, but the current technology comes with caveats. Developers can’t yet control a game’s physics or mechanics and they must manage any flaws in the model (such as a tendency to generate inconsistent worlds). In contrast, generating a 3D mesh, as World Labs does, is a more cumbersome approach, but it gives developers more control.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.gif\" class=\"kg-image\" alt=\"Graph showing how training loss affects token prediction accuracy and hallucination elimination.\" loading=\"lazy\" width=\"600\" height=\"336\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"getting-the-facts-right\"\u003eGetting the Facts Right\u003c/h1\u003e\u003cp\u003eLarge language models that remember more hallucinate less.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Johnny Li and colleagues at Lamini introduced\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3mhM1QZXPd2Wq-MVqxvdCnKRnW10xjq08jntYdW8tvmmP27QqVpVXzvPr1b8dlJW7BYFh77dhCkPW4X0BGH3h86fvW5XtDtm81XzxHN79cj0ksrxZ0W1ZBSGs2ZjtsDW7WrF446DHMCMW88V1gG7n8kfpW3swr2W1YLRdpW8yjL7f1szhRbW3SfpmQ2PxxdfW15GqWq3mCl3sN5NJGjq77R2JW6l-cmj96y75bW3g1MtJ86q_wnW6sZZsl7hRpx6MKMxLTsVvk4W1X6r-54b5yG1f7RPVLv04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eMixture of Memory Experts (MoME)\u003c/a\u003e, a method that enables large language models (LLMs) to memorize many facts with relatively modest computational requirements. (Disclosure: Andrew Ng invested in Lamini.)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;The key to getting factual answers from LLMs is to keep training it until it chooses the correct answer every time. In technical terms, train past the point where tokens relevant to the answer have a similar probability distribution, and continue until a single token has 100 percent probability. But this amount of training takes a lot of computation and, since the model may overfit the training set, it also may degrade performance on the test set. Fine-tuning is one solution, and fine-tuning a LoRA adapter to memorize facts reduces the computational burden. But a single LoRA adapter isn’t enough to store all of the knowledge in a large dataset. Training multiple adapters that are selected by cross-attention enables the LLM to memorize a variety of facts.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The authors extended a pretrained\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmf43qgyTW6N1vHY6lZ3nNW3WgmD-3-VNfJW6r44tC1MwZ69W5y4-C-83Z1lfW7YzQL31-JmXXW5tz2D46tGxPvM8dXQVhR7x5N618sdWr3BX_W7P_68t7-bP7NW7KJqvK4B8r7QW55PmJf5q3bpzW52KZDp3KF1t0W6bRJcL7NS-ZzW4jCTwl4NxMjMW2ZCK1K5q8x4pVF62v15wX0xrW7RFzBl7c7jN7W1JY1R13L8by8W3G1b8r6Y9XtXW1HyRCS6pWvktW46Ty_z5XB6fyW7QrBZn4QbkgvW3RPShF8XJMlvf408ytK04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eLlama-3-8B\u003c/a\u003e\u0026nbsp;with a large number (on the order of 1 million) of LoRA adapters and a cross-attention layer. They froze Llama-3-8B and trained the LoRA adapters to predict the next token in a custom dataset of over 1 million questions and answers.\u003c/p\u003e\u003cul\u003e\u003cli\u003eFor any given question, the model learned to select 32 LoRA adapters, each of which was associated with an embedding. The model selected adapters by performing cross-attention between an embedding of the input query and all adapter embeddings.\u003c/li\u003e\u003cli\u003eThe authors trained the LoRA adapters until they memorized all the answers as measured by the loss function (100 epochs).\u003c/li\u003e\u003cli\u003eAt inference, given a query, the model used cross-attention to select a subset of LoRA adapters and responded accordingly.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The authors\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmfn3qgyTW7lCdLW6lZ3pPW5f_dkq5-WBV-W4PpktS21G4JbW1b7mhD8kLZ64VlQ1KP1YDJnlN6pd9KWXRdl1W1wfFlw89hvnsW71b2jF3n3BJ3W1whM-M4rg0DBW8zpLNS5SZFdsW4X0tbP8-kYHQW5rg3P36z5KpbW6fvxy_11vXb_VNSNwf27L97qW6KWVNb1_0y_8N7SS224h2HZYW4CTzbD2qY7WnW6gN8vT6Ps24mW6HNGgR3sNr80W7LL2B490-TlVW1v2bC81fprkcW4_4cMT5MLztLW95zzTk8Fhz9dW7LkT007Nf1mvW1RySd341g55ff35cWfb04?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003etested\u003c/a\u003e\u0026nbsp;their LoRA-enhanced model’s ability to answer questions about a database via SQL queries. The model, which was outfitted for retrieval-augmented generation (RAG), achieved 94.7 percent accuracy. An unnamed model with RAG achieved 50 percent accuracy.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYes, but:\u003c/strong\u003e\u0026nbsp;It stands to reason that the authors’ approach saves processing, but it’s unclear how much. The authors didn’t mention the cost of fine-tuning Llama-3-8B in the usual way on their training dataset for the same number of epochs.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;The authors argue that eliminating hallucinations is possible in typical training, it’s just computationally very expensive (not to mention the risk of overfitting). An architecture designed to store and retrieve facts, via LoRA adapters in this case, makes the process more feasible.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;While some researchers want large language models to memorize facts, others want them to\u0026nbsp;\u003ca href=\"https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VX7mtD5_R0PpW4s8mgk6mslVJW2jjqKJ5psFmBN4Hzmdb5nR32W50kH_H6lZ3p7N5R_dZxTbT43W4gd7FW4FjyFjW71QYR785qhP7W8mvKrr5m6xXGN4S_r5ddJGVSW1129Q14mpyG0W1zl4tr65cY40W8p1tH-8CWTbdW77g_jt5Dmq9RW6p2nRp5x-WSGW7MYNRc7YKBPKW5dHwn_8lVfXYW7kGq461gWXbWW7FtS4S3gVLyHW1tVJF13xrRHvMHvLF1RjwPxW69ZCN31z-77KW5HHPrC1TKZBJW31hJtr7N39PKW7QDhhT29mLxqW4nW2Gh7D7JBLW3FMf7H3pt9dmW8dXM5Y6FhfVZW14JdBp2qKfh3W4-NwMz2WbCSmW4m3snd9fHsxyW3LkD9L4rk_VXW3XBz--3JlBdYW2k0QqT6HwWDDN1Nj1Lgn3yjmW5x-xTW6gsNhdW6RMRb-86tQjtf8tv_6804?ref=dl-staging-website.ghost.io\" rel=\"noopener\"\u003eavoid memorizing their training data\u003c/a\u003e. These aims address very different problems. Preventing LLMs from memorizing training data would make them less likely to regurgitate it verbatim and thus violate copyrights. On the other hand, this work memorizes facts so the model can deliver consistent, truthful responses that might be stated in a variety of ways.\u003c/p\u003e","comment_id":"6759f81f58d8b10001af9b7b","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38--1.jpg","featured":false,"visibility":"public","created_at":"2024-12-11T12:37:51.000-08:00","updated_at":"2024-12-22T12:36:12.000-08:00","published_at":"2024-12-11T12:50:00.000-08:00","custom_excerpt":"The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"6759fb8358d8b10001af9bb7","name":"Dec 11, 2024","slug":"dec-11-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/dec-11-2024/"},{"id":"6759fb8358d8b10001af9bb8","name":"issue-279","slug":"issue-279","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-279/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-279/","excerpt":"The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created numerous opportunities to build AI applications.","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Amazon Nova’s Competitive Price/Performance, OpenAI o1 Pro’s High Price/Performance, Google’s Game Worlds on Tap, Factual LLMs","meta_description":"The Batch AI News and Insights: AI Product Management is evolving rapidly. The growth of generative AI and AI-based developer tools has created...","email_subject":null,"frontmatter":null,"feature_image_alt":"Cartoon showing people stuck in wet concrete, with a person saying ‘You asked for a concrete idea!’","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/12/unnamed--38--1.jpg","dimensions":{"width":1200,"height":676}},"banner":{"title":"ChatGPT Prompt Engineering for Developers","databaseId":29452,"id":"cG9zdDoyOTQ1Mg==","featuredImage":{"node":{"altText":"","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/05/cgpt-2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-279"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>