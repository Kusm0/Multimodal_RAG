<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Amazon&#x27;s New Chatbot, Pedestrian Detection, Limits on AI in Insurance, and more</title><meta name="description" content="The Batch - AI News &amp; Insights: Large language models, or LLMs, have transformed how we process text. Large vision models, or LVMs, are starting to..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-226/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Amazon&#x27;s New Chatbot, Pedestrian Detection, Limits on AI in Insurance, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch - AI News &amp; Insights: Large language models, or LLMs, have transformed how we process text. Large vision models, or LVMs, are starting to..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Amazon&#x27;s New Chatbot, Pedestrian Detection, Limits on AI in Insurance, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-226/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2023-12-06T14:40:51.000-08:00"/><meta property="article:modified_time" content="2023-12-07T11:29:48.000-08:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-226"/><meta property="article:tag" content="Dec 06, 2023"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Amazon&#x27;s New Chatbot, Pedestrian Detection, Limits on AI in Insurance, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch - AI News &amp; Insights: Large language models, or LLMs, have transformed how we process text. Large vision models, or LVMs, are starting to..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-226/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--77--1.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--77--1.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="675"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2023-12-06T14:40:51.000-08:00","dateModified":"2023-12-07T11:29:48.000-08:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Amazon's New Chatbot, Pedestrian Detection, Limits on AI in Insurance, and more","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--77--1.png","width":1200,"height":675},"publisher":{"@type":"Organization","name":"Amazon's New Chatbot, Pedestrian Detection, Limits on AI in Insurance, and more","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch - AI News & Insights: Large language models, or LLMs, have transformed how we process text. Large vision models, or LVMs, are starting to..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-226/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 226</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Dec 6, 2023</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">14<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/dec-06-2023/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Dec 06, 2023</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">14<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-226/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-226/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-226/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends, </em></p><p><em>Large language models, or LLMs, have transformed how we process text. Large vision models, or LVMs, are starting to change how we process images as well. But there is an important difference between LLMs and LVMs: &nbsp;</em></p><ul><li><em>Internet text is similar enough to companies' proprietary text that an LLM trained on internet text can usually understand your proprietary documents.</em></li><li><em>But many practical vision applications use images that look nothing like internet images. In these settings, you might do much better with a domain-specific LVM that has been adapted to your particular application domain.</em></li></ul><p><em>This week, Dan Maloney and I announced Landing AI's work on developing domain-specific LVMs. You can learn more about it in this short&nbsp;</em><a href="https://youtu.be/29USE4U5IXo?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener"><em>video</em></a><em>&nbsp;(4 minutes).</em></p><p><em>The internet – especially sites like Instagram – has numerous pictures of people, pets, landmarks, and everyday objects. So a generic LVM (usually a large vision transformer trained using a self-supervised learning objective on unlabeled images scraped from the internet) learns to recognize salient features in such images.&nbsp;</em></p><p><em>But many industry-specific applications of computer vision involve images that look little like internet images. Pathology applications, for instance, process images of tissue samples captured using high-powered microscopes. Alternatively, manufacturing inspection applications might work with numerous images centered on a single object or part of an object, all of which were imaged under similar lighting and camera configurations.</em></p><p><em>While some pathology and some manufacturing images can be found on the internet, their relative scarcity means that most generic LVMs do poorly at recognizing the most important features in such images.</em>&nbsp;</p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--77-.png" class="kg-image" alt="Visualization of features of a pathology image using a generic LVM (left) versus a domain-specific LVM (right)" loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/12/unnamed--77-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/12/unnamed--77-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--77-.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><em>In experiments conducted by Landing AI's Mark Sabini, Abdelhamid Bouzid, and Bastian Renjifo, LVMs adapted to images of a particular domain, such as pathology or semiconductor wafer inspection, do much better at finding relevant features in images of that domain. Building these LVMs can be done with around 100,000 unlabeled images from that domain, and larger datasets likely would result in even better models.</em></p><p><em>Further, if you use a pretrained LVM together with a small labeled dataset to tackle a supervised learning task, a domain specific LVM needs significantly less (around 10 percent to 30 percent as much) labeled data to &nbsp;achieve performance comparable to using a generic LVM.</em></p><p><em>Consequently, I believe domain specific LVMs can help businesses with large, proprietary sets of images that look different from internet images unlock considerable value from their data.&nbsp;</em></p><p><em>Of course, LVMs are still young, and much innovation lies ahead. My team is continuing to experiment with different ways to train domain-specific LVMs, as well as exploring how to combine such models with text to form domain-specific large multimodal models. I'm confident that LVMs will achieve many more breakthroughs in the coming years.<br><br>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/12/unnamed---2023-12-06T153211.227.gif" class="kg-image" alt="Demo of Q, Amazon's enterprise chatbot" loading="lazy" width="600" height="336" srcset="https://dl-staging-website.ghost.io/content/images/2023/12/unnamed---2023-12-06T153211.227.gif 600w"></figure><h1 id="amazon-joins-chatbot-fray">Amazon Joins Chatbot Fray</h1><p>Amazon launched a chatbot for large companies even as internal tests indicated potential problems.</p><p><strong>What’s new:</strong>&nbsp;Amazon introduced&nbsp;<a href="https://aws.amazon.com/q/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">Q</a>, an AI-powered assistant that enables employees to query documents and corporate systems. Days later, the tech newsletter&nbsp;<em>Platformer</em>&nbsp;<a href="https://www.platformer.news/p/amazons-q-has-severe-hallucinations?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">obtained</a>&nbsp;internal documents that indicate the model can generates falsehood and leak confidential information. (Amazon Q is not to be confused with OpenAI&nbsp;<a href="https://www.technologyreview.com/2023/11/27/1083886/unpacking-the-hype-around-openais-rumored-new-q-model/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">Q*</a>.)&nbsp;</p><p><strong>How it works:</strong>&nbsp;Currently available as a free preview, Q analyzes private documents, databases, and code to answer questions, generate content, and take actions. Amazon&nbsp;<a href="https://aws.amazon.com/q/pricing/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">plans</a>&nbsp;to offer two tiers of service: a basic chatbot ($20 per month) and the chatbot plus code generation, troubleshooting, security evaluation, and human assistance from Amazon Web Services ($25 per month). Amazon promises not to train machine learning models on Q users’ data.&nbsp;</p><p><strong>The issues:</strong>&nbsp;Three days after Amazon unveiled Q, employees began to flag issues on internal Slack and security reporting channels.</p><ul><li>Q provided inaccurate recommendations on issues of digital sovereignty; that is, whether or not data should be stored within a particular jurisdiction, a thorny legal issue in Europe and other parts of the world.&nbsp;</li><li>One employee raised a “<a href="https://www.atlassian.com/incident-management/kpis/severity-levels?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">sev 2</a>” alert, indicating an issue severe enough to warrant paging engineers after hours and over the weekend.</li><li>Internal tests showed that Q could leak confidential information from Amazon such as internal discount programs, unreleased features, and locations of AWS data centers. Amazon spokespeople called such scenarios hypothetical and&nbsp;<a href="https://www.datacenterdynamics.com/en/news/amazons-q-generative-ai-chatbot-leaks-location-of-aws-data-centers/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">denied</a>&nbsp;that Q had leaked such information.</li></ul><p><strong>Behind the news:</strong>&nbsp;Amazon is not the only major AI company whose chatbot has leaked private information. Google researchers recently&nbsp;<a href="https://arxiv.org/abs/2311.17035?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">found</a>&nbsp;that they could prompt OpenAI’s ChatGPT to divulge personal information found in its training data.</p><p><strong>Why it matters:</strong>&nbsp;For Amazon, issues with a newly released system are a bump in the road to competing effectively against competitors like Microsoft Copilot and ChatGPT Enterprise. For developers, it’s a sobering reminder that when you move fast, what breaks may be your own product.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;In developing an AI system, often it’s necessary to launch — in a safe and responsible way — and make improvements based on real-world performance. We congratulate the Q team on getting the product out and look forward to seeing where they take it.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--78-.png" class="kg-image" alt="Screenshot of a pedestrian detector" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/12/unnamed--78-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/12/unnamed--78-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--78-.png 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="seeing-darker-skinned-pedestrians">Seeing Darker-Skinned Pedestrians&nbsp;</h1><p>In a study, models used to detect people walking on streets and sidewalks performed less well on adults with darker skin and children of all skin tones.</p><p><strong>What’s new:</strong>&nbsp;Xinyui Li, Zhenpeng Chen, and colleagues at Peking University, University College London, and King’s College London&nbsp;<a href="https://arxiv.org/pdf/2308.02935.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">evaluated</a>&nbsp;eight widely used object detectors for bias with respect to skin color, age, and gender.</p><p><strong>Key insight:</strong>&nbsp;When it comes to detecting pedestrians, biases with respect to demographic characteristics can be a life-and-death matter. Evaluating them requires a dataset of pedestrians labeled according to characteristics that might influence detection. Skin color, age, and gender are important human differences that can affect a vision model’s performance, especially depending on lighting conditions.</p><p><strong>How it works:&nbsp;</strong>The authors collected over 8,000 photos from four&nbsp;<a href="https://github.com/CharlesShang/Detectron-PYTORCH/tree/master/data/citypersons?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">datasets</a>&nbsp;<a href="https://eurocity-dataset.tudelft.nl/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">of</a>&nbsp;<a href="https://eurocity-dataset.tudelft.nl/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">street</a>&nbsp;<a href="https://www.vis.xyz/bdd100k/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">scenes</a>. They annotated each image with labels for skin tone (light or dark), age group (child or adult), and gender (male or female). They tested four general-purpose object detectors:&nbsp;<a href="https://arxiv.org/abs/2107.08430?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">YOLOX</a>,&nbsp;<a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">RetinaNet</a>,&nbsp;<a href="https://papers.nips.cc/paper_files/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">Faster R-CNN</a>, and&nbsp;<a href="https://arxiv.org/abs/1712.00726?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">Cascade R-CNN</a>&nbsp;— and four pedestrian-specific detectors —&nbsp;<a href="https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Wei_Liu_Learning_Efficient_Single-stage_ECCV_2018_paper.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">ALFNet</a>,&nbsp;<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_High-Level_Semantic_Feature_Detection_A_New_Perspective_for_Pedestrian_Detection_CVPR_2019_paper.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">CSP</a>,&nbsp;<a href="https://arxiv.org/abs/1910.06160?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">MGAN</a>, and&nbsp;<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123680035.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">PRNet</a>&nbsp;— on their dataset. They evaluated performance between perceived skin tone, age, and gender groups and under different conditions of brightness, contrast, and weather.</p><p><strong>Results:</strong>&nbsp;The study revealed significant fairness issues related to skin tone and age.</p><ul><li>Six models detected people with light and dark skin tones equally well, but two — YOLOX and RetinaNet — were 30.71 and 28.03 percent less likely to detect darker-skinned people. In all cases, darker-skinned pedestrians were less likely to be detected under conditions of low contrast and low brightness.</li><li>All eight models showed worse performance with children than adults For instance, YOLOX detected children 26.06 less often, while CSP detected children 12.68 percent less often. On average, the models failed to detect 46.57 percent of children, but only 26.91 percent of adults.</li><li>Most of the models performed equally well regardless of gender. However, all eight had difficulty detecting women in the EuroCity-Night dataset, which contains photos shot after dark.</li></ul><p><strong>Behind the news:</strong>&nbsp;Previous&nbsp;<a href="https://arxiv.org/abs/2010.15052?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">work</a>&nbsp;has shown that computer vision models can harbor biases that make them less likely to recognize individuals of certain types. In 2019, MIT&nbsp;<a href="https://www.media.mit.edu/publications/actionable-auditing-investigating-the-impact-of-publicly-naming-biased-performance-results-of-commercial-ai-products/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">showed</a>&nbsp;that commercial face recognition performed worse on women and darker skinned individuals. A&nbsp;<a href="https://people.csail.mit.edu/torralba/publications/datasets_cvpr11.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">plethora</a>&nbsp;of&nbsp;<a href="https://arxiv.org/abs/1711.08536?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">work</a>&nbsp;<a href="https://arxiv.org/abs/1912.07726?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">evaluates</a>&nbsp;bias in datasets typically used to train vision models.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;As more road vehicles gain self-driving capabilities and as expanded robotaxi services come to major cities, a growing number of pedestrians’ lives are in the hands of computer vision algorithms. Auto makers don’t disclose what pedestrian detection systems they use or the number of real-world accidents involving self-driving cars. But co-author Jie Zhang&nbsp;<a href="https://www.newscientist.com/article/2386635-driverless-cars-may-struggle-to-spot-children-and-dark-skinned-people/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">claims</a>&nbsp;that the proprietary systems used in self-driving cars are “usually built upon the existing open-source models,” and “we can be certain that their models must also have similar issues.”</p><p><strong>We’re thinking:</strong>&nbsp;Computer vision isn’t the only technology used by self-driving cars to detect objects. Most self-driving car manufacturers rely on lidar and radar in addition to cameras. Those technologies are blind to color and gender differences and, in the view of many engineers, make better choices for this application.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.eventbrite.com/e/llm-agent-fine-tuning-enhancing-task-automation-with-weights-biases-tickets-771861728207?aff=Batch&ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2023/12/The-Batch--3-.png" class="kg-image" alt="" loading="lazy" width="1680" height="945" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/12/The-Batch--3-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/12/The-Batch--3-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/12/The-Batch--3-.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/12/The-Batch--3-.png 1680w" sizes="(min-width: 720px) 720px"></a></figure><p>Want to learn how to fine-tune large language model-based agents? In our upcoming webinar with Weights and Biases, you’ll gain insights and techniques to enhance agent performance and specificity in automating applications.&nbsp;<a href="https://www.eventbrite.com/e/llm-agent-fine-tuning-enhancing-task-automation-with-weights-biases-tickets-771861728207?aff=Batch&ref=dl-staging-website.ghost.io" rel="noreferrer">Register now</a></p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--33-.jpg" class="kg-image" alt="Colorado flag with a neural network over it" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2023/12/unnamed--33-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/12/unnamed--33-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--33-.jpg 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="limits-on-ai-in-life-insurance">Limits on AI in Life Insurance</h1><p>The U.S. state of Colorado started regulating the insurance industry’s use of AI.</p><p><strong>What’s new:</strong>&nbsp;Colorado&nbsp;<a href="https://news.bloomberglaw.com/insurance/insurers-ai-use-for-coverage-decisions-targeted-by-blue-states?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">implemented</a>&nbsp;the first law that regulates use of AI in life insurance and proposed extending the limits to auto insurers. Other states have taken steps to rein in both life and auto insurers under earlier statutes.</p><p><strong>How it works:</strong>&nbsp;States are responsible for regulating the insurance industry in the U.S. Colorado’s&nbsp;<a href="https://www.debevoise.com/insights/publications/2023/10/the-final-colorado-ai-insurance-regulations-whats?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">rules</a>&nbsp;limit kinds of data life insurers can use and how they can use it. They took effect in November based on a&nbsp;<a href="https://leg.colorado.gov/bills/sb21-169?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">law</a>&nbsp;passed in 2021.&nbsp;</p><ul><li>Data considered “traditional” is fair game. This category includes medical information, family history, occupation, criminal history, prescription drug history, and finances.&nbsp;</li><li>Insurers that use models based on nontraditional data such as credit scores, social media activity, and shopping histories must report their use, with a description of each model, its purpose, and what data it’s based on. Insurers must test such models for biases and report the results.</li><li>Insurers are required to document guiding principles for model development and report annual reviews of both their governance structures and risk-management frameworks.</li></ul><p><strong>Other states:</strong>&nbsp;California&nbsp;<a href="https://www.insurance.ca.gov/0250-insurers/0800-rate-filings/0200-prior-approval-factors/upload/PriorAppRateFilingInstr_Ed06-05-2023.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">ordered</a>&nbsp;all insurers to notify regulators when their algorithm results in an increase to a customer’s premium; regulators can then evaluate whether the effect of the rate increase is excessive and/or discriminatory. Agencies in&nbsp;<a href="https://www.debevoisedatablog.com/2022/05/02/connecticut-requires-non-discrimination-certifications-from-insurers-using-ai?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">Connecticut</a>&nbsp;and&nbsp;<a href="https://www.dfs.ny.gov/industry_guidance/circular_letters/cl2019_01?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">New York</a>&nbsp;ordered all insurers to conform their use of AI with laws against discrimination. Washington D.C.&nbsp;<a href="https://disb.dc.gov/page/evaluating-unintentional-bias-private-passenger-automobile-insurance?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">opened</a>&nbsp;an investigation to determine whether auto insurers’ use of data resulted in outcomes that discriminated against certain groups.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;Colorado shared an initial draft of its life-insurance regulations earlier this year before&nbsp;<a href="https://www.debevoise.com/-/media/files/insights/publications/2023/06/01_the-revised-colorado-ai-insurance-regulations.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">revising</a>&nbsp;it. Among other changes, the initial draft prohibited AI models that discriminate not only on the basis of race but with respect to all protected classes; prevent unauthorized access to models; create a plan to respond to unforeseen consequences of their models; and engage outside experts to audit their models.&nbsp;The final draft omits these requirements.</p><p><strong>Why it matters:</strong>&nbsp;Regulators are concerned that AI could perpetuate existing biases against marginalized groups, and Colorado’s implementation is likely to serve as a model for further regulation. Insurance companies&nbsp;<a href="https://www.reuters.com/legal/lawsuit-claims-unitedhealth-ai-wrongfully-denies-elderly-extended-care-2023-11-14/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">face</a>&nbsp;a growing number of lawsuits over claims that their algorithms wrongfully&nbsp;<a href="https://www.nytimes.com/2022/12/14/business/state-farm-racial-bias-lawsuit.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">discriminate</a>&nbsp;by age or race. Regulation could mitigate potential harms and ease customers’ concerns.</p><p><strong>We’re thinking:</strong>&nbsp;Reporting of models that use social posts, purchases, and the like is a good first step, although we suspect that further rules will be needed to govern the complexities of the insurance business. Other states’ use of Colorado's regulations as a blueprint would avoid a state-by-state patchwork of contradictory regulations.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2023/12/unnamed---2023-12-06T155705.846.gif" class="kg-image" alt="Animated diagram depicting the problem setup and proposed method" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2023/12/unnamed---2023-12-06T155705.846.gif 600w"></figure><h1 id="robot-find-my-keys">Robot, Find My Keys</h1><p>Researchers proposed a way for robots to find objects in households where things get moved around.</p><p><strong>What's new:</strong>&nbsp;Andrey Kurenkov and colleagues at Stanford University introduced&nbsp;<a href="https://proceedings.mlr.press/v202/kurenkov23a.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R" rel="noopener">Node Edge Predictor</a>, a model that learned to predict where objects were located in houses.</p><p><strong>Key insight:</strong>&nbsp;A popular way to represent objects and their locations is a graph, in which each node is either an object or its location and an edge connects the two. If we want to track objects over time, a recurrent model could predict the locations of objects using a separate graph for each time step, but that would require a prohibitive number of graphs. Instead, a model can predict locations using a single graph in which each edge is annotated, additionally, with the time elapsed since the associated object was seen in the associated location. The model learns to predict the next most likely place to find an object based on the object’s most recent, frequent, and longstanding locations.</p><p><strong>How it works:</strong>&nbsp;The authors simulated a robot looking for things in a household. They built (i) a simulator of houses, object locations, and when and where they moved; (ii) a graph that represented a house containing objects; and (iii) a machine learning system that predicted where objects might be found.</p><ul><li>The simulator presented a household in which objects moved randomly over time — as if people were moving them — according to predefined probabilities. For example, a mug might move from a cabinet to a table. At each time step, a simulated robot observed one piece of furniture and the objects on or inside it.</li><li>The robot represented its observations as a graph. The nodes included rooms, furniture, and objects, while edges connected each object to every piece of furniture and every piece of furniture to a room. The node and edge embeddings represented the robot’s past observations; for example, where it last saw the mug, time elapsed since that observation, and how many times it had seen the mug there.&nbsp;</li><li>The authors simulated the robot moving through 100 households with various floor plans. They built a training set of 10,000 graphs.</li><li>They trained the machine learning system to predict whether an object was on/in a given piece of furniture (that is, whether an edge connected a given object and location at the current timestep). The system embedded previously observed nodes and edges using a separate vanilla neural network for each, concatenated the embeddings, and fed them to a graph neural network followed by a two-layer transformer. A vanilla neural network at the end of the transformer generated probabilities for all edges that connected a given object to various pieces of furniture.</li></ul><p><strong>Results:</strong>&nbsp;The authors tested their system’s ability to find a single object in a house versus a few baseline methods. The baselines included random guessing, always guessing the piece of furniture where the object was last seen, and a Bayesian model that guessed whether the object was on/in a given piece of furniture based on the percentage of times it had been seen there. On average, their system found the object in 3.2 attempts, while the next best model (Bayesian) took 3.6 attempts. Guessing the last-seen location required 6.0 attempts, and random guessing required 8.8 attempts.</p><p><strong>Why it matters:</strong>&nbsp;Feature engineering helps to find the best way to represent data so a model can learn from it. In this work, engineering time-related features (such as the time elapsed since an object was on a piece of furniture or the number of times an object was observed on a piece of furniture over time) enabled a non-recurrent model to learn how graphs change over time.</p><p><strong>We’re thinking:</strong>&nbsp;A physical robot likely would use object detection on its camera feed instead of a simulator that told it directly which objects were associated with which pieces of furniture. We look forward to future work that proves the concept using this more realistic setup.</p><hr><h1 id="data-points">Data Points</h1><p><strong>Microsoft announces £2.5 billion investment to boost the UK’s AI capabilities</strong><br>The investment aims to double Microsoft’s UK datacenter footprint by 2026, train or retrain over one million people for the AI economy, and extend Microsoft’s Accelerating Foundation Models Research (AFMR) program to prioritize GPU access for the UK’s research community. (Read more at <a href="https://blogs.microsoft.com/on-the-issues/2023/11/30/uk-ai-skilling-security-datacenters-investment/?ref=dl-staging-website.ghost.io"><u>Microsoft</u></a>)&nbsp;</p><p><a href="https://www.heritagefund.org.uk/about/insight/research/artificial-intelligence-digital-heritage-leadership-briefing?ref=dl-staging-website.ghost.io"><strong><u>Research</u></strong></a><strong> finds opportunities and risks as heritage organizations embrace AI</strong><br>A new study focuses on what innovation in AI looks like in the UK heritage sector, and showcases its diverse uses in museums, galleries, libraries, and archives. Notable examples include predictive analytics for exhibition popularity at the National Gallery. However, the study also highlighted risks such as discrimination, misinformation, copyright infringement, and transparency issues. (Read more at <a href="https://www.museumsassociation.org/museums-journal/news/2023/11/research-highlights-opportunities-and-risks-of-ai-for-heritage-organisations/?ref=dl-staging-website.ghost.io#"><u>Museum Association</u></a>)</p><p><strong>U.S. mandates Saudi venture capital firm must sell stake in Silicon Valley AI firm&nbsp;</strong><br>The Biden administration has instructed Prosperity7 to sell its shares in Rain AI, a Silicon Valley AI chip startup backed by OpenAI co-founder Sam Altman. Rain AI, which designs AI chips inspired by brain functionality, had Prosperity7 as a lead investor in a funding round that raised $25 million in 2022. (Read the news story at <a href="https://www.bloomberg.com/news/articles/2023-11-30/us-compels-saudi-fund-to-exit-ai-chip-startup-backed-by-altman?ref=dl-staging-website.ghost.io"><em><u>Bloomberg</u></em></a>)&nbsp;</p><p><strong>Generative AI regulation allegedly stalls EU legislation talks</strong><br>Sources revealed that negotiations on foundation models have become the primary hurdle, with a risk of shelving the act before European parliamentary elections next year unless an agreement is reached. France, Germany, and Italy form an important bloc of countries opposing foundation models. Pending issues also include establishing a definition of AI and national security exceptions. Critics argue that self-regulation may fall short of safety standards for foundation models, creating legal uncertainty and impeding European industries' planning. (Read the article at <a href="https://www.reuters.com/technology/generative-ai-stumbling-block-eu-legislation-talks-sources-2023-12-01/?ref=dl-staging-website.ghost.io"><em><u>Reuters</u></em></a>)</p><p><strong>AI fuels innovations in Pennsylvania's infrastructure projects</strong><br>In Pennsylvania, U.S., where 13 percent of bridges face structural deficiencies, engineers are leveraging AI to address challenges like the development of lighter concrete blocks for construction and noise-absorbing walls along highways. The projects aim to create more resilient structures at a reduced cost. The use of AI in civil engineering could revolutionize project development, early damage detection, and real-time incident analysis, but careful consideration and regulations are urged to ensure safety and reliability. (Read the article in <a href="https://www.nytimes.com/2023/11/19/us/ai-infrastructure-construction.html?ref=dl-staging-website.ghost.io"><em><u>The New York Times</u></em></a>)</p><p><strong>Anduril's Roadrunner: AI combat drone takes flight&nbsp;</strong><br>Anduril's latest innovation combines AI technology and jet-powered capabilities to counter the escalating threat of low-cost, sophisticated aerial attacks. The modular and autonomous Roadrunner drone aims to provide rapid response and heightened resilience against evolving threats such as suicide drones. (Read more at <a href="https://www.wired.com/story/anduril-roadrunner-drone/?ref=dl-staging-website.ghost.io"><em><u>Wired</u></em></a>)</p><p><strong>General Motors to reduce investment in Cruise self-driving division next year</strong><br>Following recent accidents involving its self-driving taxis in San Francisco, the company, initially planning expansion to multiple cities, now focuses on rebuilding trust with regulators and communities. The decision to reduce spending follows the suspension of Cruise's robotaxi license in California and a need to regain public trust in the wake of safety incidents, including a pedestrian fatality. (Read the article at <a href="https://www.nytimes.com/2023/11/29/technology/cruise-general-motors.html?ref=dl-staging-website.ghost.io"><em><u>The New York Times</u></em></a>)</p><p><strong>Sam Altman returns as OpenAI CEO</strong><br>Besides Altman’s return, Mira Murati reassumed her role as CTO, and Greg Brockman returned as President. For now, the new board comprises former Salesforce CEO Bret Taylor (Chair), economist Larry Summers, and Quora CEO Adam D’Angelo. (Read the blog post at <a href="https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board?ref=dl-staging-website.ghost.io"><u>OpenAI</u></a>)</p><p><strong>Consortium of major companies develops data provenance standards to enhance trust in AI</strong><br>Many companies (including American Express, IBM, and Walmart) formed the Data &amp; Trust Alliance, introducing new standards for data provenance in AI applications. These standards cover eight basic criteria, including lineage, source, legal rights, and data type. The goal is to offer clear data documentation and bolster efficiency and trust in AI developments. (Read more at <a href="https://www.nytimes.com/2023/11/30/business/ai-data-standards.html?ref=dl-staging-website.ghost.io"><em><u>The New York Times</u></em></a>)</p><p><strong>Amazon Web Services (AWS) introduces Titan models in Amazon Bedrock</strong><br>Amazon’s Titan Image Generator and Titan Multimodal Embeddings offer image, multimodal, and text options through a fully managed API. The Titan Image Generator enables content creators to generate images using natural language prompts, targeting applications in advertising, e-commerce, and media. The Titan Multimodal Embeddings facilitate the creation of contextually relevant multimodal search and recommendation experiences. (Read the blog post at <a href="https://aws.amazon.com/blogs/aws/amazon-titan-image-generator-multimodal-embeddings-and-text-models-are-now-available-in-amazon-bedrock/?ref=dl-staging-website.ghost.io"><u>AWS</u></a>)</p><p><strong>Voicemod launches feature to craft and share custom synthetic voices</strong><br>The app, known for its AI voice-changing program popular in the gaming and streaming communities, now enables users to craft and share their unique AI voices by modifying their own voices or choosing from various genders, ages, and tones. (Read more at <a href="https://www.theverge.com/2023/11/30/23981835/voicemod-ai-voice-creator-community-voices?ref=dl-staging-website.ghost.io"><em><u>The Verge</u></em></a>)</p><p><strong>Demand keeps soaring for prompt engineers</strong><br>Prompt engineering emerged as a lucrative and sought-after skill in the year since the public launch of ChatGPT. Google searches for "prompt engineering" have skyrocketed, and LinkedIn reports substantial increases in related terms on member profiles. The skillset, involving coaxing AI systems for better results and training colleagues in using generative AI, is in high demand. Newly-created roles offer significant compensation, often upwards of $335,000 annually. (Read the analysis at <a href="https://www.bloomberg.com/news/articles/2023-11-30/a-year-after-chatgpt-everybody-still-wants-prompt-engineers?ref=dl-staging-website.ghost.io"><em><u>Bloomberg</u></em></a>)</p><p><a href="https://www.nature.com/articles/s41591-023-02643-7?ref=dl-staging-website.ghost.io"><u>Research</u></a><strong>: Deep learning model offers precision in predicting breast cancer outcomes</strong>&nbsp;<br>The Histomic Prognostic Signature (HiPS), which evaluates both cancerous and non-cancerous cell patterns, outperformed expert pathologists in predicting disease progression. By identifying breast cancer patients classified as high or intermediate risk who could become long-term survivors, the tool offers the potential to reduce the duration or intensity of chemotherapy, sparing patients from harmful side effects. (Read the article via <a href="https://news.northwestern.edu/stories/2023/11/ai-may-spare-breast-cancer-patients-unnecessary-treatments/?fj=1&ref=dl-staging-website.ghost.io"><u>Northwestern University</u></a>)</p><p><strong>IBM expands geospatial AI collaboration to tackle climate challenges globally</strong><br>The initiative involves mapping urban heat islands in the UAE, supporting Kenya's reforestation campaign, and enhancing climate resiliency in the UK's aviation sector. Additionally, IBM is collaborating with NASA to develop a new model for weather and climate, aiming to improve the precision and efficiency of weather forecasting and address climate-related challenges on a global scale. (Read more at <a href="https://newsroom.ibm.com/2023-11-30-IBM-Advances-Geospatial-AI-to-Address-Climate-Challenges?ref=dl-staging-website.ghost.io"><u>IBM</u></a>)</p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook." data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook." data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/resources/#ebooks"><div class="absolute inset-0" data-gtm-event-title="AI is the new electricity"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-226/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-226/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-226/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm3" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-226","id":"6570cc9082a075000119b630","uuid":"0fe4b360-a8b7-4c7a-89cf-d22f87ee23e8","title":"Amazon's New Chatbot, Pedestrian Detection, Limits on AI in Insurance, a Robot That Can Find Your Keys","html":"\u003cp\u003e\u003cem\u003eDear friends, \u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eLarge language models, or LLMs, have transformed how we process text. Large vision models, or LVMs, are starting to change how we process images as well. But there is an important difference between LLMs and LVMs: \u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cem\u003eInternet text is similar enough to companies' proprietary text that an LLM trained on internet text can usually understand your proprietary documents.\u003c/em\u003e\u003c/li\u003e\u003cli\u003e\u003cem\u003eBut many practical vision applications use images that look nothing like internet images. In these settings, you might do much better with a domain-specific LVM that has been adapted to your particular application domain.\u003c/em\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cem\u003eThis week, Dan Maloney and I announced Landing AI's work on developing domain-specific LVMs. You can learn more about it in this short\u0026nbsp;\u003c/em\u003e\u003ca href=\"https://youtu.be/29USE4U5IXo?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003e\u003cem\u003evideo\u003c/em\u003e\u003c/a\u003e\u003cem\u003e\u0026nbsp;(4 minutes).\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eThe internet – especially sites like Instagram – has numerous pictures of people, pets, landmarks, and everyday objects. So a generic LVM (usually a large vision transformer trained using a self-supervised learning objective on unlabeled images scraped from the internet) learns to recognize salient features in such images.\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eBut many industry-specific applications of computer vision involve images that look little like internet images. Pathology applications, for instance, process images of tissue samples captured using high-powered microscopes. Alternatively, manufacturing inspection applications might work with numerous images centered on a single object or part of an object, all of which were imaged under similar lighting and camera configurations.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eWhile some pathology and some manufacturing images can be found on the internet, their relative scarcity means that most generic LVMs do poorly at recognizing the most important features in such images.\u003c/em\u003e\u0026nbsp;\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--77-.png\" class=\"kg-image\" alt=\"Visualization of features of a pathology image using a generic LVM (left) versus a domain-specific LVM (right)\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/12/unnamed--77-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/12/unnamed--77-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--77-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eIn experiments conducted by Landing AI's Mark Sabini, Abdelhamid Bouzid, and Bastian Renjifo, LVMs adapted to images of a particular domain, such as pathology or semiconductor wafer inspection, do much better at finding relevant features in images of that domain. Building these LVMs can be done with around 100,000 unlabeled images from that domain, and larger datasets likely would result in even better models.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eFurther, if you use a pretrained LVM together with a small labeled dataset to tackle a supervised learning task, a domain specific LVM needs significantly less (around 10 percent to 30 percent as much) labeled data to \u0026nbsp;achieve performance comparable to using a generic LVM.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eConsequently, I believe domain specific LVMs can help businesses with large, proprietary sets of images that look different from internet images unlock considerable value from their data.\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eOf course, LVMs are still young, and much innovation lies ahead. My team is continuing to experiment with different ways to train domain-specific LVMs, as well as exploring how to combine such models with text to form domain-specific large multimodal models. I'm confident that LVMs will achieve many more breakthroughs in the coming years.\u003cbr\u003e\u003cbr\u003eKeep learning!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed---2023-12-06T153211.227.gif\" class=\"kg-image\" alt=\"Demo of Q, Amazon's enterprise chatbot\" loading=\"lazy\" width=\"600\" height=\"336\" srcset=\"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed---2023-12-06T153211.227.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"amazon-joins-chatbot-fray\"\u003eAmazon Joins Chatbot Fray\u003c/h1\u003e\u003cp\u003eAmazon launched a chatbot for large companies even as internal tests indicated potential problems.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Amazon introduced\u0026nbsp;\u003ca href=\"https://aws.amazon.com/q/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eQ\u003c/a\u003e, an AI-powered assistant that enables employees to query documents and corporate systems. Days later, the tech newsletter\u0026nbsp;\u003cem\u003ePlatformer\u003c/em\u003e\u0026nbsp;\u003ca href=\"https://www.platformer.news/p/amazons-q-has-severe-hallucinations?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eobtained\u003c/a\u003e\u0026nbsp;internal documents that indicate the model can generates falsehood and leak confidential information. (Amazon Q is not to be confused with OpenAI\u0026nbsp;\u003ca href=\"https://www.technologyreview.com/2023/11/27/1083886/unpacking-the-hype-around-openais-rumored-new-q-model/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eQ*\u003c/a\u003e.)\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Currently available as a free preview, Q analyzes private documents, databases, and code to answer questions, generate content, and take actions. Amazon\u0026nbsp;\u003ca href=\"https://aws.amazon.com/q/pricing/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eplans\u003c/a\u003e\u0026nbsp;to offer two tiers of service: a basic chatbot ($20 per month) and the chatbot plus code generation, troubleshooting, security evaluation, and human assistance from Amazon Web Services ($25 per month). Amazon promises not to train machine learning models on Q users’ data.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eThe issues:\u003c/strong\u003e\u0026nbsp;Three days after Amazon unveiled Q, employees began to flag issues on internal Slack and security reporting channels.\u003c/p\u003e\u003cul\u003e\u003cli\u003eQ provided inaccurate recommendations on issues of digital sovereignty; that is, whether or not data should be stored within a particular jurisdiction, a thorny legal issue in Europe and other parts of the world.\u0026nbsp;\u003c/li\u003e\u003cli\u003eOne employee raised a “\u003ca href=\"https://www.atlassian.com/incident-management/kpis/severity-levels?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003esev 2\u003c/a\u003e” alert, indicating an issue severe enough to warrant paging engineers after hours and over the weekend.\u003c/li\u003e\u003cli\u003eInternal tests showed that Q could leak confidential information from Amazon such as internal discount programs, unreleased features, and locations of AWS data centers. Amazon spokespeople called such scenarios hypothetical and\u0026nbsp;\u003ca href=\"https://www.datacenterdynamics.com/en/news/amazons-q-generative-ai-chatbot-leaks-location-of-aws-data-centers/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003edenied\u003c/a\u003e\u0026nbsp;that Q had leaked such information.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Amazon is not the only major AI company whose chatbot has leaked private information. Google researchers recently\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2311.17035?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003efound\u003c/a\u003e\u0026nbsp;that they could prompt OpenAI’s ChatGPT to divulge personal information found in its training data.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;For Amazon, issues with a newly released system are a bump in the road to competing effectively against competitors like Microsoft Copilot and ChatGPT Enterprise. For developers, it’s a sobering reminder that when you move fast, what breaks may be your own product.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;In developing an AI system, often it’s necessary to launch — in a safe and responsible way — and make improvements based on real-world performance. We congratulate the Q team on getting the product out and look forward to seeing where they take it.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--78-.png\" class=\"kg-image\" alt=\"Screenshot of a pedestrian detector\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/12/unnamed--78-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/12/unnamed--78-.png 1000w, https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--78-.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"seeing-darker-skinned-pedestrians\"\u003eSeeing Darker-Skinned Pedestrians\u0026nbsp;\u003c/h1\u003e\u003cp\u003eIn a study, models used to detect people walking on streets and sidewalks performed less well on adults with darker skin and children of all skin tones.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Xinyui Li, Zhenpeng Chen, and colleagues at Peking University, University College London, and King’s College London\u0026nbsp;\u003ca href=\"https://arxiv.org/pdf/2308.02935.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eevaluated\u003c/a\u003e\u0026nbsp;eight widely used object detectors for bias with respect to skin color, age, and gender.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;When it comes to detecting pedestrians, biases with respect to demographic characteristics can be a life-and-death matter. Evaluating them requires a dataset of pedestrians labeled according to characteristics that might influence detection. Skin color, age, and gender are important human differences that can affect a vision model’s performance, especially depending on lighting conditions.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u0026nbsp;\u003c/strong\u003eThe authors collected over 8,000 photos from four\u0026nbsp;\u003ca href=\"https://github.com/CharlesShang/Detectron-PYTORCH/tree/master/data/citypersons?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003edatasets\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://eurocity-dataset.tudelft.nl/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eof\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://eurocity-dataset.tudelft.nl/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003estreet\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://www.vis.xyz/bdd100k/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003escenes\u003c/a\u003e. They annotated each image with labels for skin tone (light or dark), age group (child or adult), and gender (male or female). They tested four general-purpose object detectors:\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2107.08430?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eYOLOX\u003c/a\u003e,\u0026nbsp;\u003ca href=\"https://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eRetinaNet\u003c/a\u003e,\u0026nbsp;\u003ca href=\"https://papers.nips.cc/paper_files/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eFaster R-CNN\u003c/a\u003e, and\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/1712.00726?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eCascade R-CNN\u003c/a\u003e\u0026nbsp;— and four pedestrian-specific detectors —\u0026nbsp;\u003ca href=\"https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Wei_Liu_Learning_Efficient_Single-stage_ECCV_2018_paper.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eALFNet\u003c/a\u003e,\u0026nbsp;\u003ca href=\"https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_High-Level_Semantic_Feature_Detection_A_New_Perspective_for_Pedestrian_Detection_CVPR_2019_paper.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eCSP\u003c/a\u003e,\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/1910.06160?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eMGAN\u003c/a\u003e, and\u0026nbsp;\u003ca href=\"https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123680035.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003ePRNet\u003c/a\u003e\u0026nbsp;— on their dataset. They evaluated performance between perceived skin tone, age, and gender groups and under different conditions of brightness, contrast, and weather.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The study revealed significant fairness issues related to skin tone and age.\u003c/p\u003e\u003cul\u003e\u003cli\u003eSix models detected people with light and dark skin tones equally well, but two — YOLOX and RetinaNet — were 30.71 and 28.03 percent less likely to detect darker-skinned people. In all cases, darker-skinned pedestrians were less likely to be detected under conditions of low contrast and low brightness.\u003c/li\u003e\u003cli\u003eAll eight models showed worse performance with children than adults For instance, YOLOX detected children 26.06 less often, while CSP detected children 12.68 percent less often. On average, the models failed to detect 46.57 percent of children, but only 26.91 percent of adults.\u003c/li\u003e\u003cli\u003eMost of the models performed equally well regardless of gender. However, all eight had difficulty detecting women in the EuroCity-Night dataset, which contains photos shot after dark.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Previous\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2010.15052?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003ework\u003c/a\u003e\u0026nbsp;has shown that computer vision models can harbor biases that make them less likely to recognize individuals of certain types. In 2019, MIT\u0026nbsp;\u003ca href=\"https://www.media.mit.edu/publications/actionable-auditing-investigating-the-impact-of-publicly-naming-biased-performance-results-of-commercial-ai-products/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eshowed\u003c/a\u003e\u0026nbsp;that commercial face recognition performed worse on women and darker skinned individuals. A\u0026nbsp;\u003ca href=\"https://people.csail.mit.edu/torralba/publications/datasets_cvpr11.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eplethora\u003c/a\u003e\u0026nbsp;of\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/1711.08536?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003ework\u003c/a\u003e\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/1912.07726?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eevaluates\u003c/a\u003e\u0026nbsp;bias in datasets typically used to train vision models.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;As more road vehicles gain self-driving capabilities and as expanded robotaxi services come to major cities, a growing number of pedestrians’ lives are in the hands of computer vision algorithms. Auto makers don’t disclose what pedestrian detection systems they use or the number of real-world accidents involving self-driving cars. But co-author Jie Zhang\u0026nbsp;\u003ca href=\"https://www.newscientist.com/article/2386635-driverless-cars-may-struggle-to-spot-children-and-dark-skinned-people/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eclaims\u003c/a\u003e\u0026nbsp;that the proprietary systems used in self-driving cars are “usually built upon the existing open-source models,” and “we can be certain that their models must also have similar issues.”\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Computer vision isn’t the only technology used by self-driving cars to detect objects. Most self-driving car manufacturers rely on lidar and radar in addition to cameras. Those technologies are blind to color and gender differences and, in the view of many engineers, make better choices for this application.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.eventbrite.com/e/llm-agent-fine-tuning-enhancing-task-automation-with-weights-biases-tickets-771861728207?aff=Batch\u0026ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/12/The-Batch--3-.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/12/The-Batch--3-.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/12/The-Batch--3-.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2023/12/The-Batch--3-.png 1600w, https://dl-staging-website.ghost.io/content/images/2023/12/The-Batch--3-.png 1680w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eWant to learn how to fine-tune large language model-based agents? In our upcoming webinar with Weights and Biases, you’ll gain insights and techniques to enhance agent performance and specificity in automating applications.\u0026nbsp;\u003ca href=\"https://www.eventbrite.com/e/llm-agent-fine-tuning-enhancing-task-automation-with-weights-biases-tickets-771861728207?aff=Batch\u0026ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eRegister now\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--33-.jpg\" class=\"kg-image\" alt=\"Colorado flag with a neural network over it\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2023/12/unnamed--33-.jpg 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2023/12/unnamed--33-.jpg 1000w, https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--33-.jpg 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"limits-on-ai-in-life-insurance\"\u003eLimits on AI in Life Insurance\u003c/h1\u003e\u003cp\u003eThe U.S. state of Colorado started regulating the insurance industry’s use of AI.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Colorado\u0026nbsp;\u003ca href=\"https://news.bloomberglaw.com/insurance/insurers-ai-use-for-coverage-decisions-targeted-by-blue-states?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eimplemented\u003c/a\u003e\u0026nbsp;the first law that regulates use of AI in life insurance and proposed extending the limits to auto insurers. Other states have taken steps to rein in both life and auto insurers under earlier statutes.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;States are responsible for regulating the insurance industry in the U.S. Colorado’s\u0026nbsp;\u003ca href=\"https://www.debevoise.com/insights/publications/2023/10/the-final-colorado-ai-insurance-regulations-whats?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003erules\u003c/a\u003e\u0026nbsp;limit kinds of data life insurers can use and how they can use it. They took effect in November based on a\u0026nbsp;\u003ca href=\"https://leg.colorado.gov/bills/sb21-169?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003elaw\u003c/a\u003e\u0026nbsp;passed in 2021.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eData considered “traditional” is fair game. This category includes medical information, family history, occupation, criminal history, prescription drug history, and finances.\u0026nbsp;\u003c/li\u003e\u003cli\u003eInsurers that use models based on nontraditional data such as credit scores, social media activity, and shopping histories must report their use, with a description of each model, its purpose, and what data it’s based on. Insurers must test such models for biases and report the results.\u003c/li\u003e\u003cli\u003eInsurers are required to document guiding principles for model development and report annual reviews of both their governance structures and risk-management frameworks.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eOther states:\u003c/strong\u003e\u0026nbsp;California\u0026nbsp;\u003ca href=\"https://www.insurance.ca.gov/0250-insurers/0800-rate-filings/0200-prior-approval-factors/upload/PriorAppRateFilingInstr_Ed06-05-2023.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eordered\u003c/a\u003e\u0026nbsp;all insurers to notify regulators when their algorithm results in an increase to a customer’s premium; regulators can then evaluate whether the effect of the rate increase is excessive and/or discriminatory. Agencies in\u0026nbsp;\u003ca href=\"https://www.debevoisedatablog.com/2022/05/02/connecticut-requires-non-discrimination-certifications-from-insurers-using-ai?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eConnecticut\u003c/a\u003e\u0026nbsp;and\u0026nbsp;\u003ca href=\"https://www.dfs.ny.gov/industry_guidance/circular_letters/cl2019_01?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eNew York\u003c/a\u003e\u0026nbsp;ordered all insurers to conform their use of AI with laws against discrimination. Washington D.C.\u0026nbsp;\u003ca href=\"https://disb.dc.gov/page/evaluating-unintentional-bias-private-passenger-automobile-insurance?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eopened\u003c/a\u003e\u0026nbsp;an investigation to determine whether auto insurers’ use of data resulted in outcomes that discriminated against certain groups.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Colorado shared an initial draft of its life-insurance regulations earlier this year before\u0026nbsp;\u003ca href=\"https://www.debevoise.com/-/media/files/insights/publications/2023/06/01_the-revised-colorado-ai-insurance-regulations.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003erevising\u003c/a\u003e\u0026nbsp;it. Among other changes, the initial draft prohibited AI models that discriminate not only on the basis of race but with respect to all protected classes; prevent unauthorized access to models; create a plan to respond to unforeseen consequences of their models; and engage outside experts to audit their models.\u0026nbsp;The final draft omits these requirements.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Regulators are concerned that AI could perpetuate existing biases against marginalized groups, and Colorado’s implementation is likely to serve as a model for further regulation. Insurance companies\u0026nbsp;\u003ca href=\"https://www.reuters.com/legal/lawsuit-claims-unitedhealth-ai-wrongfully-denies-elderly-extended-care-2023-11-14/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eface\u003c/a\u003e\u0026nbsp;a growing number of lawsuits over claims that their algorithms wrongfully\u0026nbsp;\u003ca href=\"https://www.nytimes.com/2022/12/14/business/state-farm-racial-bias-lawsuit.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003ediscriminate\u003c/a\u003e\u0026nbsp;by age or race. Regulation could mitigate potential harms and ease customers’ concerns.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Reporting of models that use social posts, purchases, and the like is a good first step, although we suspect that further rules will be needed to govern the complexities of the insurance business. Other states’ use of Colorado's regulations as a blueprint would avoid a state-by-state patchwork of contradictory regulations.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed---2023-12-06T155705.846.gif\" class=\"kg-image\" alt=\"Animated diagram depicting the problem setup and proposed method\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed---2023-12-06T155705.846.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"robot-find-my-keys\"\u003eRobot, Find My Keys\u003c/h1\u003e\u003cp\u003eResearchers proposed a way for robots to find objects in households where things get moved around.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat's new:\u003c/strong\u003e\u0026nbsp;Andrey Kurenkov and colleagues at Stanford University introduced\u0026nbsp;\u003ca href=\"https://proceedings.mlr.press/v202/kurenkov23a.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz-9-YtT2tJE16faY8ahIYfjkZHzr58Aw8aCHmvJbH__7rZ4MemAEajO3Wt7KrHdsHZESNi3R\" rel=\"noopener\"\u003eNode Edge Predictor\u003c/a\u003e, a model that learned to predict where objects were located in houses.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;A popular way to represent objects and their locations is a graph, in which each node is either an object or its location and an edge connects the two. If we want to track objects over time, a recurrent model could predict the locations of objects using a separate graph for each time step, but that would require a prohibitive number of graphs. Instead, a model can predict locations using a single graph in which each edge is annotated, additionally, with the time elapsed since the associated object was seen in the associated location. The model learns to predict the next most likely place to find an object based on the object’s most recent, frequent, and longstanding locations.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The authors simulated a robot looking for things in a household. They built (i) a simulator of houses, object locations, and when and where they moved; (ii) a graph that represented a house containing objects; and (iii) a machine learning system that predicted where objects might be found.\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe simulator presented a household in which objects moved randomly over time — as if people were moving them — according to predefined probabilities. For example, a mug might move from a cabinet to a table. At each time step, a simulated robot observed one piece of furniture and the objects on or inside it.\u003c/li\u003e\u003cli\u003eThe robot represented its observations as a graph. The nodes included rooms, furniture, and objects, while edges connected each object to every piece of furniture and every piece of furniture to a room. The node and edge embeddings represented the robot’s past observations; for example, where it last saw the mug, time elapsed since that observation, and how many times it had seen the mug there.\u0026nbsp;\u003c/li\u003e\u003cli\u003eThe authors simulated the robot moving through 100 households with various floor plans. They built a training set of 10,000 graphs.\u003c/li\u003e\u003cli\u003eThey trained the machine learning system to predict whether an object was on/in a given piece of furniture (that is, whether an edge connected a given object and location at the current timestep). The system embedded previously observed nodes and edges using a separate vanilla neural network for each, concatenated the embeddings, and fed them to a graph neural network followed by a two-layer transformer. A vanilla neural network at the end of the transformer generated probabilities for all edges that connected a given object to various pieces of furniture.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The authors tested their system’s ability to find a single object in a house versus a few baseline methods. The baselines included random guessing, always guessing the piece of furniture where the object was last seen, and a Bayesian model that guessed whether the object was on/in a given piece of furniture based on the percentage of times it had been seen there. On average, their system found the object in 3.2 attempts, while the next best model (Bayesian) took 3.6 attempts. Guessing the last-seen location required 6.0 attempts, and random guessing required 8.8 attempts.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Feature engineering helps to find the best way to represent data so a model can learn from it. In this work, engineering time-related features (such as the time elapsed since an object was on a piece of furniture or the number of times an object was observed on a piece of furniture over time) enabled a non-recurrent model to learn how graphs change over time.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;A physical robot likely would use object detection on its camera feed instead of a simulator that told it directly which objects were associated with which pieces of furniture. We look forward to future work that proves the concept using this more realistic setup.\u003c/p\u003e\u003chr\u003e\u003ch1 id=\"data-points\"\u003eData Points\u003c/h1\u003e\u003cp\u003e\u003cstrong\u003eMicrosoft announces £2.5 billion investment to boost the UK’s AI capabilities\u003c/strong\u003e\u003cbr\u003eThe investment aims to double Microsoft’s UK datacenter footprint by 2026, train or retrain over one million people for the AI economy, and extend Microsoft’s Accelerating Foundation Models Research (AFMR) program to prioritize GPU access for the UK’s research community. (Read more at \u003ca href=\"https://blogs.microsoft.com/on-the-issues/2023/11/30/uk-ai-skilling-security-datacenters-investment/?ref=dl-staging-website.ghost.io\"\u003e\u003cu\u003eMicrosoft\u003c/u\u003e\u003c/a\u003e)\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.heritagefund.org.uk/about/insight/research/artificial-intelligence-digital-heritage-leadership-briefing?ref=dl-staging-website.ghost.io\"\u003e\u003cstrong\u003e\u003cu\u003eResearch\u003c/u\u003e\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e finds opportunities and risks as heritage organizations embrace AI\u003c/strong\u003e\u003cbr\u003eA new study focuses on what innovation in AI looks like in the UK heritage sector, and showcases its diverse uses in museums, galleries, libraries, and archives. Notable examples include predictive analytics for exhibition popularity at the National Gallery. However, the study also highlighted risks such as discrimination, misinformation, copyright infringement, and transparency issues. (Read more at \u003ca href=\"https://www.museumsassociation.org/museums-journal/news/2023/11/research-highlights-opportunities-and-risks-of-ai-for-heritage-organisations/?ref=dl-staging-website.ghost.io#\"\u003e\u003cu\u003eMuseum Association\u003c/u\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eU.S. mandates Saudi venture capital firm must sell stake in Silicon Valley AI firm\u0026nbsp;\u003c/strong\u003e\u003cbr\u003eThe Biden administration has instructed Prosperity7 to sell its shares in Rain AI, a Silicon Valley AI chip startup backed by OpenAI co-founder Sam Altman. Rain AI, which designs AI chips inspired by brain functionality, had Prosperity7 as a lead investor in a funding round that raised $25 million in 2022. (Read the news story at \u003ca href=\"https://www.bloomberg.com/news/articles/2023-11-30/us-compels-saudi-fund-to-exit-ai-chip-startup-backed-by-altman?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003e\u003cu\u003eBloomberg\u003c/u\u003e\u003c/em\u003e\u003c/a\u003e)\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eGenerative AI regulation allegedly stalls EU legislation talks\u003c/strong\u003e\u003cbr\u003eSources revealed that negotiations on foundation models have become the primary hurdle, with a risk of shelving the act before European parliamentary elections next year unless an agreement is reached. France, Germany, and Italy form an important bloc of countries opposing foundation models. Pending issues also include establishing a definition of AI and national security exceptions. Critics argue that self-regulation may fall short of safety standards for foundation models, creating legal uncertainty and impeding European industries' planning. (Read the article at \u003ca href=\"https://www.reuters.com/technology/generative-ai-stumbling-block-eu-legislation-talks-sources-2023-12-01/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003e\u003cu\u003eReuters\u003c/u\u003e\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAI fuels innovations in Pennsylvania's infrastructure projects\u003c/strong\u003e\u003cbr\u003eIn Pennsylvania, U.S., where 13 percent of bridges face structural deficiencies, engineers are leveraging AI to address challenges like the development of lighter concrete blocks for construction and noise-absorbing walls along highways. The projects aim to create more resilient structures at a reduced cost. The use of AI in civil engineering could revolutionize project development, early damage detection, and real-time incident analysis, but careful consideration and regulations are urged to ensure safety and reliability. (Read the article in \u003ca href=\"https://www.nytimes.com/2023/11/19/us/ai-infrastructure-construction.html?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003e\u003cu\u003eThe New York Times\u003c/u\u003e\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAnduril's Roadrunner: AI combat drone takes flight\u0026nbsp;\u003c/strong\u003e\u003cbr\u003eAnduril's latest innovation combines AI technology and jet-powered capabilities to counter the escalating threat of low-cost, sophisticated aerial attacks. The modular and autonomous Roadrunner drone aims to provide rapid response and heightened resilience against evolving threats such as suicide drones. (Read more at \u003ca href=\"https://www.wired.com/story/anduril-roadrunner-drone/?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003e\u003cu\u003eWired\u003c/u\u003e\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eGeneral Motors to reduce investment in Cruise self-driving division next year\u003c/strong\u003e\u003cbr\u003eFollowing recent accidents involving its self-driving taxis in San Francisco, the company, initially planning expansion to multiple cities, now focuses on rebuilding trust with regulators and communities. The decision to reduce spending follows the suspension of Cruise's robotaxi license in California and a need to regain public trust in the wake of safety incidents, including a pedestrian fatality. (Read the article at \u003ca href=\"https://www.nytimes.com/2023/11/29/technology/cruise-general-motors.html?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003e\u003cu\u003eThe New York Times\u003c/u\u003e\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSam Altman returns as OpenAI CEO\u003c/strong\u003e\u003cbr\u003eBesides Altman’s return, Mira Murati reassumed her role as CTO, and Greg Brockman returned as President. For now, the new board comprises former Salesforce CEO Bret Taylor (Chair), economist Larry Summers, and Quora CEO Adam D’Angelo. (Read the blog post at \u003ca href=\"https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board?ref=dl-staging-website.ghost.io\"\u003e\u003cu\u003eOpenAI\u003c/u\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eConsortium of major companies develops data provenance standards to enhance trust in AI\u003c/strong\u003e\u003cbr\u003eMany companies (including American Express, IBM, and Walmart) formed the Data \u0026amp; Trust Alliance, introducing new standards for data provenance in AI applications. These standards cover eight basic criteria, including lineage, source, legal rights, and data type. The goal is to offer clear data documentation and bolster efficiency and trust in AI developments. (Read more at \u003ca href=\"https://www.nytimes.com/2023/11/30/business/ai-data-standards.html?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003e\u003cu\u003eThe New York Times\u003c/u\u003e\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAmazon Web Services (AWS) introduces Titan models in Amazon Bedrock\u003c/strong\u003e\u003cbr\u003eAmazon’s Titan Image Generator and Titan Multimodal Embeddings offer image, multimodal, and text options through a fully managed API. The Titan Image Generator enables content creators to generate images using natural language prompts, targeting applications in advertising, e-commerce, and media. The Titan Multimodal Embeddings facilitate the creation of contextually relevant multimodal search and recommendation experiences. (Read the blog post at \u003ca href=\"https://aws.amazon.com/blogs/aws/amazon-titan-image-generator-multimodal-embeddings-and-text-models-are-now-available-in-amazon-bedrock/?ref=dl-staging-website.ghost.io\"\u003e\u003cu\u003eAWS\u003c/u\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eVoicemod launches feature to craft and share custom synthetic voices\u003c/strong\u003e\u003cbr\u003eThe app, known for its AI voice-changing program popular in the gaming and streaming communities, now enables users to craft and share their unique AI voices by modifying their own voices or choosing from various genders, ages, and tones. (Read more at \u003ca href=\"https://www.theverge.com/2023/11/30/23981835/voicemod-ai-voice-creator-community-voices?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003e\u003cu\u003eThe Verge\u003c/u\u003e\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eDemand keeps soaring for prompt engineers\u003c/strong\u003e\u003cbr\u003ePrompt engineering emerged as a lucrative and sought-after skill in the year since the public launch of ChatGPT. Google searches for \"prompt engineering\" have skyrocketed, and LinkedIn reports substantial increases in related terms on member profiles. The skillset, involving coaxing AI systems for better results and training colleagues in using generative AI, is in high demand. Newly-created roles offer significant compensation, often upwards of $335,000 annually. (Read the analysis at \u003ca href=\"https://www.bloomberg.com/news/articles/2023-11-30/a-year-after-chatgpt-everybody-still-wants-prompt-engineers?ref=dl-staging-website.ghost.io\"\u003e\u003cem\u003e\u003cu\u003eBloomberg\u003c/u\u003e\u003c/em\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.nature.com/articles/s41591-023-02643-7?ref=dl-staging-website.ghost.io\"\u003e\u003cu\u003eResearch\u003c/u\u003e\u003c/a\u003e\u003cstrong\u003e: Deep learning model offers precision in predicting breast cancer outcomes\u003c/strong\u003e\u0026nbsp;\u003cbr\u003eThe Histomic Prognostic Signature (HiPS), which evaluates both cancerous and non-cancerous cell patterns, outperformed expert pathologists in predicting disease progression. By identifying breast cancer patients classified as high or intermediate risk who could become long-term survivors, the tool offers the potential to reduce the duration or intensity of chemotherapy, sparing patients from harmful side effects. (Read the article via \u003ca href=\"https://news.northwestern.edu/stories/2023/11/ai-may-spare-breast-cancer-patients-unnecessary-treatments/?fj=1\u0026ref=dl-staging-website.ghost.io\"\u003e\u003cu\u003eNorthwestern University\u003c/u\u003e\u003c/a\u003e)\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eIBM expands geospatial AI collaboration to tackle climate challenges globally\u003c/strong\u003e\u003cbr\u003eThe initiative involves mapping urban heat islands in the UAE, supporting Kenya's reforestation campaign, and enhancing climate resiliency in the UK's aviation sector. Additionally, IBM is collaborating with NASA to develop a new model for weather and climate, aiming to improve the precision and efficiency of weather forecasting and address climate-related challenges on a global scale. (Read more at \u003ca href=\"https://newsroom.ibm.com/2023-11-30-IBM-Advances-Geospatial-AI-to-Address-Climate-Challenges?ref=dl-staging-website.ghost.io\"\u003e\u003cu\u003eIBM\u003c/u\u003e\u003c/a\u003e)\u003c/p\u003e","comment_id":"6570cc9082a075000119b630","feature_image":"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--77--1.png","featured":false,"visibility":"public","created_at":"2023-12-06T11:33:36.000-08:00","updated_at":"2023-12-07T11:29:48.000-08:00","published_at":"2023-12-06T14:40:51.000-08:00","custom_excerpt":"The Batch - AI News \u0026 Insights: Large language models, or LLMs, have transformed how we process text. Large vision models, or LVMs, are starting to change how we process images as well. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"6570d09082a075000119b63f","name":"issue-226","slug":"issue-226","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-226/"},{"id":"6570d09082a075000119b640","name":"Dec 06, 2023","slug":"dec-06-2023","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/dec-06-2023/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-226/","excerpt":"The Batch - AI News \u0026 Insights: Large language models, or LLMs, have transformed how we process text. Large vision models, or LVMs, are starting to change how we process images as well. ","reading_time":14,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Amazon's New Chatbot, Pedestrian Detection, Limits on AI in Insurance, and more","meta_description":"The Batch - AI News \u0026 Insights: Large language models, or LLMs, have transformed how we process text. Large vision models, or LVMs, are starting to...","email_subject":null,"frontmatter":null,"feature_image_alt":"Visualization of features of a pathology image using a generic LVM (left) versus a domain-specific LVM (right)","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2023/12/unnamed--77--1.png","dimensions":{"width":1200,"height":675}},"banner":{"title":"AI is the new electricity","databaseId":29050,"id":"cG9zdDoyOTA1MA==","featuredImage":{"node":{"altText":"AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook.","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/resources/#ebooks","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-226"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>