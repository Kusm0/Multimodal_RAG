<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Google&#x27;s Troubled Gemini Launch, OpenAI&#x27;s Next Act, and more</title><meta name="description" content="The Batch AI News and Insights: I think the complexity of Python package management holds down AI application development more than is widely appreciated..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><link rel="canonical" href="https://www.deeplearning.ai/the-batch/issue-238/"/><meta property="og:type" content="article" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:title" content="Google&#x27;s Troubled Gemini Launch, OpenAI&#x27;s Next Act, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:description" content="The Batch AI News and Insights: I think the complexity of Python package management holds down AI application development more than is widely appreciated..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:site_name" content="Google&#x27;s Troubled Gemini Launch, OpenAI&#x27;s Next Act, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="og:url" content="https://www.deeplearning.ai/the-batch/issue-238/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="article:published_time" content="2024-02-28T11:51:32.000-08:00"/><meta property="article:modified_time" content="2024-05-13T07:45:26.000-07:00"/><meta property="article:tag" content="The Batch Newsletter"/><meta property="article:tag" content="issue-238"/><meta property="article:tag" content="Feb 28, 2024"/><meta property="article:author" content="https://www.facebook.com/DeepLearningAIHQ/"/><meta property="twitter:title" content="Google&#x27;s Troubled Gemini Launch, OpenAI&#x27;s Next Act, and more" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:description" content="The Batch AI News and Insights: I think the complexity of Python package management holds down AI application development more than is widely appreciated..." data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:url" content="https://www.deeplearning.ai/the-batch/issue-238/" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:label1" content="Written by"/><meta property="twitter:data1" content="DeepLearning.AI"/><meta property="twitter:label2" content="Filed under"/><meta property="twitter:data2" content="The Batch Newsletter"/><meta property="twitter:card" content="summary_large_image" data-sentry-element="meta" data-sentry-source-file="seo.tsx"/><meta property="twitter:creator" content="@DeepLearningAI"/><meta property="twitter:site" content="https://twitter.com/DeepLearningAI/"/><meta name="twitter:image" content="https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE.png"/><meta property="og:image" content="https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="675"/><script type="application/ld+json">{"@context":"https://schema.org/","@type":"Article","datePublished":"2024-02-28T11:51:32.000-08:00","dateModified":"2024-05-13T07:45:26.000-07:00","author":{"@type":"Article","name":"DeepLearning.AI","image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","sameAs":"[\"https://www.deeplearning.ai/\", \"https://twitter.com/DeepLearningAI_/\", \"https://www.facebook.com/DeepLearningAIHQ/\"]"},"keywords":"[object Object], [object Object], [object Object]","headline":"Google's Troubled Gemini Launch, OpenAI's Next Act, and more","image":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE.png","width":1200,"height":675},"publisher":{"@type":"Organization","name":"Google's Troubled Gemini Launch, OpenAI's Next Act, and more","logo":{"@type":"ImageObject","url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","width":60,"height":60}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.deeplearning.ai"},"description":"The Batch AI News and Insights: I think the complexity of Python package management holds down AI application development more than is widely appreciated..."}</script><meta name="next-head-count" content="31"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&amp;display=swap"/><link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&amp;display=swap"/><link rel="preload" href="/_next/static/css/54b174af9991199d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/54b174af9991199d.css" data-n-g=""/><link rel="preload" href="/_next/static/css/6f396d9f2f265155.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6f396d9f2f265155.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-7690c02358b700f2.js" defer=""></script><script src="/_next/static/chunks/framework-c54e8763846ac33b.js" defer=""></script><script src="/_next/static/chunks/main-9fcc7c9a63f70912.js" defer=""></script><script src="/_next/static/chunks/pages/_app-bece9363d7a6c0bb.js" defer=""></script><script src="/_next/static/chunks/3a17f596-e9670ced3bfab562.js" defer=""></script><script src="/_next/static/chunks/36d2f571-09e32b60ec93a4dc.js" defer=""></script><script src="/_next/static/chunks/5c0b189e-c0f75ca9b44e520b.js" defer=""></script><script src="/_next/static/chunks/5567-47eb911ba5f222d7.js" defer=""></script><script src="/_next/static/chunks/2251-380253169bb2e795.js" defer=""></script><script src="/_next/static/chunks/3864-a4ae56e91852593b.js" defer=""></script><script src="/_next/static/chunks/4965-3585432476b27ea9.js" defer=""></script><script src="/_next/static/chunks/3791-0bbbd4cd0bf31c22.js" defer=""></script><script src="/_next/static/chunks/pages/the-batch/%5Bslug%5D-c03a8bcef188ef99.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_buildManifest.js" defer=""></script><script src="/_next/static/Qy9Eh4N0MrfE3ddReY9v4/_ssgManifest.js" defer=""></script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Poppins:wght@600&display=swap"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5C5VGGJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"><div data-sentry-component="Layout" data-sentry-source-file="Layout.tsx"><aside id="top-announcement" class="text-neutral-900  " style="color:#FFFFFF;background-color:#05256C;background-image:linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)" data-sentry-component="AnnouncementBanner" data-sentry-source-file="AnnouncementBanner.tsx"><div class="container--boxed py-3 flex items-center justify-between "><div class="flex items-center"><p class="text-sm lg:text-base">✨ New course! Enroll in<!-- --> <a href="https://bit.ly/3HlCuvP" class="underline" target="_blank">DSPy: Build and Optimize Agentic Apps</a></p></div><div class="flex items-center"><button class="bg-transparent p-0 border-none text-xl opacity-70 hover:opacity-100 transition-opacity"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><line x1="15" y1="9" x2="9" y2="15"></line><line x1="9" y1="9" x2="15" y2="15"></line></svg></button></div></div></aside><header id="main-navigation" data-testid="main-navigation-testid" class="static h-[64px] md:h-[100px] top-0 w-full z-[100] flex items-center bg-white transition-all ease-in-out duration-200" data-sentry-component="Header" data-sentry-source-file="index.tsx"><div class="container--boxed flex justify-between items-center"><div class="max-w-[185px] lg:max-w-[235px]"><a href="/the-batch/"><div class="flex items-center"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27300%27%20height=%2792%27/%3e"/></span><img alt="The Batch" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="The Batch" loading="lazy" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" srcSet="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=384&amp;q=75 1x, /_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75 2x" src="/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdlai-batch-logo.a60dbb9f.png&amp;w=640&amp;q=75"/></noscript></span></div></a></div><div class="flex items-center"><div class="hidden lg:flex items-center"><nav aria-label="Primary" data-sentry-component="Nav" data-sentry-source-file="Nav.tsx"><ul class="flex items-center p-0 m-0 list-none"><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/courses/"><div class="NavItem_navItemLink__Aq6E5"><span>Explore Courses</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/the-batch/"><div class="NavItem_navItemLink__Aq6E5"><span>AI Newsletter</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/"><div>The Batch</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/letters/"><div>Andrew&#x27;s Letter</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/data-points/"><div>Data Points</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/the-batch/tag/research/"><div>ML Research</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/"><div>Blog</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/community/"><div class="NavItem_navItemLink__Aq6E5"><span>Community</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="https://community.deeplearning.ai/"><div>Forum</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/events/"><div>Events</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/ambassador/"><div>Ambassadors</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/blog/category/ambassador-spotlight/"><div>Ambassador Spotlight</div></a></li></ul></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/resources/"><div class="NavItem_navItemLink__Aq6E5"><span>Resources</span></div></a></li><li class="NavItem_navItem__FJTIV first-of-type:ml-0 relative flex justify-center whitespace-nowrap" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a class="dlai-gtm-nav-item inline-block text-slate-500 hover:text-brand py-4 lg:px-2 xl:px-4" href="/about/"><div class="NavItem_navItemLink__Aq6E5"><span>Company</span><span class="text-xl ml-1 -mr-1"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="6 9 12 15 18 9"></polyline></svg></span></div></a><ul class="NavItem_subMenu__qK1m4"><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/about/"><div>About</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/careers/"><div>Careers</div></a></li><li class="NavItem_subMenuItem__2oKDr"><a class="dlai-gtm-nav-item NavItem_subMenuItemLink__35KOd" href="/contact/"><div>Contact</div></a></li></ul></li></ul></nav><a class="btn--primary text-base font-medium whitespace-nowrap shadow h-fit py-3 px-4 lg:ml-2 xl:ml-10" data-sentry-element="Link" data-sentry-source-file="index.tsx" href="https://bit.ly/3RB9T8a">Start Learning</a></div><div class="flex items-center" data-sentry-element="Menu" data-sentry-component="MobileMenu" data-sentry-source-file="MobileMenu.tsx" data-headlessui-state=""><button class="lg:hidden" data-sentry-element="MenuButton" data-sentry-source-file="MobileMenu.tsx" id="headlessui-menu-button-:R1qa6:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-4xl text-slate-600" data-sentry-element="FiMenu" data-sentry-source-file="MobileMenu.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div></div></div></header><main><div id="content"><nav aria-label="Secondary" class="h-[66px] bg-white sticky top-[60px] z-40 shadow hidden lg:block" data-sentry-component="SecondaryNav" data-sentry-source-file="index.tsx"><div class="container--boxed h-full w-full flex items-center justify-between "><div class="relative flex h-full"><button class="h-full w-14 items-center justify-center absolute top-0 left-0 z-10 group bg-white bg-opacity-75 hidden"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="15 18 9 12 15 6"></polyline></svg></span></button><ul id="nav-secondary" class="list-none p-0 m-0 h-full flex items-center  overflow-x-scroll relative SecondaryNav_navItems__dok3i"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Weekly Issues</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/letters/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Andrew&#x27;s Letters</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/data-points/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Data Points</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/research/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">ML Research</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/business/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Business</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/science/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Science</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/culture/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Culture</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/hardware/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">Hardware</div></a></li><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/tag/ai-careers/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">AI Careers</div></a></li></ul><button class="h-full w-9 items-center justify-center absolute top-0 right-0 group bg-white bg-opacity-75 flex"><span class="flex items-center justify-center w-5 h-5 text-white rounded-full bg-slate-500 group-hover:bg-slate-700"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span></button></div><div class="flex items-center h-full"><ul class="list-none p-0 m-0 h-full flex items-center mr-5"><li class="mr-6 last:mr-0 h-full" data-sentry-component="NavItem" data-sentry-source-file="NavItem.tsx"><a data-sentry-element="Link" data-sentry-source-file="NavItem.tsx" href="/the-batch/about/"><div class="h-full relative flex items-center text-base whitespace-nowrap border-solid border-t-2 border-t-transparent border-b-2 text-slate-400 transition-colors border-b-transparent hover:text-slate-500">About</div></a></li></ul><button type="button" class="bg-white border btn--tracking border-solid border-brand text-brand hover:bg-brand hover:text-white transition-colors px-3 py-1 rounded-md mr-4">Subscribe</button><a href="/search/"><div title="Search" class="transition-colors text-slate-400 hover:text-slate-500"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="text-2xl" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg></div></a></div></div></nav><article class="pt-5 pb-16 bg-white lg:pt-16 lg:pb-16" data-sentry-component="ArticleDefault" data-sentry-source-file="ArticleDefault.tsx"><header class="post_layoutGrid__0BDX2"><nav aria-label="Breadcrumb flex items-center" data-sentry-component="Main" data-sentry-source-file="Breadcrumb.tsx"><ul class="list-none flex items-center flex-wrap"><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">The Batch</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/"><div class="text-sm md:text-base text-brand-teal font-medium hover:text-brand-teal-1 transition ">Weekly Issues</div></a></li><span class="mx-1 md:mx-2 text-base text-slate-400" data-sentry-component="Separator" data-sentry-source-file="Breadcrumb.tsx"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" data-sentry-element="FiChevronRight" data-sentry-source-file="Breadcrumb.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><polyline points="9 18 15 12 9 6"></polyline></svg></span><li data-sentry-component="Item" data-sentry-source-file="Breadcrumb.tsx"><a data-sentry-element="Link" data-sentry-source-file="Breadcrumb.tsx" href="/the-batch/issue-238/"><div class="text-sm md:text-base text-slate-400 font-normal "><h1 class="capitalize">issue 238</h1></div></a></li></ul></nav><aside class="flex mt-6 lg:hidden"><div class="flex flex-col items-start items-start mr-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm text-sm">Published</div></div><div class="mt-1 text-slate-600 text-base text-sm">Feb 28, 2024</div></div><div class="flex flex-col items-start items-start" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm text-sm"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm text-sm">Reading time</div></div><div class="mt-1 text-slate-600 text-base text-sm">12<!-- --> min read</div></div></aside></header><div class="post_layoutGrid__0BDX2 mt-9"><aside style="grid-column:wide-start / main-start" class="flex-col items-end hidden pr-10 lg:flex"><div class="flex flex-col items-start items-end" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg></div><div class="ml-2 text-sm undefined">Published</div></div><div class="mt-1 text-slate-600 text-base undefined"><a href="/the-batch/tag/feb-28-2024/"><div class="inline-flex px-2 py-1 text-sm font-normal transition-colors rounded-md bg-slate-100 hover:bg-slate-200 text-slate-500">Feb 28, 2024</div></a></div></div><div class="flex flex-col items-start items-end mt-6" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg></div><div class="ml-2 text-sm undefined">Reading time</div></div><div class="mt-1 text-slate-600 text-base undefined">12<!-- --> min read</div></div><div class="flex flex-col items-start items-end mt-6 sticky top-20" data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-238/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-238/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-238/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></aside><div class="prose--styled justify-self-center post_postContent__wGZtc"><p><em>Dear friends,<br><br>I think the complexity of Python package management holds down AI application development more than is widely appreciated. AI faces multiple bottlenecks — we need more GPUs, better algorithms, cleaner data in large quantities. But when I look at the day-to-day work of application builders, there’s one additional bottleneck that I think is underappreciated: The time spent wrestling with version management is an inefficiency I hope we can reduce.&nbsp;</em></p><p><em>A lot of AI software is written in the Python language, and so our field has adopted Python’s philosophy of letting anyone publish any package online. The resulting rich collection of freely available packages means that, with just one “pip install” command, you now can install a package and give your software new superpowers! The community’s parallel exploration of lots of ideas and open-sourcing of innovations has been fantastic for developing and spreading not just technical ideas but also usable tools.<br><br>But we pay a price for this highly distributed development of AI components: Building on top of open source can mean hours wrestling with package dependencies, or sometimes even juggling multiple virtual environments or using multiple versions of Python in one application. This is annoying but manageable for experienced developers, but creates a lot of friction for new AI developers entering our field without a background in computer science or software engineering.</em></p><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE-1.png" class="kg-image" alt="Illustration of a Python inside a cardboard box" loading="lazy" width="1200" height="675" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/PYTHONPACKAGE-1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/02/PYTHONPACKAGE-1.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><em>I&nbsp;don’t know of any easy solution. Hopefully, as the ecosystem of tools matures, package management will become simpler and easier. Better tools for testing compatibility might be useful, though I’m not sure we need yet another Python package manager (we already have pip, conda, poetry, and more) or virtual environment framework.&nbsp;</em></p><p><em>As a step toward making package management easier, maybe if all of us who develop tools pay a little more attention to compatibility — for example, testing in multiple environments, specifying dependencies carefully, carrying out more careful regression testing, and engaging with the community to quickly spot and fix issues — &nbsp;we can make all of this wonderful open source work easier for new developers to adopt.</em></p><p><em>Keep coding!</em></p><p><em>Andrew</em></p><p><em>P.S. Built in collaboration with Meta: “Prompt Engineering with Llama 2,” taught by Amit Sangani, is now available! Meta’s Llama 2 has been a game changer: Building with open source lets you control your own data, scrutinize errors, update models (or not) as you please, and work alongside the global community to advance open models. In this course, you’ll learn how to prompt Llama chat models using advanced techniques like few-shot for classification and chain-of-thought for logic problems. You’ll also learn how to use specialized models like Code Llama for software development and Llama Guard to check for harmful content. The course also touches on how to run Llama 2 on your own machine. I hope you’ll take this course and try out these powerful, open models!&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener"><em>Sign up here</em></a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/02/GEMINI_MultimodalDemo_NoCC_600px--1-.gif" class="kg-image" alt="" loading="lazy" width="600" height="338" srcset="https://dl-staging-website.ghost.io/content/images/2024/02/GEMINI_MultimodalDemo_NoCC_600px--1-.gif 600w"></figure><h1 id="context-is-everything">Context Is Everything</h1><p><em>Correction: This article has been corrected to state that Gemini 1.0 produced anachronistic images of historical scenes. An earlier edition incorrectly stated that Gemini 1.5 Pro generated anachronistic images. </em></p><p>An update of Google’s flagship multimodal model keeps track of colossal inputs, while an earlier version generated some questionable outputs.</p><p><strong>What's new:</strong>&nbsp;Google&nbsp;<a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">unveiled</a>&nbsp;Gemini 1.5 Pro, a model that can converse about inputs as long as books,&nbsp;codebases, and lengthy passages of video and audio (depending on frame and sample rates). However an earlier version, recently enabled to generate images, produced wildly inaccurate images of historical scenes.</p><p><strong>How it works:</strong>&nbsp;<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Gemini 1.5 Pro</a>&nbsp;updates the previous model with a mixture-of-experts architecture, in which special layers select which subset(s) of a network to use depending on the input. This enables the new version to equal or exceed the performance of the previous&nbsp;<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Gemini 1.0 Ultra</a>&nbsp;while requiring less computation.&nbsp;</p><ul><li>The version of Gemini 1.5 Pro that’s generally available will accept up to 128,000 input tokens of mixed text (in more than a dozen languages), images, and audio and generates text and images. A version available to selected users accepts up to 1 million input tokens — an immense increase over Anthropic Claude’s 200,000-token context window, the previous leader. You can sign up for access <a href="https://aistudio.google.com/app/waitlist/97445851?utm_source=agd&utm_medium=referral&utm_campaign=blog-feb&utm_content=" rel="noreferrer">here</a>.</li><li>In demonstration&nbsp;<a href="https://deepmind.google/technologies/gemini/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF#gemini-1.5" rel="noopener">videos</a>, the version with 1 million-token context suggested modifications for 100,000 lines of example code from the three.js 3D JavaScript library. Given 500 pages of documentation that describes Kalamang, a language spoken by fewer than 200 people in West Papua, it translated English text into Kalamang as well as a human who had learned from the same materials. Given a crude drawing of one frame from a 44-minute silent movie, it found the matching scene (see animation above).&nbsp;</li><li>In experiments, the team extended the context window to 10 million tokens, which is equivalent to 10 books the length of Leo Tolstoy’s 1,300-page&nbsp;<em>War and Peace</em>, three hours of video at 1 frame per second, or 22 hours of audio.</li></ul><p><strong>Alignment with what?:</strong>&nbsp;The earlier Gemini 1.0 recently was <a href="https://blog.google/products/gemini/google-bard-gemini-pro-image-generation/?ref=dl-staging-website.ghost.io" rel="noreferrer">updated</a> to allow users to generate images using a specially fine-tuned version of&nbsp;<a href="https://blog.google/technology/ai/google-imagen-2/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Imagen 2</a>. However, this capability backfired when social media posts appeared in which the system, prompted to produce pictures of historical characters and situations, anachronistically populated them with people of color, who would not have been likely to be present. For instance, the model illustrated European royalty, medieval Vikings, German soldiers circa 1943 — all of whom were virtually exclusively white — as Black, Asian, or Native American. Google quickly&nbsp;<a href="https://blog.google/products/gemini/gemini-image-generation-issue/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">disabled</a>&nbsp;image generation of people for “the next couple of weeks” and explained that fine-tuning intended to increase diverse outputs did not account for contexts in which diversity was inappropriate, and fine-tuning intended to keep the model from fulfilling potentially harmful requests also kept it from fulfilling harmless requests. But other users found flaws in text output as well. One asked Gemini who had a greater negative impact on society: Adolf Hitler, who presided over the murder of roughly 9 million people, or “Elon Musk tweeting memes.” The model replied, “It is difficult to say definitively who had a greater negative impact on society.” The ensuing controversy called into question not only Google’s standards and procedures for fine-tuning to ensure ethics and safety, but also its motive for building the model.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Gemini 1.5 Pro’s enormous context window radically expands potential applications and sets a high bar for the next generation of large multimodal models. At the same time, it’s clear that Google’s procedures for aligning its models to prevailing social values were inadequate. This shortcoming derailed the company’s latest move to one-up its big-tech rivals and revived longstanding worries that its management places politics above utility to users.</p><p><strong>We’re thinking:</strong>&nbsp;How to align AI models to social values is a hard problem, and approaches to solving it are in their infancy. Google acknowledged Gemini’s shortcomings, went back to work on image generation, and warned that even an improved version would make mistakes and offend some users. This is a realistic assessment following a disappointing product launch. Nonetheless, the underlying work remains innovative and useful, and we look forward to seeing where Google takes Gemini next.</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/02/GROQ-LLMPERF.webp" class="kg-image" alt="" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/GROQ-LLMPERF.webp 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/02/GROQ-LLMPERF.webp 1000w, https://dl-staging-website.ghost.io/content/images/2024/02/GROQ-LLMPERF.webp 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="blazing-inference-speed">Blazing Inference Speed</h1><p>An upstart chip company dramatically accelerates pretrained large language models.</p><p><strong>What’s new:</strong>&nbsp;Groq offers cloud access to Meta’s Llama 2 and Mistral.ai’s Mixtral at speeds an order of magnitude greater than other AI platforms. Registered users can try it&nbsp;<a href="https://groq.com/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">here</a>.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Groq’s cloud platform is based on its proprietary GroqChip, a processor specialized for large language model inference that the company calls a language processing unit or LPU. The company plans to serve other models eventually, but its main business is selling chips. It focuses on inference on the theory that demand for a model’s inference can increase while demand for its training tends to be fixed.&nbsp;</p><ul><li>For approved users, Groq offers API access to Llama 2 70B (4,096-token context length, 300 tokens per second) for $0.70/$0.80 per million tokens of input/output, Llama 7B (2,048-token context length, 750 tokens per second) for $0.10 per million tokens, and Mixtral 8x7B SMoE (32,000-token context length, 480 tokens per second) for $0.27 per million tokens. A 10-day free trial is available.</li><li>The benchmarking service Artificial Analysis&nbsp;<a href="https://artificialanalysis.ai/models/llama-2-chat-70b/hosts?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">clocked</a>&nbsp;the median speed of Groq’s instances of Llama 2 70B at 241 tokens per second, while Azure’s was around 18 tokens per second. In addition, the platform&nbsp;<a href="https://github.com/ray-project/llmperf-leaderboard?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">outperformed</a>&nbsp;several other cloud services on the Anyscale LLMPerf benchmark, as shown in the image above.</li><li>A variety of&nbsp;<a href="https://wow.groq.com/wp-content/uploads/2023/05/GroqISCAPaper2022_ASoftwareDefinedTensorStreamingMultiprocessorForLargeScaleMachineLearning-1.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">novel design features</a>&nbsp;enable the chip to run neural networks faster than other AI chips including the industry-leading Nvidia H100.</li></ul><p><strong>Behind the news:</strong>&nbsp;Groq founder Jonathan Ross previously worked at Google, where he spearheaded the development of that company’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/computers-making-computers/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">tensor processing unit</a>&nbsp;(TPU), another specialized AI chip.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Decades of ever faster chips have proven that users need all the speed they can get out of computers. With AI, rapid inference can make the difference between halting interactions and real-time spontaneity. Moreover, Groq shows that there’s plenty of innovation left in computing hardware as processors target general-purpose computing versus AI, inference versus training, language versus vision, and so on.</p><p><strong>We’re thinking:</strong>&nbsp;Autonomous agents based on large language models (LLMs) can get a huge boost from very fast generation. People can read only so fast, the faster generation of text that’s intended to be read by humans has little value beyond a certain point. But an agent (as well as chain-of-thought and similar approaches to prompting) might need an LLM to “think” through multiple steps. Fast LLM inference can be immensely useful for building agents that can work on problems at length before reaching a conclusion.</p><hr><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/?ref=dl-staging-website.ghost.io"><img src="https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png" class="kg-image" alt="" loading="lazy" width="1680" height="945" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png 1680w" sizes="(min-width: 720px) 720px"></a></figure><p>Join “Prompt Engineering with Llama 2” and learn best practices for model selection and prompting, advanced prompting techniques, and responsible use of large language models, all while using Meta Llama 2 Chat, Llama Guard, and Code Llama.&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Sign up for free</a></p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/02/AGENT_1200px--1-.gif" class="kg-image" alt="" loading="lazy" width="1200" height="676" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/AGENT_1200px--1-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/02/AGENT_1200px--1-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/02/AGENT_1200px--1-.gif 1200w" sizes="(min-width: 720px) 720px"></figure><h1 id="openai%E2%80%99s-next-act">OpenAI’s Next Act?</h1><p>OpenAI is focusing on autonomous agents that take action on a user’s behalf.</p><p><strong>What’s new:</strong>&nbsp;The maker of ChatGPT is developing applications designed to automate common digital tasks by controlling apps and devices,&nbsp;<em>The Information</em>&nbsp;<a href="https://www.theinformation.com/articles/openai-shifts-ai-battleground-to-software-that-operates-devices-automates-tasks?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;OpenAI has two agent systems in the works. It has&nbsp;not revealed any findings, products, or release dates.</p><ul><li>One system is designed to automate the use of business software such as accounting and contact management systems. The other performs web-based tasks such as collecting information on a particular topic or booking travel arrangements.&nbsp;</li><li>A user would enter a prompt, such as a request to transfer data from a document to a spreadsheet or fill out expense reports and transfer them to accounting software. The agent would respond by moving cursors, clicking buttons, selecting or entering text, and so on.</li><li>In November, OpenAI introduced the&nbsp;<a href="https://platform.openai.com/docs/assistants/overview?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Assistants API</a>, designed to help developers build agent-like assistants that follow instructions to automate certain tasks. In 2022, it published&nbsp;<a href="https://arxiv.org/abs/2206.11795?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">research</a>&nbsp;describing an agent that used a keyboard and mouse to play the video game Minecraft after being trained on video of humans playing the game.</li></ul><p><strong>Behind the news:</strong>&nbsp;Agents are on Silicon Valley’s radar, especially since January’s Consumer Electronics Show&nbsp;<a href="https://www.deeplearning.ai/the-batch/ces-2024-showcased-ais-reach-beyond-browsers-and-smartphones/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">debut</a>&nbsp;of the Rabbit R1, which accepts voice commands to play music, order food, call a car, and so on. Several other companies, academic labs, and independent developers are pursuing the concept as well.</p><ul><li>Sierra, a&nbsp;<a href="https://sierra.ai/news/introducing-sierra?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">startup</a>&nbsp;cofounded by OpenAI chairman Bret Taylor, is creating conversational agents for businesses that can take actions like tracking packages, exchanging products, and resolving issues on a customer’s behalf.</li><li>Longtime Google researchers Ioannis Antonoglou, Sherjil Ozair, and Misha Laskin recently left the company to&nbsp;<a href="https://www.theinformation.com/articles/google-deepmind-veteran-departs-to-launch-ai-agent-startup?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">co-found</a>&nbsp;a startup focused on agents.</li><li>Google, Microsoft, and other companies are exploring similar technologies that enable agents to move or edit files and interact with other agents,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2023/10/16/technology/ai-agents-workers-replace.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">reported</a>.</li><li>The Browser Company recently&nbsp;<a href="https://twitter.com/joshm/status/1753129075487478157?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">announced</a>&nbsp;that its browser Arc would integrate agents to find and deliver videos, recipes, products, and files from the internet.</li><li>Adept&nbsp;<a href="https://www.adept.ai/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">offers</a>&nbsp;a system that monitors a user’s actions and can click, type, and scroll in a web browser in response to commands. (ACT-1 is available as an alpha test via waitlist.)</li></ul><p><strong>Why it matters:</strong>&nbsp;Training agents to operate software designed for humans can be tricky. Some break down tasks into subtasks but struggle with executing them. Others have difficulty with tasks they haven’t encountered before or&nbsp;<a href="https://www.theinformation.com/articles/regulation-drama-in-silicon-valley-why-ai-agents-havent-lived-up-to-the-hype?rc=xlwylo&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">edge cases</a>&nbsp;that are unusually complex. However, agents are becoming more reliable in a wider variety of settings as developers push the state of the art forward.</p><p><strong>We’re thinking:</strong>&nbsp;We’re excited about agents! You can learn about agent technology in our short course, “<a href="https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">LangChain for LLM Application Development</a>,” taught by LangChain CEO Harrison Chase and Andrew.&nbsp;</p><hr><figure class="kg-card kg-image-card"><img src="https://dl-staging-website.ghost.io/content/images/2024/02/PRUNING--1-.gif" class="kg-image" alt="" loading="lazy" width="853" height="480" srcset="https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/PRUNING--1-.gif 600w, https://dl-staging-website.ghost.io/content/images/2024/02/PRUNING--1-.gif 853w" sizes="(min-width: 720px) 720px"></figure><h1 id="better-faster-network-pruning">Better, Faster Network Pruning</h1><p>Pruning weights from a neural network makes it smaller and faster, but it can take a lot of computation to choose weights that can be removed without degrading the network’s performance. Researchers devised a computationally efficient way to select weights that have relatively little impact on performance.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Mingjie Sun, Zhuang Liu, Anna Bair, and J. Zico Kolter at Carnegie Mellon University, Facebook AI Research, Meta AI, and Bosch Center for AI respectively devised a method for pruning by&nbsp;<a href="https://arxiv.org/abs/2306.11695?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">weights and activations</a>, or Wanda.&nbsp;</p><p><strong>Key insight:</strong>&nbsp;The popular approach known as&nbsp;<a href="https://arxiv.org/abs/1506.02626?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">magnitude pruning</a>&nbsp;removes the smallest weights in a network based on the assumption that weights closest to 0 can be set to 0 with the least impact on performance. Meanwhile, unrelated&nbsp;<a href="https://arxiv.org/abs/2208.07339?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">work</a>&nbsp;found that, in very large language models, the magnitudes of a subset of outputs from an intermediate layer may be up to 20 times larger than those of other outputs of the same layer. Removing the weights that are multiplied by these large outputs — even weights close to zero — could significantly degrade performance. Thus, a pruning technique that considers both weights and intermediate-layer outputs can accelerate a network with less impact on performance.</p><p><strong>How it works:</strong>&nbsp;The authors pruned a pretrained&nbsp;<a href="https://arxiv.org/abs/2302.1397?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">LLaMA</a>&nbsp;that started with 65 billion parameters. Given 128 sequences of tokens drawn from a&nbsp;<a href="https://jmlr.org/papers/v21/20-074.html?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">curated dataset of English text from the web</a>, the model processed them as follows:&nbsp;</p><ul><li>For each intermediate layer, the authors computed the norm (the magnitude across all the input sequences for each value in the embedding).</li><li>For each weight in the model, they computed its importance by multiplying its magnitude by the corresponding norm.</li><li>They compared the importance of weights in a layer’s weight matrix row by row; that is, neuron by neuron. They removed 50 percent of the least important weights in each row. (By contrast, typical weight pruning removes the lowest-magnitude weights in all rows of the weight matrix; that is, across all neurons in the layer.)</li></ul><p><strong>Results:</strong>&nbsp;The authors tested versions of LLaMA unpruned and pruned via various methods. The models performed a language modeling task using&nbsp;<a href="https://arxiv.org/abs/1609.07843?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">web text</a>. The unpruned LLaMA achieved 3.56 perplexity (a measure of the likelihood that a model will predict the next token, lower is better). Pruned by Wanda to half its original size, it achieved 4.57 perplexity. Pruned by the best competing method,&nbsp;<a href="https://openreview.net/forum?id=gsP05g8IeK&utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">SparseGPT</a>&nbsp;(which both removes weights and updates the remaining ones), it achieved the same score. However, Wanda took 5.6 seconds to prune the model, while SparseGPT took 1,353.4 seconds. Pruned by magnitude pruning, the model achieved 5.9 perplexity.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The ability to compress neural networks without affecting their output is becoming more important as models balloon and devices at the edge of the network become powerful enough to run them. Wanda compared weights from each row in the weight matrices (pruning per neuron), rather than each weight matrix (pruning per layer) or the model as a whole. The scale at which weights are compared turns out to be important — an interesting avenue for further research.</p><p><strong>We’re thinking:</strong>&nbsp;We came up with a joke about a half-LLaMA, but it fell flat.</p><hr><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> </h1><p>More AI news of the week includes:&nbsp; </p><ul><li>Baby's eye-view footage trains AI</li><li>Singapore invests $1 billion in AI development</li><li>Stability AI announces Stable Diffusion 3</li></ul><p>Stay in the know with Data Points, a spin-off of The Batch. <a href="https://www.deeplearning.ai/the-batch/data-points-issue-238/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now</a>.&nbsp; </p></div><aside style="grid-column:main-end / wide-end" class="flex-col hidden pl-10 lg:flex"><div class="relative shadow rounded-lg overflow-hidden hover:shadow-sm transition-shadow" data-sentry-component="Advertisement" data-sentry-source-file="Advertisement.tsx"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:200%"></span><img alt="AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook." data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded-lg" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook." data-sentry-element="Image" data-sentry-source-file="Advertisement.tsx" loading="lazy" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-lg" sizes="100vw" srcSet="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=640&amp;q=75 640w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=750&amp;q=75 750w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=828&amp;q=75 828w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1080&amp;q=75 1080w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1200&amp;q=75 1200w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=1920&amp;q=75 1920w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=2048&amp;q=75 2048w, /_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=3840&amp;q=75 3840w" src="/_next/image/?url=https%3A%2F%2Fhome-wordpress.deeplearning.ai%2Fwp-content%2Fuploads%2F2023%2F03%2F2.png&amp;w=3840&amp;q=75"/></noscript></span><a href="https://www.deeplearning.ai/resources/#ebooks"><div class="absolute inset-0" data-gtm-event-title="AI is the new electricity"></div></a></div></aside><footer class="mt-8 lg:hidden"><div class="flex flex-col items-start items-start " data-sentry-component="MetaItem" data-sentry-source-file="MetaItem.tsx"><div class="flex items-center text-slate-400"><div class="text-sm undefined"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="18" cy="5" r="3"></circle><circle cx="6" cy="12" r="3"></circle><circle cx="18" cy="19" r="3"></circle><line x1="8.59" y1="13.51" x2="15.42" y2="17.49"></line><line x1="15.41" y1="6.51" x2="8.59" y2="10.49"></line></svg></div><div class="ml-2 text-sm undefined">Share</div></div><div class="mt-1 text-slate-600 text-base undefined"><ul class="list-none m-0 grid grid-cols-3 gap-3 items-center mt-1" data-sentry-component="ShareIcons" data-sentry-source-file="ShareIcons.tsx"><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://twitter.com/intent/tweet?url=https://www.deeplearning.ai/the-batch/issue-238/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.deeplearning.ai/the-batch/issue-238/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a></li><li class="text-lg text-slate-500 hover:text-slate-600 transition-colors" data-sentry-component="ShareIcon" data-sentry-source-file="ShareIcons.tsx"><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.deeplearning.ai/the-batch/issue-238/" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a></li></ul></div></div></footer></div></article><div class="py-16 bg-slate-50"><section id="subscribe" data-sentry-component="CtaNewsletter" data-sentry-source-file="CtaNewsletter.tsx"><div class="container--boxed relative"><div class="text-center"><h2 class="text--l2 text-slate-900">Subscribe to The Batch</h2><p class="text-base lg:text-lg text-slate-500 mt-3 max-w-md mx-auto">Stay updated with weekly AI News and Insights delivered to your inbox</p></div><div class="flex flex-col items-center mt-9"><div><div id="reactHubspotForm17" style="display:none"></div><div class="flex items-center justify-center"><svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-brand-teal" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" data-sentry-element="svg" data-sentry-component="Spinner" data-sentry-source-file="Spinner.tsx"><circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4" data-sentry-element="circle" data-sentry-source-file="Spinner.tsx"></circle><path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z" data-sentry-element="path" data-sentry-source-file="Spinner.tsx"></path></svg></div></div></div></div></section></div></div></main><footer class="py-16 bg-brand-teal-900" data-sentry-component="Footer" data-sentry-source-file="index.tsx"><div class="flex flex-col items-center justify-center text-center container--boxed"><div class="max-w-[220px] flex items-center justify-center text-white"><svg viewBox="0 0 272 34" fill="none" xmlns="http://www.w3.org/2000/svg" width="272" height="34" aria-label="DeepLearning.AI" data-sentry-element="svg" data-sentry-component="DLAILogo" data-sentry-source-file="DLAILogo.tsx"><g fill="currentColor" data-sentry-element="g" data-sentry-source-file="DLAILogo.tsx"><path d="M56.775 16.108c0 6.206-4.252 10.005-10.747 10.005H39.42V5.961h6.608c6.495 0 10.747 3.924 10.747 10.147zm-10.747 7.306c4.778 0 7.337-2.724 7.337-7.306 0-4.581-2.56-7.452-7.337-7.452H42.73v14.758h3.298z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M66.97 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.259-8.226 8.006-8.226c4.571 0 7.804 3.159 7.804 7.856.007.535-.027 1.07-.103 1.6H62.412c.233 2.638 2.123 4.232 4.57 4.232 2.038 0 3.173-.988 3.786-2.234h3.582c-.915 2.802-3.448 5.032-7.38 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.484-4.03-2.24 0-4.044 1.525-4.394 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M84.938 26.371c-4.601 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.792 9.792 0 01-.116 1.6H80.367c.233 2.638 2.128 4.232 4.57 4.232 2.042 0 3.177-.988 3.786-2.234h3.582c-.902 2.802-3.435 5.032-7.367 5.032zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M104.917 9.885c4.221 0 7.541 3.245 7.541 8.166 0 4.92-3.32 8.32-7.541 8.32a7.277 7.277 0 01-3.095-.664 7.248 7.248 0 01-2.516-1.914v9.915h-3.319v-23.57h3.32v2.347a7.004 7.004 0 015.61-2.6zm-.729 2.871c-2.473 0-4.86 1.943-4.86 5.364 0 3.42 2.387 5.39 4.86 5.39 2.473 0 4.894-2.02 4.894-5.46 0-3.437-2.391-5.303-4.894-5.303v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M119.074 5.961v17.484h6.841v2.668h-10.16V5.961h3.319z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M135.584 26.371c-4.602 0-8.007-3.244-8.007-8.26s3.263-8.226 8.007-8.226c4.57 0 7.803 3.159 7.803 7.856a9.927 9.927 0 01-.116 1.625h-12.258c.233 2.639 2.128 4.233 4.571 4.233 2.041 0 3.176-.988 3.785-2.235h3.582c-.902 2.777-3.435 5.007-7.367 5.007zm-4.541-9.683h8.878c-.056-2.462-2.007-4.03-4.48-4.03-2.244 0-4.048 1.525-4.398 4.03z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M153.116 9.885a6.864 6.864 0 013.088.633 6.839 6.839 0 012.475 1.946v-2.325h3.349v15.974h-3.349v-2.38a6.906 6.906 0 01-5.611 2.638c-4.165 0-7.514-3.39-7.514-8.32s3.353-8.166 7.562-8.166zm.699 2.87c-2.473 0-4.86 1.853-4.86 5.304 0 3.451 2.387 5.45 4.86 5.45 2.473 0 4.864-1.938 4.864-5.39 0-3.45-2.361-5.372-4.864-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M169.72 26.114h-3.319V10.139h3.319v2.325c.928-1.595 2.534-2.579 4.804-2.579v3.438h-.863c-2.447 0-3.958 1.014-3.958 4.405l.017 8.386z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M188.966 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.044 1.504-4.044 4.435v8.922h-3.319V10.14h3.319v1.826a6.16 6.16 0 014.774-2.08c3.755 0 6.582 2.347 6.582 6.812v9.416h-3.293v-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M196.049 5.905a2.105 2.105 0 011.309-1.931 2.117 2.117 0 012.294.458 2.102 2.102 0 01-1.48 3.588 2.109 2.109 0 01-1.509-.612 2.08 2.08 0 01-.614-1.503zm.431 4.234h3.319v15.974h-3.319V10.14z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M215.558 17.191c0-2.93-1.602-4.435-4.019-4.435s-4.048 1.504-4.048 4.435v8.922h-3.337V10.14h3.319v1.826a6.192 6.192 0 014.796-2.08c3.755 0 6.56 2.338 6.56 6.803v9.425h-3.289l.018-8.922z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M229.538 9.885c2.62 0 4.571 1.216 5.559 2.579v-2.325h3.349V26.37c0 4.35-2.823 7.629-7.829 7.629-4.282 0-7.454-2.119-7.864-5.656h3.289c.496 1.655 2.274 2.785 4.575 2.785 2.559 0 4.48-1.569 4.48-4.758v-2.664a6.903 6.903 0 01-5.559 2.665c-4.222 0-7.571-3.392-7.571-8.321 0-4.93 3.337-8.166 7.571-8.166zm.699 2.87c-2.478 0-4.864 1.853-4.864 5.304 0 3.452 2.386 5.45 4.864 5.45 2.477 0 4.86-1.938 4.86-5.39 0-3.45-2.357-5.372-4.86-5.372v.009z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M242.702 26.316a2.134 2.134 0 01-1.987-1.287 2.114 2.114 0 011.53-2.908 2.138 2.138 0 012.194.896c.235.349.361.76.361 1.18a2.096 2.096 0 01-1.289 1.956 2.11 2.11 0 01-.809.163z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M260.584 21.996h-8.477l-1.455 4.117h-3.453l7.251-20.2h3.846l7.247 20.2h-3.492l-1.467-4.117zM256.38 9.932l-3.341 9.365h6.612l-3.271-9.365z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path d="M268.681 5.961H272v20.152h-3.319V5.961z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218zm.126-1.59c-3.734 0-6.76-3.207-6.76-7.16 0-3.954 3.018-7.16 6.75-7.16 3.734 0 6.76 3.206 6.76 7.16s-3.021 7.16-6.76 7.16h.01zm-.126-6.28c.729 0 1.44-.214 2.046-.617a3.67 3.67 0 001.356-1.646 3.652 3.652 0 00-.798-3.995 3.687 3.687 0 00-4.012-.794 3.679 3.679 0 00-1.653 1.35 3.655 3.655 0 00-.62 2.037c.002.971.39 1.902 1.08 2.59a3.698 3.698 0 002.601 1.076z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73zm-.125-2.918c-6.289 0-11.386-4.925-11.386-11.002C5.257 6.52 10.36 1.59 16.643 1.59c6.284 0 11.386 4.93 11.386 11.007s-5.097 11.002-11.386 11.002zm-.242-4.508c4.77 0 8.633-3.679 8.633-8.218 0-4.538-3.885-8.221-8.633-8.221-4.747 0-8.632 3.679-8.632 8.221 0 4.543 3.885 8.218 8.632 8.218z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M16.643 33.145c-3.292 0-6.51-.972-9.246-2.793a16.588 16.588 0 01-6.13-7.438A16.507 16.507 0 01.32 13.34a16.55 16.55 0 014.555-8.485A16.665 16.665 0 0113.396.318a16.71 16.71 0 019.616.944 16.628 16.628 0 017.47 6.103 16.522 16.522 0 012.804 9.207c0 4.396-1.753 8.61-4.874 11.719a16.68 16.68 0 01-11.769 4.854zm.125-6.628c6.906 0 12.517-5.698 12.517-12.73 0-7.03-5.61-12.725-12.517-12.725-6.906 0-12.517 5.698-12.517 12.725 0 7.027 5.611 12.73 12.517 12.73z" data-sentry-element="path" data-sentry-source-file="DLAILogo.tsx"></path></g></svg></div><nav class="mt-6 md:mt-10"><ul class="flex flex-wrap justify-center space-x-8 gap-x-8"><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/courses/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Courses</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/the-batch/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">The Batch</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/community/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Community</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/careers/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">Careers</div></a></li><li class="mt-4 md:mt-0 !ml-0 flex-1 sm:flex-auto"><a href="/about/"><div class="text-xl text-brand hover:underline whitespace-nowrap ">About</div></a></li></ul></nav><div class="flex mt-12"><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.facebook.com/1027125564106325" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsFacebook" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.instagram.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsInstagram" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C5.829 0 5.556.01 4.703.048 3.85.088 3.269.222 2.76.42a3.9 3.9 0 0 0-1.417.923A3.9 3.9 0 0 0 .42 2.76C.222 3.268.087 3.85.048 4.7.01 5.555 0 5.827 0 8.001c0 2.172.01 2.444.048 3.297.04.852.174 1.433.372 1.942.205.526.478.972.923 1.417.444.445.89.719 1.416.923.51.198 1.09.333 1.942.372C5.555 15.99 5.827 16 8 16s2.444-.01 3.298-.048c.851-.04 1.434-.174 1.943-.372a3.9 3.9 0 0 0 1.416-.923c.445-.445.718-.891.923-1.417.197-.509.332-1.09.372-1.942C15.99 10.445 16 10.173 16 8s-.01-2.445-.048-3.299c-.04-.851-.175-1.433-.372-1.941a3.9 3.9 0 0 0-.923-1.417A3.9 3.9 0 0 0 13.24.42c-.51-.198-1.092-.333-1.943-.372C10.443.01 10.172 0 7.998 0zm-.717 1.442h.718c2.136 0 2.389.007 3.232.046.78.035 1.204.166 1.486.275.373.145.64.319.92.599s.453.546.598.92c.11.281.24.705.275 1.485.039.843.047 1.096.047 3.231s-.008 2.389-.047 3.232c-.035.78-.166 1.203-.275 1.485a2.5 2.5 0 0 1-.599.919c-.28.28-.546.453-.92.598-.28.11-.704.24-1.485.276-.843.038-1.096.047-3.232.047s-2.39-.009-3.233-.047c-.78-.036-1.203-.166-1.485-.276a2.5 2.5 0 0 1-.92-.598 2.5 2.5 0 0 1-.6-.92c-.109-.281-.24-.705-.275-1.485-.038-.843-.046-1.096-.046-3.233s.008-2.388.046-3.231c.036-.78.166-1.204.276-1.486.145-.373.319-.64.599-.92s.546-.453.92-.598c.282-.11.705-.24 1.485-.276.738-.034 1.024-.044 2.515-.045zm4.988 1.328a.96.96 0 1 0 0 1.92.96.96 0 0 0 0-1.92m-4.27 1.122a4.109 4.109 0 1 0 0 8.217 4.109 4.109 0 0 0 0-8.217m0 1.441a2.667 2.667 0 1 1 0 5.334 2.667 2.667 0 0 1 0-5.334"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://twitter.com/deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsTwitter" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334q.002-.211-.006-.422A6.7 6.7 0 0 0 16 3.542a6.7 6.7 0 0 1-1.889.518 3.3 3.3 0 0 0 1.447-1.817 6.5 6.5 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.32 9.32 0 0 1-6.767-3.429 3.29 3.29 0 0 0 1.018 4.382A3.3 3.3 0 0 1 .64 6.575v.045a3.29 3.29 0 0 0 2.632 3.218 3.2 3.2 0 0 1-.865.115 3 3 0 0 1-.614-.057 3.28 3.28 0 0 0 3.067 2.277A6.6 6.6 0 0 1 .78 13.58a6 6 0 0 1-.78-.045A9.34 9.34 0 0 0 5.026 15"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.linkedin.com/company/18246783" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsLinkedin" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"></path></svg></a><a rel="noopener noreferrer" target="_blank" class="mx-3 text-2xl text-white transition-colors lg:text-3xl hover:text-white" href="https://www.youtube.com/c/Deeplearningai" data-sentry-element="SocialLink" data-sentry-source-file="index.tsx" data-sentry-component="SocialLink"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" data-sentry-element="BsYoutube" data-sentry-source-file="index.tsx" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8.051 1.999h.089c.822.003 4.987.033 6.11.335a2.01 2.01 0 0 1 1.415 1.42c.101.38.172.883.22 1.402l.01.104.022.26.008.104c.065.914.073 1.77.074 1.957v.075c-.001.194-.01 1.108-.082 2.06l-.008.105-.009.104c-.05.572-.124 1.14-.235 1.558a2.01 2.01 0 0 1-1.415 1.42c-1.16.312-5.569.334-6.18.335h-.142c-.309 0-1.587-.006-2.927-.052l-.17-.006-.087-.004-.171-.007-.171-.007c-1.11-.049-2.167-.128-2.654-.26a2.01 2.01 0 0 1-1.415-1.419c-.111-.417-.185-.986-.235-1.558L.09 9.82l-.008-.104A31 31 0 0 1 0 7.68v-.123c.002-.215.01-.958.064-1.778l.007-.103.003-.052.008-.104.022-.26.01-.104c.048-.519.119-1.023.22-1.402a2.01 2.01 0 0 1 1.415-1.42c.487-.13 1.544-.21 2.654-.26l.17-.007.172-.006.086-.003.171-.007A100 100 0 0 1 7.858 2zM6.4 5.209v4.818l4.157-2.408z"></path></svg></a></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"cmsData":{"settings":{"processEnv":{"siteUrl":"https://www.deeplearning.ai","platform":"vercel","darkMode":{"defaultMode":"light","overrideOS":true},"nextImages":{"feature":true,"inline":false,"quality":80,"source":false},"rssFeed":true,"memberSubscriptions":false,"commenting":{"system":null,"commentoUrl":"https://cdn.commento.io","disqusShortname":"short-name-here"},"prism":{"enable":true,"ignoreMissing":true},"toc":{"enable":false,"maxDepth":2},"isr":{"enable":false,"revalidate":10,"maxNumberOfPosts":20,"maxNumberOfPages":20},"algoliaEnv":"production"},"title":"The Batch | DeepLearning.AI","description":"Weekly AI news for engineers, executives, and enthusiasts.","logo":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","icon":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","accent_color":"#F65B66","cover_image":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","facebook":"DeepLearningAIHQ/","twitter":"@DeepLearningAI","locale":"en","timezone":"America/Los_Angeles","codeinjection_head":null,"codeinjection_foot":null,"navigation":[],"secondary_navigation":[],"meta_title":"The Batch | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-1.png","og_title":"The Batch | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter.png","twitter_title":"The Batch | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","members_support_address":"noreply","members_enabled":true,"donations_enabled":false,"allow_self_signup":true,"members_invite_only":false,"members_signup_access":"all","paid_members_enabled":false,"firstpromoter_account":null,"portal_button_style":"icon-and-text","portal_button_signup_text":"Subscribe","portal_button_icon":"icon-3","portal_signup_terms_html":null,"portal_signup_checkbox_required":false,"portal_plans":["free","monthly","yearly"],"portal_default_plan":"yearly","portal_name":false,"portal_button":true,"comments_enabled":"off","recommendations_enabled":false,"outbound_link_tagging":true,"default_email_address":"dl-staging-website@ghost.io","support_email_address":"noreply@dl-staging-website.ghost.io","editor_default_email_recipients":"disabled","labs":{},"lang":"en","url":"https://dl-staging-website.ghost.io","version":"5.121","iconImage":{"url":"https://dl-staging-website.ghost.io/content/images/size/w256h256/2021/05/logo.png","dimensions":{"width":256,"height":256}},"logoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/LogoFiles_DeepLearning_PrimaryLogo.png","dimensions":{"width":2677,"height":601}},"coverImage":{"url":"https://dl-staging-website.ghost.io/content/images/2021/04/v2osk-Ovn1hyBge38-unsplash.jpg","dimensions":{"width":2000,"height":1335}}},"post":{"slug":"issue-238","id":"65df8a8a893f37000157dff5","uuid":"c12642f2-b8b5-4025-ba15-b412613e85ba","title":"Google's Troubled Gemini Launch, OpenAI's Next Act, Groq's Blazing Inference Speed, Faster Network Pruning","html":"\u003cp\u003e\u003cem\u003eDear friends,\u003cbr\u003e\u003cbr\u003eI think the complexity of Python package management holds down AI application development more than is widely appreciated. AI faces multiple bottlenecks — we need more GPUs, better algorithms, cleaner data in large quantities. But when I look at the day-to-day work of application builders, there’s one additional bottleneck that I think is underappreciated: The time spent wrestling with version management is an inefficiency I hope we can reduce.\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eA lot of AI software is written in the Python language, and so our field has adopted Python’s philosophy of letting anyone publish any package online. The resulting rich collection of freely available packages means that, with just one “pip install” command, you now can install a package and give your software new superpowers! The community’s parallel exploration of lots of ideas and open-sourcing of innovations has been fantastic for developing and spreading not just technical ideas but also usable tools.\u003cbr\u003e\u003cbr\u003eBut we pay a price for this highly distributed development of AI components: Building on top of open source can mean hours wrestling with package dependencies, or sometimes even juggling multiple virtual environments or using multiple versions of Python in one application. This is annoying but manageable for experienced developers, but creates a lot of friction for new AI developers entering our field without a background in computer science or software engineering.\u003c/em\u003e\u003c/p\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE-1.png\" class=\"kg-image\" alt=\"Illustration of a Python inside a cardboard box\" loading=\"lazy\" width=\"1200\" height=\"675\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/PYTHONPACKAGE-1.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/02/PYTHONPACKAGE-1.png 1000w, https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE-1.png 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003cp\u003e\u003cem\u003eI\u0026nbsp;don’t know of any easy solution. Hopefully, as the ecosystem of tools matures, package management will become simpler and easier. Better tools for testing compatibility might be useful, though I’m not sure we need yet another Python package manager (we already have pip, conda, poetry, and more) or virtual environment framework.\u0026nbsp;\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAs a step toward making package management easier, maybe if all of us who develop tools pay a little more attention to compatibility — for example, testing in multiple environments, specifying dependencies carefully, carrying out more careful regression testing, and engaging with the community to quickly spot and fix issues — \u0026nbsp;we can make all of this wonderful open source work easier for new developers to adopt.\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eKeep coding!\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eAndrew\u003c/em\u003e\u003c/p\u003e\u003cp\u003e\u003cem\u003eP.S. Built in collaboration with Meta: “Prompt Engineering with Llama 2,” taught by Amit Sangani, is now available! Meta’s Llama 2 has been a game changer: Building with open source lets you control your own data, scrutinize errors, update models (or not) as you please, and work alongside the global community to advance open models. In this course, you’ll learn how to prompt Llama chat models using advanced techniques like few-shot for classification and chain-of-thought for logic problems. You’ll also learn how to use specialized models like Code Llama for software development and Llama Guard to check for harmful content. The course also touches on how to run Llama 2 on your own machine. I hope you’ll take this course and try out these powerful, open models!\u0026nbsp;\u003c/em\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003e\u003cem\u003eSign up here\u003c/em\u003e\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch1 id=\"news\"\u003eNews\u003c/h1\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/02/GEMINI_MultimodalDemo_NoCC_600px--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"600\" height=\"338\" srcset=\"https://dl-staging-website.ghost.io/content/images/2024/02/GEMINI_MultimodalDemo_NoCC_600px--1-.gif 600w\"\u003e\u003c/figure\u003e\u003ch1 id=\"context-is-everything\"\u003eContext Is Everything\u003c/h1\u003e\u003cp\u003e\u003cem\u003eCorrection: This article has been corrected to state that Gemini 1.0 produced anachronistic images of historical scenes. An earlier edition incorrectly stated that Gemini 1.5 Pro generated anachronistic images. \u003c/em\u003e\u003c/p\u003e\u003cp\u003eAn update of Google’s flagship multimodal model keeps track of colossal inputs, while an earlier version generated some questionable outputs.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat's new:\u003c/strong\u003e\u0026nbsp;Google\u0026nbsp;\u003ca href=\"https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eunveiled\u003c/a\u003e\u0026nbsp;Gemini 1.5 Pro, a model that can converse about inputs as long as books,\u0026nbsp;codebases, and lengthy passages of video and audio (depending on frame and sample rates). However an earlier version, recently enabled to generate images, produced wildly inaccurate images of historical scenes.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;\u003ca href=\"https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eGemini 1.5 Pro\u003c/a\u003e\u0026nbsp;updates the previous model with a mixture-of-experts architecture, in which special layers select which subset(s) of a network to use depending on the input. This enables the new version to equal or exceed the performance of the previous\u0026nbsp;\u003ca href=\"https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eGemini 1.0 Ultra\u003c/a\u003e\u0026nbsp;while requiring less computation.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eThe version of Gemini 1.5 Pro that’s generally available will accept up to 128,000 input tokens of mixed text (in more than a dozen languages), images, and audio and generates text and images. A version available to selected users accepts up to 1 million input tokens — an immense increase over Anthropic Claude’s 200,000-token context window, the previous leader. You can sign up for access \u003ca href=\"https://aistudio.google.com/app/waitlist/97445851?utm_source=agd\u0026utm_medium=referral\u0026utm_campaign=blog-feb\u0026utm_content=\" rel=\"noreferrer\"\u003ehere\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eIn demonstration\u0026nbsp;\u003ca href=\"https://deepmind.google/technologies/gemini/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF#gemini-1.5\" rel=\"noopener\"\u003evideos\u003c/a\u003e, the version with 1 million-token context suggested modifications for 100,000 lines of example code from the three.js 3D JavaScript library. Given 500 pages of documentation that describes Kalamang, a language spoken by fewer than 200 people in West Papua, it translated English text into Kalamang as well as a human who had learned from the same materials. Given a crude drawing of one frame from a 44-minute silent movie, it found the matching scene (see animation above).\u0026nbsp;\u003c/li\u003e\u003cli\u003eIn experiments, the team extended the context window to 10 million tokens, which is equivalent to 10 books the length of Leo Tolstoy’s 1,300-page\u0026nbsp;\u003cem\u003eWar and Peace\u003c/em\u003e, three hours of video at 1 frame per second, or 22 hours of audio.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eAlignment with what?:\u003c/strong\u003e\u0026nbsp;The earlier Gemini 1.0 recently was \u003ca href=\"https://blog.google/products/gemini/google-bard-gemini-pro-image-generation/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eupdated\u003c/a\u003e to allow users to generate images using a specially fine-tuned version of\u0026nbsp;\u003ca href=\"https://blog.google/technology/ai/google-imagen-2/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eImagen 2\u003c/a\u003e. However, this capability backfired when social media posts appeared in which the system, prompted to produce pictures of historical characters and situations, anachronistically populated them with people of color, who would not have been likely to be present. For instance, the model illustrated European royalty, medieval Vikings, German soldiers circa 1943 — all of whom were virtually exclusively white — as Black, Asian, or Native American. Google quickly\u0026nbsp;\u003ca href=\"https://blog.google/products/gemini/gemini-image-generation-issue/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003edisabled\u003c/a\u003e\u0026nbsp;image generation of people for “the next couple of weeks” and explained that fine-tuning intended to increase diverse outputs did not account for contexts in which diversity was inappropriate, and fine-tuning intended to keep the model from fulfilling potentially harmful requests also kept it from fulfilling harmless requests. But other users found flaws in text output as well. One asked Gemini who had a greater negative impact on society: Adolf Hitler, who presided over the murder of roughly 9 million people, or “Elon Musk tweeting memes.” The model replied, “It is difficult to say definitively who had a greater negative impact on society.” The ensuing controversy called into question not only Google’s standards and procedures for fine-tuning to ensure ethics and safety, but also its motive for building the model.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Gemini 1.5 Pro’s enormous context window radically expands potential applications and sets a high bar for the next generation of large multimodal models. At the same time, it’s clear that Google’s procedures for aligning its models to prevailing social values were inadequate. This shortcoming derailed the company’s latest move to one-up its big-tech rivals and revived longstanding worries that its management places politics above utility to users.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;How to align AI models to social values is a hard problem, and approaches to solving it are in their infancy. Google acknowledged Gemini’s shortcomings, went back to work on image generation, and warned that even an improved version would make mistakes and offend some users. This is a realistic assessment following a disappointing product launch. Nonetheless, the underlying work remains innovative and useful, and we look forward to seeing where Google takes Gemini next.\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/02/GROQ-LLMPERF.webp\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/GROQ-LLMPERF.webp 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/02/GROQ-LLMPERF.webp 1000w, https://dl-staging-website.ghost.io/content/images/2024/02/GROQ-LLMPERF.webp 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"blazing-inference-speed\"\u003eBlazing Inference Speed\u003c/h1\u003e\u003cp\u003eAn upstart chip company dramatically accelerates pretrained large language models.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Groq offers cloud access to Meta’s Llama 2 and Mistral.ai’s Mixtral at speeds an order of magnitude greater than other AI platforms. Registered users can try it\u0026nbsp;\u003ca href=\"https://groq.com/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003ehere\u003c/a\u003e.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;Groq’s cloud platform is based on its proprietary GroqChip, a processor specialized for large language model inference that the company calls a language processing unit or LPU. The company plans to serve other models eventually, but its main business is selling chips. It focuses on inference on the theory that demand for a model’s inference can increase while demand for its training tends to be fixed.\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eFor approved users, Groq offers API access to Llama 2 70B (4,096-token context length, 300 tokens per second) for $0.70/$0.80 per million tokens of input/output, Llama 7B (2,048-token context length, 750 tokens per second) for $0.10 per million tokens, and Mixtral 8x7B SMoE (32,000-token context length, 480 tokens per second) for $0.27 per million tokens. A 10-day free trial is available.\u003c/li\u003e\u003cli\u003eThe benchmarking service Artificial Analysis\u0026nbsp;\u003ca href=\"https://artificialanalysis.ai/models/llama-2-chat-70b/hosts?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eclocked\u003c/a\u003e\u0026nbsp;the median speed of Groq’s instances of Llama 2 70B at 241 tokens per second, while Azure’s was around 18 tokens per second. In addition, the platform\u0026nbsp;\u003ca href=\"https://github.com/ray-project/llmperf-leaderboard?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eoutperformed\u003c/a\u003e\u0026nbsp;several other cloud services on the Anyscale LLMPerf benchmark, as shown in the image above.\u003c/li\u003e\u003cli\u003eA variety of\u0026nbsp;\u003ca href=\"https://wow.groq.com/wp-content/uploads/2023/05/GroqISCAPaper2022_ASoftwareDefinedTensorStreamingMultiprocessorForLargeScaleMachineLearning-1.pdf?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003enovel design features\u003c/a\u003e\u0026nbsp;enable the chip to run neural networks faster than other AI chips including the industry-leading Nvidia H100.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Groq founder Jonathan Ross previously worked at Google, where he spearheaded the development of that company’s\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/computers-making-computers/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003etensor processing unit\u003c/a\u003e\u0026nbsp;(TPU), another specialized AI chip.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Decades of ever faster chips have proven that users need all the speed they can get out of computers. With AI, rapid inference can make the difference between halting interactions and real-time spontaneity. Moreover, Groq shows that there’s plenty of innovation left in computing hardware as processors target general-purpose computing versus AI, inference versus training, language versus vision, and so on.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;Autonomous agents based on large language models (LLMs) can get a huge boost from very fast generation. People can read only so fast, the faster generation of text that’s intended to be read by humans has little value beyond a certain point. But an agent (as well as chain-of-thought and similar approaches to prompting) might need an LLM to “think” through multiple steps. Fast LLM inference can be immensely useful for building agents that can work on problems at length before reaching a conclusion.\u003c/p\u003e\u003chr\u003e\u003ch2 id=\"a-message-from-deeplearningai\"\u003eA MESSAGE FROM\u0026nbsp;DEEPLEARNING.AI\u003c/h2\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003ca href=\"https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/?ref=dl-staging-website.ghost.io\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1680\" height=\"945\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png 1000w, https://dl-staging-website.ghost.io/content/images/size/w1600/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png 1600w, https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png 1680w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/a\u003e\u003c/figure\u003e\u003cp\u003eJoin “Prompt Engineering with Llama 2” and learn best practices for model selection and prompting, advanced prompting techniques, and responsible use of large language models, all while using Meta Llama 2 Chat, Llama Guard, and Code Llama.\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eSign up for free\u003c/a\u003e\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/02/AGENT_1200px--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"1200\" height=\"676\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/AGENT_1200px--1-.gif 600w, https://dl-staging-website.ghost.io/content/images/size/w1000/2024/02/AGENT_1200px--1-.gif 1000w, https://dl-staging-website.ghost.io/content/images/2024/02/AGENT_1200px--1-.gif 1200w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"openai%E2%80%99s-next-act\"\u003eOpenAI’s Next Act?\u003c/h1\u003e\u003cp\u003eOpenAI is focusing on autonomous agents that take action on a user’s behalf.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;The maker of ChatGPT is developing applications designed to automate common digital tasks by controlling apps and devices,\u0026nbsp;\u003cem\u003eThe Information\u003c/em\u003e\u0026nbsp;\u003ca href=\"https://www.theinformation.com/articles/openai-shifts-ai-battleground-to-software-that-operates-devices-automates-tasks?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003ereported\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;OpenAI has two agent systems in the works. It has\u0026nbsp;not revealed any findings, products, or release dates.\u003c/p\u003e\u003cul\u003e\u003cli\u003eOne system is designed to automate the use of business software such as accounting and contact management systems. The other performs web-based tasks such as collecting information on a particular topic or booking travel arrangements.\u0026nbsp;\u003c/li\u003e\u003cli\u003eA user would enter a prompt, such as a request to transfer data from a document to a spreadsheet or fill out expense reports and transfer them to accounting software. The agent would respond by moving cursors, clicking buttons, selecting or entering text, and so on.\u003c/li\u003e\u003cli\u003eIn November, OpenAI introduced the\u0026nbsp;\u003ca href=\"https://platform.openai.com/docs/assistants/overview?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eAssistants API\u003c/a\u003e, designed to help developers build agent-like assistants that follow instructions to automate certain tasks. In 2022, it published\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2206.11795?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eresearch\u003c/a\u003e\u0026nbsp;describing an agent that used a keyboard and mouse to play the video game Minecraft after being trained on video of humans playing the game.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eBehind the news:\u003c/strong\u003e\u0026nbsp;Agents are on Silicon Valley’s radar, especially since January’s Consumer Electronics Show\u0026nbsp;\u003ca href=\"https://www.deeplearning.ai/the-batch/ces-2024-showcased-ais-reach-beyond-browsers-and-smartphones/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003edebut\u003c/a\u003e\u0026nbsp;of the Rabbit R1, which accepts voice commands to play music, order food, call a car, and so on. Several other companies, academic labs, and independent developers are pursuing the concept as well.\u003c/p\u003e\u003cul\u003e\u003cli\u003eSierra, a\u0026nbsp;\u003ca href=\"https://sierra.ai/news/introducing-sierra?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003estartup\u003c/a\u003e\u0026nbsp;cofounded by OpenAI chairman Bret Taylor, is creating conversational agents for businesses that can take actions like tracking packages, exchanging products, and resolving issues on a customer’s behalf.\u003c/li\u003e\u003cli\u003eLongtime Google researchers Ioannis Antonoglou, Sherjil Ozair, and Misha Laskin recently left the company to\u0026nbsp;\u003ca href=\"https://www.theinformation.com/articles/google-deepmind-veteran-departs-to-launch-ai-agent-startup?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eco-found\u003c/a\u003e\u0026nbsp;a startup focused on agents.\u003c/li\u003e\u003cli\u003eGoogle, Microsoft, and other companies are exploring similar technologies that enable agents to move or edit files and interact with other agents,\u0026nbsp;\u003cem\u003eThe New York Times\u003c/em\u003e\u0026nbsp;\u003ca href=\"https://www.nytimes.com/2023/10/16/technology/ai-agents-workers-replace.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003ereported\u003c/a\u003e.\u003c/li\u003e\u003cli\u003eThe Browser Company recently\u0026nbsp;\u003ca href=\"https://twitter.com/joshm/status/1753129075487478157?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eannounced\u003c/a\u003e\u0026nbsp;that its browser Arc would integrate agents to find and deliver videos, recipes, products, and files from the internet.\u003c/li\u003e\u003cli\u003eAdept\u0026nbsp;\u003ca href=\"https://www.adept.ai/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eoffers\u003c/a\u003e\u0026nbsp;a system that monitors a user’s actions and can click, type, and scroll in a web browser in response to commands. (ACT-1 is available as an alpha test via waitlist.)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;Training agents to operate software designed for humans can be tricky. Some break down tasks into subtasks but struggle with executing them. Others have difficulty with tasks they haven’t encountered before or\u0026nbsp;\u003ca href=\"https://www.theinformation.com/articles/regulation-drama-in-silicon-valley-why-ai-agents-havent-lived-up-to-the-hype?rc=xlwylo\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eedge cases\u003c/a\u003e\u0026nbsp;that are unusually complex. However, agents are becoming more reliable in a wider variety of settings as developers push the state of the art forward.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;We’re excited about agents! You can learn about agent technology in our short course, “\u003ca href=\"https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eLangChain for LLM Application Development\u003c/a\u003e,” taught by LangChain CEO Harrison Chase and Andrew.\u0026nbsp;\u003c/p\u003e\u003chr\u003e\u003cfigure class=\"kg-card kg-image-card\"\u003e\u003cimg src=\"https://dl-staging-website.ghost.io/content/images/2024/02/PRUNING--1-.gif\" class=\"kg-image\" alt=\"\" loading=\"lazy\" width=\"853\" height=\"480\" srcset=\"https://dl-staging-website.ghost.io/content/images/size/w600/2024/02/PRUNING--1-.gif 600w, https://dl-staging-website.ghost.io/content/images/2024/02/PRUNING--1-.gif 853w\" sizes=\"(min-width: 720px) 720px\"\u003e\u003c/figure\u003e\u003ch1 id=\"better-faster-network-pruning\"\u003eBetter, Faster Network Pruning\u003c/h1\u003e\u003cp\u003ePruning weights from a neural network makes it smaller and faster, but it can take a lot of computation to choose weights that can be removed without degrading the network’s performance. Researchers devised a computationally efficient way to select weights that have relatively little impact on performance.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhat’s new:\u003c/strong\u003e\u0026nbsp;Mingjie Sun, Zhuang Liu, Anna Bair, and J. Zico Kolter at Carnegie Mellon University, Facebook AI Research, Meta AI, and Bosch Center for AI respectively devised a method for pruning by\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2306.11695?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eweights and activations\u003c/a\u003e, or Wanda.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey insight:\u003c/strong\u003e\u0026nbsp;The popular approach known as\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/1506.02626?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003emagnitude pruning\u003c/a\u003e\u0026nbsp;removes the smallest weights in a network based on the assumption that weights closest to 0 can be set to 0 with the least impact on performance. Meanwhile, unrelated\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2208.07339?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003ework\u003c/a\u003e\u0026nbsp;found that, in very large language models, the magnitudes of a subset of outputs from an intermediate layer may be up to 20 times larger than those of other outputs of the same layer. Removing the weights that are multiplied by these large outputs — even weights close to zero — could significantly degrade performance. Thus, a pruning technique that considers both weights and intermediate-layer outputs can accelerate a network with less impact on performance.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eHow it works:\u003c/strong\u003e\u0026nbsp;The authors pruned a pretrained\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/2302.1397?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eLLaMA\u003c/a\u003e\u0026nbsp;that started with 65 billion parameters. Given 128 sequences of tokens drawn from a\u0026nbsp;\u003ca href=\"https://jmlr.org/papers/v21/20-074.html?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003ecurated dataset of English text from the web\u003c/a\u003e, the model processed them as follows:\u0026nbsp;\u003c/p\u003e\u003cul\u003e\u003cli\u003eFor each intermediate layer, the authors computed the norm (the magnitude across all the input sequences for each value in the embedding).\u003c/li\u003e\u003cli\u003eFor each weight in the model, they computed its importance by multiplying its magnitude by the corresponding norm.\u003c/li\u003e\u003cli\u003eThey compared the importance of weights in a layer’s weight matrix row by row; that is, neuron by neuron. They removed 50 percent of the least important weights in each row. (By contrast, typical weight pruning removes the lowest-magnitude weights in all rows of the weight matrix; that is, across all neurons in the layer.)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cstrong\u003eResults:\u003c/strong\u003e\u0026nbsp;The authors tested versions of LLaMA unpruned and pruned via various methods. The models performed a language modeling task using\u0026nbsp;\u003ca href=\"https://arxiv.org/abs/1609.07843?utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eweb text\u003c/a\u003e. The unpruned LLaMA achieved 3.56 perplexity (a measure of the likelihood that a model will predict the next token, lower is better). Pruned by Wanda to half its original size, it achieved 4.57 perplexity. Pruned by the best competing method,\u0026nbsp;\u003ca href=\"https://openreview.net/forum?id=gsP05g8IeK\u0026utm_campaign=The%20Batch\u0026utm_source=hs_email\u0026utm_medium=email\u0026_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF\" rel=\"noopener\"\u003eSparseGPT\u003c/a\u003e\u0026nbsp;(which both removes weights and updates the remaining ones), it achieved the same score. However, Wanda took 5.6 seconds to prune the model, while SparseGPT took 1,353.4 seconds. Pruned by magnitude pruning, the model achieved 5.9 perplexity.\u0026nbsp;\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWhy it matters:\u003c/strong\u003e\u0026nbsp;The ability to compress neural networks without affecting their output is becoming more important as models balloon and devices at the edge of the network become powerful enough to run them. Wanda compared weights from each row in the weight matrices (pruning per neuron), rather than each weight matrix (pruning per layer) or the model as a whole. The scale at which weights are compared turns out to be important — an interesting avenue for further research.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eWe’re thinking:\u003c/strong\u003e\u0026nbsp;We came up with a joke about a half-LLaMA, but it fell flat.\u003c/p\u003e\u003chr\u003e\u003ch1 id=\"data-points\"\u003e\u003ca href=\"https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eData Points\u003c/a\u003e \u003c/h1\u003e\u003cp\u003eMore AI news of the week includes:\u0026nbsp; \u003c/p\u003e\u003cul\u003e\u003cli\u003eBaby's eye-view footage trains AI\u003c/li\u003e\u003cli\u003eSingapore invests $1 billion in AI development\u003c/li\u003e\u003cli\u003eStability AI announces Stable Diffusion 3\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eStay in the know with Data Points, a spin-off of The Batch. \u003ca href=\"https://www.deeplearning.ai/the-batch/data-points-issue-238/?ref=dl-staging-website.ghost.io\" rel=\"noreferrer\"\u003eRead now\u003c/a\u003e.\u0026nbsp; \u003c/p\u003e","comment_id":"65df8a8a893f37000157dff5","feature_image":"https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE.png","featured":false,"visibility":"public","created_at":"2024-02-28T11:33:30.000-08:00","updated_at":"2024-05-13T07:45:26.000-07:00","published_at":"2024-02-28T11:51:32.000-08:00","custom_excerpt":"The Batch AI News and Insights: I think the complexity of Python package management holds down AI application development more than is widely appreciated. AI faces multiple bottlenecks — we need more GPUs, better algorithms, cleaner data in large quantities.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"tags":[{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},{"id":"65df8dd9893f37000157e01f","name":"issue-238","slug":"issue-238","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/issue-238/"},{"id":"65df8dd9893f37000157e020","name":"Feb 28, 2024","slug":"feb-28-2024","description":null,"feature_image":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/feb-28-2024/"}],"authors":[{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"}],"primary_author":{"id":"1","name":"DeepLearning.AI","slug":"deeplearning-ai","profile_image":"https://dl-staging-website.ghost.io/content/images/2021/06/Icon_Black.png","cover_image":null,"bio":null,"website":"https://www.deeplearning.ai/","location":null,"facebook":"DeepLearningAIHQ","twitter":"@DeepLearningAI_","meta_title":null,"meta_description":null,"threads":null,"bluesky":null,"mastodon":null,"tiktok":null,"youtube":null,"instagram":null,"linkedin":null,"url":"https://dl-staging-website.ghost.io/author/deeplearning-ai/"},"primary_tag":{"id":"60bfddad274d5b003b10621c","name":"The Batch Newsletter","slug":"the-batch","description":"Weekly AI news and perspective for engineers, executives, and enthusiasts.","feature_image":null,"visibility":"public","og_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-3.png","og_title":"The Batch Newsletter | DeepLearning.AI","og_description":"Weekly AI news for engineers, executives, and enthusiasts.","twitter_image":"https://dl-staging-website.ghost.io/content/images/2021/08/thebatchlogotwitter-2.png","twitter_title":"The Batch Newsletter | DeepLearning.AI","twitter_description":"Weekly AI news for engineers, executives, and enthusiasts.","meta_title":"The Batch Newsletter | DeepLearning.AI","meta_description":"Weekly AI news for engineers, executives, and enthusiasts.","codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"url":"https://dl-staging-website.ghost.io/tag/the-batch/"},"url":"https://dl-staging-website.ghost.io/issue-238/","excerpt":"The Batch AI News and Insights: I think the complexity of Python package management holds down AI application development more than is widely appreciated. AI faces multiple bottlenecks — we need more GPUs, better algorithms, cleaner data in large quantities.","reading_time":12,"access":true,"comments":false,"og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"Google's Troubled Gemini Launch, OpenAI's Next Act, and more","meta_description":"The Batch AI News and Insights: I think the complexity of Python package management holds down AI application development more than is widely appreciated...","email_subject":null,"frontmatter":null,"feature_image_alt":"Illustration of a Python inside a cardboard box","feature_image_caption":null},"seoImage":{"url":"https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE.png","dimensions":{"width":1200,"height":675}},"banner":{"title":"AI is the new electricity","databaseId":29050,"id":"cG9zdDoyOTA1MA==","featuredImage":{"node":{"altText":"AI is the new electricity. Are you ready to flip the switch? Download your free copy of the ebook.","mediaItemUrl":"https://home-wordpress.deeplearning.ai/wp-content/uploads/2023/03/2.png"}},"bannerCustomFields":{"bannerUrl":{"url":"https://www.deeplearning.ai/resources/#ebooks","isUrlExternal":null}}},"announcementBanners":{"nodes":[{"title":"Databricks C1","date":"2025-06-04T07:12:29","databaseId":36631,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/3HlCuvP","courseName":"DSPy: Build and Optimize Agentic Apps","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(126deg, rgba(27, 50, 57, 1) 0%, rgba(97, 135, 149, 1) 100%)","isOpenInNewTab":true}},{"title":"Predibase C2","date":"2025-05-21T07:27:34","databaseId":36555,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/4jfKdc6","courseName":"Reinforcement Fine-Tuning LLMs with GRPO","backgroundColor":"#05256C","backgroundGradientColor":"linear-gradient(118deg, rgba(255, 188, 165, 1) 0%, rgba(255, 98, 43, 1) 53%, rgba(255, 98, 43, 1) 100%)","isOpenInNewTab":true}},{"title":"Anthropic C2","date":"2025-05-14T07:50:27","databaseId":36509,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#000000","courseLink":"https://bit.ly/3YJduVg","courseName":"MCP: Build Rich-Context AI Apps with Anthropic","backgroundColor":"#d35050","backgroundGradientColor":"linear-gradient(311deg, rgba(217, 119, 87, 1) 0%, rgba(241, 210, 199, 1) 100%)","isOpenInNewTab":true}},{"title":"LiveKit C1","date":"2025-05-07T08:03:11","databaseId":36482,"announcementBannerCustomFields":{"text":"✨ New course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4m8aEmO","courseName":"Building AI Voice Agents for Production","backgroundColor":"#000000","backgroundGradientColor":null,"isOpenInNewTab":true}},{"title":"MemGPT C1","date":"2025-04-30T01:43:46","databaseId":35628,"announcementBannerCustomFields":{"text":"✨ Updated course! Enroll in","textColor":"#FFFFFF","courseLink":"https://bit.ly/4eb7j0L","courseName":"LLMs as Operating Systems: Agent Memory","backgroundColor":"#8c1d0a","backgroundGradientColor":null,"isOpenInNewTab":true}}]}}},"__N_SSG":true},"page":"/the-batch/[slug]","query":{"slug":"issue-238"},"buildId":"Qy9Eh4N0MrfE3ddReY9v4","isFallback":false,"isExperimentalCompile":false,"gsp":true,"scriptLoader":[]}</script></body></html>